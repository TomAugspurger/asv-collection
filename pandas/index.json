{"pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]], "hash_length": 8, "show_commit_url": "https://github.com/pandas-dev/pandas/commit/", "params": {"sqlalchemy": [""], "matplotlib": [""], "numexpr": [""], "Cython": [""], "xlsxwriter": [""], "pytables": [""], "cpu": ["Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz"], "xlwt": [""], "python": ["3.6"], "os": ["Linux 3.13.0-116-generic"], "numpy": [""], "xlrd": [""], "pytest": [""], "openpyxl": [""], "scipy": [""], "arch": ["x86_64"], "machine": ["asv-runner"], "ram": ["501692"], "branch": ["master"]}, "graph_param_list": [{"Cython": "", "numpy": "", "pytables": "", "xlrd": "", "arch": "x86_64", "python": "3.6", "sqlalchemy": "", "matplotlib": "", "numexpr": "", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "ram": "501692", "xlwt": "", "xlsxwriter": "", "os": "Linux 3.13.0-116-generic", "pytest": "", "openpyxl": "", "scipy": "", "machine": "asv-runner", "branch": "master"}], "project": "pandas", "machines": {"asv-runner": {"os": "Linux 3.13.0-116-generic", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "ram": "501692", "arch": "x86_64", "machine": "asv-runner", "version": 1}}, "tags": {"v0.17.0rc2": 12867, "v0.19.2": 14719, "v0.14.1": 10140, "debian/0.8.0_b2+git68-g7240b87-1": 3344, "v0.18.0": 13633, "v0.13.0_ahl2": 8327, "v0.8.0": 3412, "v0.16.0rc1": 11528, "v0.15pre": 10501, "v0.21.0": 16155, "v0.13.0": 8139, "v0.15.2pre": 11042, "debian/0.4.3-1": 1084, "debian/0.4.0-1": 874, "v0.9.1rc1": 4249, "v0.16.1": 11906, "debian/0.8.0-1": 3418, "v0.20.0": 15378, "v0.15.0rc1": 10793, "v0.11.0": 5863, "debian/0.6.1-1": 1632, "v0.14.0rc1": 9617, "v0.8.0rc1": 3360, "debian/0.7.3-1": 2555, "v0.23.2": 17931, "v0.17.1": 13165, "debian/0.5.0+git7-gcf32be2-1": 1194, "v0.17.0rc1": 12722, "v0.7.0": 2072, "v0.23.1": 17760, "v0.22.0": 16735, "v0.23.0rc2": 17546, "v0.21.0rc1": 16109, "v0.24.0.dev0": 17604, "v0.20.0rc1": 15313, "v0.8.0b1": 3074, "v0.8.0rc2": 3361, "v0.24.1": 19583, "v0.12.0": 6794, "v0.25.0.dev0": 19502, "v0.20.3": 15699, "v0.10.1": 5022, "debian/0.8.0_b2-1": 3266, "v0.23.4": 18135, "v0.19.1": 14448, "v0.19.0": 14343, "debian/0.8.0_rc2+git26-g76c6351-1": 3393, "v0.24.2": 19819, "v0.4.3": 1029, "v0.22.0.dev0": 16156, "v0.7.3": 2539, "v0.19.0rc1": 14289, "v0.18.0rc1": 13531, "v0.8.1": 3551, "v0.21.0.dev": 15385, "v0.13.1": 8680, "v0.18.0rc2": 13622, "v0.8.0b2": 3262, "v0.21.1": 16606, "v0.13.0_ahl1": 8234, "v0.15.1": 10956, "debian/0.8.0-2": 3494, "v0.20.2": 15587, "v0.23.0.dev0": 16708, "v0.10.0b1": 4723, "v0.20.0rc2": 15370, "v0.24.0": 19501, "v0.23.0": 17603, "v0.10.0": 4816, "v0.9.0": 4026, "v0.23.0rc1": 17544, "debian/0.8.1-1": 3557, "v0.16.2": 12077, "v0.4.0": 862, "v0.4.1": 926, "v0.16.0": 11564, "v0.12.0rc1": 6664, "v0.24.0rc1": 19420, "debian/0.4.1-1": 933, "debian/0.7.0-1": 2077, "v0.13.0rc1": 7983, "v0.6.1": 1440, "v0.9.0rc1": 3912, "v0.23.3": 17958, "v0.7.0rc1": 1812, "v0.11.0rc1": 5767, "v0.15.0": 10853, "v0.9.1": 4289, "v0.4.2": 981, "v0.7.1": 2196, "0.3.0": 288, "v0.20.1": 15384, "debian/0.7.1+git1-ga2e86c2-1": 2247, "v0.14.0": 9713, "v0.7.2": 2358, "v0.6.0": 1342, "v0.9.0rc2": 3955, "v0.15.2": 11188, "v0.17.0": 12896, "v0.16.3": 12091, "v0.18.1": 13843, "v0.5.0": 1185}, "revision_to_hash": {"16384": "50f432de81078e522b12c1247376f459bb235feb", "8203": "2a8cd09acbe78e5b325f14082de2b0b496af2747", "16399": "f745e52e168790bff06a55928c3491cdea389508", "16400": "1043a46bcdebf974e1e656837e46aab9b31da5f5", "16401": "f7c79be4d5bc966a631c9876e272d19a54fd8edf", "16402": "4fd104a72a825914851820fee623fbcdf1a989a7", "16403": "262e8ff367c9291c79c4df0c2daf4713de52abc0", "16405": "88ab6934e78117359719eb09c7d580906155575d", "16406": "7463f86632571547184854faedf5ad8fa13c846e", "16407": "6148e5853460dc5325468fe3ec8f6e5c2b52b8b6", "16408": "94f3923c99ef612a953942d6c76fc605e8e5c6d9", "16409": "2a0e54bc841f27164b116135ebda4b74bae2fc4a", "16410": "32f562dbe459ee9e437da3a67631949d34531411", "16411": "48c5bfca5d95b08ce01de3b2cdb9250b6515fa5c", "16412": "d3c3c2b092b17aa720b489101d59d60aff8799da", "16413": "e459658b79c228c908c9070fadcd957cf737339d", "16414": "7627ccaf9442f4101afda69b6077e7f035e23543", "16415": "a47ad560d5ff030bb67b51feaf03d7c4b6d3e55b", "16416": "c40c8f8b3baccbd658d078816698f85e3268a781", "16417": "67c4d0f4f9f45b981d3e6cb07521f9c0bbb459d7", "16418": "5da3759b30167cd5ef5cb02f5bbfb98ac1be1103", "16419": "5cd5e3b81fc3850367bb3e25644cbe3197cdea5a", "16420": "1eedcf664cab1ca23a1d10071b2b7fb8095d0160", "16421": "d74ac70ffd44e9d00e6ffa8ecf7a1a88312e8065", "16422": "d5ffb1fc9653a47e5426121fefeccdf2be9e8c46", "16423": "f7df0ff3b4a4b391c8cf21aeeb7b11403b5515bf", "16424": "d270bbb1448ecaccbb567721c991350bac715059", "16425": "d163de70c93547035579870e2ae9008cb3640b45", "16426": "e1ba19a1fea96726f57415669b57316ba060bc1e", "16427": "0e168188811677f9de72a6a5b97253e551b6b04a", "2738": "47abe8cc8d7a66032cfc705e2696adb8cf30161f", "16437": "73ed6de17ca390418d23a5698cf4db78aa8b7b80", "16438": "3e4e4b3bfc38651d728074df1eb4c42d3b033047", "16439": "02e72ecf1ce75e1fbfc6be0e8fb3568c36fa7fa3", "16440": "e99cb9c0448ed2dad3be33c22179da8a1177c65c", "16441": "2c903d594299b2441d4742e777a10e8c76557386", "16442": "a7646638d06f1ce98481b88f3505e2b4badf172c", "16443": "52fefd50f8bffa493018ba8ff8b8c46b95c94ada", "16444": "52838e609c1b2a495069964dea862a39dd067b2b", "16445": "c3c04e266cbc5e176cc6ef4dc385cdd88fda0669", "1342": "010a620da89e5babc137b924dd1f632b4f6e6fee", "16455": "1d88cdb022da8c62dfb2c2132365a801e93bca0a", "16456": "2145e89267e3d489ba95d7bbac4e6dbd9778349b", "16457": "19ce05eb9eb0de6c0cfdd438f505293c3acde040", "16458": "330fb57a92699e907763eb2956b92984859cc09f", "16459": "fdba133336c2ec8f1269eb15e73d48797840c48b", "16463": "d9163516dfcf3b16bb1a0a212fd4f802f3839ee4", "16464": "15ad5427cbd7ae928d69825c87fc992a72dc13e7", "16465": "695e89345a46c0cab06c479c83007f5adbb70ad5", "16466": "279578c0e281a51c5e7d105abb96b70d870c9a80", "16467": "3e506a363e40d2426936a0ee570e3d56830b0d5f", "12373": "f1719b72c46f88807dd91cf6a092c2da12e676ca", "16475": "1fa55d23d83be6d8ae65fb5ac1c86834c9f142fe", "16476": "0ebdc1003e6689c2b6a9acbf7a19ff47dabd1090", "16477": "f7eb4aef42a620cb4003a38a08fed9bb1795e00e", "16478": "0229538165d9a7dc63d6fe99451c960db5977bd8", "16479": "288bf6e5e3287a8c66a7ed41050db0ebf56d7ea6", "16480": "27a64b2bb9d631ef584a941a3a3f66aebc2477f5", "16481": "e65814814c5f80df120d19f693c816c660e04a4c", "16482": "1a46dba2449c18ad7682926f4d4c165ffc54b867", "16483": "86606b2541c615821c73007dc949d2837a5af2d0", "16484": "34a8d36e45c1623d2e61671561cdbd5de36adac8", "16485": "16de5f9e6c6ffda91be323c8cc4b6c0de628cdd3", "104": "138b3ef6caa3a27da268cf32d06f181dcc140f8e", "4203": "f41775415c060ba053ad8a50939ad843b87741fc", "16498": "5d9151c582bf814b460927e1822dbeaf2b01c561", "16499": "c753e1e08b01a438aaa252327de046109bf4bcfd", "16500": "38210407e1462aec987d08ba692f1040aed5c1d3", "16501": "e909ea0b2a583bcc9cfe3e759652351d7f0266cb", "16502": "2aa4aa947df59d7f0a5bd86145394f5db124250a", "17770": "b5fc76954963e30b7d7dd4c30ed7363568fd01ee", "19819": "cb00deb94500205fcb27a33cc1d0df79a9727f8b", "8327": "48c005ea761adcaf6b76a84aa94da0d35db8c6d6", "14360": "e70252b794070dc5bb4dd4e27be76d1323572d23", "4249": "2d576ee9b9337210a8c85f11e48177db42ecd57f", "19373": "62a2a11d2be09bf468eab304fd876a21a9658411", "15964": "0e85ca7f5afb26880e81ba6ff3965c8c0f27bbaf", "4289": "9867f8af6e20cd2248626548f9b3f9a66b57789c", "19148": "d9c814fd38f6ff73c53f286fdc71ca9512b81aef", "16590": "38c6fc8eef863df0f23545f5678df9040431fee6", "19149": "df3b045e92ad139e1b22fce1cb2056c94430f6d5", "208": "49bb4b643c35271affd5e9e98677cad52f8b3fd4", "18829": "24bce1a5fdd70a66b9fb5e2f9f51631d1df6add3", "16601": "d23fa5830e6e68dcef5814cf5927df8ff1f99723", "16604": "99d384d4f7ef6e2b6cb5a4eebea127e8bddf521b", "16606": "7bb204a05fee20c3c825e7da39ccaf39fbeb8ca5", "16607": "b70b05c620f929e8a69e022bd0a9850fa040c88e", "16608": "96439fb13e941100080a8fb5c78b7b291a2dd2fe", "16609": "d2fd22e1f995a638f1e84b0ef091eaf70e171fdc", "16610": "6a06d50bc2588801495ce1d396900064ba8001bf", "16611": "22f924b5df318f3eedaadd6eea61002d0046de13", "16612": "9705a480615201ce1e89e5385f48fde155726e8b", "16615": "54eaca88f1c725753dc8b6cf3509a177ac570ec2", "16616": "265e3272b8709a7be274321ee8b505a0e74b8e10", "16617": "34ef9eb8e9ed70b7fdbc13ed1cd9793dbfdbbb93", "16618": "76b35c6662136302d212448906c1c8bf8225fffd", "16619": "5b9b4a89c9bf6ca23aa4431973d67da6df50ced9", "16620": "6c02c9efc916e5a742fda33e5d2440897710136d", "16621": "7b4229aa1b95b2050b31cc93e38fda1a72258675", "16622": "fe900cb787949ea9f949ba72f9390dcd6c83df1d", "16623": "0303d0d6cd983758fbe5c4618ceabf1b880a95f4", "16624": "a845187755f65087129e1cd71f3900f2b1ea6db6", "16625": "c28b6249471ffddfed51d62437a65ca97766fb7f", "16626": "f5415d82f48f210fc9ccf023ecb11d97c6a7ab92", "16627": "b5f1e716d89487423bb12d6cc4e6da2b39184531", "16628": "73085773998e12e85f1044771069f63f4e8d65ad", "16629": "8e0e35447f3a66764b2ea92ca23569b30b341d43", "16630": "78dd03508494fdfa23aa1ad080dd547b001f4bbb", "16631": "fb178fc5e9793a0684d486c37d5bd8c2c54bcbf5", "16632": "7a0ee19e95e29042c3373a1d912d2db27108c828", "10964": "68d483fa7db48c10f4282620f855c8c733f4ce76", "3418": "f5a1bc9cda068f724d2de2ddc0da8ac2c518095b", "8234": "db18d443dc0eac6454b864e179579619493899dc", "16638": "852c53e199d0cd14ef0f4370d7c0949deb89405f", "16639": "6747ab50acf808389b96ae5083aa172ad824e291", "16640": "26c6c19a37c4f77f173533ecd4e54f708cb06151", "16641": "b2a02bd0e022e166c45b4c03c20a00b241b59d3f", "16642": "b32dd634c8d4ee46c328e75ed949b2c237994fa7", "16643": "856d9e5b50cb79444a3586e8f88b68577bdf4221", "16644": "04db779d4c93d286bb0ab87780a85d50ec490266", "16645": "07d8c2d93af3fe24f18d6c80096275de3b6794b4", "16646": "c1af9a83f9cdfca5541c5c5ccd7c9c052b3a3c05", "16647": "15f6cdb6404a8949bc5532248de0a4a30c9a037a", "16648": "8e33a71bf0f93dc8e5140312bf2d217d47c755e4", "16649": "775099cde4a2424dfb369d79b8b6e2687e5af7f9", "16650": "ac8ac158377d60c8c8e10e6905d49d48bbe80855", "16651": "f833103a1883672751b45d94d14a3641095df672", "16652": "ff865b464d6d0edf3dad6fc8a01c0e8f0a6528ca", "4374": "5ecae6bd055ac4e5738c0fdc97c275bb6f539600", "16666": "75b97a70110b0d924a557bd8e7929bcf1f4509a2", "16667": "08a66e111a60b9a25fb59a0dcc691c3f1ec0ad1e", "16668": "316acbf065f5d1e30fdc7fcced3a53a2f4b14655", "16669": "eccafcc0285b9d2e46ecf5b35cf3cfc4f20dd040", "16670": "6164da24a7d3f9469fcad8b987c9c7fac1c8dd25", "288": "4906ee79d730f77be02ec586ec7f66c95a0433da", "16676": "b9cc8212b69b84ab75a229669b58b207c1c86544", "16677": "175cc4fe044ef26f9e978f766127bee488eaae92", "16678": "507157dbedd960d9b47d4d0fe46eb16230b170b4", "16679": "81adbe6298231bbfb9e68b6f71127941f2f036fe", "16680": "cdebcf374598e9141df7dc23bc75c9528e92c004", "16681": "e85f43222d743a696126a3beaf0603a5940138cc", "16682": "dbb41216a9bb5f1fd1592f3c32ed48ba68f094f9", "16683": "ee9c7e9b19a1fa3c4499d10885dec72f1d651832", "16688": "fb95f7f305e85d474cc44283fc642abc900e0096", "16689": "a18d7259e385732540392aab2532fa09b168207e", "16690": "674cf4ff66266f7cc6aff0261e7fcdfcfcfbcf84", "16691": "3e40255b423c4a6f3868aac47e493f8fd09dd206", "16692": "feef9041d84b3e3b7b68121d903a5ae1a4bf42b0", "16698": "80a5399e59f409749f08f2f38903e25b1c92d5e0", "16699": "e56794984f17d1651d74e6dbcdbf77fbec53d45f", "16700": "e1b638e94f80ff4cb17ac6a1f1079195a931b481", "16701": "f42ae789a5c7c15e8faf3c7b88c9db6033efa64f", "16702": "ef753900b5c3956c43068ff64d271e1332024f52", "17569": "b3f07b2551b7eb40408ca28416ca5e21f8fb37b4", "16705": "e1d5a2738235fec22f3cfad4814e09e3e3786f8c", "16706": "7818d5168c509199c1f318855299d2a8942bb69d", "16707": "4883a432a21e65d998a57708e20196627f7c60d7", "16708": "fae79204e2b60ac1ff2b2309352ffb5d9382a017", "16709": "dedfce905e49270485d5cc84dd59a215cbb7c56f", "16717": "4d571bb34aa963bfbe367c0504881094b5403873", "16718": "84335621ad0a0d83302a80b6911d3985c00b5cee", "16725": "faeac49687d1ce1c3310bf365d402a4a2ab783bb", "16726": "c24a0d2815b717a33edc5de9d3f09eeecc810670", "16727": "e92d788bc3fc6d6248cdb84cb75beaedc458eb8d", "17842": "838e8dac435e1d5a08004e21c0e630a299b6dac0", "16735": "a00154dcfe5057cb3fd86653172e74b6893e337d", "16736": "e957dcd9a51a63bc7fdce7006df3ab1c2f802ed0", "16737": "461221dd58d7fa7fcc247a7eec0e409309e82394", "16738": "34f12654bce2c1cbeea90a0fcb2e0395824861d9", "16739": "b63453f6826992b5c068e0aeaba4456f7ae133f7", "16740": "0e3c797c4c12fa04fd745e595e822886e917b316", "16741": "ace46636f96b916a5617345e860d48da7c448465", "16742": "2030a072a454f6e00ba2b49b5cb2c5e886194df6", "16743": "beb1e69cae8a62e0836b671749a1058ce1e67515", "16744": "cfa5ea6969f4a6a63bb26937181bdd0d00f54a59", "16745": "c19bdc98fa3f856e2e6b3495bbab88b587801987", "16746": "a69742181f20f02b9a86ff1a89314efe62cdd21f", "16747": "04beec77e5a713dd90ba31dcf7ad43fd64ac55bb", "16751": "e581b140b115f634e4ce110bf8c182784650bf81", "16752": "f5fc3a035ffb05069b6c61815198f0b558c005b7", "16753": "9e4418218e17857f32df472b00714812a11ab1dc", "16754": "c8831285c5d0732a32f16c4571fea7c48224b502", "16755": "6552718d2a908a57b88354fe916609631793131e", "16756": "02fb95459f062d34985177f5cd191ffd22a427e7", "16757": "61ed3e5f8b3b53b41f13c1ba822581f2198462a8", "16758": "3198b9df59b7a0e946a37d7ede4167e1bb71d91a", "16759": "93033151a8d8aaa650a81df9f41347758bf6c393", "16760": "f9117658514ad4c31130adfc921fa098c38a6f7a", "16763": "cadbf2dce6ad84d6d059df230d908b5533277b24", "16764": "a355d5c0d224eff6b3b0155b1feffc5dcb722fa9", "16765": "77ec4e8cbc3a5249d9abe2c5ad9f1a8f955e2d0c", "16766": "acbfdf83ddb0cea63eaed0b3281e673d5094184d", "16767": "35b2aba7386619dc156ca245cab781d3aea37789", "16772": "f2d8db1acccd73340988af9ad5874252fd5c3967", "16773": "e1888f09630bdd236be1f3ec9577c275d6d67457", "16774": "821028f68fa75c0d6d341148a3ab6f08bc8d3515", "16775": "685813b82f08ebb2b48f99fbfd39ce8c1463348f", "16776": "c0e37670dd578728f988a33bc21bc173b336249a", "15085": "a1b118cf46dc0a92fc16f2268b07731e27ed00d3", "16784": "bbfbe48e84f40c22187879b94a7039ff06b6d21a", "16785": "e1d525cffd2751ab8d30743d31dd89ac47621682", "16786": "b1a9421de9a8c3833b1e6f3f7a39b7aef1561942", "16787": "5fb018bc477c69da1052adc1e986153f40b7ad9b", "16788": "36a71eb00ea61c4e6aef78b9ad9f865760a3cfd4", "16791": "1265f66860a1a108b835881ef41ca4e52d397b3f", "16792": "0ffcf9e52b947d9faf45e236178db1af648d4736", "16793": "6d3740bc8cb5820a967712266041e3f23f6c6e70", "16794": "3314ab16c0d14fe3bf0a9c5739dfcd0bdc84f3c6", "16795": "f6c0f8a17005e7aaffa6de1b429b2cdf9889459f", "16797": "5205283078ea574dc4d0e29aef73464f3063da89", "4510": "8781bf4cf0b1106bec806038946707809e7edc42", "16799": "7c8c1fd3ab44923f4ba2e61f992e2123c6a69663", "16800": "45a70121c5932b1e4300161114f691af517997e4", "16801": "23fb3392adedd3a618bbdf9ccb0ed81263fa3eb2", "15771": "142b5b61a0433c256511649a993b0fe1b6f64524", "16807": "7351b435975188ef0f645b2529751b2a51fc1cde", "8616": "667c6cd760466c4e1dc2c82f56827e5b8beceb12", "16809": "fabc316ecf0ebed12cd3ddc4240d3ffafc7b474e", "16810": "8badfd572a0110ee3567722d0bf001915317665f", "16811": "055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "16812": "982e11233698bc54e59be87eb257da2f33b8eb10", "16813": "a31e739a0429c776933ab8f1f32a12ca19a7a1fb", "16814": "1954a830398d33458cc686b4591869f651b0b7b4", "16815": "8acdf801c501a0ce2ac14ddd676cd248f0f32180", "12722": "9687145e06aed545c14630460d24a9693c9a0b39", "16821": "499802c08c6049419266c95349dd0a5de6751c4d", "16822": "27a503958639185ca40edd8e660579aaed1f32cf", "16823": "8912efc3884133bd4141af3a8bb2faed8ae1d341", "16824": "5853b7953d6e25894fba59056652b9aab61d8beb", "16825": "8347ff8c9d8876fa46f73dbc48919a672caef1d2", "16826": "08a3d3afca2ebbb8e189c173550ec90b4a27b7d9", "12731": "57b5fff36002217578e2340fda6631d6823aff1c", "16828": "53be5206c97fbe09e5f10194bf170593148629e8", "16829": "787ab5556f23d2e10b798d2e58e66789d79fd4d5", "16830": "de42bee01230cd67cb0fc905788653d1b4c18ba4", "16831": "1a240f609ff6809f3eaf3cc405d5d7c50fe36d0e", "15776": "c0a84b59f5b9638ddabcd49ad664fa5850f02135", "16835": "c26c49dc57990c5bf64bbb782b90524629690575", "16836": "72086101327c584d2b6f515ffacbaa062e6279bc", "16837": "eee83e23ba0c5b32e27db3faca931ddb4c9619aa", "16838": "c271d4dd0b014c41bd91048fa6e8d33c5bf27b44", "16839": "4ebdc50f250ab2fd4312f82d119e5370a5128810", "16840": "6a6bb40bdd407f37d7ca6477f0dfacac6e11a62b", "16841": "3db6f6661768d46aee04b7b29a1c798326b3b324", "16842": "04a6815f7da0f6d879725d553c7a45f47bb4a15c", "16843": "65d1b62dfe46cd5cfd80d8b1aafd633575c72ee6", "15778": "ee6412aee8bbf350aea89bbafbfdfb0f8d7620ed", "16846": "94cdc16b6357cde99ca08a2b81a3901a748f3d2a", "16847": "51d71cd2c3d37be8b5ed4fa249494b939711dca7", "16848": "6e0927ec352ac5d05332eb9b86b7a84d4a6fbde4", "16849": "d7a2e94914b7707e1c37a4524a9a7c3fef649d01", "16850": "4086e420c8c7a5f72fb9090a7d2d97045cf443bb", "19875": "f39a9ce580d25c8273cff717d13a7bc8601aa339", "16852": "93dd55ef237843b8fa6c0792b48b718bf72e2250", "16853": "0f1c9c5fd95d45bcfbfa59e5aed73c77e2e5cb22", "16854": "1c0a48c0211f9513e774e727e46f7acc7c327c01", "16855": "f0cd23ca6485940e3a6572cc4f5afdce4c3921ab", "16856": "1245f0673074316b53d1d1ee10abd6077058b133", "473": "8720b1632eb10d665027605bd1de63e160505d2d", "19877": "aab42a2a4cf154c710d4c9e265742c00adb6b4c5", "16865": "bcaa5da3671b2fd1b3dfca98ebd529d3525815c0", "16866": "6ba65ca8a69560d526762bdbded64b3139f66d7a", "16867": "b6acf5e784471fad52b2c74ae23fc235e5de5049", "16868": "37024923d23cf49cf44c15134df56bce977d04b5", "16869": "2952fbd556e1bc4b5fac70c727652b5419e8e096", "16870": "d409eaf22f0aa1cf4088ebbbe0b1ab8b3917973b", "16871": "9872d6757e5117dce070981141cee562f675694e", "16872": "45aa0ce963df5c766063d7f4bfc6493b852028ba", "16873": "9fdac02ebafa287471a1f406606c0c2eb54be45d", "16874": "5fdb9c0edef57da4b29a437eca84bad5f20719b7", "15783": "e7c10bb8d715390c95925bf20c06e98a7eb1b234", "16879": "eb9e8233965c1b1695381a5af5b207457d8ba330", "16880": "b4662cd9cbcc81f7d55ab15323d8227b8b0803b2", "16881": "83e95e09a08b4f46643a49071edf40bbb3581e13", "16882": "e865b774e463525614d0aad1de5a783929c01a79", "16883": "250574eda5302b6941f8c766f520f67226aadad7", "16884": "0597c7939962e0460a46616eacca30cbaeb210fe", "16885": "86d9af0594ecd0ce4811f3078e405535b4ca4219", "16886": "d3f7d2a666aa824e2df98083aa5c1fd9bb63252e", "16887": "b951c0a565dca09e40a8816c6e5ff1169e0515fd", "16888": "41e02a0c28e03e104abbd455e7545ef6b2805c5d", "16889": "68cdd46139fb1e0ab2f30b223583c07610b00f45", "16890": "8a7aca9eda989243fedae4ef525ddef4511ab241", "16891": "dfc605483f514dc7becc1556dc7eac6295ae950f", "16892": "1d7b075579ace4d53fe47b13fc50c8e2795998a7", "16893": "eec7f578b79bc82e7101d4b3529c20e99c30a24f", "16894": "43f11618d89a416148843f75348d4fa64caac822", "16895": "5f6c80b5e3641ab96f747bd9967e4d58b5852814", "16896": "860c99cd6d9996383960279ab21bf9ca15d859ef", "16897": "5f79123c574b2d5817707516a827c4ee60d95355", "16898": "24d95098789c8685e7c0ce6a57982d0372ffc3e0", "16899": "8cbee356da1161c56c64f6f89cb5548bcadc3e44", "16900": "272cabb03c6720a922e63d97188640f29d92a24a", "16903": "e0d9651b2721b2a009e23b5597fa7549521538c8", "16904": "4618a0918e1bbdb40a493d8a32d46ab8c94fd0b4", "19884": "6e0f9a971bcd07a4a6283dc03190b4363d42e292", "16906": "8a567750e5d56b604411808dabf7c1c700be717a", "16907": "238499ab0a48a0ad4a2011e2ce1c6a02c86124eb", "16909": "65639e67b045a4849c47583d3b32144089a81bb4", "16910": "d9daec83341baa1ae660245d12e76999feeb8d2d", "16911": "01cbc645ec4e3858ea0a098d5afc46f22a7e3e06", "16912": "1bd7b3ad1644ad9d26ac02f507ec7cc0832377bb", "16913": "fb3b23782534c925ab7158c59dcb32c8f8390d71", "19886": "2618b218eb4fad936310dcce011acc1b79e0ed96", "15839": "a2c454373b8cd2334b93a68d52104e9cbcdd3721", "16921": "113f78886907a77fd4c73e1456833e83ee48594f", "16922": "d3851ac09d6a9121cea44aabbdc7e4f60f06b7d9", "16923": "c7688299e0621a072ae27ad480c9d35f223a08ce", "16924": "09307dd06a73b5702095987fb5868275d44cc1f7", "16925": "35812eaaecebeeee0ddf07dee4b583c4eea07785", "4638": "eb64630c9c62677979f7e0157344533a1a2c40f6", "19888": "dca809b0151adb744940a727f5d82ca43f4c3ea4", "15793": "e2588d9a88805cc12754d7271356ddcc6ab22338", "15794": "f9a552dc12262d1d208f9cdc2c5ffd1731f9c361", "15796": "5c185e07f0210c148ced62d4dda3275a1ded954d", "19893": "d37c531075322b4aa115f5f9f0cb9173773afbdc", "12867": "071cffd63e4b99362c68a5e2d472b629618c50a1", "16970": "36f905285c0089228985cffc9f9f6c7d28789128", "19895": "48d76d65261611d423754b62a7d860f5b5362faf", "16972": "432642eac39c8063d2cc06cd0175bd48463282ac", "589": "2134ded168d91461ccb96f66cd674d2f59048d74", "16974": "b83512773ab0dd3908cf2ef5ccaddcd8e0337c64", "16975": "f30345f13974ef325118d499cf8c1033443fe6c9", "16976": "7dcc86443fd9b1aa94b6f7e4e33b6fbd0210b8db", "16977": "a214915e241ea15f3d072d54930d0e0c8f42ee10", "16978": "6485a36483884fb817800a8380a4a4197d6df4ad", "19897": "324bb84c8e4c84b4103e9b2bdda2d99e8ef549db", "16986": "d7797b44b12f80a6f6e447b3523b820fadd85b7b", "16987": "13bd008edbbe0780600072d404fa989accb5e762", "16988": "507a2a24c6b8cfa8484c6b98ece1603c28a85519", "16989": "c0e75a59b8fd2870c55b8e15565d1f5f8be9ec00", "16990": "cd484cc525951320ee03c620f581c8bd9fa4000d", "12896": "fe48704835323c140846d1bde5e1387aa0cac3d4", "15803": "f2b0bdc9bc4e57e101e306db7555eb7db28172e9", "16997": "7a5634e79f0b42ddbf602720dc184e9ce69f929c", "16998": "a2771089d87afe8104765f12a07a6cd125e532ac", "16999": "569bc7a35c06ef8eb9a121ca983ba8951399a124", "17000": "d6fe1940a5d7ea10624e1cc871a6eef13f32b382", "15804": "7358f096ef76207b05bcce0bd02f3a45246e8b09", "17002": "df38f66b417b754afdd2b0e17282255bbf2c769e", "17003": "07137a5acdfc761c7cc30a081600e4c4f23c7d3d", "17004": "8cace882612a6f51ed05ffec43763b8f7ffc110b", "17006": "b9bd0d7fb2083b29a4943e67d6f646309449bebe", "8815": "26312e15b2f9d9a379d97c31ce0aba3c0b4ea2e0", "17008": "39e7b6916b07982240bac87132848fb2665806a2", "17009": "5a20717ddc58c4d961227a482fa88f905f159bab", "17010": "d198a6efd5a3d2e7d5afb4a3cf556507c7501dd4", "4723": "78ce0ce8baef9c66bbee77083c0d12a47d5e294f", "17012": "6cd42ebf269436baa49159d24d2610d9506b50b6", "17013": "db55f4786f0888f19c23ad8c03b791e0ef69ffa1", "17014": "d59aad656d55a95dd5e52e8de17bd42836d2e872", "17015": "405ed25b214740f2e0457ee84007567072b6fd18", "17016": "2fdf1e256e5e0b7f1fe909629e2f0b7893c8c7c3", "17017": "44c822de8dee0bf0e1ed2e8bc15424bb323b786f", "19903": "95c78d650a420eb3282d5862a088b00617e09588", "19904": "2beb1b4ccc78f16d5277a33157c7415ebd702b92", "17857": "a3e56f25a4f7c71a2b53ef9dc3b66000c093b084", "19906": "850fbb503203f2fb9a8a1448522e02f0437b2136", "17859": "0b63e81dfcd7860a8c30e0837238ff9cc7bbe88d", "19908": "68dd97931c364b2ce281c3ad124de21dbb6efe72", "19909": "31b4019ef290bc55855e079b2b7dddcc39a16fc4", "4770": "241e630dbd3ee499fee5aebc265f269b95f9ba26", "15814": "a4c0e72094622ef8b6b4d24c36e532467a00caf9", "15815": "90913306595c36facde65b6858ff94b6e6d51668", "19229": "b66114d8cf9c5ab47fca0848807a4d78f322207c", "15816": "55ae03986dab53f39c1df2b8a5e3532f89ad22be", "694": "dc1b32055a09d5b723932d0238bdc5fa3f583fb8", "15817": "0c4bc059d7a99b66f0f5251d699a753c9fe81ced", "15818": "9b07ef4a5b656a1532512c270533053ee338e30d", "15136": "10589887016f4c9280fdeec01f9fcdbe9cea4dfa", "15819": "929c66fd74da221078a67ea7fd3dbcbe21d642e0", "4816": "1751bae723d336904bca81945097b3b700b11801", "15823": "7cc0fac9a77547d2017e70807858ba0c5be5c4ff", "15824": "cda091f85a31fd67b2b3957e77718373e92ff883", "15825": "65e04510b1576a0bfddd307f19154a44f0fb58d8", "19922": "f0ba498f71a9aed5b9cfda6ad6099fe9e7292cda", "19938": "435e2b58c8279560b5053ec0fbc1a27a1e79f2b3", "15827": "3c833db29b6f5977c78d1ade791a09a5b29cedb8", "19924": "de3a85c8404505ace0c0febc26b1fbe824f48034", "15829": "5d8319e51909870f4694b26370eb03832f56e627", "19926": "b727c6b328c3c586ddab54baae36680a0992e961", "14074": "1ce8f8e0b8540252dac25497f29d4de66a8bea3f", "15833": "556effcba52f4712fed21b269e9782f1a309ea93", "15834": "073c14544436d95969258928e2554cb2fc093c99", "798": "c27e09c0a541f4be51ed8724310e7b6d52d5a056", "19931": "485cbbb9da072e19b5bd81b1e6b7f0643b5e5bc0", "19932": "f90f4aad4589727ebb3235326970a9110aaa309f", "15837": "dbffba81914c922925e098411d0f773a759f7992", "15772": "869be8d6981d364d01e4000845583f1035104f2f", "19934": "9caf58f3ee712a26b4ac9b9a2501141844a455ce", "13114": "89f46a5e5db4d55a99b90a00ca68bbc3da0cbb1f", "19935": "d591ade7b1053ce6bebb4501578474cf9544582a", "9020": "47785e30d6257c6ff2987a221cf62761860782fa", "19936": "1172d61aa8cb66e76af2bfdf8a70444802b28c6b", "15841": "989babdec1f11edd208d94eaf5806f931ecb8fc9", "19941": "70773d952bf52229d7214707ce6d66cee70607cb", "4941": "a52df7d6b6013bafefe9b5429fe775fd33fee068", "15843": "d11fae62ae6a9a5e712d3165c721179c31d961bd", "13531": "9259a56c600f6ea247a9c58c00af017790fe5e21", "15844": "06850a148ad880eb2fd2564cc0ad7cae8606dd90", "862": "9e406c50b77949433ed8f7fd094fd30b5421a35e", "3557": "23fa6f8b3d1f823dbafb64dc52e5a96fefe9236c", "874": "645d61131ad5acf768fff906a25e9e34b53efb92", "13165": "6c30cbecf8e5ae610f2a37ba821116bd9f77044d", "15853": "47b397309e9601640170aedd6f70486a54d638fd", "915": "04cc1eb08c6e267b73378794c2a2ca8a9f2961cc", "15854": "6fe68325de93a5f745ff49eac57589d33a1d53c1", "17625": "ac32ce8fca6bdbc40ec1ca14e45e49d73b5176a5", "15855": "57befd18cb8ea8d641ea88a5c8ef916a09a9a1aa", "5022": "31ecaa9d06f71b5d652d15441cf6b2dcc6f7e640", "15856": "ecaac87c526f5642389dc36e6ee565fe8d21bfd7", "933": "ba1ff88c95b081741eb28c8630aaa6b0423900e0", "17905": "62a0ebc5837a4a1f7cc925e13344be1adf1acc59", "19954": "fc5f292377412fa7bc824d2c2cc69f2ae45bd7f9", "15859": "24b6349c013fb9e59ea7fa4b1d40088026c32d25", "15860": "34c4ffd7c454848311f71e6869b5cad4bc132449", "10399": "12a39bb05973573e5fcfcba28c3d25a76737239d", "15861": "7818486859d1aba53ce359b93cfc772e688958e5", "16808": "5a926a7d1d9041749c1cd8f73e4e5e3cc5a7f360", "15862": "4e9c0d1f2156c656df5da4ac3f00190f0da5828b", "19959": "d2f9228b060a6a5a4d3d3cd2c573cce60f924a13", "19960": "6de813364fd4ebfd16e2794e5ac3422d3bef87e7", "981": "35c6b68facf00788e9092d1fcedd53acbf99be89", "15865": "58d872903449b8a29237288ade6227cdb280fe18", "5082": "ccaa428aa8872c4c3b7899901f492a348eef1f41", "19962": "af0ecbe01a7f70461f28e9ff383ffda0246a0850", "15867": "8354a1dfa9073eab1b120d39be31103fc29394bb", "15868": "91245a758ee32658c66bdecd9556f7054cd99901", "13291": "6b8a7211ca88cb7f2536d3546e0ccf3b4290e6b2", "19965": "2769ebf3da8d9c2869ba5811ae9409d84b0cf28a", "19966": "6bb9ab8a60b9914bfc306ca3691130d583e02656", "1029": "a8b14798fe18050e486845b26370d4899f46a8b3", "1033": "549453aa779ef24a5f1942781e61da248bc6467f", "17421": "0c4e611927772af44b02204192b29282341a5716", "9230": "97e87b8dbd1699f5627867ff609f1aa3637971ed", "17423": "1bf36b0b9e64a911c83e8c2125836869e2ab37af", "17424": "14889f1bb808c7e60b4f63f28787e07400c46285", "17425": "c4b4a81f56205082ec7f12bf77766e3b74d27c37", "17001": "d9551c8ee2a09ccc4c39d2b661f199334162edb6", "17430": "d7a4f5b0b40525d58ebcd51b40186c0d8af91f84", "17431": "89813f5d7acf72d88efabe93040dbae02148fe01", "17432": "14f03ce4c3d41f70c0e998023478d11475340035", "17433": "f71cd9ad53d9760a51837979a517880e746272bd", "17434": "2eefe5a8671bb25a9b5ad45f4ff5f5171d46fd44", "17435": "d2ab4076512f5571b74e6ea2936910841b10dbe2", "17436": "5d1f5abec3f4f3b614534865e50166955c42f4fc", "17437": "6a22cf786e9e09ceb8ca44b712dce4af5bbcfd65", "17438": "a77ac2bb9fc47b970378985446e6b983ac51a6b7", "17439": "4efb39f01f5880122fa38d91e12d217ef70fad9e", "17440": "fac2ef1b2095c7785006c901e941e2657571d935", "17441": "5edc5c4acde1f0d05b598825ab5c6a86fe551484", "17444": "e71c02aa533a809290c1029438f04ff50f8dd8fc", "17445": "6eda77e7245ff0555f28d84674b541c0e80436c8", "17446": "73cb32e71469cf1615907544728bb9a751089de4", "17447": "85c790082328feaaf2cb606c46beee5e6fd068c1", "17448": "aa3fefc898b2f101f3cf83f90add69857926fcbe", "17449": "6d610a4d9393c0d0335267dc3252ccabb9e51e43", "17450": "eb168b76f66756b54d65b60077c176035bba69ab", "17451": "2431641ad7882326d3d65a35319ef4093cdbae9c", "17452": "e8f206d8192b409bc39da1ba1b2c5bcd8b65cc9f", "17453": "4e6aa1c012d91d663edcfd13658a35f88a49da30", "17454": "d91b706642569aa87173c8449e2fa14e27f72c93", "17455": "fa24af91a156587e7f8d1aab27a45644b59c7e49", "17456": "2794474334cbd53315c248b605953579d010c693", "17457": "fa231e8766e02610ae5a45e4b2bc90b6c7e9ee6f", "17458": "0e42a99ecbef822885a488cd4d8d85362d5b24b2", "17459": "ad5affb6417c26bc7f3bc10668f0cf63fd867940", "17462": "2acce77d0f579dfd8733c6e9482a13d746e5f7e2", "17463": "d104ecd4eb3ec359177a99dd372ad1644b66ff19", "17464": "3885cedb884a8b22e0875d9ffbc8d28123d82b48", "17465": "ec7968d023a9edee0c8be926f008d3b91ec2d0f8", "17466": "d5d5a718254f45b4bdc386c360c830df395ec02a", "17467": "b16974ada8cd833fbeeda793d4ddfaaacc4cfb48", "17468": "e1e1e54720d98901849aa55dec3f76e8c93672fa", "19978": "5a150694731d2ecce670cca65760c472338a04fa", "17470": "7f7f3d49bba842881b5f26a4fe973a6f3eca8757", "17471": "d04b7464dcc20051ef38ac2acda580de854d3e01", "17472": "804101c8888c7c9cf33a5224489a4c75c4118fe1", "17473": "1e4e04bf47417aadaf11c7d55c206508f2899fa5", "17474": "8756f55234e4fa00a116cb105d36861f1bc6100b", "17475": "da33359b4d19c9bc25710854472cb67918611a2d", "17476": "4a344972722cc3c27250cbc8e382472b13e66bde", "17477": "6245e8c983a685a46e3b64d64aaa59afc4655ed6", "17478": "75295e16dbd449c29609ec6e3e09087df977744b", "17479": "bb095a6e96217f162544b10e9e7a46f04071fb37", "17480": "7ed1f5371601f3300c8b4592c87159fb3eaec5cd", "17481": "b9f826f46d9ec9871a00f2d2a95a0e13f520483e", "17482": "07739aadda4a9afda31fe9ab5d7b01d19f3f1199", "17483": "ede11af8d02a4ac37ed866593839024b941a8086", "17484": "78fee04e95e3c53c83c938285580c39e7761ddc8", "17485": "3e691a4cba566472bef03ef9bbaec701498670e1", "19981": "e26e2dfe6e93922830fb5fb7868b87238b85911a", "17492": "7e75e4ae7cc8a693ca25f7bfe255574b8a91fa03", "17493": "0d199e4e8bb2b9ce73a35889b49d847283fadce5", "17494": "8def64931af8a01f4af50d79a8d628fe3e63f00c", "17495": "4de2e9bc0d0a7a20232b4c41e2e5861c14bcf4b2", "17496": "0ae7e9090cee6e10ebb4124a0b7f3b30811ccc53", "17497": "ada3fa41d2d7efbbdb7747d2d030dbfdcd2231bb", "17498": "a80c7839c7389483d8c9a29d75bb07195d0651dc", "17499": "31e77b0b4129134d20cd5027dac0adb9fbd2dca0", "17500": "add3fbfbd1f3abb157398d0167bb31fa4aa00a22", "17501": "41db52730b47ff1d707004decd1214fb87e5c533", "20223": "0dbb99efc259c5182ac88f116ebb76ae6e2db6ee", "15313": "19fc8dac68e088126ffd132dc322dbf8a163ec69", "17511": "0ae19a156e3d0307bbb5c022b40ef49186e995bc", "17512": "ce8f6e89b83af4c8632c9cb61aa78b868beeaecc", "17513": "8bee97a81764c5211d719d61a62424b1edfacd80", "17514": "d1ace10555f06061c99f478f3a757da07546bd6a", "17515": "7ec74e5f7b1f9a379b318153da88092cccb855cc", "17516": "60fe82c8a2829e831d28cf6d4b3595637c3c5802", "17517": "4aac0c8a3ffd841a6916a5b49a8c4aa55fa8b080", "17518": "21e884f556c175865320f3c25854bc9243a388fe", "17519": "630ef1649cb57a4068474baaff8c4a2b8a14b313", "17520": "e9190bf325311c717d4dfb977ccdf67fdece4db3", "17521": "6cacdde5630c593999059833b516e1fec60aaf72", "17522": "96f2f57379afab0e9050fb3f4f5be4258613740e", "1139": "6e418a97858b771fc58255f4307271abc969487b", "17524": "563a6ad108a79b0192a25d51d743812a18e21b15", "17525": "632204359249093d1305e71183be932ceceeee78", "16132": "e4573255664660441ebbcf9df163327cecd71045", "17528": "4afc7563895830d224ac949f571edef2f069c314", "19988": "b90f9db6d23f64b0ce9ff469445e1c31013a07c0", "17530": "d274d0b22ec3fa0048b27df7b5f349f1779a8c3f", "14527": "c0e13d1bccd4a783486eba8cc769db48a7875de8", "17532": "f799916d0dbf35cd309a42f03fb311e446cd8021", "15893": "b9d48e48904b0e607c4d18738df50dec744b745f", "17540": "93e712327d5aee09cd2994519f9af45495fb5f7a", "17541": "c4da79b5b322c73d8e61d1cb98ac4ab1e2438b40", "17542": "3471b9809b6432aaab9426864b8777630a19ec7d", "17543": "f851699cf086ca7d6011061031c959bcc39d1e71", "13448": "d77f0724b21cb290a0daec0202f2119543644236", "19308": "f67c97e16fe181573d9d3d9bbc14524d4153abdd", "17546": "b02c69ac7309ccf63a17471b25475bf0c0ebe3c3", "17547": "2ab37272b06b21b5bffd846c44ebc387248f5618", "17548": "3340f27e2210553b5bd7b08a3ade3d20ca3b1220", "17549": "ce4ab828d882a0c50f2f63921621ccae0d14b5ae", "17550": "d3d33524cccee1c4c9c00318e286270b5196fde3", "17551": "21f5fb1a3507cbec3b97ae9ff2a23a01bdebdcec", "17552": "cb5c86933f1e0a7f7781c7f07affb7f184c5f356", "17553": "28dbae9f306ade549eb1edd5484b3e1da758bcdb", "17554": "ec4609eecbd7fe4d46291b092bfe93f130b77ee5", "5267": "7b03ff2e63c15f1545dab417b1adedcd257872c7", "17556": "be6f11e5bb4643e44b134681f3830b13c35b1620", "17557": "c94a68c60d0f2259cd0fa55182a723b51ea5edee", "17558": "e8e6e89643bad03e50e4f5b568a3d1da560312ae", "17559": "bd4332f4bff135d4119291f66e98f76cc5f9a80e", "17563": "e0513038e6d2ada60345d4445183c3d3d6daa930", "17564": "620784f1bec8f8895937c545ff9693152483dfff", "15898": "764cf2abca9ae3d0c730c98b5103fcde5b4fd88b", "17566": "2299693d079033a0dd502ed5f59a4ad6e7a24b20", "17567": "d98f25a4771d317a34c88c1e9d9a6ab22a8f5046", "17568": "3dd90a2ae1725c5df5a328ea78fe873f6459e4df", "1185": "8f79f7c6e01874bbf7f3b9bc38af01551c90121e", "17570": "673fe6e02d50eedd87b835723d82e509372dd7e7", "17571": "21ee836b7f1f36cdc6da0310f4ce7584b6692377", "17572": "e9782795c77b91beeebce863cd28b1b20feb16f6", "17573": "eff1faf2729fa0fb0c2d7913107201e475de33d6", "17575": "21dd192d491829d694e8ed81d9f3610382c2390d", "17576": "780b8d257575c65a875ce53cac0f23c6493c263d", "17577": "6d5d701566615b736a6c11b369bb5ab53176600c", "17578": "8e2a4a9e0b5a960b1330ab4a3c2a330120b9a458", "17579": "c30f0bbc94d420ecef4d5c0c79c3da81599ff220", "17580": "52effcb6848c05226bfdc103e28beb01d972c63f", "17581": "17a0ca172c5fbe3095644d6a491d3f11b142f961", "17582": "0e00151aafb6c1f97b6a0cd711c83b4fba53f53b", "17583": "648ca95af696266b18ded6bfc5327d0666e3ad23", "17584": "3d03fdb24b1a9c1438fe65f5242cbea5418787bf", "17585": "3283ae82bba9b3172551e699ee034941cc273c79", "17586": "1dcddba2200b89cffe97ae7a32a34cdec3a7c8fb", "19953": "0b031306746511130f19e6af33ca317f942f862c", "20030": "fdda543e9c3158e166291e31b50231e6ada69a36", "17596": "186ce4e772c8884b5bc87ab767adc94d6870a4e0", "17597": "8aff1243a54fecf6002268d5bafe1c893067bf37", "17598": "dfb265166c51fa20c473fbb0726f11442042ee03", "17599": "3be623b8e9822a16ba3a815257731056dc384006", "11808": "28b1488a35d1a916f59c251dc47e1e14baf73784", "17603": "3147a86e1b20571766b488a8444c74cef29729ad", "17604": "2eb5a67999552d60f7a2a9e1922549d5417d714f", "17605": "cff6e014171539aaa6415a318f47f22b5a2119f0", "17606": "d63d0152f148bafc82b0af5175a5f1d10700991a", "17607": "a327920673868db898d85ed937c1582fc6437ca2", "17608": "27581e919a4e76113e2ee0a6e1c598507ab35f0d", "17609": "501f0418c00064f5041ef156ed5a2289a9064da3", "17610": "9f40757c9c8e8cc5df4984599f7047daff6685ae", "17611": "1ee5ecf3ddbf1ce92e1a78e90a4ef07fc3cf0840", "17612": "d623ffd90f57abda2beb34d807da58ca95b3743d", "17613": "6cc5f235b083a3505eb4ca9b18cad1f3eda29f5b", "17614": "e033c0616158d3ba974456b4f84810492936b1fe", "17615": "cc8d33e00bcf7d1e0bf08f58ffae3f16d37ff118", "17616": "ed784a897047db2aab88e3cd87e62f17647289a4", "17617": "af2b6094b93ec04c5f26c16552cf339b4d037150", "17618": "bc37ea2e05019a89adaa48159b220483598d1898", "15907": "25d529905521c4710c13b9a2c189a39479c529cb", "17620": "3cae0a26e7fb681dddb5cdf64a2a29c27e2c8f86", "17621": "e80cc43d9eeaec088bbbe61b4bba15e2aa993aed", "17622": "0ebbafd13b586a7f41e089edfb509127ea00b93a", "17623": "508ec3d3686338c7ddb4b5b121c677c6864b1f80", "17624": "81358e862022cedbac009985abac5135a873dde3", "15908": "84a39f99013f238a2e1df9ba63bdaa8a3fd00c08", "14543": "0699c89882133a41c250abdac02796fec84512e8", "17628": "791de95b7e5b7991d4ea39db68b2fc847e38d1b5", "1245": "ac5f314e001dafae9b13ddcfedea7b200821db48", "17630": "be90d492836fa604b4b914ab6c7387752a6ba9e6", "17631": "1abfd1bfdb26e9f444b4f44ffbcd2e37026e6497", "17632": "6f1f9759ba8319736c2d51b6d05b071998f1add6", "17633": "f91e28c3fdd4e0708e4cc2ec45a96b068ed0a44b", "17634": "e0f6c2281bf803889d4ac6c7f8bdfd721715665b", "17635": "dc02831f7b267ef152c9bb6a1c8e39c652c1ac3c", "17636": "f6abb6148c8dc14e6279f31f2e620ecf52822107", "17637": "1c2844aca8e3dad7373576d5de40ee6810f7e5ad", "17641": "d30cc746f39e8d8442849cdcccc625ea4dd036d2", "17642": "a5259cc7f1ba092dccc73e0f066d5ae6ffd5ee97", "17643": "f0c2330082e71d8723ca9f3f62ccacff78669bd6", "17644": "b64e9d5bf17888667bff8f37411d71fd45603891", "17645": "b2eec25f4600ba17ef4b9d23cccbf0122da56279", "17646": "c85ab083919b59ce84c220d5baf7d34ff4a0bcf2", "17647": "4cbbcc648436ac21aed296206ace61da96aa7614", "17648": "bc9241d51bd4ad40d4863fde5ac84d13fe42b48e", "13553": "69baf4c30a8b404f8626728e89a4c5fd5b606a44", "17651": "5348e06c4e9e8a03cbd0011483d2dd087e850940", "17652": "9af5fee41ddb2b13f2dd23792c3bc537795a3a63", "17653": "b237b11ba9f7e0465642fd0286b2a483289eaad0", "17654": "f1631bec96dd9a1dc4890677b9c5475d0677e102", "17655": "4274b840e64374a39a0285c2174968588753ec35", "12181": "4a03e936426936068afb063e44393312d82d12ae", "17657": "cbec58eacd8e9cd94b7f42351b8de4559c250909", "17658": "686f6047312fe7671d8a5e1b2ffd1866f7c7a766", "17659": "9f95f7dbffef7752175ca9ed918314cb6f0b9b18", "17660": "b32fdc44206c38aecbbe5fdb4ed543a5d213ebb9", "17661": "15b39cdb2ee521964a00308f09d45f92be2feaf5", "17662": "67e6e6fcd19d1d89cb60abc3a78372bc85fd8e29", "17663": "7dc6f7023ce439e8ef10ef336f314b10192911c5", "17664": "dd91539c02b9afb0895b88ce7bc99c075f316795", "17665": "fbb47d67a6355a4aa77267b87300cd448a4bfc32", "17666": "0c65c57a279e755ab7093db925d1e580f9878dae", "17672": "a65e4af2a7af17c533017ebcf1227279f7423ec3", "17673": "5bbbaf6ae48681699cfbdf8f4a726661118e0dcb", "17674": "649bfae90f70e8ee7181aba31b0f0b44f09b76e6", "17675": "c460710f32193c65e33d366921f9eaf919bc8da4", "17676": "abfac97b2d22447d41bfccaa53e0a264ca34d6d4", "20013": "c4bf97a3ed615705aac1d170569a5f162bdcc1c2", "17683": "d79203af0552e73933e6f80f4284ac2697372eaa", "17684": "05e55aad0b6b55418cef437a5b562ed72cef3ceb", "15918": "aee2ae086e0972aabcb43d05fa2a404153e3b3b5", "17686": "324b324f91021e57106ffc7937f35d54279aac5c", "17687": "415012f4f38ca0cf41717c51e49bd2349cba09a8", "15919": "3a291bb7170ca900cb1b886a3c0b39976a9870ef", "14909": "dda3c4292b28d4dbead8bb6ae9927373aea9fe23", "16138": "77b4bb30ed5afc95f2c264c6b25e96ea8a9a5aee", "13622": "e5ed87b33ab6cd9dade10df945bc5d7452310b7d", "17722": "7000b899038e9d6559ce80d3c018ec0ad5412efe", "17723": "480790531ffcc4329f280ddf6877d028d08e969f", "17724": "66d9b1559eb524a5cb12815e5c45d81be8967fc4", "17725": "879b15f3476d81d51f236d13684444579bafb8fd", "17726": "defdb34bafa3900069d399ce597c0abbd4a2b0cc", "3637": "39c735c67a4f8ae4203a671deaee07b060f8e201", "13633": "e462ece64b7cb12fe7cad6e085f62f3bfe9785c6", "17730": "e77dc7e337dbce19d26a25c9b2f9651aede5ad49", "17731": "ffffa5cbb6134d0b6c6e49d460e5735bbdd6d5a2", "17732": "92e9882d723c57b3135b17bded1a6495fec0ebda", "20022": "84fa2ef3d17f63709805aae74b2a56b143c551da", "1350": "7912b5221accd92a6f586d1792816892f9874773", "15927": "23050dca1b404d23527132c0277f3d40dc41cab8", "20231": "0e3bf7f3478ffb85d64e795d72888bdb9bd9cb4b", "20024": "61edc765ee3d12a2341ee667d6aee3d96be3db72", "8419": "e97e2be5c11be14e1eede230d60a113946fbc965", "15929": "e6aed2ebb7374ed2a6a7c284750d47728aec285e", "13657": "2a531131abf396d438500fcd770cae010dd83c8f", "17757": "ab668b0a56a9f2aee959bde787e9a0af4068d7a7", "17760": "1a23779f09abc6ebf908d66ee88b973b767e2e3c", "15931": "f3b6d1f91643d245d6b43b41e7c9fd1349fb8de5", "17766": "bc4ccd7dfaceb92ac2c6dc345c1bc4489407108f", "17767": "c8f27ccd40611e15b9c8e7f75c16b41a78e9ef72", "17768": "b3744a11ccbed5bcb020c2e994a9267a2d080c84", "17769": "576d5c6b76e039a411a7cc4c0de29813e2de0149", "5482": "a12d480b38c16bccd111af772d78b8f172e612f7", "20029": "b9e46ad1b10bce78464a07454dafd680273af6ff", "17778": "49188296a363f52784abd30f8074f20acd4d0a00", "17779": "c50a9dc20d6e5b72e07a35c2cde4a9fdaa62730a", "17780": "ec5956ed350d33ac2cee07bf9a24ea5315529443", "17781": "6c71c4586296d2861717fa541875f83bbd07ca1f", "17782": "9e982e18678c47c83ce2bb5932f844e2d9ee21f3", "17847": "f9cc39fb1391cb05f55232367f6547ff9ea615b8", "17786": "076635ac3a33b819f4ae0fb1f95106bf8e4bf329", "20031": "a13ef664aac05570eb70e5d6d28656468f6d467b", "17788": "6131a598a614b93e70a28b36d35819cb6081965b", "17789": "6d346576669fe7bd9c2b3c103cc8d29ef3d00cd4", "17790": "71c53f0be9b49af0fdf5c6965b2a5a217b9f7179", "15936": "e682902327bd883a207b291b0326f277b3dcdd12", "17794": "cb57fa6d9602018cabfe1cc61fa3369137da9ba9", "17795": "2625759abeb78655558067d55a23c293628c3165", "17796": "89874d34f3ce7f30207fa1f8dfc082d835a3fba5", "17797": "ec2020735d72ff73e0a6a607689281aad173c702", "17798": "b36b451a74bc16d7ea64c158a3cd33fbfb504068", "20033": "d74901b1a114d70244fb919e8de630fb53481b00", "17800": "f91a7049d1730aa1924584a07a1265d9f57a2f35", "9611": "48729e29ff1081c7b32fc75761d0b8e2a36a2f19", "17804": "1c0740cf654d1e9ddba5e946305e736e3b95ecac", "17805": "6a5a565b44583ea8a5faa00aff988bfead9fd9ad", "17806": "e24da6c9f92d2b04ffb39a7fe0db85015af7ff3f", "17807": "1638331172cb260c7c642d02e5cf97373f7bcba6", "17808": "f1ffc5fae06a7294dc831887b0d76177aec9b708", "9617": "76f6cf0050025ec5a6187e17957ea9a158cc2d56", "15940": "f11bbf2f505d81900cc83ce387a6a1b1d2a2f866", "17818": "7d8626dfabef595245af44bf74d329f251ce42ca", "17819": "c6347c4c4fcc911e31cc22005fe2d42cd520b7cd", "17820": "66fea91e915ca5e3f096055f3ad0f07335483e3f", "17821": "5fdaa9717f7550c5293d421205bfa19011278396", "17822": "7bee353cd69ab846317301fdf614a94fbae50117", "17823": "eb40557a7897a6138b605b1fe5291451027ec01b", "1440": "d5fbdcc26520d1c92b5dd73bb6e9a9902756ad16", "18672": "b9fc22db9ddd8b2aa10be4680f4c7bf1b5c50ad8", "17826": "7829ad3290dc6894d24c1c853ffc4dabef50294a", "17827": "3433f1990333324d88a7e0b768921b28e921c55b", "17828": "44f7b144afa19e1ff65f36609184d133d538324a", "17829": "51d548dbe6dedfb001cdca3a65bea46b8faa5fd0", "17830": "1033e8b1195d4071253889ada60523832285354c", "17840": "9d38e0ef5842fafcc4e391abc6aba486684e6dc7", "17841": "2a7e1f297316ddbe64e1a14e235d6f08e524e7eb", "1458": "9bb210ccfd7866cd614fb11045188e75874219b2", "17843": "ebe480a9035095b6e72f2e8055ce7ea1e02743cd", "17844": "45e55af9cf74aede00a8b10f8922537f285a573a", "17845": "b35cb1c127aae894c2a1ee5ab2f16987b91e9000", "17846": "44c54607828f03d2b4b172838d5270e66b2a5312", "20041": "3de7139db646e705050dd38402929820a3b265df", "17848": "a620e7255ce896c9185275d82172513268b1a719", "15946": "06a6e63c317e5291eb78081e2a21bc163ddaab6e", "17855": "66b517c2f51ed20d4c6823272d5c2a0f47f96d84", "17856": "5afb95358efbde0ec1327378d12e9287a9ae1c6b", "13761": "2267bd32c3b4e6cdf50ff52306fc09d5f9a279a1", "17858": "5c761f1c8a19ea3d87fcf365f7a2c6ae00b355f8", "20043": "77855a1e2d4a406e6dff7c629ee32c0b50c5eec4", "17860": "dc45fbafef172e357cb5decdeab22de67160f5b7", "15948": "94266d48e5f54287a877cf7a0e94ef740e3eda22", "15949": "9b21c5456eb4b2cdbc7f74569c4b8660ada951fe", "15950": "72c38883f09c6902863345de432d3c90a29140b3", "15951": "328c7e179b72e257e27adf92a06718fd5a40473f", "17888": "1af2f6cd29385b481d7d3de1e1a30cf1a64e9eb6", "17889": "be14333ab00a68a9f7fa8ea3b35ef5ff4571fd02", "17890": "823478c6eaf773cd7e1803a0353232c0b7e56af2", "17891": "8b2070a1a5e6e250b05cf7e47523c857f5e97b57", "17892": "7cd2679982138e1e7f9f1a759827647e6e521d43", "17899": "8f322149ebd2a30f2f2d48c06863cd783166fa84", "17900": "e77e428d8ee37f15471974362bd48d0863f71ae4", "17901": "0c2ab656ed2e9aad0031efb644a160fdd6bfc4f8", "17902": "0cb0886bba5805babd1f2907bf2748886f00f792", "17903": "2b136054db3b8f4c8d1aa33160c4bbe3b8ce940e", "17904": "7bb010cf1206f924cdc225f00669fda3daba758e", "9713": "da0f7ae362bb0ee747c3c5c141327d1d8ba161bc", "17906": "10709762e95be2b98d68b95db93a287ee5af74d4", "5628": "b5840b3d5cb533e1b6a0f32e6f316de44040da7e", "20053": "51980fe369f75e827143f21b6b26e0d6a86c8c78", "20054": "9feb3ad92cc0397a04b665803a49299ee7aa1037", "17929": "bd8ba3680eae9c19221ef7200928bcef68508f4a", "17931": "9b0f560a73d11b2fa72c48d7fd16126b5137f349", "17932": "c7e4b212205b6b18cdd7f0d7c079da80b58fad82", "17933": "d24a9507ba539f455d9b90885edf098c7dc93e99", "17934": "861287bde7c04179d8b8d3fe78c3e8d38f52c55f", "17935": "04caa569e5316e1a6526f0c78142a677ca4b2ee9", "13843": "87b0f4dc1e91571cc4dd933b7cb181b99606ad20", "20005": "c18c8be779240be49872860ddbfec9bc5ef0a548", "17943": "2543795597a01a485d8ff355068ee4e0debe496f", "17944": "a740b8905a8fa23ea9d80162e6cf845cbf6d4710", "17946": "3be3254c06a97ffe4b73b9a55df30422ceeca36d", "17947": "30eb48cc485bb7c7c47a4e7e26f87e469fbd8b8a", "17948": "620abc403d371446afe38fc1e63f0d90ea27b80a", "15963": "37e23d03e1ba2298d9df05ded69028dfac0e823e", "17958": "edb71fda022c6a155717e7a25679040ee0476639", "13865": "f0e47a9c9350e0d8fc0fe00a1ca0237582437e9d", "15785": "c55dbf067d85c3a060a6ffeff2aad24991e95eae", "20061": "34da8be0c0c5eb869a1f57efb76bdf97ee0667fe", "20062": "b6324be64884afdd2829e046748b7e843e338c65", "15967": "21a38008e3cab7a0459cce4fab4ace11379c3148", "9798": "fa8a5ca1dd27c4169727070ddbdcb248002fddb4", "20065": "d3b9d9f1350117d257d3f6832a2b5adce1b4e35b", "19869": "4c21e5c982614436c1fcc32ef32ac83f01c0b7af", "19012": "bdeddb139c1f9d95a7b32095884849856994ec41", "15941": "eef810ef2c64be00943696b33e8bab0b4dd66e9e", "20068": "7fafb356549f1c52a9896429ce0241487f42bea9", "1632": "2ca93a17ed4609960f0ee3b8704b8b2edca1db5b", "16167": "39a6b8f20fe95f5b6bb91c577cf5dea81214932c", "12566": "fb42766b3eb55155d67548d364672d254be7ffb6", "5767": "258c7e3c5ec5dca7bec32308925b94267fbcff61", "1678": "dfd2926502dfbc5933169767a64ccfd871d08d65", "13970": "eefe71e27131bc4848e549e3688ef6700b57b73a", "17469": "0bd8a5a62b7831084fe17b40b75127d311f669bd", "5781": "e71db13f98edc715abb481e239cf321999210616", "20242": "6ce7fc70a0103aaf8d6d6ff908a61b561447c218", "17787": "91451cb7dbaaf6fb3f9bdfca73fe6adc2ee68cce", "18607": "a9ddafea8799f16a9eb80b87b63bff0642de537d", "17824": "f1aa08c4631aea435d66c161557e44f7c72a618e", "18135": "0409521665bd436a10aea7e06336066bf07ff057", "14925": "f2246cfa215d01b68aebd2da4afb836d912d248d", "16971": "8f4ad305dc3a98332cc9765200b0535669dfafa2", "15880": "d45e12b87ce867b2df3254c386c0f17f175efbf0", "5863": "f9eea308611152f1f7bb89981380fa5d85685f48", "15942": "fa557f7391589f351b1260f46b3b3db22492f50b", "1786": "9637b509780997019d9089ea8ed2f2f01e2755e7", "19413": "4bd286a5ee2c15f0e9c9ef56be1474d9abee9f41", "1812": "06f608182ecd516abcd140531c65e07b30293eb0", "10015": "6f0ccafa8fd796742be127032e58b919e10ad046", "20225": "437efa6e974e506c7cc5f142d5186bf6a7f5ce13", "16155": "81372093f1fdc0c07e4b45ba0f47b0360fabd405", "19421": "33f91d8f9f2e84f2b5f3ac3f0481b691c977c427", "17656": "88c3f08d9b031f6559b9db6574ec02da5f81f6a8", "1562": "c2ce8039cb77cc69525fb3249fb163d3b3914276", "19975": "22c2b73857d1035685d42b0df56f4762ffad0611", "5980": "4670e9f35a130078290722ff538985104f401915", "15900": "dad39d593eacd1ee2b2465dc2ac025b0cfaffe2a", "14178": "0e7ae89115e60419b807c38b9e4b8a19d4c8f830", "315": "2ad94dc4bd36dbb638d8169a841aaf74cca2120b", "19431": "306e733626b07a3bbc8f9d6e1fde6f84d9b4d579", "19977": "b1340829eaf6ea8e470507329fe6e504ec99e2c5", "1931": "fcb200561fa486316efda2d38a86fbc78cfae5b6", "15886": "36dadd70376c6033037af281a4669a360fc71cfa", "19439": "0bd454cdc9307d3a7e73403c49cc8350965628ce", "10140": "d839555f5e080a981ce5faf89b4df7dfe0924541", "17523": "2cbdd9a2cd19501c98582490e35c5402ae6de941", "20251": "5d2d6b4d21439861177a1edef74fbfce0c7d720f", "15346": "de8734474daddf772d97c66a9ef759e23a3d362f", "20127": "304d8d4bc3b3cde7e2b463426bf484701df142cd", "19979": "190a69e3d6bc3f106ef635ae18ff0fb8fdfe85c0", "14283": "e88ad28c97457c8c1c8a83bf5252257c1eb802bf", "20130": "612c24433b8486eb6b6b0013354dd6d6a296c100", "14289": "497a3bcbf6a1f97a9596278f78b9883b50a4c66f", "20131": "7ba2ec8a6300289cf5dba39782dbc019103e0343", "10199": "7f10211d2ed7d28a5bdc89c689d90b6610bb4e83", "20132": "ef7dc2f46279a7fe13c75f36e88678717096af11", "19980": "4e7e7f0dd6f60556a2b3abc6078af043302ed852", "20133": "e5d15b20e828c66182a4e175dd5a5b9b951d9950", "14306": "5e665b373393365dec03c9b55f488aee36e1b5c9", "16038": "baadad7581c48b0b1c6401b7e3b32fd09e7f0863", "15357": "20fda2223d5121be3f8204702b5ce1e6037e5b18", "14323": "7dedbed8988db9dc6453320383202bf97deaf14a", "17799": "506935c3482cb678b75dc7a70f48707c70b4ae79", "14343": "b97dbd01e49f54ae6fa8df382d6f6e4c771d2bc0", "14344": "96b364a4a337b608c92dd6d5a00ceedd80c29315", "3074": "5b98fdfeae2ef42d78242c4cca1e0959b9c710db", "2066": "9fea06df74c87fb606efe564e6eae67177977181", "2072": "13f5db0ac0ba5a30d64866cdbd02b9985efa6303", "2077": "abc59ab02622560f226dd32bd068857053bc96d0", "14376": "13088842a7218e8e4626ab68f0c4f204f25f0ba4", "19905": "ac318d26cdbe3d10030f4863b84a06e938da9bba", "15891": "0618f9950ad72f6f30283bbcf44fcdcf5918756d", "6199": "31512a2705070b3bd4f975ba087e2657c849529f", "14392": "31ca7170edd1fa3cfcfd96b283d6821491324711", "14393": "e7ac84d2988284604bff781c67a50974e51afdec", "15370": "2002da33b0a755fcf7ef64b2c87ca4252f0e7df0", "19469": "402d5dbd455bf35b875ea3c57feeef3141eb2bf0", "17422": "93bc32b156780aadcb953f91408d90f7e97c72c0", "11528": "9e859f40c1651b38f9528aaccd211b1706cf317e", "14439": "252526cc0f197fb4c6b93cad41ca7cbcc5a82ed7", "19474": "6d918f07240275272999784e775b3952aeb2ecfb", "14448": "27b783986230a3d044d045604b72a51acd13b7be", "14463": "a7604fcd8e105221c5cd5d469be9a3a308325631", "18564": "4eaaf3623725181c73c49ba92df169b778923947", "18565": "4a11eacf01dea84f9cdb69dd43b771dabe341e90", "18566": "92fd46c8bf719746b4c720bf7599d4080b319c8d", "18567": "5dd4cae70d5013925c712d0933220c03d20e0efb", "18568": "1c26375c0743a2cbdcfe14a62ad10806001cbee8", "18569": "c584ae7856cf9d6c8838b4e1c3cd2fa0bebfee98", "18570": "a20b09759f833cfd71e059319a41b9bd25a96751", "18571": "6b8e5e871dc4544db0e9a24463b1e64d1164147e", "18572": "0a2d5019dc2b8f9521879f47a197076d9cef38ce", "14479": "dca0185388d7dce3b1f9e39955c209de1184836a", "15384": "e346c663cf76186c22f4d3b703461b1b60db280f", "19986": "455a2cdc4808890dd7eea41494100f48f34794d5", "16067": "48d0460ab9acbee223bae1be699344f8fd232224", "2196": "776d80c2145ce4a4df1cf5c9ad21140b09df671d", "15385": "e5134306bd47db9f6d0f125d2cafd0b8a789e065", "18586": "88a57c9cc861f066abc0caa0bb902fd827b2fa97", "18587": "48782a8f6de2564cff08517a3f6753734690b711", "18588": "5d84bc08ea7c45b0d2b3aa021a425b11531336f1", "18589": "caea25a8b91d62b30eef99aa0c523448e19cd6db", "18590": "f662c5f2a7b392ee96a43f055073c8523f8f0339", "14495": "6ad6e4e1d9251a9fddcbed80bdaad18ed07c66ae", "20123": "b48d1ff87237cb68792590f4377e3be5c73d5ea7", "18606": "2360f5ac758683c8f9871f94eca3a21e4f87162f", "14511": "423c16a2ee88d82202c1e6b24a31d47ec6a04b82", "18608": "05be7699bbf96be7965ce01f10e57afb5a4c80f6", "18609": "e14c5505ff25f245bfdd6f8bc901279dabe34a38", "18610": "62a15fa4071d0711b2b97771b981d527c1c4af10", "18620": "a26005a3481b0079f80c4f3edccb25066ede81b9", "18621": "360e7271756b4129e0dcd22ed15755a5fa0b87d0", "18622": "96d321c70e55c619ad6eab40a84e3fa166982a4c", "18623": "184bcd3386a835d058a802d18a8b6d201df4a584", "18624": "0d6cb3c21d1305d75878eee7a470bf463b6754bd", "18625": "a2e599499667b256bc5b8b13a75f0601eccfd432", "18626": "ea17df51e26ab7568f801b3936a45fea8fc76540", "18627": "da9e35883b28c83fcf55635f73c65bef89902f21", "18628": "218389ba3f741cfb32502bf6120bb8fdcade550d", "18629": "353a0f9ebfbd87642d1dd7154f25be0286cdaf93", "2247": "483ca398bd20ae42dd1a9d12f972634b384d560b", "14536": "51f725f7e817df964387b3b68bdf01a07e9fb8cc", "18635": "3b50d94e286087b82f8deaf391235fab66e5d629", "18636": "16c0bbb0e769dbc6a6d105a841c4f6e76214745f", "18637": "a4f9a44e8e348744e2dc95f243c44e9829546d5f", "18638": "d4aaf615a6cf92602ec2f755a073491b7fad6f41", "18639": "9019582c45d17035098941a666a8b6072c13a357", "18640": "6b9318c132f53fd4e2ca588c67c16249b75c3b16", "18641": "555adc2497746986e24e471beba61c40031f3cbf", "18642": "2eef8652fac582978a3828ac307b808c739932ad", "19491": "5761e359b65631db491349a65fc21d0da51dcc0f", "18648": "2073fc28fb0bf1ee4a094f9cda86b7852e951db5", "18649": "4f717551b8e49ecd978bb4f5a985d6f6a96d86e9", "18650": "f7f0c597f34dd7346ed736f3c588b32c35dd1556", "18651": "916d5be8076c761b4270abf8a484b00087f801dc", "18652": "ee7d856b86114cb29ce272dc85a599af8e2d3b1e", "14559": "428c106a051e6adfbac94a39022e8e7d89ef4bdb", "18656": "430b17271343d7db90dca351de89fa1a1a60bb26", "18657": "528ce15557c4816bd17420442b100206222aed5e", "18658": "d78bd7a65f87022bae5021d36c8656c0ea5a7b76", "18659": "8586644429a8c0054a74e645830601419da6613f", "15897": "b98e688c7d483777a21fb46ec46e86b72b90e5a3", "18663": "0aa9efa5593f87f1268e2dab5b55ee0cc4492458", "18670": "0fe97bcbf9b157288417c8a475f763824ba79e41", "14575": "84cad615564175119635abaea8b83b36a6550d7c", "2288": "5353a7c75b16b1f9f6ded1eb0b9e4fd4fc98eeed", "18673": "6db8d19f6bc5a1aeed58d2c53a2c642cefcc3ca7", "18674": "24ab22f75aae1c9b9491c26e6f753814b7d6fd8e", "14719": "825876ca7ee8ac7bea463925399c083d5f190b3e", "18686": "02abc73ef05b2554bf11e8ba8358ff36e302c6f0", "18687": "ce8e05dfa0dcb7d7b1a15d7d04f70834b17dbfa6", "18688": "6a5c34c650a4f38025ea860ecadcd7aeb5e10785", "18689": "11c0d284c60775e134b9c85a5ebd6656c7ec6626", "18690": "c6366f5c15acee213bad0d9f7a15ad69d4445a64", "10501": "12248ffc942acf3a224922495102462c6999c804", "19990": "aad77394b14f1997786850e6110154d4c78faffd", "15405": "1bee0357a97c2c3d79adcd5f120773d7627baca0", "19901": "d40446044fc240f4ec6904d12a7821f0091f3b29", "15899": "062f6f118fe4ea439ae255a8ff886a532e20ecdb", "16164": "44893893db479894a156dccb28c56f7087b32e14", "6439": "7ea6bdc9df375bfc4d239e7948f48fd2099df3ef", "3791": "3a940300dc55c58dd5f1d84d6e3a0fcd27f1d310", "18739": "8ed92efc65b51a9010bd14e0e666fc722226e50a", "18740": "b930303e111767ccb7ecb29828d33dc555195cb4", "18741": "383d0525831d7301ae4ab26bb8c2d475ee4ab72a", "2358": "4117b4fde3ffbc74a48b01f3a28f1f76b2db05fd", "18745": "274ef6ff9eeb6e0b3dc2c42e494d5c20ad454108", "14650": "6f4e36a0f8c3638fe5dfe7bf68af079a2f034d00", "18747": "2cea659a9a6a88d16e0d1fa698fb61dc6c3ce3d5", "18750": "00ca0f9cafa8528c8835d920ff24c71104690def", "18751": "4c63f3e0672be8345ad2a152f5ba506eefde8312", "18752": "43a558f551555486df3ce495c54157e64113897c", "18753": "da230304097a96d77d0cfd695a66bda6349be853", "18754": "58a59bd606911f11a4f679df18a00cfc25536c30", "18757": "592fd64363659969065896a070459ee701dce627", "18758": "bb32564c3e1a9c40fb117d87c78073ac235d884f", "18759": "dcb8b6a779874663d5cfa8b61d3a2c6896f29a0f", "18760": "8a7eceee59b7b8d0a54012a7528a9b351b96fdc4", "18761": "a092e91f3c6d77c24518dff8fd829a96d26e5007", "14666": "0ac3d98fa000bc4fa33b8a3c74d087f0106c57bb", "18765": "0bc458092c3512883bcd34f0ca0e17e650609c72", "18766": "011b79fbf73b45313b47c08b4be1fc07dcb99365", "18767": "b9ba7085983bd287ef08963bffbb5acf964db041", "18771": "c7385239340050b7643c614f52fb513f19ac0ed4", "18772": "2d4dd508fa7419a39201ad7befb287d0d72378ef", "10585": "605d2fcc308fb33bf5443ff069bf62806786f099", "14682": "07c83eedba7494ff293acd7d800190cc29ebb888", "18781": "2e1ce1a069537b1cef47ef698d1b029bc5f50cc0", "18782": "71cd230f3ce3e29760b31dfcfa391cd2c4371842", "18783": "454ecfc61891be610fbb586a7d946eb61b87f32d", "18784": "fe52d9f29416dd7d19c04ba7d47434b68c411bbd", "18785": "a197837c4067469478b13e491a21b58cb78ed165", "1084": "a0aa6a96d8a2456523d9f407d3f9f936f24dd7c8", "14698": "6bea8275e504a594ac4fee71b5c941fb520c8b1a", "18796": "fcb840349caa1a922b1d15e7a8e1ab05bfeed94e", "18797": "5a04e6ec929dc46f938197484142ca72f2aa1ba2", "18798": "6d031f2b739ac1197cbb81b36cdea5f954d4e065", "18799": "e413c491e090274aad78489cc17a2e29cbd8e269", "18800": "b4b945adad587851d570e950d05a1da75c5dc76c", "14711": "f293d6219dcad0b0f4d572a36d52c8b28f8c7b07", "18808": "ee5e79f75fece9254b716fee6e596f72ebba9a07", "18809": "e50b5fee953472c4cff6ec0df5dfb0875f5a1a2b", "18810": "8af76370a10399b539e93e2533ad7f25d77263c5", "18811": "a23f90142352b6427916292b2b9faa7bb61d07bc", "18812": "e98032db44c95325edec23292be84cebed9af867", "18813": "4a6a9187ce14d84f802c09fdef12dd2bd59e3aa5", "18814": "57347e8c7c2b8742b94903809fc988673681787d", "18815": "b92f85cf1068d9623c86240b7b708cd49f6ada3b", "18816": "b53a1a8197dbce71a5d63d28ad9170059a40ddcb", "18817": "db2066b7d31450aaa87f2efcef492162a3d08309", "18825": "f8727ce4e201994f25b7f9fbcf27916d3066d2f5", "18826": "1a42c70e532ae01c95596d071ab62dc535e2bac9", "18827": "e9aee5b5e921a1127e1d2cc57db761840675005b", "18828": "731ac60627257f94e9881cea34839d7a34899ada", "14733": "975a440b08cce771e286de86706fa213d6479d45", "16109": "c277cd76416d4e930b1f05da873b9eaf101139da", "18839": "cc712c9e4325a6ec88afceb30b0142900bc18262", "18840": "84cc0fb71393b685a28afc6bfe323a782296e455", "18841": "97b612f0f95e4650778d12f20d5943efde5f8392", "18842": "e538182203fc243e0fe964883c1e53566bc93058", "18843": "0ab8eb26817191bb88b6fa45b02443c4aba04326", "14750": "7dd451d881964d958acbd078e8dba505906b01bf", "14765": "6eb705f5350a0eeffd9e7663d7b4bf54acb4d6af", "18863": "34e8d52295d4403670196dcdc8b6e0f29a30411b", "18864": "295c2781049ee29952d4e2a13fb516b1d5cd9c2a", "18865": "9f17a0744440d95f56a08f2469827d0fa14d2657", "18866": "7a6ecf71e0846c0f39864da8fad90041559b06f0", "18867": "df5eeece8ed28462832ee6e762192629c446670c", "16798": "78147e9c84fb55a67af382a2d3a090e6b0828532", "18872": "f0b2ff3c0397795c1dca976c3585eb03f1edc6dd", "18873": "01cb440f2953821418e640d163b138518f16fd50", "14781": "c71f214a7024a3a8d679f8c2eafdd4e870d7c216", "18879": "99df7da9ef5b3b210f3045ee19279808368def28", "15768": "7d9d6d3465d1c102c69d799161ebd9e28540acba", "18893": "3625e1e2fa886f4533a68ac839db2749539fec17", "18894": "4f16dff3d9cdcd9c4465a02df773885f8862035e", "18901": "6e932f8d5621c26ed939adbdc740e0aa4524dab6", "18902": "280781aee7b2c689a0f807ae939b59e83911d469", "18904": "3e01c384b532e32872053bcd71e627c69ec61cb3", "18905": "e405a105a717f55874ef8d5b4cbcdae0b8a21236", "18908": "20ae4543c1d8838f52229830bfae0cc8626801bb", "14813": "4c65d5fc79ea435bc4e47d8af2914cba324117bd", "3494": "1c24700c3ba74419988e74319fd46e1f937c1f4d", "14824": "4515be9ca7c20783cf8ca00da3da168e00ed315f", "2539": "9d0949396a8533d9fb9b0a6d0fb90a9f0ac16b23", "14829": "79b181196e897ec9bdf9771b2d9e4227721f6e1c", "18926": "e5c90e5e355077c4ee5245a4a72833f4e8af72b9", "20221": "73d8f96bac5bb0bc58eb6f69d47ea4329b07c6ae", "18929": "94ce05d1bcc3c99e992c48cc99d0fd2726f43102", "18930": "dc0674d66c1e8cd1917a6ec28f0b5a6d3e23c5e6", "18931": "f2839fe813391140a1e08d3c5f71c04bbaf5ab56", "18932": "bea9da2ee55e741a850680f1fcb211f5ebeb4fa1", "18933": "d865e5213515cef6344f16f4c77386be9ce8f223", "2555": "dfd7447e47562a941bb355af51c475823520f9e3", "14845": "64d7670d99a11ec4e263da73f2bb1335cb4290d3", "16128": "a0a0f5a691e7b5f949e21034df69339e092a6a1d", "18948": "209e7f5e2d3d63a043e6d9a99af77267d62761e2", "18949": "1f02bf240c3d0d3da338af868d056bfc169b28c2", "18950": "dc3323eb32d883843b49615977e139a41546cc21", "18951": "f1cee69a455a3bfbac29685d26e5e73cafe15b9e", "6664": "b96ab6bddd5f2e84bd88a0659c4d98154819cffc", "14861": "48fc9d613323ada9702a7d5c78c23eb0e8cae8a8", "18962": "448c9bc32ef49a40bef5f4c0f7d0fc055cd0d4a7", "18963": "39229473bc025b1c4fedc79962a5089949c5a296", "18964": "d53a4cc856e7fbdfd7d0db75e8e3416b0640ce98", "18965": "a215a7b7a4661b657969ecd5865609a7579de7e7", "18966": "ee283faee006abf5b879d37fe17c2db4e0fa51fd", "6679": "015e926a0d6d0b3b4fca0099dee2ca9050af4804", "18969": "0e7cf4814ae8f85dc90ed6d8e24f0459be0b75e3", "2479": "cab9cab52fbdfd3305b7416d4774d10cfb52efcc", "14877": "bf8194a74c84c0ba3976d40cc8380df76aa32cdb", "16133": "a2e54006218c824d562e43ac5092e30600f6e863", "18977": "2712c8ff8d46b49868ec8704fb915cfbd9cf5c7a", "16134": "29a9f63a567e3a28abca547f3fad07c35860c786", "18982": "30c1290610c65d53bcdd1665be3104104ca27eb2", "10793": "8dfbe09c1443334fc3036465712195a36c773f4b", "18986": "15f70464580d9e6223a63278117b8baaa3261c22", "18987": "440469b806a169ba7467c36ff7c565797b87a0fd", "18988": "580a0941475d856a0cde2df4ef3472404706cbba", "14893": "e8840725447859531ddcc4b878266f2043fb6465", "3360": "5f5df2aa34f027d3fc83abb19cf7840ababd4557", "16136": "a441d239e159fe67915dfdcf69b347841ffa60d3", "16137": "cd477c838ffff6032128afdf591649b225086a63", "19001": "03658288ce478b2170819fccd8e5bdb48eceb2ce", "19002": "7653a6b43a8a302bc1d88903c8c99730a00bcc80", "19004": "87c643364acde61dac9cc1c0828f7f3056facb43", "19005": "5a91c5330d7d79e6f3fd6aa4d1a224d0ea8e2b44", "19006": "dc8d35aa53d496b651f5e1ab4cb2604e9f7236c7", "19010": "5411421799d14a12dd1762ae618c34eab469411d", "19011": "cfacd4c0167b16d7fc65ed93929de3ca23fbeb42", "2628": "f750485c264a6fdf1a69c9374673fa95c8373860", "19014": "fa547d83cc566e77ba54c1b8fe16eaba7be718e2", "20236": "454b8c5cdcea0cbba981d607293b990cc704f3a1", "19019": "5b6b346b9db57b610df2965f60753473ef16e16f", "19021": "5b0610b875476a6f3727d7e9bedb90d370c669b5", "19022": "b45eb265dd88648fb02ebb0fdcfb168364ab664e", "20237": "c07d71d13b21e0b6e22146f0f546f1f8e24a64b3", "14928": "c7300ea9ccf6c8b4eeb5a4ae59dc2419753c9b18", "20238": "e25fd0d8ab10d6cc4dfe0f5808976f7921512c9f", "19033": "92d25f0da6c3b1175047cba8c900e04da68920b8", "16143": "5b99ae2c0b77e7a6fc9c3bb7cbeecd42b6c80bd7", "14941": "e1d54074ce8448bfcc69dc08d8a800ef9ef918ff", "20240": "c57f206360108c327d8256e716080fb1a2523fd8", "16827": "04778805dd595e37e33f6ef0e02d9337a1154e09", "10853": "017adeaa4b70d63fe6c788db457dc9d31562f4d6", "16145": "e1dabf37645f0fcabeed1d845a0ada7b32415606", "19876": "e31b4f46df6ab1182c16183f48df76fb4beaca0f", "14957": "3fe85afef47e9e079a0fa24f826bb6faaa2341d5", "16147": "6779ac0efb166052deced47f23e18196808439ed", "20244": "e0c41f79104c5bc61952c9a14f1883cd5bda53f7", "14973": "23889d3ec8396925269210d6d5782574e61769bd", "20245": "047d32d20640898978dbf6d9855cd6fecbbcf0d5", "6794": "8c0a34f15f8a87def3f7ad6ebdac052de44669f2", "16151": "79498e399f271c530c658484cdf42f5ffe538ed8", "14989": "24a2155eec4a24242cdecd9ddd7e61d02d8d6aeb", "16184": "08158c076d89177a962d00e4851649f1ef76d12f", "20248": "f8b4c57ad1e4f1a105905c53ffcf40a5dc5080c3", "15775": "28622c5c120d73c2cb4d2292bc0837534b4e9dfe", "16153": "cc7abd9ee19912c165cfd8d08f95e8e3f4450ecd", "15005": "84bbeae9f10d63fcd546c632649828621a80f64d", "15639": "5b88d2f4c721299b44802b21f03fe08f28576fc7", "19106": "baad046d15093ef1503e77f4f666752dfbf42397", "19107": "53899874f8c33bf00b68d270beee2640078f3cd6", "17685": "8d5032a8c7b00d47fe5d0886145e1ad9dd17e0d3", "19109": "8221ee91d15b01a190d73ea10d47af81de296c90", "19110": "91802fb0accde031c3b6aca040a8b533a193fef6", "19111": "7f753892eb6b29aaa62176cb9f00ad84c092c09a", "19112": "9f29f8824f8c0b7462ce657b60f35d4513c77c1f", "20252": "78ba7fcecd46b039739f13bb04bf6147463ea376", "19114": "c994e98c0e216622ad025c0c9e28421a4a3ee6af", "19115": "f6c7f6be80c83ad9f4680fc7bcd5bf9e5b426d92", "15021": "8daf677b04b6797e7db894b85da7f6e5a4d356c5", "19121": "33ca356ec63827acf09c34c296e64f28fd93dbaa", "19122": "250dd5f7336196ac6e93744b671edddb449bd9cc", "19123": "1d18430d0b55b260ab54bfaea7b9a91e3c5382ee", "19124": "b7ee8292b465aa507a37777443efbaecb07b3f57", "19125": "2f6d682a06573e0aab64ae90eeaba216f224db12", "15032": "27b0ba70c7a62965af1f669f91162f01a2c7e2f5", "15037": "470c3276479925a198f38f9c0aacd745ef3a64bd", "20222": "9a42cbe85461c28417a5130bc80b035044c5575a", "19135": "4974758cf59e21b19fbf3b0943d896ebb223db0c", "19136": "d564c42d3dbf82aa0e9fd013466d07c2db86484b", "19137": "4efc8197e825c12b83c584902d4b93ac944f3def", "19138": "1e658f717de4b8342bcd1abe27cf018a4831d1ba", "19139": "7b0fa8e94e22aa4a491fa574bc56f8ca791f7608", "17526": "8ddc0fd801d794fcd7735816790dff66d1c678e2", "19146": "ca85a41242af245b32f6c62580b072d1685342d4", "19147": "66e9cfe86497e5e848b56e0b89c4eb0a3e8c89ec", "10956": "d8ab3415373ea42713c096a97c3d9ed5c9cb82ee", "15053": "35109568489401dd2172fb76fd38c1c212355227", "19150": "41681c89df25e78d072c862feabe24ec715eed54", "14797": "a19b0d86105a52a86e3cac4a72bb7580456faa2c", "19156": "49b51b81f8e1eec2ae6740919ba14fc143f8ac69", "19157": "66fb79853cc699ec45feee097191c58de042cf3d", "19158": "6077b886045c5fb8d16d88d85ad2f0f19be19255", "17529": "70468dfaacf6ae3d62d1ebd29d66826c6d797e27", "19160": "3675c29a7bf8714d3f83d1c6a854325702f81969", "19161": "216986d4691297d5cfec33b5c62be7890b9a54d7", "16905": "44bbd5a4d33643c9270bbefd7419f45aecaa4667", "15069": "fe15466cff9184e38ecee16639c1eefaa45c3c92", "17531": "c8fcfcb6035d2bd76e4e83e9eabf4cfd86f74377", "16166": "1977362f2c2949811b30268bb98e7fb52f49b8cc", "6887": "5544b896540bac844d5e8fd6cb27e0a3d305495d", "19178": "c230f297c279bcac536f4689a30f1894d0278d06", "19179": "14c33b0e531ba955ae20a6e37750261133e5391e", "19180": "88aebed582f5ae898aa78e8b3491c212e92c5d13", "19181": "1c37ce94d88021a03a6ada2e2cfea919bb350f7e", "19182": "f6cf7d9e2606e82fd3934e1dac8119c43f5ee643", "19183": "ff69f45f10fdd08dc901b2f671094974194fa693", "19184": "5d134ec1a9ab118abbd16157bd161783547117e6", "20264": "cf25c5cd3ab1f647f780167df622c74b737fa8f5", "19187": "b36e06c704fac35224d984102bb0db50ef1a20f9", "19188": "71332c4f7b5c6f496e4e5dab75cf1e33c2400d74", "19189": "95f73c3dab1eb472d27121c09723b8abeab9eeb7", "19190": "bab279ab76125e2622cc8dc9a8e6521e88a5a1d4", "19191": "0bb3772219c5532f4c9703e4e4f2a2e844ee55d3", "19192": "8c58817bd0eaca46d7c0d0c975715ad37fe43710", "19193": "aa3d56effe18031e6377a0714a145287445a4b89", "19194": "3e0358d869f8a76b3223e8bb313a92edbaa369db", "15101": "771e36c32f922c6a0c4a147f08fef32a011d534f", "19199": "d7bf6f2cc870c6ba5e465307c5e8271cbaab8af7", "19200": "0c593ae9b6c6b843026809ced54251014688c123", "19201": "1cd077a3077352d63c1226d554db1e46cb9d2c1a", "19202": "0d2cd533bf93260d866dc8ac3479ba3797ac6a14", "19203": "fc7bc3f74d1f5702bf66c519ad190126538a8f5b", "19204": "a71c1216f4b89884f6bcb631b84873240a38e3df", "19205": "9f62f5e6cbc153cda48b6e8b3c768916c80ad968", "19206": "195cbef27ffc2ce59bb65083801ffc6c773a1967", "19207": "6b31abdbad403255ec995603daa42ccbffec7543", "19208": "159772d0c9d49977d4b7f871c62c26e06890143a", "15117": "fb7af6e257d5ca162487ea417eae675e3edbe271", "16173": "4af9a8b6d9e164301a4183ae4e2c93e645b04ec1", "19217": "52a2bb490556a86c5f756465320c18977dbe1c36", "19218": "8b4b38fd7995cb59b0595f2d06cb4b984b5886a9", "19219": "1d86861681d0d4046f3d391f641c8bdfd86eb61d", "19220": "9fa063ea398b44d20f16c12ca04e533c9ca6223a", "19221": "9ed49eb936f2dcbe824a91fa1339647f052f73f3", "8005": "5a750ce760fbdcbc70f566bd52b0a13ca3cb77f2", "7983": "16052e501adc3dedec3bf8cf65a7ea24300de1b1", "2844": "00a3abbde4d1d15515393d195591996b92aa7ba7", "15133": "156bfd2ed5db2837fe740ec2934a782f56e99864", "19230": "73801ab9cc0dee4637e52f16e571bba28e0f21c6", "19231": "24a50fc3028ff52ab37ea38911f34c05a746181c", "19232": "459ebb2ad309938e9e68ae79e3bdb312efac0ca2", "19233": "aa1549f7fd8ce81bf23296bf92fe9713aa8d6e20", "11042": "f1b270fcf5d505eebe4bf964f0541d6a43c3560e", "19235": "5a9f4521fa2e33cfbdaa48616471ab4d16fc3a62", "19236": "6cfa23e68f62069c4f16be80b80e6d1596a90234", "19237": "5b61eafbbf6fefe4c06eeb7b269838a2185d98ec", "19238": "ab55d05e7a12ebbccfd71511d36efa075fcfa0dc", "19239": "336b8d62e3ba184f5e9a857187f9b06e83092e2b", "15149": "1dab800b412be3613e8f666eb1be88458b631312", "17544": "44ccca1f3c27795322b979cf6e5dbd49422b5173", "17545": "24930465344008bc3b7e3dbcd31e66b37b3034d4", "19256": "70bc919316db6be6be8cce1a53dd54d34f25ff98", "19257": "6c5057258b332add112727fe40f1197ff09749d5", "19258": "aeff38d3301d4d31650f6624304259d0dfdbd69b", "19259": "41b2b18b94ade34a172483cf8307ce16bbbfc7c1", "19260": "02a97c0a150377fab02fa22580d232c8242b5baa", "15165": "48749ce4a774fba73ea38501cd99820537549d5a", "16181": "62dd2d3e10d2b5beb93d83b5027fbe31d203a4b8", "20278": "9413591e3e43c5b3e653f129029dea032e2efda6", "19270": "0efbbc29e58bb46835b8f0cd642c87b996fa40a9", "19271": "c4ac0d68b2418e261f2fd8f3a9f8eca0d5e20474", "19272": "fce9ccfa575a4b3c88c0313f3969e1501fedf65d", "19273": "03244659485a1d5fab229bbb0a083638fac1336c", "19274": "43c4dcd45a50de04658dc78c7f2e5c62eaf6b5d2", "20279": "f8225bc68bd3326fa3c5191852ff776d1e78b6fd", "15180": "f49f9058d152efc9a309e01541762407e16dc953", "19873": "0bf9f146f208e5df2e192569c3e34149a9317b08", "15196": "dbc1654fb1604b99c1b4fe31a26b5548ea623565", "19301": "091cfbb053c8522acd4f851f6a93626751e77dbb", "19302": "c5af28263f7eda1bcb9c15c238141727507c8e46", "19303": "8f3aa2be78dd42fc43de6106c372c45040f025e0", "19304": "d659e7d3df1576b265037f596086b4dfc3a51d70", "19305": "945445d84daa07664dd3691142d23356a5aff70a", "19307": "71efe61b457892dbd7dce5ebba5d1cd364a8ebbd", "15212": "c25fbde09272f369f280212e5216441d5975687c", "19309": "48dad14953c26230fa297cfabe1d57f15b736123", "19310": "f67aa133d0332a8a1290aa775db582558163204f", "19311": "e76c90ed99efe6b2b827b10c01d759f85ece8045", "8680": "d10a658673b7d2c2e7a346461c9a4bfc5233d7e1", "15646": "b2b5dc32e24cfa5ab1c37d09c4e505d4a82d171c", "17555": "ef019faa06f762c8c203985a11108731384b2dae", "15228": "c3c60f0d7a782cd429e3d7115a99cdc068a6d528", "19330": "afc2c86c7d4df06ce4b82585ec93d6925b66e206", "19331": "268150f191884a554359de512ad6330977501796", "19332": "00391586e86f990804f5034c6f9894575080b4b0", "19333": "db051b94d50cec2a5f2a160b36d67716c47839c7", "19334": "479ddcb63131ed48862c2ebffb8a94411f389d83", "2951": "0600425d541a26587204b33f2bdf7b738c032c51", "15242": "73222392f389f918272a9d96c5f623f0b13966eb", "15245": "cd35d22a04e22aa6a0ca6a98633fbe654f087960", "18925": "8edf972fa07aa3b761756aba87c08fea98499687", "11156": "d5963dcf31c9fe8529b704efd72306a34eb77953", "15261": "8daf9a7e45344dc5a247410e037dccb41b97a3db", "16193": "bc88240d9cfc35675a01267cde33442adc290b7e", "20012": "3e90d436e82ffafb9df287ebd9e5052387a251c0", "19370": "c6b09e418873003c6913d3ae3b60e496a44c3d59", "19371": "8730ea9ee3c76382525148b56f3b822f1194b728", "19372": "3ae422930836192aa285649e58b9a3dffbf843cc", "15277": "f53d38b94d963cff081b4fe0a1e7242e8d5eb221", "19374": "d106e9975100cd0f2080d7b1a6111f20fb64f906", "17565": "d15c104d0596454c289ba48906a397be45dda959", "3912": "e1b6e44bed02f47f59bf2d71c836f42f6e130dea", "11188": "18ea1d856d45c87fe18a41d1a267ede46e10880e", "19383": "e2fb47badb6ea386ca9c468e19714dcf8c78d788", "19384": "b9d2700a548d8dcdd3e97f67c86e2f4f8f8f4cec", "19386": "dc91f4cb03208889b98dc29c1a1fe46b979e81c7", "19387": "88ca968ff95583678f257bcad08c821e9f0f82c7", "15293": "064f57fcfacaab7d45c7597552017d91ec3056a4", "19390": "393d0aa1dc1b2b0cd478cbded6fb13e530589c4e", "19391": "7c842b0312064bbc6bf1201ba6dbb774da90ba0d", "19392": "c4994ca56b5d6af35643bd9f20d39b090acbe5ff", "19393": "ca842cc4bab2aa9d2b48c051a597d860f38345d8", "19394": "4bf3a0e11d2e98afc9ee76dbe54a667410d0220e", "19396": "be406f316d7aa27d565894059fc609329f055972", "19397": "4e7f0747944a920278791d051ec8e587a513da2b", "19398": "fbd39d9a708b6a1b41372c7372f0a238a5a86c43", "19399": "f13859dd3f5d89f3e45ecc67f719793326099ada", "19400": "f57bd72310207b36e96604056f01cb77f0640b3b", "19401": "6bd17055ee2b6fefc77029ef082c29dee5eb03ac", "19402": "2897fca7f7c3febd13a4558827be29689d087aea", "19403": "caf462c2a7699daf4b149d49f5aeaff822700113", "15309": "f0bd908336a260cafa9d83c8244dd1a0a056f72d", "19406": "9744a4de1952188114587bc43cc797448390305f", "19407": "ea8c9bf5167c6ae3740f56b9fe2ba60500c96ffb", "19408": "46a31c9944a2f6c25282f65a8bf8247abe848bc9", "19409": "decc8ce5601c32dc2313f0d2b1d611164262cae9", "19410": "d56db9d6a20b063ce27b6e8c898f0d3b5db2e175", "19411": "3f1e5940e3929577f094ea2708f94ee184e7a336", "19412": "021cbae52061b660b2251d6c4dbbfa6d2a246325", "7125": "22f04f7906b8f533cd59541c2a88788388719c8b", "19414": "bad02e8875e11e03d438d66e38785203549a0b87", "19415": "d46d2a5ea900c59439dff58942e79ea8b39e918d", "19416": "e2b20686464b5990594b079e15449766f85dd85a", "19417": "3fe28fcb6f4292e7d6c01ea78d6a2a21b0bac16a", "19418": "7c4efe09b7803967f75656f856138c732a888884", "19419": "c1a81fe512604ff1b241e688d145dc7628558241", "19420": "fdc4db25a9988a7b595a3756760d05a6c177123d", "15325": "8ab8ad027a98b3219d9bbdb1cc39f7e577deed55", "15786": "1d0e6a151668ffde51270c03274b7e6f529a6132", "19428": "f160c7d7c63c11f8807ddd1e653a95821e82269d", "19429": "10a353b5ef2d9436a276c95d5ae58d778cd2a2a9", "19430": "cef5e8a1a463351b8742ed7baff7e09b8be42eaa", "19878": "f2bcb9f0060d030085cdbaeeb638664c6f73e636", "19432": "453fa85a8b88ca22c7b878a3fcf97e068f11b6c4", "19433": "e2bf1ff491dbdabce1590506d2b1dafca34db82e", "19434": "ff40c2f74abecd3e898eae79274b24b4745eaa0e", "19435": "6d3565a5181b3d0fb8342e69dd1d21a98ac3d380", "15341": "669973aafdcf239c2e657601231879659ee3249c", "3055": "3c1cc3504caa08d1105a67690be196002c5f8dae", "19440": "02b5d9f509cd20dcaf08d65844f270439767dbb4", "19441": "57a6f44868a0400dff9c62cfc7fa12fc631c4f05", "19442": "8ce64b73fa33d85fb2c900f0a6e2b6c382e49500", "19443": "5a15a37dfec62678788aba6e0d4b0dc77fe43549", "19444": "b99f8bc3ce4b0d5aa71e2caf8db5e6dc4dbc42de", "19445": "98f46f7f08e9f15374fd840507438cb237313a9e", "19446": "0bf62b31e431faa102caa926ca1ff148ede53ec9", "19447": "17a6bc56e5ab6ad3dab12d3a8b20ed69a5830b6f", "19448": "be26f6dc467a92108132b309d9fe9443bce43ef8", "19449": "9f4357b40a3d844aeff53e7cccb627277275ab73", "19450": "512830b46e678a1c6bd86cc60f54d74ff75792db", "19452": "2bbe418409d88f60daeb9e12e738cf8c9633eccc", "19453": "08f92c4c86fbb4e03d030f24ea66402f6deee6df", "19454": "ccde0a8bcf25285160a67847057ebe8847f71a3f", "19455": "a07d68582cdc49daf3e6a14a1e1fd7064670d696", "19456": "7e6ad8634ef6858664d3c9b48bb1942f23ad8890", "19457": "aa05e542bc47140123157c5854cac498c3541a8c", "19458": "bd3c001ca668906c0956abd76cc48318c9bc95ea", "19459": "e984947ab42b2c95c5acbe37cf2e24786a51980d", "19460": "1dcfc5fed3645627642a4e5c7453bdaf2809fca3", "19461": "f78790f5932e0648da4edecffbb1aeceef35432a", "19462": "f4458c18287288562b21adece524fc1b046e9724", "19465": "2d47349122a8baf61d7b33d190d0d1d54505c776", "19466": "518b237ef515a250abf5ba403563721754d39c05", "19468": "01e7872b018f8ceb1c5d1217caf03d5ba4da3602", "15373": "a54efdd3f8ff4c9d9248c71e87679af29c856806", "15378": "a31c96d34d00dc757908b564dc93991e867d83e2", "19475": "12bb6d0536b947f74b66ebe18b5f451bfdd7453f", "19476": "a49be7f4ea4773af5b801ebd9504a20e5b40b245", "19477": "853cd7031ff98737b9a50404c4a181dcda67a0be", "19478": "597f9f31639eeb5724e49bec602e15b9bf8be092", "1194": "da3e95da95e1e07acc535b8e734b9b80a0972609", "19480": "8972ddf13f6d0ba827f99a63d4261944baf3f29f", "19481": "14eac280e1b7516714d117e65b45023dee7feee7", "19482": "4b937ff59127bf0edec8e07a667fa222bf2e3b4e", "19483": "6a745d826d9d5f5f46e208b0dad4d4ce0524defe", "19484": "2fa0835737a0e3e111e893d30ed2f25b7249fd4b", "15389": "b8f6556cad57e60a4a522ff6574003b40c06f688", "19488": "e2c0b120eb19ecc93a70f9a9c3cb51417cb55d1f", "19489": "0a4665a5fe716c28ec2e756611b64efd32d63148", "19490": "fa12b9ecbea36a504249e74579ee2124f98bcc3f", "19880": "cd057c7a3675354ffdf6fbd1939fa84b6c06ded2", "19492": "539c54f30736b4163b70f1ba903aee7a4243ab1f", "19498": "14b68eabb4b7750c04ccd3ed17247504aceae35a", "19499": "8a8a0830f5a021f7c8d272fabdfa699b4502edd3", "19500": "c8aae3540e4d22d2581e66843740fba10e9ea0b1", "19501": "83eb2428ceb6257042173582f3f436c2c887aa69", "19502": "0c4113fa0906273007cc12a4bcadff85d943dc84", "18952": "b7294dd3ec47dffa50f3c8bdf89aa8a01f4494f2", "17587": "a5c02d5c4225a90cda8ed7f328306bd9754d0f93", "19510": "69a2c54ef4c3df06104a0528b2d59a5b7521b23f", "19511": "95415406d191eb5b0886ae107a7d01f0ef39b019", "19512": "37a224d216e8d49a05681e2c87482bd8e67385fc", "19514": "602eda47da1f560252ba4bf386875a68e561452c", "19515": "95f8dca47723192ddeed5a2f198d0521c687c9aa", "19516": "2b16e2e6c5a298396727fc2e66a60edf1eb13bf9", "15421": "42e2a87f2a8848795238de1259a3daa5612e393d", "15437": "6dcf2ed2706b00020f6a3be5530ff8dc121ba989", "11353": "5dc8009c401bdf29564c73d9abfcbd7928fdec50", "15450": "e905f9ef7e28116e723b412593a4571aa78d187e", "15453": "6614e266bca32771c761e904367eff10dd4c8979", "3170": "092fa15d220eeeccf9da8b16b452b000d9378bdb", "17595": "1a9937dd6c43eec3f51d985b6d81145994999d6a", "15469": "b0a51df89e40691608bb8d9aa80f2d7e4861b9e1", "15791": "13b57cd6ace5b0288431ec13e54c1066e952adea", "19870": "85c3f82dff73ede6d5d961611518e007c8ba0098", "19883": "2b67692bee7a9d7315eac93eca1a01950e2813a9", "19583": "1700680381bdbfbc1abe9774f96881801b24d6ca", "10777": "3834259a93ab0b5540fe10fb7f77be647165c573", "926": "cdc607c8ebd05419c0c446298a89814eac817459", "15529": "92d07992e826808cd56f0bd8fec083b510ca402d", "7344": "efb7b0d3c56df52fc77f8618467eee5b62e8cbe0", "3955": "6d9bd5a6374f1d6b4c18d3d53fc0413c82a16b49", "15545": "7b106e44286187f6b8fed2d6124c8b3c33a922e9", "3262": "fde270b20861fbf36d3063d504fb299d0b58695b", "3266": "a1d768829015796d16486cbc1e99020348901e25", "15930": "42ed4f143f8b0b386c90df9fa8a55d0f2e5a857c", "15561": "50a62c17c16d24b8a20be9ef281a86bf589144f2", "3282": "b31610d5ef4a85d029b2c2def56b9e67992cc8e8", "9423": "20ba83d241dd3aaa84c98daa7c9821fd313c4f22", "15811": "f4330611ff5ac1cbb4a89c4a7dab3d0900f9e64a", "15587": "2814061730893bc8122caa4e01197c699da352e6", "15599": "ceaf85233d434a226b23f891465b4abfdc602e46", "15601": "18a428da81f7fe0f41f8ec78f03a385b731bb6a3", "15603": "d915c7ec5ded5cae5292d8df1feb135432648718", "15606": "b72519e45bbfe7387e0c576c9315475aace69a2b", "15610": "466e4253ae466aaa422cc3f3b3a4143d1466158c", "15613": "3caf858b0ab0dd62126be7ca1021d71409b70d98", "15932": "46856c3936540a47df719d10a7699eb35673e4a4", "15617": "b7e7fd3f17d4d2a2f87b9d169cf87143f04e5d33", "15621": "3ff845b4e81d4dde403c29908f5a9bbfe4a87788", "15622": "125c414389320dc67ecaffddc65878c01822064e", "15623": "09d8c22d9f56f4a067880a28fbb1235bcf0a1e49", "15624": "8b5e3d65bbc52b155efdc1cfcf3dc10e50691742", "15625": "196eb8e5c05952574dcdd5d0fb4d0a73e4bd6e91", "15626": "520f87b95639e4fc0344a6c6b9851b5cc5a1376b", "15627": "c38f2822786a81bc0820a0469a3163193ef688c3", "15628": "25e057654f9b9d4196ebf02961867ae26fb93547", "15629": "8a98f5ed541c87a9bf101c9331bd6cfa8f007cc9", "15630": "18f7b1ccee1c723cac7f23a16099d08c17ed0a91", "15631": "9c9d5fb64de1dda51c6ed4874bcec83dbb9e35ae", "15632": "1265c27f4bbd06e1bb75f846139a164bdadd5b31", "15633": "f6f5ce5f9ce2afc3b6f55a3228b93024b121b88f", "15634": "aade74a13bb8105328a0997eeb910a96080fac04", "15635": "65a0e642e1270791e6586c967758b362b865b6a8", "15636": "18c4f88526712c5ab97253030e1b0ad9c555c9ef", "15637": "664348c440ccb4dab3d4c420d6aaee7c688c9b0e", "15638": "85740a5b6285e529931aab7a205468e57d023b7f", "15660": "500cd0f1935d89c64d93f42cbf373a1209870600", "15640": "5e776fb6cf4e7b3ae0f36b480e1f4e5da154b313", "15641": "794e06032a34c62a2f8757e7d92820192301fa1e", "15642": "6ae92a8b68ec792526c3cc7eb1a4bd75663e7151", "15643": "06fc667f7a26f136b11f33a658124bf64cd57ab4", "15644": "6b729ddd740b6d2efb739757180dbbbef9b092c7", "15645": "7c27b9d99a945bd228c173eaac8042ca2f70bb72", "11550": "9772a5b3890ebe5473dda012b302aa05f67b78a8", "15647": "9462379038c69885cf74869fff3e97c1a6d70394", "15648": "e5fd3e023c52c6756fa83604c5909cc102808fdc", "3361": "5d90f7d0e7e9bb53e55fdb7b70f972aa502004ed", "15650": "92e1cc829181f9a4cea47f6a81cec986e8ef2707", "17627": "90c2237677975885a42f0d38ff59ed0f78928e7d", "15652": "04de578b173c6901e75d24647c49d6a697ceec4b", "15653": "15db50bbdbce91608c9c4c0bc1398c41a619a9be", "15654": "cc5d20f50c059f02472b029f4455b2609620374e", "15655": "7d0a98e9bfb6c59d5f1738927732ddb80013b581", "15656": "1c3752334dcec4666bb7e6d51fb718a7674849ed", "15657": "8d197ba63128a4cdbbb8627e48e7f1b4f150330c", "15658": "5cc1025a78ba316ea058ad6ea70a2104cc05345a", "15659": "f6edaeffb3de7f9787d049c67d90bf83442864bb", "11564": "c91bdbadfdbf9f60879ead8dd86bd1e72ca18ccf", "15661": "e9e434d9ab522496ab1a6c72dbdd057c9c9e5386", "15662": "d8cd9ca5ac96b4edbb8f47c6b734c8f2513d5f01", "17629": "cd04471023d7b02dfcc168e5bdfcf1d7f960e8aa", "15664": "7be9db9c2ca46099723500af88850c2ef2eef0ce", "3393": "c91f6d1f62d02a65af78651f61f8db9a62c58b1b", "3403": "d8a0b4fd0d39dcac4fb7a2297bf25cc442e12729", "15697": "18f929fa83d2d1f335f8ccf325c05a6ce314b94d", "15699": "3a7f956c30528736beaae5784f509a76d892e229", "3412": "a901af2cdfe411d6aa9f9b1f6fa3223738f3e514", "15701": "3be2de63e4c6cfbd04671f86d07869dfc984e9ed", "15702": "a5477b760d939a1f62ab5d38c75bf9d802a2bcf3", "15703": "a43c1576ce3d94bc82f7cdd63531280ced5a9fa0", "15704": "3e20eab7ad5639810b4824790cd559367b326b0b", "15705": "f4b12d8488434d5f9a45fba1cbe7ad5a77c776ff", "15706": "114feb9290c684b5e5b3a2456307f9116372e89f", "15707": "6a85e88bee498e7e218f0eeb766f15b9d78e9eaa", "15708": "d236f31c7cfc740549b363926580ec0c94559b25", "15709": "55af1ab626baf62dbbc00c2521c20be29b819a06", "15710": "a9421af1aac906cc38d025ed5db4a2b55cb8b9bc", "15711": "9d13227345882daaa90f03078c09a9b44a18ce72", "15712": "63536f4a80a1f1f03732411d015910c55a1f9290", "15713": "25384ba459ba7de9fb9d36821f0a4ae239cc40b2", "15714": "4ca9fcd73225af9cb1dc2acc99bb494dc5f8926a", "15715": "6000c5b9624fdd8925099f215eba282bfbef87ce", "15716": "a587d568d213c62307a72d98d6913239f55844e8", "15717": "6858d0f6caa60c98acc4b6c3eaa6cd0309aedca6", "15718": "ad24759871ea43131711cfce1e5fc69c06d82956", "15719": "5f2b96bb637f6ddeec169c5ef8ad20013a03c853", "15720": "6cee09ebfd2e8fb15f3e225bd9770852a6a533d1", "15721": "80e40f81d78ade9921607a092a00b83f9d34cfd3", "15722": "61f0c5ce2eae8a548e4729ee5cc8a8633faa8316", "15723": "0e47b280ae6159dbc8817f3c7bd3e296af480c5d", "15724": "d7bf220c2daeaf86ba2e2026b4fe900d441720d8", "15725": "794fd789603e06e86456375f92489ae4de92a99a", "15727": "4c498f8451fe4c491a6f38ed9e35da3d3ab6b9b8", "15728": "7500218947bffd4915832e9037d9f48991e53ca3", "15729": "3955261c04d5b838488a45fe7b186399bcdca137", "15730": "96168ef698ac8bbccba251258ee66958359b11bf", "15731": "2cd85ca748f62d7430b30e2d9ddd036e972cc64e", "15732": "8e3d8315d63f61c1cc7a0ea9ad24cdd63b63f6b8", "15733": "4f04d0be1fe22dabaff6c0eeb6162bffb763af46", "15734": "1212fe034b7302f40bf253aedd9e3989514eeb52", "15735": "3524edb82e7945998876591813b7e77fe620ce36", "15736": "53ae390f442e745503745e5fa8ed7b06b72fd102", "15737": "01a8be3578e9d0b2a66b8318c5477e3e6cfb75f2", "15738": "148e038bfaf2a3893b52e28b6469cf5984eec794", "15739": "9c096d29a1e9a68b8151de4896b0d9684383821a", "15740": "7ffe7fc21f3dc4ca444de9c83dbf61313b6986e2", "15741": "1d1c03ef807b5ea3cd589b60ea578c88a0c1227c", "15742": "745c01265e31afb9048fe461dfd8c88ad2606702", "15743": "cbd0354d024d6d45c67fceab69f908eb51339f70", "15744": "692b5eeeff9b8e8c750f3e64db0c39dc149a73e8", "15745": "ea487fc9b197285f25b066450c46fc456db09e2a", "15746": "ec927a47e472eebb5ba7086dcc15f3dda1c832cd", "15747": "0bd871fb9634e8b73efcc1aeabb93961fbc43d53", "15748": "dc54b6bbfd1da0947f3b66d4919e4b80e3207bce", "15749": "81f8acef11e8d1e2f0ea78a7b57ee04bef1f6038", "15750": "7b9a57fc99fcd63c55b041ea7c76f5c390c12aa0", "15751": "fcb0263762a31724ba6db39bf1564569dda068a0", "15752": "9e7666dae3b3b10d987ce154a51c78bcee6e0728", "15753": "6a5e56dc9402136e74e8c818a6947fd495bcd3b2", "15754": "34210ac4d8c61ec4d695baba24d84bd7a1826af4", "15755": "a1dfb037de79e6982a0e7ccf883e5af11e9cc843", "15756": "01d7be51132b31771ff5b5c7a9c333557a902e8e", "15757": "e5de21a991408b3d3783489989201826af8ada67", "15758": "aead041fece0ef17a81218585329109e17b5deb9", "15759": "1dc93b521f54b0259c77e8079b03c6fae791dd24", "15760": "47e909dc9d619e20b139c43236efde66b52f9d11", "15761": "5a024494fef4f0afaffa85665370f884857e298d", "15762": "dd1852d59e51e28c2f9b589eefa1916ef5d9bdc9", "15763": "af5eafb5905ad9a5eaa43645716cefc684a20813", "15764": "031d7a9fe24f2799454de34a1e595ae4fa6cfc9f", "15765": "f511d8237322589c59eff8c16ffe00b8293ff4a1", "15766": "8d0c025a4584c0f2d412d060c30fe459dc90b53b", "15767": "8e582254e3bbdd717ec8193364420913a7fc786d", "7576": "6f484a7e65e39e851d92ea9a76105106317989df", "15769": "a2d03d4a63147e2f56615852814de4d2f77c373c", "15770": "8f309db542c893b46e7cc6cff72638f68f5a855b", "19867": "27aa9d8733d20c5d96d9678dd7a0c0773ede58b7", "19868": "37d04a3d3df82c3abb80afc2ef6fcfa0b7d5df44", "15773": "4efe6560e07f28de6a1834fa90e31cef31b0fb18", "15774": "d884e51909a887119c0558146de31284a4278931", "19871": "fbe25233345b750031911f0d4b0845fa115c4432", "19872": "cdfdd77b65df350386ce27142ef3babd9e5186d2", "15777": "09108fae0fc7d2234bad765634213007172d4407", "19874": "8b56ea30f185dfe9e05cbbd5e5be261388354ae8", "15779": "8d7d3fb545b4273cf9d1a61bf7ea3bfdde8a1199", "15780": "a7eb1a775354b43a2bf82ed3a284c0538bc41583", "15781": "4ce5340fec2ec075815e0aac3d4223c2598f1d84", "15782": "811bcbcf4daf6a1118eb898e4e55320c68ec5159", "19879": "1f7ef05ef4e2e5b72763d8f32d79e3495c364d35", "15784": "ef3aae5ca658ccc4dd21c18485762fda52cc3957", "19881": "0d3e0e68cc4dbe0620008d98274d0004dbf5a734", "19882": "9e27f1298d4cd1dcfcf559937125e547c0341f0e", "15787": "9e6bb42fa50df808bffd60a665bf921e49b87032", "15788": "395f712133a4f6003ec8029458ade7ab423096d0", "15789": "793020293ee1e5fa023f45c12943a4ac51cc23d0", "15790": "920a5778a6c3289e9e9e1118de710a8c755d7cb5", "19887": "72f4098ca91fb7f9051021b0f78adecec3f28fdf", "15792": "a7b4a9c7eed794872c5d7dcc558a10ff9f076682", "19889": "fd6681eb4eaab3c359588f1da0bcdc5bb978d851", "19890": "9821b77de692716d7c2b62db1a68cac9ffc456c3", "15795": "9de416aa1445deac056972be537846420cd0a7c6", "19892": "d8642e903cccb8fa0ea4d4477c89bbc1523b8c8e", "15797": "e3b784068a654d13ede6dd4062c8a2b6c9b945c5", "15798": "3ab56bde78e85939a8c5ba73f86ddb888483d395", "15799": "c6e5bf6bfdaad8945120bd54600b3eac79de26b2", "15800": "465c59f964c8d71d8bedd16fcaa00e4328177cb1", "15801": "b03f7e52e859c5d20141a47aa4d6880a321af84d", "15802": "6b8e43688f3363ab19c8a3049e0ade70c13bd4b2", "19899": "b878f5b5e3a8b90a75815de25815525d49673de3", "19900": "923ac2bdee409e4fa8c47414b07f52e036bb21bc", "15805": "ab49d1fcda17cdb5571959a0d85d5ee872638b4c", "15806": "6ac609d8b43769fd80866ebfbf0749e75dddcf04", "15807": "563fa082e32af200d98cfbc1dc30b7ea5247d5d2", "15808": "f394409b0053ffb8a24ffef34f1f758175a7ecf5", "15809": "611d29606263d12ecdcc38a2b8a790e99aa443d6", "15810": "3ed51c2b4b24c391587b78b9dd3faea8d09066e2", "19907": "882961df6025b800b899d351c243412e799accf4", "15812": "8e6b09ff3a09de58e82da6dcabbfddba61a743d6", "15813": "3fadc62e75bb09b2f39ddd2169baa182fb2ea720", "19910": "96a128eaa0a7425dd4285d219780ef29c2727e46", "19911": "8b9f933b221f7a1e69c2c1559cfeef5e4dca7ef8", "19912": "7721f7009249e2b1fa2647526114e7c423fef4ea", "19913": "d2d9e2df7c73df370f7985385c1dc5f3b4a56b4a", "19914": "19626d2567487f8e698174de835c28c900784ed3", "19915": "1d4c89f4d747854def6c32733383b4afa250165d", "15820": "dd776a9f88734ea0769ffdec83423b6ab0c7a59a", "15821": "cdabac1df8220b12d57db021b4b06d391459bed0", "15822": "3ab7d5c0a9fe8c90a5ce2dc52cb77d219e1112da", "16973": "34b86fd75d3620723d0bd6ff2a16bef6adb8b079", "19920": "e1aa6f3c911ff46cd19abd964cab82d400fc14c7", "19921": "3de913705283b8c6618f32693e65399458fc1bab", "15826": "62f464ff73c4ce3137c896b34613659cdf331075", "19923": "819fc1525488b4da7f3d76051a85971a2e004fed", "15828": "e5aad1a2e31ede967c09c2c19236bed701e3c97a", "19925": "e01bcc3a28c92e39f79ae0acd13b9abbcfc5ec11", "15830": "7bef6d873b8af5ee0d35ba4b42c8a4775a6b3f24", "15831": "64129d11e5a4f668378a6c8ace6cad1abd864aa3", "15832": "3e9e947b89d8edd7426bf8c748b1c6e3de5a7afb", "19929": "c7c4c94389103c017e950b37191d7c267a75fa22", "19930": "00c119c50728bee88a5e5d1538cf3a405e36997c", "15835": "b82253590a66b4a35ed682bca244f668f16c3e0b", "15836": "a09db4b156cd9129fd38214e039097ae944c062c", "19933": "4814a2875d078d6e9e9300bd1f77af15ef4f0f0a", "15838": "f165b90ed27487287e1c8a0a6c4e66344b2c731d", "3551": "4e95b311bbf320d7b88edd6f8ce17194e48b8145", "15840": "d59a7b5c4ab842399d79ffac120e9a46b4c0f8fa", "19937": "caad3b5e566d74d5cf0a018378d71625c30bf145", "15842": "236241465a0c10376d032da3c02a381f2b927246", "19939": "8b15dff89a0386110459bfd8ef6af96c75320439", "19940": "1679e542385ea6e4b80908b9520390420cc5c2dd", "15845": "a4a566531685eff6ea001bf6bd60f96791e8d076", "15846": "3ea2993a7dd3f477e2be6911d39d647b0e74d712", "15847": "330b8c1c195174f729a1d2ee6f916ebd1579217e", "15848": "0fafd4f8f7967f83845a74905d7e3ed9432807b6", "15849": "0f25426eac5c0097214df78b45125ac039c85770", "15850": "924b43359b2450cd1e6e364c468c30ee7694f0c1", "15851": "133a2087d038da035a57ab90aad557a328b3d60b", "15852": "a46e5beed5ee0c2395f11ab325eb1b71e6d23c60", "19949": "9fbb9e7c71cf10852b84c1f393263ee04bd790d5", "19950": "1322eb05f315802d36b3896a59e8e314d2ffcb9e", "19951": "db2d16aa671517d28f06ad3c337125f9e1fb9fd8", "19952": "77713d5791a21faf88d49ce4c2505cc2eb7f6642", "15857": "95f4f7dc78ac21a132b86b01c31efc5b0fdbceab", "15858": "0ee1675c51a276649e6e45af962c076c526d1c75", "19955": "fa9c7de77ab09835cd0ce883623111cd9af68811", "19956": "181f972d2f4e6bd5c8c33721175f68188cfa1a0d", "19957": "a1fee9199eba7ebf423880243936b9f1501d3d3a", "19958": "6c613c8e40c2210826bb2450803ec52658d5667c", "15863": "ab32c0a3e2033456ede23dbfeffc6adc8c4ea190", "15864": "3b02e73b856a6f8d53382bf3908f04447bf90e03", "19961": "0610a60d06c190cdd597480962f98b97de7b4286", "15866": "e14431f897c7c0afd76d627ba933c07c277f8deb", "19963": "2f6b90aaaab6814c102eb160c5a9c11bc04a092e", "19964": "9d66bdf1c6f252ba8a9f7b3298877d9c021a84c9", "15869": "d0d28fec180ee61de17921fe5068ecde95adae8a", "15870": "91c2f1f6acde8e5f571d12716e72327747183247", "19967": "6d9b702a661891724e6c10dd96eb149404205c67", "19968": "e02ec8f89a743cc56a79e660b7be850448d15f61", "19969": "a07ed594ec6a5befc967fb1b18244bbeb3bc2bf1", "19896": "51c6a05477ffb5835ee52fc0bbb26e2f64f13bf7", "19974": "feefca8398c930cbbb1c636b328dbfccfa7dbc72", "15879": "66ec5f3e616f6449ef2c88401042cf2a282234d7", "19976": "90a85e0b154833577a4023f643d8aace0c0ae7f5", "15881": "6993c1ba981554cdd8f45675db5807077a28e2c0", "15882": "62527c0f328caa4ae716328246df75a6f2b33028", "15883": "96f92eb1c696723b6465fdc273dc8406201c606a", "15884": "473a7f3c186f6b0bfd9d3ce413fb627cf7a8f111", "15885": "376483e12e4a08140d594eab86bf22423684fbcb", "19982": "d9c9e2f01ab53de2ba4031367bc570ce66dac374", "15888": "6bab9d18bef3b7fccab2830d6dad78d0fb476ed8", "15889": "9a1dfca9182c86c90fffa26579844244cfd7cd7a", "15890": "e8a1765edf91ec4d087b46b90d5e54530550029b", "19987": "7b3bf2dc6b8b00133d2cf46c1f70f2865666a13f", "15892": "0d676a3ccf1d7aa986416a7488b941496f936d98", "19989": "d86553b00fe263d264bd0b2ce691724591dc7b01", "15894": "77bfe21c7229e724d01721bb84861283baf7e9d3", "15895": "ad7d6fc0248edaf098537e5674dcc0c9dd059491", "15896": "64c8a8d6fecacb796da8265ace870a4fcab98092", "19993": "4b1624edd6af26b11d59696479aae60a1c8ae7c3", "19994": "fd1c3f868d2d8f8763cf126054ebbb5ae367017a", "19995": "68b1da7f53f043b21e3f722e8872e19941a10250", "19996": "057b2423ac7d5a972a05f4ba602d49ed6a3f75be", "15901": "9e425d637b0c635f1ec73407e6b45d1c53cd7fca", "15902": "f7fe4295f84937bc0fa82c9718e62ec19fc36e6a", "15903": "8351f86a0079b6b0cb95414807a2c2248530ef2c", "15904": "1981b679b0619de0765c2009684ce4abd886189d", "15905": "c2d048137c7288644e8276fed3c5a7071a80221e", "15906": "5bca6ce860f66ca6f92327086a954b9e0326a85f", "20003": "dd9c585e7093dd752b7b3630abc7a1e77571f39f", "20004": "1c0f8cf0546120627f4133896c1cfc510667a82d", "15909": "d4577911c750f2f48f760ce451d413116bed72da", "20006": "ecbb0efaaaedd5b3a2937eb52af761a8402c67c4", "20007": "f53bb061939fb54d6c826c4db408c458d3d2a1db", "20008": "c79b7bb91236a2e4cde3782d23109ac1f5e76dce", "20011": "3face07520a50678d001987f0f57e327ab4dfb87", "15916": "8a8a4fd74dc1dd2804d5f605fcad47e6f0fd4b60", "15917": "9dc01c4f9142908c4a7db5a3a0300685f6d43308", "20014": "7706741fb92a97d09c63d1858cba8558e032ce1e", "20015": "dc86509b44b3fb0cd9a1a6d6ed564b082dc50848", "15920": "ee6185e2fb9461632949f3ba52a28b37a1f7296e", "15921": "46832ac8f465aa911ba79ebc1b1a4d0f6baf46f9", "15922": "9c4e4c8959853c7cda554d8e9b530efdd8ef9cb1", "15923": "7e4e8acf5b5d68b3dfadecd3ba816d4f0b9be0ce", "15924": "3ccb88c912d898b2fd8decd3d988aca264e4e820", "15925": "d6df8ea99f2574480e934aae01a1e142f935145e", "15926": "fdbc6b8f4b36f07da62fc901b19754f922ae3952", "20023": "5fa8a3158226178655d2bd46ad65af61b88971ab", "15928": "c3ad501ed31e2e71ab91a201ed72779fdd597698", "20025": "bbcfc7fba2c730d4df18f93f7f95ad439c26c31b", "20026": "947bd7662afa8b6dc4406ec52cefc39d76d2d6cd", "20027": "fecee8ffe39446d213f425257c6de24b5a7f9021", "20028": "e134ddb727069e50bd76c319d9d220fc23ca170f", "15933": "34cc2e812f60687d2a4417ff26fc180f7c042674", "15934": "9a8427404efb3df5deda12f76352725d628adf5e", "15935": "d46b027e793e0f7b03a9372b82ac68cd35c1f35f", "20032": "3de4a85089c4c3647137f8c5b41390f6b490e5d6", "15937": "83436af8ae1ccad49b7ceac7471c060d823d10ab", "15938": "633be31adcd43fc8bfe9a9fd9e7621ff3fc8ccbd", "15939": "f6d4d7078d49503adf990f0c159eb603ca1f0c1a", "20036": "b62e9aeac6b646a7d4a1f63d88dd15e347ad3719", "20037": "4d9de8dd9569be2eaa23652d00b9577d91ebfd89", "20038": "88062f75dbca929ec082295c936edd07cc912dbf", "20039": "33e05d7432e3f580d27c949a0ccd87e5bff307e2", "15944": "97abd2c9c11aeee0e3d2c58a74d85fa75062ca1f", "15945": "0097cb712a7361a69eb4f5ebb9bc13c2b8733f19", "20042": "b2b09b7fcd2cc4fd151eb2ddbdea6cb0dee81993", "15947": "ad70ed4ba921360169820dabd16e4475c527479f", "20044": "e464a88a90d1c4b61ac1f3f240ccc0a88347f04d", "20045": "65466f04025474c3ee1bd2f4e49a1c5e24b76f7b", "20046": "64104ec343f0770afa88f02da47b34fbe62c8281", "18671": "aaaac86ee019675119cb0ae9c3fb7a2b7eef9959", "15952": "9ec157be1cc0908e3d20e099c7a36cd76d3454cc", "15953": "f5cfdbb1f4b715819aceac4b00cf18ba5f467f85", "20050": "187630bfe314fe4428e41704f9bfc01797f7ea3a", "20051": "48ea04fe5d3ba9b618152ae83aef703dbbb2c3f4", "20052": "f572ec4d6f652a9cdb793071d182c0febda14153", "15957": "643fc1e0670eaa9e4a332a3a87805b03f68da74c", "15958": "138be889e74ae64132249232ad90f9e4239fd1c7", "15959": "26b461bb6706fe387caf191293bf511de70291d9", "15960": "553a829bf8b433ca7c555fad527c6e0d9f020e91", "15961": "cbb090fac6a39d0e687a01b2ad1b7c136f5d92fc", "15962": "9cc33333fa035e842f35fceccde6afa71f3f1d1b", "20059": "f54945ea0678742c4785b0e88a2fa99f62cafa49", "20060": "66d60239b4c43afef35035150d14a9e00e00486c", "15965": "6630c4eddf2762d519507304ad73de189a7e0c6c", "15966": "3795272ad8987f5af22c5887fc95bb35c1b6bb69", "20063": "7eff62725a3988d6d4ecc9edb87441355e33d75a", "20064": "80be9b5defaff892e3362a31b44ca1479c2847b6", "3344": "1c08383fc3cf24d503ae221c5d31b93899da6473", "20066": "4df308f441f84b99d59691e7387c791cb84222c2", "20067": "c2c79399377f59375723e58b8f9ccf86cc608be7", "7780": "6f31fd1b6c39322bbb7015b1b0e8b4a729ffc1e9", "20069": "d1e4ec38576ed558f8a14664b30f8e63e00b586a", "20070": "d49ebd4191887ebf35ebedc6c1a1608ce8e9505f", "20071": "1175933e11e018a8afcb91820917d650e4774359", "20072": "0989339c2bb9ed583889ee86d584f4eb8c4362f9", "20073": "e854ccf173a195e582b965063c17eee75ef2c92c", "20074": "a8d61d39d252bb126dc7972cefb00947dd9d59d2", "20075": "f46ab96fc3f6fb2e764295b4922f5f5e2323d2d8", "20077": "8ac31233f376291c231a286b69851526552348ed", "20078": "a0c965e7b203d54633c7ea30fe8be60cecf8c3bd", "20079": "ec2846a117c098ad9bfc6f71cb77c45bac0d9cb0", "20080": "cc3b2f0a185e5e81ff219fc06f57eea92f629b2b", "20081": "71207255f32af73cd701fe4ecf56a643c925a9e1", "19992": "32d66e0c6c44e26831a0a369301f2d316f53a844", "20087": "2e4e0b9058cf9f5a3ca81d2fb405fcd3b9317951", "20088": "ca1a36ab3a793d9a87900537de066fa676cbf237", "20089": "07cea1971902cf35b2094d06962ae0bcabe026f9", "20090": "749f456c181376e682b40f0eaa3818810bbc6f16", "20091": "5eead579fa9eebe4af8eea8fa36248737fbc39c3", "20092": "64c1127aaf01b501fcc8dc4d31d00accc712952c", "20093": "2f182aa5909df64fff79b3a4152bf2d24b3d810a", "20094": "f65742cd47d6b364a2cbf150869b282c5aa7daf0", "20095": "2bbc0c2c198374546408cb15fff447c1e306f99f", "20096": "fe98ba82c356ea47ea42ffe33f45e6be88f5658e", "20097": "20fa58d48a7788e980a084ac05196cab2cc055ac", "11906": "ca9eefc3c4733f368c054e33537ff18384114b43", "20099": "7bd7fab10796a8559040880098c927cf9bb0ae4c", "20100": "6d7ba051508b93fbbc80f6929ed6f2254ab7b938", "20101": "7bfbd81b44526c88bab575a6ff6d229cb89f5e1a", "20102": "23b611533a3f66eb42db23b8532adb7a14f23df2", "20103": "d024aaef04f938f30ef926e7839ac70e5311f1d1", "20104": "cf9ed41a51211027e313261a4001b74adb17ad9f", "20105": "2bca899a6e96a310fcc14c1ad978340a71ba04ed", "20106": "17247edf8439d290cd5f9410df477af8d399c839", "20107": "ee6b1318ff07806ead79dac8119ad9ce580afe1c", "20108": "58fd4491ee4aa49f628da81af978b15db16164b7", "20109": "c8eedd26853f1ca0a8923ee3196a13656b141eb4", "20111": "bb0376c209d97e49b9c94038926ee62ddc0ee84d", "20119": "971dcc11c8d9d71605582e6d37a4cdc65d996ff3", "20120": "6b51c941b29db9cfc48327da680de4b2ab46178c", "20121": "4a30fa52f9b31abf9bb6e59a2baf2686e8af5640", "20122": "bc75a7244fe77cc52cc7cb96426abca2f9462570", "17007": "76f175bec48d51749bbc8b48526ac0f63c01b89a", "20124": "e26aa00151f8dda02e4c6ddf3e8c6dc8b31400c5", "20125": "a6e43a43f2cb1b4b7d46b262be2efb825d033eb8", "20126": "2123a96d6bc5b511ae1d1109000be7055deb2b8c", "16031": "00e52abe927150d10a72e397893bee56f4cc6505", "16032": "ffa86c5d154e7013863f94a5a72b574aa2846508", "16033": "54f6648cdebfa376c83f9fc03b53effe82df7492", "16034": "ad7d051bdfdbadc4221307d691fd55412d9d7ae8", "16035": "e2a0251d32a1467e9ab86281a31f57aca582a88f", "16036": "b8467c00f78eec73efd14f159f1ba935a65b4ee7", "16037": "030e374940a93b7920c0c2ac5c950668564c3703", "20134": "3b24fb678672ecb6ef24a1915c49f3cf815d5556", "16039": "fd336fbea59edf6324d5c4ac8b22ed696312f50e", "16040": "7d4a260cbe6d5c1825541adcd0d5310f32a3ba42", "20140": "241af3dad76e1410b34e7e0dbab8e019673e9af4", "20141": "e101dd94094636bcc7dca43c97ce5f0ca5a3634b", "20142": "0382f204a8f3fa72db433232cbd7d6d4bd66d823", "20143": "80e261555adc2f58930f2dad6c765f25e7dc8e08", "20144": "9c5165e26260483ae64300c4d98939bf575aab7e", "16049": "1a6b7ab8ecb0270227066ec7cca8a6bbcd9ddbc3", "16050": "a3d538ab72380471f5de7b8e4a3f811aa4de84af", "16051": "2310faa109bdfd9ff3ef4fc19a163d790d60c645", "16052": "def3bce010eb0eaea2580ad6b6f44c0318314296", "16053": "72c7a396fbd10559f0862e59f55a93beb52c35db", "19902": "af6ccf64dab57cc90cce1582fea60fba13b2998a", "16059": "170411ff666153fa1275c8cdba657729441d2b12", "16060": "8e89cb3e135f6ef746437211857776136747388f", "16061": "9e67f4370ebf4d63ae65878f5dde6e8371538134", "16062": "2ff1241fa794231b8317ebe96b66f71dce99e0c2", "16063": "50c1dda3f1e0c0a4e439c73ac12943536cf58806", "16064": "9ac7c51faf15bfef0756f9ab50cef3177d7fe5a8", "16065": "69024a0110fdc5d8e8a015ea2c5316826e2f80be", "16066": "81694dce171ecd93a65e32ed455612ee967d3951", "16331": "8efd1a0162a643c06af998bb1bc60a2cc9f5dbf6", "15649": "329fdaae294ae3dc45d4d7301f0f1eec2d26cb4b", "16075": "3c1923287cf1365ef653efa4abb5c6a4c0a9bd1c", "16076": "e7bb63c4a4f4e5ca04481e4957f1c1394fdcd598", "16077": "7740a6ea71c1e414728a5f81b3e49f066fd7d69e", "16078": "7a57b83a8c1e362920e5e358c21d2a090c8706aa", "16079": "22515f58c178cdb5cd38c4e56f26dc91c7053550", "15651": "9e55af2552664267ce27c7fc6c932acb0651c259", "16084": "4379d04cd933fdaa2b9cbc9be4169cab2c506a92", "16085": "3b4121b5fca88a84bcc9dba56af568c8a2f901c0", "16086": "5bb693a85ef061520936a4feeea30fd382918a76", "16087": "1335090b5da9706419b60e610997c10d9a023fc8", "16088": "e63c935d5a0705f83fc726932eb82bac4c272106", "16089": "7db7f82ed34dfe9b9768f2449b291d5abd6ef60a", "12002": "24633ec81de4b960a9213cc29aecc8e731024c60", "12923": "c0f5cb1f1c4494155bcbb055f2df98cb911bfcdc", "20040": "444ba646944c6a44490633587fc779d39b55cbfc", "20205": "8154efb0c1a64295cf54e00025b4ab09bcd02752", "20206": "a60d1bd45a99519fad5024068db956e0aa1cc6a1", "20207": "7c8041b9b6dd44a7388bc8518dc0cd2f7303c2d2", "20208": "4c54dd298692783f417cbaa57d5fc1c0dc1f7c72", "20209": "0041935572774c6599dd9b48e9acc7cceb559004", "20210": "7f318658b92155678b31780722277d1f8c8df569", "20211": "c6a7cc1e08f9203caf57599244cd1c51f6347875", "16122": "c9876947831b8a2093d87613a83777a98dfbfcaa", "16123": "00f23ca69e8999592f1bad02c6d763df48365a97", "16124": "a2ff3f0a4d847b9798b76046db05f723c2723355", "16125": "34978a72107b3c77cf295fadbf1f5244ccb6afdf", "16126": "9092445b1b8bdc6cb031a2319ac98204b13f908c", "16127": "5bf7f9a4ff6968fd444fa7098f8dc95586591994", "20224": "3db9dc308bad04f180950630f5966cbee27916a7", "16129": "bbaa576ac691f69fde076d22587736b989ab69ef", "16130": "6691285bbf5af202483c24f62f4e68198a92f279", "16131": "5687f9e8f63c325249caabf0c8b7f0bee0a12f09", "20228": "efc2adaa3553f647737307aec85399b627002c03", "20229": "5c6dd43e3e85235f32444df73abb66528336b319", "20230": "4f332f6f4b27111c9ab7ba686b3bc51db2e6f7bc", "16135": "51c5f4d2a20179041114fac0262ef567d0b0373f", "20232": "635458029e11ff6d94e8132577075269fb79832c", "20233": "23b0788118bd95bdf1adb8f86d667fa54a033423", "20234": "8d124ea4c5200f218db7cea8e3ff504b0045a4e6", "20235": "101370645d13e1d0f256f367f4ef56a8329b56b6", "16140": "5314578d859d891427609da0698469824d81e530", "16141": "058da72fe62e9f80aa553c305bab8b501f329b7d", "16142": "e2b49ba93a662d042294c6d65572453ad613355c", "20239": "01d97d48b08c546a46b91c27a5886f52b46f22c2", "16144": "097eb6916b84e027e216fd9f69966e271a40b30e", "20241": "758e35d7c8aa46279cbb9d6191ddb9842f1ce31b", "16146": "36c309ed51b98e97fb64238232ecdc795040ad24", "20243": "8ef9a6356f9f00e22908dd04aa47b2a5d6c38725", "16148": "6a945180165aaf9f1657ce6f3b190963769f5fc0", "16149": "7aeccd392f0c07ecd1c8d929a0d0312fd8151971", "20246": "1d7ad5fd7577f3da1c8eb19cf547f62d392405d0", "20247": "30d9cf30c680596fc6e00b3e06a30d2fc62bad69", "16152": "e38bd749dfb39fb25e9038bc51dbeb6ae78b63b1", "20249": "891a419a5155e6b42c0696a81cf853b6f3febbf7", "20250": "5a724b5cd796a6ede3cb95b8687eaf561e9d57b2", "15663": "e832ddfc8bb6362a465de18ccdd25a42585ba2bd", "16156": "fc1e50733ea4c372f4c9eb3a53bf35e102d5d215", "20253": "c9c6c221865f2988c0f52dcada6b033afaf23a8a", "20254": "649ad5c91aabb95d7f200eec84b82cae1459fc65", "16160": "dff5109abfd1e29dcd349d04d535a9c8735219b3", "16161": "5dd2ea0b3211528ffcfe9b231ce6c00f02918153", "16162": "f39f62ec798d5bacb596aa505faef882405fedf9", "16163": "78c8e17d1aef9f2f327fd46b997c46424c961a32", "20260": "4d916eff3ba30bcbf9f16b8f53469088a02ff19b", "20261": "9a67ff478a2e9fb8c78e43fee348bbdb26d6d9d4", "20262": "ef30df84fcd89e8476c5ba9eab8fa4ad36d5e51c", "20263": "1cf1b96fdfa3d6153637f3540d6bf9dbcf126167", "16168": "34abef282cc7f27257ed873c60a91f69f67b36b5", "16169": "b2d0d1bfe578ce91d545bd2f806655d0bf497440", "16170": "5959ee3e133723136d4862864988a63ef3cc2a2f", "16172": "a355ed2a8c32a29c1dc93466f9b65870cac272fa", "12077": "06832891870119984c6a5404bc7f7a471f43b99c", "16174": "3f4089d3d74cd793b7e773fffa2f5d199bde8363", "16175": "52fe6bc15acd1598290b53195ea7fefecda5fce3", "20272": "be2face9bf243583f05a128d2be32a2365caa6d6", "20273": "caed3133555fb80c8b6b78af6365d9de81e421de", "20274": "c865eec3bf7ff04cd420082d3fa3952d6d09b6f0", "20275": "b9a7f612677315a602a0a2b82d88e26677c6e2b5", "20276": "c7748ca057cad4a80a6c4cbf8b49c5d9f3e7ea1c", "20277": "a387110c054e0f9db40cef6b05d3cfa804532dd9", "16182": "823cfc409ac493e3d3aef1381f6200005a13e4b5", "16183": "c65a0f554b0381ac3f50762050a56bcff188ffa1", "20280": "e935c7061e2806de05349276ab07b994effddbf7", "20281": "0f3e8e8bd2118d56c7febe5d6081c5058cb22be7", "12091": "6b1055c765c488e6fb411eed452abf75ff8df4bb", "16190": "f62c85ad5a9c1a2c96a23a1590f416dbb43a1f69", "16191": "ff805c3f215eaa10279074c4b1ae0242d0d5dbf2", "16192": "1719437dbf0a24939e0ce7e46e0a5aa742bff773", "3905": "a2f5e56b13dff45a82c4fa068ec5edf35bece645", "16194": "15fa4bd62c5c7ac7ac618a7e68742b7eb1f90d21", "16196": "21f9e1a47b8331e2894d0bd2d401710d78850f7b", "16197": "bb4fa658483cc0f9aa714dfc5733fe7ab7945f73", "16198": "194dbff2c3e986dc385237b7e56fe9c6d27358bc", "16199": "94bca94daf64cc6cd36705a9bfe4d6d9f8306202", "16200": "0fd3bd73e17e4123f1d334f4ebd305e33cd75fe1", "16201": "804fb99a868f09e9035cc2bd438ba1642e4e35fd", "16202": "90fb0e3c551cc121571b54c6b8615bea084bffd6", "16203": "427d2839e58db6fedab61db9cbf5a127a56a04bc", "16204": "b4375bde87afdc037056ff90e4f93b606c76e140", "16205": "27bbea7ee125f4dc19dca2a7703c9a13ca754f9b", "16206": "86e9dcc164760c5197438968151b2b852647de84", "16215": "8388a47b7b09d345f463fe5fe91f32e87f7bb550", "16216": "e1f3a70239c636e0dc05f5ee289bbd4bfb4c1436", "16217": "de299f663d3a1df063baed7656d9062b9c3b003b", "16218": "58c2f098ab13178f7cf3d3a61c9f4e0fa5d54ead", "16219": "bc69dc69b168bae59d0ed6a461f18222b8137fa1", "16220": "f7f214ba5241d84c107d318df4f85129b9ffc938", "16221": "1181622fbfc9208a906ae9e70716b83fc7b3ae5a", "16222": "9c49e648da8d90a27eba13e11fa12dcdd22bb925", "16223": "f17aa265021b084ec2b4ff9d97e75700dd24f680", "16225": "6f0ff1a6f5fdc2cc135ffffc6e54b471977d2659", "16226": "e23bd24912af10a39f86415221f293619a37e079", "16227": "c176a3c29ccabe7e471fa0b76c6cc1ceeb9bcd77", "16228": "d7c04fba56a704663108da31e064e37ad2ed60f9", "16229": "537e880d2bdb6f3e71d6b66f6489783102b70443", "16233": "d3d60f845b2f324ddc1afbf698788db1efbe145d", "16234": "93c755e0ea64b6039c8ecd55fc637d1dd67dbd6e", "16235": "079f6786f90553a6fae569354273c80d7c1e44ff", "16236": "6b29671e558df9a7ce17e67fd3c86973f9de5fd0", "16237": "535033033002592b8fce94f9365b6671baaf59ec", "16241": "4054632e151c33e8e31c201a1e4ffb5f857b0652", "16242": "8dac633142daa8d5bcd0cf77ad89b97628d474eb", "16243": "ba231d47fbb6891a8f7710b7609802cc8e702771", "16244": "8113b87e017ccce2f78fe885404840838e360033", "16245": "17e0b13095b23ade8e64434e88300b849bfadf01", "16249": "6b3641b48439922ce4c1225a1d338dfe0b1f8967", "16250": "a6345c7cd8c41842d61902801e7bef9cacb0c2d5", "16251": "150f6d41245f42596123998bacbb254b15ccbd75", "16252": "276b3c30b1c3c35dfee1e7249e887dd26d02d9de", "16253": "75c1fa01ebcfe3a61cb1ec9899729062336724a6", "16256": "d8129b49b76362ed148938bcb64e095a95aaf19a", "16257": "bbadc81fc93383bbcd264e2de7a1c1128a6b2c8e", "16258": "f68bf254a5a9503bbaef64e23bd53cd85527d20e", "16259": "b37e4f5c46a3c262015388188264bffcf93ab3f3", "16260": "3493abaa9c47e39b410752833c901fd27f5b3a76", "16261": "b36dab50a5dc7ca2d8de2b62a81014e095117771", "16262": "85e6864177af5d90c633943ee0d86b46ea5150d9", "16263": "96a527434a6138b291c1b4a782bd2793cff51f74", "16277": "4292a27e7e64dc0da6fb6dade7b8304a4251360e", "16278": "c3cfe90d8b7be9435c59f279fc933c7931f0e215", "16279": "feaa0d0a48c01ec5dbf38ef4e51964afd1700ace", "16280": "cff284258c3e7a9474e0ac49f5e7a3b75d939310", "16281": "7f4c960c7d0c100e5df9f0a3bc68401fc4eace4d", "16284": "22fcf43a22866bb4c75dd59d7f91ddf7ff2e8c2e", "16285": "7857c684c38c478190ff5b045f396d05a69c83a1", "16286": "1e30886c09b63ea33236d02f9fb3ae854387ae67", "16287": "77f10f0805651493b95a462085c9a3cd98e9197a", "16288": "ef4e30b85fa3058f0127a969ae7576f0ef3f7454", "16289": "63e8527d32aaf6afe1cd4b2a7b3bfadb088c9a72", "16290": "148ed63f9287cc55f7a2802da300b717d01cabe6", "16291": "9aaf50a367933bad65a4c46920901d58c76e569b", "16292": "fa4ebd4df50853e4cd3f3574738ba9f5964bfafc", "16293": "9c799e2c4331e5e42cfda03323eef165feb5be1a", "16297": "2a6023e83a7428eed5c705b3e606de4b32ec2d01", "16298": "54f2a5e91e90e35f7cbd15214297169831d6a6a6", "16299": "498a1e19555c41d416d0c66095d98211f1eeb4b4", "16300": "7c4ae124c2cf9a2087b0f08828c71ff1e8e4fb75", "16301": "6405919ea341877218ee78c4dae86d1d10d4b8a0", "16305": "d5c490841242e490aa4f510233847861f2ef7144", "16306": "774030cf77a2a2aaea2663c8a3bbc5470ae23c74", "16307": "d6049a0efb7c04996bc374f3747bab8fe4c84bac", "16308": "a39f967b3d6e43edc62e3feae040e22eb69f20b4", "16309": "cfad581e9a6d35c7d05d2b1f34e4a19f7ee15cc6", "16310": "fe4c34bf2053ade8e8e5f6e5b703f5d8be11b6f8", "16311": "0522dcc37899d755a3dc18a7fd1f3fc9b93a51ff", "16312": "f724066f4b3e8b402f7307a132b0d9c5e89ab60f", "16313": "1798c9df8144890f9d9b74cca9f3134ea523b201", "4026": "b5956fdc123b0208cf36fafc1b80a9671c66efbb", "16323": "f85cdfd67a8bbb024f38b3a8adc9a36b8dc4ea56", "16324": "84bce214ca0b44a371a10692124990d4cb23de6a", "16325": "7aa273733b876b548aa9e853cd392f1c5ab2539f", "16326": "8486c7361a1dfa771e738346cb5bf4bf55ce0ec6", "16327": "1647a724ae5c9038cdd3cf4ebbf2273d1b6ab109", "16328": "8d04dafd48d541042613548183b62288ef7e97b3", "16329": "8512cc5f4751fff754cbf8b7f5f95e65eb7e18dc", "16330": "509e03c6b113e78935ae46707572e4bf7f7a1df5", "8139": "a5410ed841759badae2c3fe4cc71335c9dd6ad92", "16332": "c4a2cd362afdfbc21cb62a8e09758226e86735c4", "17729": "d8a1feff3947cd8759c20bf3c7479014d41ee732", "16340": "b6b9f3faa16907a158676cf949b5a8191a21d42a", "16341": "103ea6fa33cbee3d9a193010016faa4cec7abf87", "16342": "c619a6746048a1b0f2dfb0119d80295b1c7e4f28", "16343": "977686801378978c54472f8ff0981b5da3ecc1d3", "16344": "d421a09e382109c1bbe064107c4024b065839de2", "19108": "a771b471ba26e4e637d6b159691f465964e5c624", "16347": "dac9b43f7c12b3785250b0e7805b43421a03dc8c", "16348": "717c4a28f6a979c856642bb4d74fddecc8030efb", "16349": "bd145c8d2b14e506609b251a11bd8268582ebc85", "16350": "fedc503f0d25b04850a931398fc0556d892d69ea", "16351": "c63435207375b172db9efdd0d31f32e0da555a72", "16359": "b45325e283b16ec8869aaea407de8256fc234f33", "16360": "492040b401772e95b755f74f09b20ca236016fb5", "16361": "5e670653e50dcbbafc0ba004b16328f49925f041", "16362": "e6eac0b308af9869ee123caa8c256bd8a7cc126b", "16363": "154c41690fdc23b62aa69ad2d6774a02f6334ece", "16367": "4fce7846be56e12999fe8758abb2ea2f2794259d", "16368": "66606381317a131406220df96b5511b33559cfa4", "16369": "e728f94b1e9f16f4720b0c99d2eec2ff184c0301", "16370": "aaee541b538559f8887881ab23d2734dddd920d3", "16371": "412988ed972a929203b2e867c8fdc7fcb0e7d312", "4084": "023b1d4ae2e3c81b07e95736e17aa500d01928e5", "19113": "9ea8176f598a2fb61d16d8a6aa0463f22df061e2", "15700": "9c44f9b2cad863bde17c7dd061d5b5b5ccbada21", "16381": "3d4422173ee2c169afd19b6762e3b5003d8a954f", "16382": "1fab80852f90cecd852d8f89f7e963cf89d69d79", "16383": "20f65126e0de65876bf412fa4280d8725afe2260"}, "project_url": "http://pandas.pydata.org/", "benchmarks": {"series_methods.IsInForObjects.time_isin_short_series_long_values": {"min_run_count": 2, "version": "0c80773d0c28387f80e18a0518b0ac07840b5e01627379928f27ad43c2c28507", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInForObjects:\n    def time_isin_short_series_long_values(self):\n        # running time dominated by the preprocessing\n        self.s_short.isin(self.vals_long)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10**4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10**4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10**5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10**5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10**5,\n                                    dtype=np.float)).astype(np.object)\n        self.vals_long_floats = np.arange(10**5,\n                                          dtype=np.float).astype(np.object)", "number": 0, "name": "series_methods.IsInForObjects.time_isin_short_series_long_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Reindex.time_reindex_axis0": {"min_run_count": 2, "version": "05097d2b27161a34f80319d9b9040ab1353c91927988cae923916a09b4a2b0f4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Reindex.time_reindex_axis0", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_title": {"min_run_count": 2, "version": "4d25fafa8df7e9cbf44acf248bf062a689b2733ee7c8dc8c40f023d318e57bfc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_title(self):\n        self.s.str.title()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_title", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {"min_run_count": 2, "version": "d84c8d3591709c8383c32bf351c82886a08f0a9b3b61b63da01e8bd61aaf6247", "processes": 2, "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "type": "time", "warmup_time": -1, "param_names": ["sep", "decimal", "float_precision"], "timeout": 60.0, "code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(self.data(self.StringIO_input), sep=sep, header=None,\n                 engine='python', float_precision=None, names=list('abc'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [''.join(random.choice(string.digits) for _ in range(28))\n                  for _ in range(15)]\n        rows = sep.join(['0{}'.format(decimal) + '{}'] * 3) + '\\n'\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_series_float": {"min_run_count": 2, "version": "d7a0a431bc3ffdb91cfde8a60e53e4f583fff565594969f0ead9acd5175c3138", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df['floats'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_series_float", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.ToTimedelta.time_convert_int": {"min_run_count": 2, "version": "380a5cc0adea708f6b1a9e401f28151ebd0f88243cbd5a1f75d7a2fdb9a02fd0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit='s')\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append('{0} days'.format(i))\n            self.str_seconds.append('00:00:{0:02d}'.format(i))", "number": 0, "name": "timedelta.ToTimedelta.time_convert_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Nunique.time_frame_nunique": {"min_run_count": 2, "version": "f7e9a2a2bfaa0bd91728100f010a191c5df8ebb6b4195374fab430a8ed55aec4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))", "number": 0, "name": "frame_methods.Nunique.time_frame_nunique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.IntervalIndexing.time_getitem_list": {"min_run_count": 2, "version": "2ceabe9099f794f534a3cee65209eef67ef8fe5910032d09dc873b61f7db9311", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:220", "number": 0, "name": "indexing.IntervalIndexing.time_getitem_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "ctors.SeriesConstructors.time_series_constructor": {"min_run_count": 2, "version": "60ff11f84349dd83134b5c6946ff4b5debb3ebc2bdb4ef8ecd36587357657365", "processes": 2, "params": [["<function no_change at 0x7f5599115488>", "<class 'list'>", "<function list_of_str at 0x7f5599115510>", "<function gen_of_str at 0x7f5599115598>", "<function arr_dict at 0x7f5599115620>", "<function list_of_tuples at 0x7f55991156a8>", "<function gen_of_tuples at 0x7f5599115730>", "<function list_of_lists at 0x7f55991157b8>", "<function list_of_tuples_with_none at 0x7f5599115840>", "<function list_of_lists_with_none at 0x7f55991158c8>"], ["False", "True"], ["'float'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["data_fmt", "with_index", "dtype"], "timeout": 60.0, "code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        N = 10**4\n        if dtype == 'float':\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None", "number": 0, "name": "ctors.SeriesConstructors.time_series_constructor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {"min_run_count": 2, "version": "c78a4b570cb1baaf415184384721328ac04bd0cb27004e9392fe1927c5b09648", "processes": 2, "params": [["<Nano>", "<Hour>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10**3\n        np.random.seed(1234)\n        idx = date_range(Timestamp('1/1/1900'), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()", "number": 0, "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Rename.time_rename_axis0": {"min_run_count": 2, "version": "03643668797cecb2fb3a6ef73f3873b823511bb6ed4ab7e15f4e1fcd0f1fd0a6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Rename.time_rename_axis0", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.GroupManyLabels.time_sum": {"min_run_count": 2, "version": "5b70f52b943e8d1c375a69663a0b6ae86596f170b8e7a1f57fd4866f5dad6b9f", "processes": 2, "params": [["1", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["ncols"], "timeout": 60.0, "code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)", "number": 0, "name": "groupby.GroupManyLabels.time_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_iteritems_indexing": {"min_run_count": 2, "version": "5d6175489022685c0cc94bd486c07b77634ded5dfda3a90a1f2ca09e61f50440", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_iteritems_indexing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_getitem_slice": {"min_run_count": 2, "version": "72e11ffc99b1f8e5b957f63fea4532ae6883c332c70a219653eb26787cf70ace", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_getitem_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor_date": {"min_run_count": 2, "version": "5f182c223296e68e68c19fa563c214a1d6c8cb8815eba76bd54d137ae14a9499", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor_date", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {"min_run_count": 2, "version": "847d8becb941360b520bcf832fb999a4351e0ddfae42d4cbdbda536ae81c2acd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list('a' * N + 'b' * N + 'c' * N))\n        self.s = pd.Series(self.c)", "number": 0, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_floats_with_dt_index": {"min_run_count": 2, "version": "895d148a756f317ff1cdd789a8e144e8aa843f86904317c2c9d2b257ba88b41d", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_floats_with_dt_index(self, orient):\n        self.df_date_idx.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_floats_with_dt_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_read_first": {"min_run_count": 2, "version": "e0e7db84cbde32e22615671c95b90b89e2d9a302970496387d182d03555ad0e5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_read_first", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Align.time_series_align_left_monotonic": {"min_run_count": 2, "version": "63fe6567acd17878f40b412bf40493532185660e999c412ea3730f68ed0aae01", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join='left')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64('now').view('i8') + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "number": 0, "name": "join_merge.Align.time_series_align_left_monotonic", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Covariance.time_cov_series": {"min_run_count": 2, "version": "a664c1d202b4caab114dd50db045ccaf0ab463fff96b7ca09103a11b933554f7", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["use_bottleneck"], "timeout": 60.0, "code": "class Covariance:\n    def time_cov_series(self, use_bottleneck):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))", "number": 0, "name": "stat_ops.Covariance.time_cov_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Apply.time_apply_np_mean": {"min_run_count": 2, "version": "cf5eedb6a52139403d893309aca0d26faf3074a40b35f970000536a5698f39e1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_apply_np_mean(self):\n        self.df.apply(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Apply.time_apply_np_mean", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.DateAttributes.time_len_groupby_object": {"min_run_count": 2, "version": "50c90f625b49f984d7d91cc484c06cc1f3e952d2b6f1cba75cb021bc9f4ea51f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range('1/1/2000', '12/31/2005', freq='H')\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)", "number": 0, "name": "groupby.DateAttributes.time_len_groupby_object", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ReadJSONLines.time_read_json_lines_concat": {"min_run_count": 2, "version": "8d1295efddc1388985299eea75b1c418657ad939fa426ef3dd654e169a43bfab", "processes": 2, "params": [["'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient='records', lines=True,\n                         chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {'int': np.arange(N),\n                   'datetime': date_range('20000101', periods=N, freq='H')}\n        df = DataFrame(np.random.randn(N, 5),\n                       columns=['float_{}'.format(i) for i in range(5)],\n                       index=indexes[index])\n        df.to_json(self.fname, orient='records', lines=True)", "number": 0, "name": "io.json.ReadJSONLines.time_read_json_lines_concat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.JoinIndex.time_left_outer_join_index": {"min_run_count": 2, "version": "0f6eac4c38465f70da515107e13ce5bfc30dbb19ec3270870755478dba398e20", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on='jim')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 50000\n        self.left = DataFrame(np.random.randint(1, N / 500, (N, 2)),\n                              columns=['jim', 'joe'])\n        self.right = DataFrame(np.random.randint(1, N / 500, (N, 2)),\n                               columns=['jolie', 'jolia']).set_index('jolie')", "number": 0, "name": "join_merge.JoinIndex.time_left_outer_join_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Apply.time_apply_user_func": {"min_run_count": 2, "version": "1d72598ae551aa9d64a2a010f4baa2d6d0bc0aeae7fa9902333aac3f1c9b0e29", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Apply.time_apply_user_func", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_tz": {"min_run_count": 2, "version": "ef87c7002f774794252e7f651cdd522bc195d4fa64005e1302c0c7cd6397e227", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_tz(self, tz, freq):\n        self.ts.tz\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_tz", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelGroupbyMethods.time_loop": {"min_run_count": 2, "version": "6ed7329633e14c41dfab8c193c98645b299abd453c79e6441ecb1f3a47d5b640", "processes": 2, "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "type": "time", "warmup_time": -1, "param_names": ["threads", "method"], "timeout": 60.0, "code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame({'key': np.random.randint(0, ngroups, size=N),\n                        'data': np.random.randn(N)})\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby('key')['data'], method)()\n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby('key')['data'], method)()\n        self.loop = loop", "number": 0, "name": "gil.ParallelGroupbyMethods.time_loop", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.TimeseriesPlotting.time_plot_regular": {"min_run_count": 2, "version": "8e4ad2d184f70b708e3cc9651f4ed4b41930a487768062f6ad7ab7007b2faec7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range('1/1/1975', periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(np.concatenate((idx.values[0:10],\n                                                      idx.values[12:])))\n        self.df2 = DataFrame(np.random.randn(len(idx_irregular), M),\n                             index=idx_irregular)", "number": 0, "name": "plotting.TimeseriesPlotting.time_plot_regular", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.mem_itertuples_raw_start": {"timeout": 120, "code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "80e1d520d71de358eb9febcb43bd308ba565ba00af50eb3f77ccce6a880fe8dd", "params": [], "name": "frame_methods.Iteration.mem_itertuples_raw_start", "param_names": [], "unit": "bytes", "type": "memory"}, "algorithms.DuplicatedUniqueIndex.time_duplicated_unique": {"min_run_count": 2, "version": "0823811b87a4588d104d62b475904fc2a90fd3c5847da557a326ca35b44fc593", "processes": 2, "params": [["'int'", "'uint'", "'float'", "'string'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class DuplicatedUniqueIndex:\n    def time_duplicated_unique(self, dtype):\n        self.idx.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedUniqueIndex:\n    def setup(self, dtype):\n        N = 10**5\n        data = {'int': pd.Int64Index(np.arange(N)),\n                'uint': pd.UInt64Index(np.arange(N)),\n                'float': pd.Float64Index(np.random.randn(N)),\n                'string': tm.makeStringIndex(N)}\n        self.idx = data[dtype]\n        # cache is_unique\n        self.idx.is_unique", "number": 0, "name": "algorithms.DuplicatedUniqueIndex.time_duplicated_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.Methods.time_rolling": {"min_run_count": 2, "version": "c37448c950a67a0a785ee2aec6ce3895c45b542e3533775565131c5cdd20c271", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "type": "time", "warmup_time": -1, "param_names": ["contructor", "window", "dtype", "method"], "timeout": 60.0, "code": "class Methods:\n    def time_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "number": 0, "name": "rolling.Methods.time_rolling", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.ToNumericDowncast.time_downcast": {"min_run_count": 2, "version": "a3bf441be7d1a1da58fe7040606ed5576597205aa570100b6ca3d07c8ecdb8da", "processes": 2, "params": [["'string-float'", "'string-int'", "'string-nint'", "'datetime64'", "'int-list'", "'int32'"], ["None", "'integer'", "'signed'", "'unsigned'", "'float'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype", "downcast"], "timeout": 60.0, "code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]", "number": 0, "name": "inference.ToNumericDowncast.time_downcast", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameStringIndexing.time_loc": {"min_run_count": 2, "version": "9d8d5765ba33fa6795197fd87b467db5f9cad0055fb510978ca7fd850436e675", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        self.df = DataFrame(np.random.randn(1000, 30), index=index,\n                            columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "number": 0, "name": "indexing.DataFrameStringIndexing.time_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Categories.time_groupby_ordered_nosort": {"min_run_count": 2, "version": "c9fedee7fc0495ffce8a51d2ec8f4155dc15f62a080f7bb2b2986868cd56679e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Categories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby('a', sort=False)['b'].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {'a': Categorical(np.random.randint(10000, size=N)),\n                'b': arr}\n        self.df = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(10000, size=N),\n                                 ordered=True),\n                'b': arr}\n        self.df_ordered = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(100, size=N),\n                                 categories=np.arange(10000)),\n                'b': arr}\n        self.df_extra_cat = DataFrame(data)", "number": 0, "name": "groupby.Categories.time_groupby_ordered_nosort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.Reindex.time_reindex_dates": {"min_run_count": 2, "version": "9535d71dea74996dbd9844d418f5fb3cfe9c08a819fa40f7273187f5305d9c8a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start='1/1/1970', periods=10000, freq='1min')\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng,\n                            columns=range(10))\n        self.df['foo'] = 'bar'\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(index=range(10000),\n                             data=np.random.rand(10000, 30), columns=range(30))\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "number": 0, "name": "reindex.Reindex.time_reindex_dates", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Melt.time_melt_dataframe": {"min_run_count": 2, "version": "9ff7dccd7a3661c168095f93092a4c07ebcbcbe7e2dbb5c04d9038a8f4f23489", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Melt:\n    def time_melt_dataframe(self):\n        melt(self.df, id_vars=['id1', 'id2'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 3), columns=['A', 'B', 'C'])\n        self.df['id1'] = np.random.randint(0, 10, 10000)\n        self.df['id2'] = np.random.randint(100, 1000, 10000)", "number": 0, "name": "reshape.Melt.time_melt_dataframe", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_float_mod": {"min_run_count": 2, "version": "159cce47c532ed4522b323129e23e44192389d57696c4c9588eddd9e6693baba", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_float_mod", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Transform.time_transform_multi_key3": {"min_run_count": 2, "version": "418eee471c52fa60c61d27ca6fe9a5173da9ac4fce2a32020babc1c2a7e8de7b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby(['jim', 'joe'])['jolie'].transform('max')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(levels=[np.arange(n1), tm.makeStringIndex(n2)],\n                           codes=[np.repeat(range(n1), n2).tolist(),\n                                  list(range(n2)) * n1],\n                           names=['lev1', 'lev2'])\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=['col1', 'col20', 'col3'])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(np.random.randint(1, n, (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df2 = self.df1.copy()\n        self.df2['jim'] = self.df2['joe']\n    \n        self.df3 = DataFrame(np.random.randint(1, (n / 10), (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df4 = self.df3.copy()\n        self.df4['jim'] = self.df4['joe']", "number": 0, "name": "groupby.Transform.time_transform_multi_key3", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Correlation.time_corr": {"min_run_count": 2, "version": "6ad9887e035f00eb84c2f47efa0156b930f59e7b3245c71aeb4c76fbd8423811", "processes": 2, "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["method", "use_bottleneck"], "timeout": 60.0, "code": "class Correlation:\n    def time_corr(self, method, use_bottleneck):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "number": 0, "name": "stat_ops.Correlation.time_corr", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor_year": {"min_run_count": 2, "version": "ff9461fe3639435c8bdbbd7902d014cdb5b41d6a90eda65e77f11f907ca70b94", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor_year", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.Take.time_take": {"min_run_count": 2, "version": "8cd5ca46f57feb3f777a6575d8a9c3e40153dafa1f1e19ac6ef52769ef3696ea", "processes": 2, "params": [["'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {'int': Int64Index(np.arange(N)),\n                   'datetime': date_range('2011-01-01', freq='S', periods=N)}\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = [True, False, True, True, False] * 20000", "number": 0, "name": "indexing.Take.time_take", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelTake1D.time_take1d": {"min_run_count": 2, "version": "a50d1b7424918875dc88236b44a61e50671b3ae374a307b613ac18e1989f690a", "processes": 2, "params": [["'int64'", "'float64'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        df = DataFrame({'col': np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_1d(df['col'].values, indexer)\n        self.parallel_take1d = parallel_take1d", "number": 0, "name": "gil.ParallelTake1D.time_take1d", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Range.time_max": {"min_run_count": 2, "version": "df04062acb66a8bbaf86d523f30b0a0fd80aeeaf195e757a3c725202f471df14", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**7, step=3)\n        self.idx_dec = RangeIndex(start=10**7, stop=-1, step=-3)", "number": 0, "name": "index_object.Range.time_max", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {"min_run_count": 2, "version": "92d6600eaa8aa59d62746e211d71ad2c2ef61db951d57422539de525c97bf5b5", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_datetimes_with_nat": {"min_run_count": 2, "version": "38ed3719ee4d2eb5623b95d010bdcb47c0645610f6e73bada7233f97fa43392e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_datetimes_with_nat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeCache.time_dup_string_dates": {"min_run_count": 2, "version": "5f878e245734bb44f30d468ac923f1f202ff15cda7ccc68bba13b961da245079", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["cache"], "timeout": 60.0, "code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = ['2000-02-11'] * N\n        self.dup_string_with_tz = ['2000-02-11 15:00:00-0800'] * N", "number": 0, "name": "timeseries.ToDatetimeCache.time_dup_string_dates", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.Quantile.time_quantile": {"min_run_count": 2, "version": "ab257a398266575adf19c2ae12badaf5b818a658fb887b1ed13b58bbbdeb798a", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor", "window", "dtype", "percentile", "param5"], "timeout": 60.0, "code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile,\n                      interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "number": 0, "name": "rolling.Quantile.time_quantile", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_zfill": {"min_run_count": 2, "version": "2b86da2648eeaf9a25e565ac326f96503c38591e3b2bb408b753bca0d5662b0d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_zfill(self):\n        self.s.str.zfill(10)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_zfill", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ReadJSON.time_read_json": {"min_run_count": 2, "version": "ce310f760271ec92ff092e2c8f644e86f470721088a66ce1303931746397095c", "processes": 2, "params": [["'split'", "'index'", "'records'"], ["'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["orient", "index"], "timeout": 60.0, "code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {'int': np.arange(N),\n                   'datetime': date_range('20000101', periods=N, freq='H')}\n        df = DataFrame(np.random.randn(N, 5),\n                       columns=['float_{}'.format(i) for i in range(5)],\n                       index=indexes[index])\n        df.to_json(self.fname, orient=orient)", "number": 0, "name": "io.json.ReadJSON.time_read_json", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.Any.time_any": {"min_run_count": 2, "version": "4d3f7427a6293f97c55191636d560f09ce77f87bdd2cd7b4597939f12ccedd60", "processes": 2, "params": [["1000", "1000000"], ["'fast'", "'slow'"]], "type": "time", "warmup_time": -1, "param_names": ["N", "case"], "timeout": 60.0, "code": "class Any:\n    def time_any(self, N, case):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case):\n        val = case == 'fast'\n        self.s = Series([val] * N)", "number": 0, "name": "series_methods.Any.time_any", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeISO8601.time_iso8601_format": {"min_run_count": 2, "version": "5edeb25d7e8e8afa72656613ba9bf3c44475487a36b5f678f3ad10b7d279217e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format='%Y-%m-%d %H:%M:%S')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start='1/1/2000', periods=20000, freq='H')\n        self.strings = rng.strftime('%Y-%m-%d %H:%M:%S').tolist()\n        self.strings_nosep = rng.strftime('%Y%m%d %H:%M:%S').tolist()\n        self.strings_tz_space = [x.strftime('%Y-%m-%d %H:%M:%S') + ' -0800'\n                                 for x in rng]", "number": 0, "name": "timeseries.ToDatetimeISO8601.time_iso8601_format", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Concat.time_concat_empty_right": {"min_run_count": 2, "version": "3718bf2aa0e2f4742e90164ea30a491fcf771afba895e407cec4543f71da95cf", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:- i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame({'A': range(N)},\n                       index=date_range('20130101', periods=N, freq='s'))\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "number": 0, "name": "join_merge.Concat.time_concat_empty_right", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameStringIndexing.time_getitem_scalar": {"min_run_count": 2, "version": "8eedb8a4730463f7c0aefe6f16628f8a5cc746243b5bb0bd6ee7ac3c4e3b4225", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        self.df = DataFrame(np.random.randn(1000, 30), index=index,\n                            columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "number": 0, "name": "indexing.DataFrameStringIndexing.time_getitem_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_normalize": {"min_run_count": 2, "version": "8b7b75a5b6b6da21dfb1b95822ff9d899b366e42d1b4e3b45131b36b780a75ea", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_normalize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Reindex.time_reindex_axis1": {"min_run_count": 2, "version": "9abf4b2a8a85282aec57bcc6e4fc0f3dd9a52029e4ceb5448dbcd7f25d3d55cf", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Reindex.time_reindex_axis1", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_get_indexer_list": {"min_run_count": 2, "version": "68bc8b8339d60ab59371ded09f05e4a4f6005d417cdca2eb9437b656cb367704", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.SetCategories.time_set_categories": {"min_run_count": 2, "version": "926745104e6906a380ef6c9b9b1a2b683cec5457cc3d8d224cff469fb1327d12", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = ['s{:04d}'.format(i) for i in np.random.randint(0, n // 10,\n                                                              size=n)]\n        self.ts = pd.Series(arr).astype('category')", "number": 0, "name": "categoricals.SetCategories.time_set_categories", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_dot": {"min_run_count": 2, "version": "6021ec8a85c3a8c150039edf0982cf2e0aa4b8581f8cb341e131a25651959766", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_dot", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_cut_float": {"min_run_count": 2, "version": "81f732e5e39b4500edff46d860e0cfb2008676e7652db23eb911ad37fd392180", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_cut_float", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeOrdered.time_merge_ordered": {"min_run_count": 2, "version": "86c9454e849c65f79396028198dec05fa111c44dd14bd2334770a93779be22c3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on='key', left_by='group')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = tm.makeStringIndex(10).values\n        self.left = DataFrame({'group': groups.repeat(5000),\n                               'key': np.tile(np.arange(0, 10000, 2), 10),\n                               'lvalue': np.random.randn(50000)})\n        self.right = DataFrame({'key': np.arange(10000),\n                                'rvalue': np.random.randn(10000)})", "number": 0, "name": "join_merge.MergeOrdered.time_merge_ordered", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.Arithmetic.time_add": {"min_run_count": 2, "version": "0d136ab28e84e46c4e65cc5c620cda2db76499833c04fd23e4e5ec0feaf2f85c", "processes": 2, "params": [["0.1", "0.01"], ["0", "nan"]], "type": "time", "warmup_time": -1, "param_names": ["dense_proportion", "fill_value"], "timeout": 60.0, "code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "number": 0, "name": "sparse.Arithmetic.time_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.TimeseriesPlotting.time_plot_regular_compat": {"min_run_count": 2, "version": "0ad703b2df8a2865448c3241ded65ed8ca8c5b4ef4da06f6f534533f71227fa1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range('1/1/1975', periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(np.concatenate((idx.values[0:10],\n                                                      idx.values[12:])))\n        self.df2 = DataFrame(np.random.randn(len(idx_irregular), M),\n                             index=idx_irregular)", "number": 0, "name": "plotting.TimeseriesPlotting.time_plot_regular_compat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDicts.time_list_of_dict": {"min_run_count": 2, "version": "308d600de04822c9309bd15640fb6e2c2587e7fbac5658bc6926ffeea972d49c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index,\n                          columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient='records')\n        self.data2 = {i: {j: float(j) for j in range(100)}\n                      for i in range(2000)}", "number": 0, "name": "frame_ctor.FromDicts.time_list_of_dict", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Rename.time_rename_axis1": {"min_run_count": 2, "version": "ad1cfc438960e74198a359a4bb1bd894c91189b245231e8a6f9723a8dea5e6e9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Rename.time_rename_axis1", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVParseDates.time_multiple_date": {"min_run_count": 2, "version": "3717ac9a37154b757a6f039b42d0d1735bbbacb3e3785942b4f2ac7ef71e5940", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadCSVParseDates:\n    def time_multiple_date(self):\n        read_csv(self.data(self.StringIO_input), sep=',', header=None,\n                 names=list(string.digits[:9]),\n                 parse_dates=[[1, 2], [1, 3]])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = ['KORD,19990127'] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ReadCSVParseDates.time_multiple_date", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {"min_run_count": 2, "version": "a5e8b23cfdacc13bcfa9f1d2a3967cbceaee5752d9cd27cdca1d467243cc3505", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=['A'])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "number": 0, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffestDatetimeArithmetic.time_subtract": {"min_run_count": 2, "version": "b55fecdee22d38d00c96d704c751c2419fb5139e5438bf2c22eea3d3ccda3a6a", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64('2011-01-01 09:00Z')", "number": 0, "name": "offset.OffestDatetimeArithmetic.time_subtract", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffestDatetimeArithmetic.time_add": {"min_run_count": 2, "version": "239bd18da68fb7be7235eac7fbd36267719a336acdc8aeaf0b142843f2865c5f", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64('2011-01-01 09:00Z')", "number": 0, "name": "offset.OffestDatetimeArithmetic.time_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_month_start": {"min_run_count": 2, "version": "f7e8963a4580727002192d1b56e4f768e142dde6850d0344f5d86104272545b9", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_month_start(self, tz, freq):\n        self.ts.is_month_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_month_start", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_floats_with_int_index": {"min_run_count": 2, "version": "ef0adc068504b0dc1ed71459189c3c476c43f84f439836227b4e6848e518e3b0", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_floats_with_int_index(self, orient):\n        self.df.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_floats_with_int_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.InferFreq.time_infer_freq": {"min_run_count": 2, "version": "8c0a1e7aeeeaa84ea01b9e4d81eef7c54e85d310ee7528691d5e4d4b2723ebe5", "processes": 2, "params": [["None", "'D'", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["freq"], "timeout": 60.0, "code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start='1/1/1700', freq='D', periods=10000)\n            self.idx.freq = None\n        else:\n            self.idx = date_range(start='1/1/1700', freq=freq, periods=10000)", "number": 0, "name": "timeseries.InferFreq.time_infer_freq", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVCategorical.time_convert_post": {"min_run_count": 2, "version": "453688035ee74d4c0a3c13214995cf70509bb2fb02695854d270033590084f4e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadCSVCategorical:\n    def time_convert_post(self):\n        read_csv(self.fname).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self):\n        N = 100000\n        group1 = ['aaaaaaaa', 'bbbbbbb', 'cccccccc', 'dddddddd', 'eeeeeeee']\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list('abc'))\n        df.to_csv(self.fname, index=False)", "number": 0, "name": "io.csv.ReadCSVCategorical.time_convert_post", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Contains.time_categorical_index_contains": {"min_run_count": 2, "version": "ec9d8f8c495f584315db66c9aed5c6a9c4076331d68eab8d4457d5d92dbce29c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "number": 0, "name": "categoricals.Contains.time_categorical_index_contains", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodConstructor.time_period_constructor": {"min_run_count": 2, "version": "ddb92ac438e94cf385080a0e1486b8b8373b48d1c88551e6a2905fdbdc89c10d", "processes": 2, "params": [["'D'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["freq", "is_offset"], "timeout": 60.0, "code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period('2012-06-01', freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "number": 0, "name": "period.PeriodConstructor.time_period_constructor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_store_str": {"min_run_count": 2, "version": "6202a79d18076437d1b36cda3a2690d508825449ce1cb6f747b761a966474bfb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_store_str", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_lstrip": {"min_run_count": 2, "version": "a9773282c8259841d1b123e4b7358b494c93ef73be67e92ddfeda61d248005c8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_lstrip(self):\n        self.s.str.lstrip('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_lstrip", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_to_list": {"min_run_count": 2, "version": "6fd03152a301fefda716e78871d40df86d04b6074a070c0c894b75a77464357a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_to_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.TimeDatetimeConverter.time_convert": {"min_run_count": 2, "version": "86ea9d7194a6992898477a15bb2bb1ea2a372322a2b448897073c019b5b0c4ed", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start='1/1/2000', periods=N, freq='T')", "number": 0, "name": "timeseries.TimeDatetimeConverter.time_convert", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_slice_step": {"min_run_count": 2, "version": "9ed1e38e6e904f8bfca613453c5baa10e8f5b04fa02d848e65e19660ac0ee610", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_slice_step", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_qcut_float": {"min_run_count": 2, "version": "9ffb5a7eef36f934b59f4881cd2413f98ccee465ffec60c5548e8c23607ae1d7", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_qcut_float", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {"min_run_count": 2, "version": "791f88ffdc8ac37027d12e5dab9d8bab2fbe303fd45a7dbd27cad1e6e16f845e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list('a' * N + 'b' * N + 'c' * N))\n        self.s = pd.Series(self.c)", "number": 0, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_float_floor_by_zero": {"min_run_count": 2, "version": "4b5168a31076ff89a35654f622b06e87379d2d366919e4d777a912cfdf2f65b6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_float_floor_by_zero", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_timeseries_is_month_start": {"min_run_count": 2, "version": "6eb6090188def009a3927b6a59940599afb5621ea564b6e6e721b24cf6302278", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_upper": {"min_run_count": 2, "version": "97fc9ef4ba304acdcdaa07c0494263350bfcc908ceee19cd5c99f930dae1acea", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_upper(self):\n        self.s.str.upper()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_upper", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.SetOperations.time_operation": {"min_run_count": 2, "version": "40ca898c325ceb01dc464328224bccc201f01996a3087540b381a80f43d2a9ed", "processes": 2, "params": [["'datetime'", "'date_string'", "'int'", "'strings'"], ["'intersection'", "'union'", "'symmetric_difference'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype", "method"], "timeout": 60.0, "code": "class SetOperations:\n    def time_operation(self, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, dtype, method):\n        N = 10**5\n        dates_left = date_range('1/1/2000', periods=N, freq='T')\n        fmt = '%Y-%m-%d %H:%M:%S'\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        str_left = tm.makeStringIndex(N)\n        data = {'datetime': {'left': dates_left, 'right': dates_left[:-1]},\n                'date_string': {'left': date_str_left,\n                                'right': date_str_left[:-1]},\n                'int': {'left': int_left, 'right': int_left[:-1]},\n                'strings': {'left': str_left, 'right': str_left[:-1]}}\n        self.left = data[dtype]['left']\n        self.right = data[dtype]['right']", "number": 0, "name": "index_object.SetOperations.time_operation", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.PeakMemFixed.peakmem_fixed": {"timeout": 60.0, "code": "class PeakMemFixed:\n    def peakmem_fixed(self):\n        # GH 25926\n        # This is to detect memory leaks in rolling operations.\n        # To save time this is only ran on one method.\n        # 6000 iterations is enough for most types of leaks to be detected\n        for x in range(6000):\n            self.roll.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixed:\n    def setup(self):\n        N = 10\n        arr = 100 * np.random.random(N)\n        self.roll = pd.Series(arr).rolling(10)", "version": "77ce1c06e460c88101541ae777e23badf244aa97c5ec3ac3b20b71aca6c82186", "params": [], "name": "rolling.PeakMemFixed.peakmem_fixed", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "io.csv.ToCSVDatetimeBig.time_frame": {"min_run_count": 2, "version": "c39ff8669126a503ab8e2a8897c81daad236b1b571e95aedd50034f193850fcc", "processes": 2, "params": [["1000", "10000", "100000"]], "type": "time", "warmup_time": -1, "param_names": ["obs"], "timeout": 1500, "code": "class ToCSVDatetimeBig:\n    def time_frame(self, obs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, obs):\n        d = '2018-11-29'\n        dt = '2018-11-26 11:18:27.0'\n        self.data = DataFrame({'dt': [np.datetime64(dt)] * obs,\n                               'd': [np.datetime64(d)] * obs,\n                               'r': [np.random.uniform()] * obs})", "number": 0, "name": "io.csv.ToCSVDatetimeBig.time_frame", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "ctors.SeriesDtypesConstructors.time_index_from_array_string": {"min_run_count": 2, "version": "0e8b905a2341af27ae705e2142a46a110359a9facf055f40527343b6be7723e3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array(['foo', 'bar', 'baz'], dtype=object)\n        self.s = Series([Timestamp('20110101'), Timestamp('20120101'),\n                         Timestamp('20130101')] * N * 10)", "number": 0, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {"min_run_count": 2, "version": "896e9990bbf159ada61b4623fff67e6bd58789eca5e50cbb51add7f87dc81866", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array(['foo', 'bar', 'baz'], dtype=object)\n        self.s = Series([Timestamp('20110101'), Timestamp('20120101'),\n                         Timestamp('20130101')] * N * 10)", "number": 0, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Merge.time_merge_dataframe_integer_key": {"min_run_count": 2, "version": "6ff6e607ec8c29543b1e48cd7cb9aafd1d97872daef0aa4432834cbfc87745ce", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on='key1', sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame({'key': key, 'key2': key2,\n                               'value': np.random.randn(80000)})\n        self.right = DataFrame({'key': indices[2000:],\n                                'key2': indices2[2000:],\n                                'value2': np.random.randn(8000)})\n    \n        self.df = DataFrame({'key1': np.tile(np.arange(500).repeat(10), 2),\n                             'key2': np.tile(np.arange(250).repeat(10), 4),\n                             'value': np.random.randn(10000)})\n        self.df2 = DataFrame({'key1': np.arange(500),\n                              'value2': np.random.randn(500)})\n        self.df3 = self.df[:5000]", "number": 0, "name": "join_merge.Merge.time_merge_dataframe_integer_key", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffestDatetimeArithmetic.time_apply_np_dt64": {"min_run_count": 2, "version": "5316320ed78c435f986b5d2ad0126a46982b3372a097707418559b0429801b41", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffestDatetimeArithmetic:\n    def time_apply_np_dt64(self, offset):\n        offset.apply(self.dt64)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64('2011-01-01 09:00Z')", "number": 0, "name": "offset.OffestDatetimeArithmetic.time_apply_np_dt64", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_iloc_scalar": {"min_run_count": 2, "version": "f6aac4ba76c369fe8af819313b87a05abebf8eca7b9d46ae36cc707c52b66e61", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_iloc_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OnOffset.time_on_offset": {"min_run_count": 2, "version": "642e9bf7b243d80a6d3fdfa39787d73f57cb783a9bcc7d089526de4090ac7f35", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.onOffset(date)\n\n    def setup(self, offset):\n        self.dates = [datetime(2016, m, d)\n                      for m in [10, 11, 12]\n                      for d in [1, 2, 3, 28, 29, 30, 31]\n                      if not (m == 11 and d == 31)]", "number": 0, "name": "offset.OnOffset.time_on_offset", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVThousands.time_thousands": {"min_run_count": 2, "version": "dbe86cde594d28cf8609a8012bd493f2c24b09c53b8b202babc57ad7b3cd25f1", "processes": 2, "params": [["','", "'|'"], ["None", "','"]], "type": "time", "warmup_time": -1, "param_names": ["sep", "thousands"], "timeout": 60.0, "code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands):\n        read_csv(self.fname, sep=sep, thousands=thousands)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = ':{}'.format(thousands)\n            fmt = '{' + fmt + '}'\n            df = df.applymap(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)", "number": 0, "name": "io.csv.ReadCSVThousands.time_thousands", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Rank.time_rank_string_cat": {"min_run_count": 2, "version": "84e26ca3b644fa2faf9d3eca05445c5b3a10e9129678552e427a135d00280924", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = self.s_str.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_str_cat_ordered = self.s_str.astype('category',\n                                                       ordered=True)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = self.s_int.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_int_cat_ordered = self.s_int.astype('category',\n                                                       ordered=True)", "number": 0, "name": "categoricals.Rank.time_rank_string_cat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.excel.Excel.time_read_excel": {"min_run_count": 2, "version": "f88ee2da591a1a7695ca8f2cee5bfea573e9502aa599f28521fba13d8a02d6fe", "processes": 2, "params": [["'openpyxl'", "'xlsxwriter'", "'xlwt'"]], "type": "time", "warmup_time": -1, "param_names": ["engine"], "timeout": 60.0, "code": "class Excel:\n    def time_read_excel(self, engine):\n        read_excel(self.bio_read)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Excel:\n    def setup(self, engine):\n        N = 2000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.bio_read = BytesIO()\n        self.writer_read = ExcelWriter(self.bio_read, engine=engine)\n        self.df.to_excel(self.writer_read, sheet_name='Sheet1')\n        self.writer_read.save()\n        self.bio_read.seek(0)", "number": 0, "name": "io.excel.Excel.time_read_excel", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDicts.time_nested_dict_int64": {"min_run_count": 2, "version": "189f4b632b0fa7e9a9167c406c7d7fa69d7c854082e246fe20ab85d7b4daa274", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index,\n                          columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient='records')\n        self.data2 = {i: {j: float(j) for j in range(100)}\n                      for i in range(2000)}", "number": 0, "name": "frame_ctor.FromDicts.time_nested_dict_int64", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "attrs_caching.CacheReadonly.time_cache_readonly": {"min_run_count": 2, "version": "09932b155c4d43557cb36f57589ef3d1e2e06968e0adb6bb05fc05ad5d2884b9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CacheReadonly:\n    def setup(self):\n    \n        class Foo:\n    \n            @cache_readonly\n            def prop(self):\n                return 5\n        self.obj = Foo()", "number": 0, "name": "attrs_caching.CacheReadonly.time_cache_readonly", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDicts.time_nested_dict_index": {"min_run_count": 2, "version": "b0f190b6578b26e8ada74a2a0799fc3d496268b4e33d31f2fc8358d305542965", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index,\n                          columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient='records')\n        self.data2 = {i: {j: float(j) for j in range(100)}\n                      for i in range(2000)}", "number": 0, "name": "frame_ctor.FromDicts.time_nested_dict_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.MethodLookup.time_lookup_ix": {"min_run_count": 2, "version": "b831ca1369b3c78d45afe08bdd3124f200210485f2383e0a0bde9e3f96523e20", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MethodLookup:\n    def time_lookup_ix(self, s):\n        s.ix\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:282", "number": 0, "name": "indexing.MethodLookup.time_lookup_ix", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_find": {"min_run_count": 2, "version": "a4c4842f8b7a8cdc4f13144915e527344e4d0af92b25a323dd59d05cee8c1f26", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_find(self):\n        self.s.str.find('[A-Z]+')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_find", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.MethodLookup.time_lookup_loc": {"min_run_count": 2, "version": "513fe43a7b6d5bafa7f3ab6edd7d17d16ee76988a435c950cfd10a89236d6c7c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:282", "number": 0, "name": "indexing.MethodLookup.time_lookup_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.AggFunctions.time_different_str_functions": {"min_run_count": 2, "version": "ff2229aacb6b3b38042603a402897d754686e16bcc1b2ecb9d8f3194eaa4931f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby(['key1', 'key2']).agg({'value1': 'mean',\n                                          'value2': 'var',\n                                          'value3': 'sum'})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        df = DataFrame({'key1': fac1.take(np.random.randint(0, 3, size=N)),\n                        'key2': fac2.take(np.random.randint(0, 2, size=N)),\n                        'value1': np.random.randn(N),\n                        'value2': np.random.randn(N),\n                        'value3': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:214", "number": 0, "name": "groupby.AggFunctions.time_different_str_functions", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.DropDuplicates.time_series_drop_dups_int": {"min_run_count": 2, "version": "57887d596d88ffd60a1221cc0954e88cea53b5fa3f314c80c3dac59d3e00e6ce", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame({'key1': key1, 'key2': key2,\n                             'value': np.random.randn(N * K)})\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({'key1': key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10),\n                                                   dtype=bool))", "number": 0, "name": "reindex.DropDuplicates.time_series_drop_dups_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelGroups.time_get_groups": {"min_run_count": 2, "version": "ba00edac2f208257692d21efdb11e6330e8e7b12ff9b5b8e0886358f42baf4e1", "processes": 2, "params": [["2", "4", "8"]], "type": "time", "warmup_time": -1, "param_names": ["threads"], "timeout": 60.0, "code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        size = 2**22\n        ngroups = 10**3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n        self.get_groups = get_groups", "number": 0, "name": "gil.ParallelGroups.time_get_groups", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Range.time_max_trivial": {"min_run_count": 2, "version": "634f6c12789c57a965a9be94b658fb4943f362742cd390438896367b1626ae78", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**7, step=3)\n        self.idx_dec = RangeIndex(start=10**7, stop=-1, step=-3)", "number": 0, "name": "index_object.Range.time_max_trivial", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelGroupbyMethods.time_parallel": {"min_run_count": 2, "version": "5bb8339bc5daf19262fd5f4a9a47afddf95b9363849d34a46fedf456f8882c50", "processes": 2, "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "type": "time", "warmup_time": -1, "param_names": ["threads", "method"], "timeout": 60.0, "code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame({'key': np.random.randint(0, ngroups, size=N),\n                        'data': np.random.randn(N)})\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby('key')['data'], method)()\n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby('key')['data'], method)()\n        self.loop = loop", "number": 0, "name": "gil.ParallelGroupbyMethods.time_parallel", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.NumericInferOps.time_divide": {"min_run_count": 2, "version": "7308ec976387fddd094803e30d49775f2122ebf50d66c83af836ec161abba542", "processes": 2, "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df['A'] / self.df['B']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame({'A': np.arange(N).astype(dtype),\n                             'B': np.arange(N).astype(dtype)})", "number": 0, "name": "inference.NumericInferOps.time_divide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_existing_series": {"min_run_count": 2, "version": "3c853acba6aae34578f5fd759db7d7f37799ebe9aed8f849cd10e351d10b5c7f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_existing_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_slice": {"min_run_count": 2, "version": "794f38bac4d5c60783004c3403df5a4faefd56fe86d8f9ff3d3032f5b4875184", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_slice(self):\n        self.s.str.slice(5, 15, 2)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_unique": {"min_run_count": 2, "version": "85881223e6f402855faf8f81ef300a39117dfbf064133812b066af1745a8103d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_series_dot": {"min_run_count": 2, "version": "0518fd9038b0fb0cac8931891de40ae4278b6adb129d476f62983abb0e170e24", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_series_dot", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Sortlevel.time_sortlevel_int64": {"min_run_count": 2, "version": "ebc0379f7062091aa1b64e8fb82f64863ac38ab02e144950feb9e1aa28503666", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [np.repeat(np.random.randint(low, high, (n // k)), k)\n                for k in [11, 7, 5, 3, 1]]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "number": 0, "name": "multiindex_object.Sortlevel.time_sortlevel_int64", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.Reindex.time_reindex_columns": {"min_run_count": 2, "version": "299d4cfa7c239d209b757213d27d0b077ca58c6681477d43798159d3bf27afc8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start='1/1/1970', periods=10000, freq='1min')\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng,\n                            columns=range(10))\n        self.df['foo'] = 'bar'\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(index=range(10000),\n                             data=np.random.rand(10000, 30), columns=range(30))\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "number": 0, "name": "reindex.Reindex.time_reindex_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_float_div": {"min_run_count": 2, "version": "8ba0caad66648cca90b6c2ae479b59cfb4612b5ace6850056fa4e138c0c09058", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_float_div", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromNDArray.time_frame_from_ndarray": {"min_run_count": 2, "version": "6fb5f6568d301464fbdc79a5b9701a4b5435aee21d09337b878ce3a016c89d80", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)", "number": 0, "name": "frame_ctor.FromNDArray.time_frame_from_ndarray", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Split.time_rsplit": {"min_run_count": 2, "version": "d87346b85d236b71aea26ddd8cd6182f8a0af6fee52c20acc935e7e38ece3a4c", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["expand"], "timeout": 60.0, "code": "class Split:\n    def time_rsplit(self, expand):\n        self.s.str.rsplit('--', expand=expand)\n\n    def setup(self, expand):\n        self.s = Series(tm.makeStringIndex(10**5)).str.join('--')", "number": 0, "name": "strings.Split.time_rsplit", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.CountMultiInt.time_multi_int_count": {"min_run_count": 2, "version": "5a4077e68efb98b3cec471d06896f83cc47386eb91304c7fa367a17993cb4a18", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby(['key1', 'key2']).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame({'key1': np.random.randint(0, 500, size=n),\n                        'key2': np.random.randint(0, 100, size=n),\n                        'ints': np.random.randint(0, 1000, size=n),\n                        'ints2': np.random.randint(0, 1000, size=n)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:197", "number": 0, "name": "groupby.CountMultiInt.time_multi_int_count", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Rank.time_rank_string": {"min_run_count": 2, "version": "2b37b35c9b061fca1392fe0ca0dcb0e7f90637afec9592da85623321d7b7517a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = self.s_str.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_str_cat_ordered = self.s_str.astype('category',\n                                                       ordered=True)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = self.s_int.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_int_cat_ordered = self.s_int.astype('category',\n                                                       ordered=True)", "number": 0, "name": "categoricals.Rank.time_rank_string", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_year_end": {"min_run_count": 2, "version": "eaff818df2139b7c0f81e1ae6747fd8c295d9a15f2b3ee8f7843a4261e458b10", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_year_end(self, tz, freq):\n        self.ts.is_year_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_year_end", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampAcrossDst.time_replace_across_dst": {"min_run_count": 2, "version": "2753f2e4836bfe6344d533745807566c63b19ba7488b986cff77956ff38d92e3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime.datetime(2016, 3, 27, 1)\n        self.tzinfo = pytz.timezone('CET').localize(dt, is_dst=False).tzinfo\n        self.ts2 = Timestamp(dt)", "number": 0, "name": "timestamp.TimestampAcrossDst.time_replace_across_dst", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.ValueCounts.time_value_counts": {"min_run_count": 2, "version": "96468feb76190801a31466445c331b28d4e65aba6b0197a5009ee4474cb02953", "processes": 2, "params": [["'int'", "'uint'", "'float'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class ValueCounts:\n    def time_value_counts(self, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000)).astype(dtype)", "number": 0, "name": "series_methods.ValueCounts.time_value_counts", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {"timeout": 60.0, "code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient='records', lines=True,\n                         chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {'int': np.arange(N),\n                   'datetime': date_range('20000101', periods=N, freq='H')}\n        df = DataFrame(np.random.randn(N, 5),\n                       columns=['float_{}'.format(i) for i in range(5)],\n                       index=indexes[index])\n        df.to_json(self.fname, orient='records', lines=True)", "version": "ac55075b26f6151b655d20bfeee8c6f9bad68691c5887d6672ea4f33c6c0f510", "params": [["'int'", "'datetime'"]], "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat", "param_names": ["index"], "unit": "bytes", "type": "peakmemory"}, "multiindex_object.GetLoc.time_med_get_loc": {"min_run_count": 2, "version": "5c6569cf420dc79fcf77ef6c5c87b64a8c118705ffe5b32536593516ada30801", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, 'A'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=['one', 'two', 'three'])\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list('A')],\n            names=['one', 'two', 'three'])\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list('A'), list('A')],\n            names=['one', 'two', 'three'])", "number": 0, "name": "multiindex_object.GetLoc.time_med_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Unstack.time_without_last_row": {"min_run_count": 2, "version": "3e8620145aeb1e26faae19c8d13dbbd101f15c56764af80802c25aa40f49c884", "processes": 2, "params": [["'int'", "'category'"]], "type": "time", "warmup_time": -1, "param_names": ["param1"], "timeout": 60.0, "code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == 'int':\n            values = np.arange(m * m * n).reshape(m * m, n)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n        self.df = DataFrame(values, index, columns)\n        self.df2 = self.df.iloc[:-1]", "number": 0, "name": "reshape.Unstack.time_without_last_row", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "08ea273d3699bb259359293157138abbac8819bf6408bf361e0e3b88f22e0f56", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "timeseries.DatetimeIndex.time_add_timedelta": {"min_run_count": 2, "version": "0b5fbaf57e00d2bb0bd97d1dd2a2b5d80376f55b2763741099965d11b1b0ab9b", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_add_timedelta", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Lookup.time_frame_fancy_lookup": {"min_run_count": 2, "version": "1f8ce97eadf7bc31ca727258ed6110f13ec7a0a0061be4b42a1cfb58717cad3c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Lookup:\n    def time_frame_fancy_lookup(self):\n        self.df.lookup(self.row_labels, self.col_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8),\n                            columns=list('abcdefgh'))\n        self.df['foo'] = 'bar'\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype='object')\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype='object')", "number": 0, "name": "frame_methods.Lookup.time_frame_fancy_lookup", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.FramePlotting.time_frame_plot": {"min_run_count": 2, "version": "8a352da8734840ca66f0904ccbac60ce23de837137f6ba707697ed9b90c29cb9", "processes": 2, "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'", "'scatter'", "'hexbin'"]], "type": "time", "warmup_time": -1, "param_names": ["kind"], "timeout": 60.0, "code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x='x', y='y', kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in ['bar', 'barh', 'pie']:\n            n = 100\n        elif kind in ['kde', 'scatter', 'hexbin']:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in ['area', 'pie']:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({'x': self.x, 'y': self.y})", "number": 0, "name": "plotting.FramePlotting.time_frame_plot", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelRolling.time_rolling": {"min_run_count": 2, "version": "b3a88e4dd2ded5d628206c4b8fd288d3e2d35453d3837837aaf3192112a9134f", "processes": 2, "params": [["'median'", "'mean'", "'min'", "'max'", "'var'", "'skew'", "'kurt'", "'std'"]], "type": "time", "warmup_time": -1, "param_names": ["method"], "timeout": 60.0, "code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, 'rolling'):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {'median': rolling_median,\n                       'mean': rolling_mean,\n                       'min': rolling_min,\n                       'max': rolling_max,\n                       'var': rolling_var,\n                       'skew': rolling_skew,\n                       'kurt': rolling_kurt,\n                       'std': rolling_std}\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError", "number": 0, "name": "gil.ParallelRolling.time_rolling", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.TimeseriesPlotting.time_plot_table": {"min_run_count": 2, "version": "60398892f1b6933cfce5e0b715c58f0d27bd6748f3243be223568c1a7acf8236", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range('1/1/1975', periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(np.concatenate((idx.values[0:10],\n                                                      idx.values[12:])))\n        self.df2 = DataFrame(np.random.randn(len(idx_irregular), M),\n                             index=idx_irregular)", "number": 0, "name": "plotting.TimeseriesPlotting.time_plot_table", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.DateInferOps.time_add_timedeltas": {"min_run_count": 2, "version": "197f4e6f418e1915bfd7d2d1dc45744745faea5435c1dd38e680fd7cd800edf9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df['timedelta'] + df['timedelta']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({'datetime64': np.arange(N).astype('datetime64[ms]')})\n        df['timedelta'] = df['datetime64'] - df['datetime64']\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:36", "number": 0, "name": "inference.DateInferOps.time_add_timedeltas", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Equals.time_frame_object_equal": {"min_run_count": 2, "version": "84138491a8bf938b7cf378207bac6b1be61fbdd780ae996b9070fa6a60545a61", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame('foo', index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = ['A'] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "number": 0, "name": "frame_methods.Equals.time_frame_object_equal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Unstack.time_full_product": {"min_run_count": 2, "version": "84f7e50645107b30af81d10d0bba72c12806e4e6ff50e4cf9b5889382aee722d", "processes": 2, "params": [["'int'", "'category'"]], "type": "time", "warmup_time": -1, "param_names": ["param1"], "timeout": 60.0, "code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == 'int':\n            values = np.arange(m * m * n).reshape(m * m, n)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n        self.df = DataFrame(values, index, columns)\n        self.df2 = self.df.iloc[:-1]", "number": 0, "name": "reshape.Unstack.time_full_product", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Algorithms.time_drop_duplicates": {"min_run_count": 2, "version": "13568d09a813b66ba82e3fc454a69761611bb32c6cd92a0dff09b303941c0421", "processes": 2, "params": [["'index'", "'series'"]], "type": "time", "warmup_time": -1, "param_names": ["typ"], "timeout": 60.0, "code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [Period('2011-01', freq='M'), Period('2011-02', freq='M'),\n                Period('2011-03', freq='M'), Period('2011-04', freq='M')]\n    \n        if typ == 'index':\n            self.vector = PeriodIndex(data * 1000, freq='M')\n        elif typ == 'series':\n            self.vector = Series(data * 1000)", "number": 0, "name": "period.Algorithms.time_drop_duplicates", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.IrregularOps.time_add": {"min_run_count": 2, "version": "f92d79ae9f80fb267dee1f222045492b405d50a945a28810795449b239a5af50", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10**5\n        idx = date_range(start='1/1/2000', periods=N, freq='s')\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)", "number": 0, "name": "timeseries.IrregularOps.time_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Duplicates.time_remove_unused_levels": {"min_run_count": 2, "version": "fa542ac54bbc217d26212018908ec74758f12280c017ce10ace73a27b062ed26", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size),\n                  np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]", "number": 0, "name": "multiindex_object.Duplicates.time_remove_unused_levels", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_unique": {"min_run_count": 2, "version": "23649288213f71428a309069ca4d6fd0c1ce46d62a81e3c21fb7437cfcb957a2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_partition": {"min_run_count": 2, "version": "7e0da1f04d47c1429e0aab3ec88632c900a11fbc9d8f7d74fb5f043879d8c4be", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_partition(self):\n        self.s.str.partition('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_partition", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.DatetimeAccessor.time_dt_accessor": {"min_run_count": 2, "version": "f1d34238960840c80b96c1796526209f01fb8e299120bbf964f04ff1317dc421", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range('1 days', periods=N, freq='h'))\n        return series", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:102", "number": 0, "name": "timedelta.DatetimeAccessor.time_dt_accessor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.Misc.time_plot_andrews_curves": {"min_run_count": 2, "version": "8f47bd0d5438464b173f9ee18371bb42204c8000e20b5168017dbc86c33830ca", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df['Name'] = [\"A\"] * N", "number": 0, "name": "plotting.Misc.time_plot_andrews_curves", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelKth.time_kth_smallest": {"min_run_count": 2, "version": "dffa5ddb01af06c249a08bcb310a5f1cbe62258d755efbca855bf8d781c01399", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**7\n        k = 5 * 10**5\n        kwargs_list = [{'arr': np.random.randn(N)},\n                       {'arr': np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n        self.parallel_kth_smallest = parallel_kth_smallest", "number": 1, "name": "gil.ParallelKth.time_kth_smallest", "sample_time": 0.01, "unit": "seconds", "repeat": 5}, "groupby.Categories.time_groupby_nosort": {"min_run_count": 2, "version": "3f1fc82278d57930118e8fed28a073bfb47fda99b4414171e3def8a7f6ace495", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Categories:\n    def time_groupby_nosort(self):\n        self.df.groupby('a', sort=False)['b'].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {'a': Categorical(np.random.randint(10000, size=N)),\n                'b': arr}\n        self.df = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(10000, size=N),\n                                 ordered=True),\n                'b': arr}\n        self.df_ordered = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(100, size=N),\n                                 categories=np.arange(10000)),\n                'b': arr}\n        self.df_extra_cat = DataFrame(data)", "number": 0, "name": "groupby.Categories.time_groupby_nosort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_rstrip": {"min_run_count": 2, "version": "f5b7b44f19ad4140d76e2e07f39342b2373f5d9a76001d585cf9e3f27b51813a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_rstrip(self):\n        self.s.str.rstrip('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_rstrip", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.AddOverflowScalar.time_add_overflow_scalar": {"min_run_count": 2, "version": "0476db784a12d674a0f6fa7b3be1cc3a6af3b22c984f3739f05471aa89ccb8a6", "processes": 2, "params": [["1", "-1", "0"]], "type": "time", "warmup_time": -1, "param_names": ["scalar"], "timeout": 60.0, "code": "class AddOverflowScalar:\n    def time_add_overflow_scalar(self, scalar):\n        checked_add_with_arr(self.arr, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowScalar:\n    def setup(self, scalar):\n        N = 10**6\n        self.arr = np.arange(N)", "number": 0, "name": "binary_ops.AddOverflowScalar.time_add_overflow_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.ArithmeticBlock.time_addition": {"min_run_count": 2, "version": "5e83060484a52a482a1152491fa5dc1a63a38e32d6ee8b21a3bd046b6aadab5f", "processes": 2, "params": [["nan", "0"]], "type": "time", "warmup_time": -1, "param_names": ["fill_value"], "timeout": 60.0, "code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)\n        self.arr2 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)", "number": 0, "name": "sparse.ArithmeticBlock.time_addition", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Sortlevel.time_sortlevel_one": {"min_run_count": 2, "version": "aeed8480bcb392a4f9f3988627007deb15b30c3b22ff8cc94bbeba5a839fe8c8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [np.repeat(np.random.randint(low, high, (n // k)), k)\n                for k in [11, 7, 5, 3, 1]]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "number": 0, "name": "multiindex_object.Sortlevel.time_sortlevel_one", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Join.time_join_dataframe_index_single_key_bigger": {"min_run_count": 2, "version": "b9fac92a0adc1dff01edd1fd0688af089e445b82d591d372113b6d0c4d27a31b", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on='key2', sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2],\n                            codes=[codes1, codes2])\n        self.df_multi = DataFrame(np.random.randn(len(index2), 4),\n                                  index=index2,\n                                  columns=['A', 'B', 'C', 'D'])\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame({'data1': np.random.randn(100000),\n                             'data2': np.random.randn(100000),\n                             'key1': self.key1,\n                             'key2': self.key2})\n    \n        self.df_key1 = DataFrame(np.random.randn(len(level1), 4),\n                                 index=level1,\n                                 columns=['A', 'B', 'C', 'D'])\n        self.df_key2 = DataFrame(np.random.randn(len(level2), 4),\n                                 index=level2,\n                                 columns=['A', 'B', 'C', 'D'])\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "number": 0, "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Apply.time_scalar_function_multi_col": {"min_run_count": 2, "version": "d558a24afc983b101b6dd13def74be5ba0c6a135ee034145acffabc1899f7486", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_scalar_function_multi_col(self, df):\n        df.groupby(['key', 'key2']).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10**4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame({'key': labels,\n                        'key2': labels2,\n                        'value1': np.random.randn(N),\n                        'value2': ['foo', 'bar', 'baz', 'qux'] * (N // 4)\n                        })\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:35", "number": 0, "name": "groupby.Apply.time_scalar_function_multi_col", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.CountMultiDtype.time_multi_count": {"min_run_count": 2, "version": "745d2d06d247752abe3d43af5f57f85dd1f4b516349ce469d36ff5b754be377a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby(['key1', 'key2']).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype('timedelta64[ns]')\n        dates = np.datetime64('now') + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64('nat')\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64('nat')\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list('ab'), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame({'key1': np.random.randint(0, 500, size=n),\n                        'key2': np.random.randint(0, 100, size=n),\n                        'dates': dates,\n                        'value2': value2,\n                        'value3': np.random.randn(n),\n                        'ints': np.random.randint(0, 1000, size=n),\n                        'obj': obj,\n                        'offsets': offsets})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:171", "number": 0, "name": "groupby.CountMultiDtype.time_multi_count", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Values.time_datetime_level_values_copy": {"min_run_count": 2, "version": "2856b85a22c764b065a36cc0345ebfd5f330450a84325608bdfd002e1bf204ff", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start='1/1/2012', periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/multiindex_object.py:115", "number": 0, "name": "multiindex_object.Values.time_datetime_level_values_copy", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Apply.time_copy_function_multi_col": {"min_run_count": 2, "version": "8797436b49b3c5cfd9d2cde36d984ab46eab787e72b9ae243e4129c7d36e3829", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_copy_function_multi_col(self, df):\n        df.groupby(['key', 'key2']).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10**4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame({'key': labels,\n                        'key2': labels2,\n                        'value1': np.random.randn(N),\n                        'value2': ['foo', 'bar', 'baz', 'qux'] * (N // 4)\n                        })\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:35", "number": 0, "name": "groupby.Apply.time_copy_function_multi_col", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.MaybeConvertNumeric.time_convert": {"min_run_count": 2, "version": "a97674952d90d96d38e85f58ed9b0cfca9f1754f0773ed7e53f56775e1fe1095", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10**6\n        arr = np.repeat([2**63], N) + np.arange(N).astype('uint64')\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:100", "number": 0, "name": "inference.MaybeConvertNumeric.time_convert", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.ToNumeric.time_from_float": {"min_run_count": 2, "version": "e2bce81507edf5a8120567b31717559114d825c302cc05fc1f4bda2e691448ed", "processes": 2, "params": [["'ignore'", "'coerce'"]], "type": "time", "warmup_time": -1, "param_names": ["errors"], "timeout": 60.0, "code": "class ToNumeric:\n    def time_from_float(self, errors):\n        to_numeric(self.float, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype('str')\n        self.str = Series(tm.makeStringIndex(N))", "number": 0, "name": "inference.ToNumeric.time_from_float", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeCache.time_unique_seconds_and_unit": {"min_run_count": 2, "version": "d9774571b3928fb940ce11c8a7131f9b7f5b7abe461d2c998b8c57d1f8acea92", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["cache"], "timeout": 60.0, "code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit='s', cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = ['2000-02-11'] * N\n        self.dup_string_with_tz = ['2000-02-11 15:00:00-0800'] * N", "number": 0, "name": "timeseries.ToDatetimeCache.time_unique_seconds_and_unit", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.ToNumeric.time_from_str": {"min_run_count": 2, "version": "f4a8e383426560126beb615baa2f1a7e3b7e481047532e16ad7120c0aa31fb98", "processes": 2, "params": [["'ignore'", "'coerce'"]], "type": "time", "warmup_time": -1, "param_names": ["errors"], "timeout": 60.0, "code": "class ToNumeric:\n    def time_from_str(self, errors):\n        to_numeric(self.str, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype('str')\n        self.str = Series(tm.makeStringIndex(N))", "number": 0, "name": "inference.ToNumeric.time_from_str", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.MultiIndexing.time_index_slice": {"min_run_count": 2, "version": "e8f887ef53e0c77da4c904b546e09db60f97da572f6643fc3a9cad088909ae4e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiIndexing:\n    def time_index_slice(self):\n        self.mdt.loc[self.idx, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        self.mdt = DataFrame({'A': np.random.choice(range(10000, 45000, 1000),\n                                                    n),\n                              'B': np.random.choice(range(10, 400), n),\n                              'C': np.random.choice(range(1, 150), n),\n                              'D': np.random.choice(range(10000, 45000), n),\n                              'x': np.random.choice(range(400), n),\n                              'y': np.random.choice(range(25), n)})\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index(['A', 'B', 'C', 'D']).sort_index()", "number": 0, "name": "indexing.MultiIndexing.time_index_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Rename.time_dict_rename_both_axes": {"min_run_count": 2, "version": "3ef9ad4db7bb3691f5ddd227c2e399453847e51c9ff831a1d003110276104d5d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Rename.time_dict_rename_both_axes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.GetDtypeCounts.time_info": {"min_run_count": 2, "version": "3f9da084cf6f28a48a82fd2244d9854c98469727387a60271fc1b0da6df4e4a3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "number": 0, "name": "frame_methods.GetDtypeCounts.time_info", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Repr.time_html_repr_trunc_mi": {"min_run_count": 2, "version": "640e4b10b23c1fa98c0a07091d957e75121bc0a9d12182901ff89421df574cb9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "number": 0, "name": "frame_methods.Repr.time_html_repr_trunc_mi", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Contains.time_categorical_contains": {"min_run_count": 2, "version": "0f8d1e542cff226c25fc0a03f606bb601f8a75897e3fa8455d80ceb60675f099", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "number": 0, "name": "categoricals.Contains.time_categorical_contains", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.GetLoc.time_large_get_loc_warm": {"min_run_count": 2, "version": "da7826b6c6bedce1776b670d54d6824607219d2e80c51a992f347ab508faff85", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, 'Z'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=['one', 'two', 'three'])\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list('A')],\n            names=['one', 'two', 'three'])\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list('A'), list('A')],\n            names=['one', 'two', 'three'])", "number": 0, "name": "multiindex_object.GetLoc.time_large_get_loc_warm", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_align": {"min_run_count": 2, "version": "2143adff9bd5dd3024c0131ee4d60bbb410eded682ba27fbd2773ac1cca4fac3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({'a': self.series, 'b': self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_align", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_float_div_by_zero": {"min_run_count": 2, "version": "0135797921846b7e296be7ce10060bbef482180499667f98017a5198cb90d339", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_float_div_by_zero", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaOps.time_add_td_ts": {"min_run_count": 2, "version": "c06169d18f5f36ceb0b63a52d296cbd8bb3251aa273c40e8cb484cbb618c8120", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp('2000')", "number": 0, "name": "timedelta.TimedeltaOps.time_add_td_ts", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_getitem_scalar": {"min_run_count": 2, "version": "5af165d551969dddb2aba2d9a376d8fc3dc5adbc1a1b362cf50f99b56dc78812", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_getitem_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "attrs_caching.DataFrameAttributes.time_get_index": {"min_run_count": 2, "version": "724af0b0b4b503c9c173dad92121ac975bf7f69a8816d35742b2f9303aa5729d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.foo = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "number": 0, "name": "attrs_caching.DataFrameAttributes.time_get_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples_to_list": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "fee329aac7fc1cfb9936c7c26efca455fc0b770c68c58e6a9eb9362163f867f7", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples_to_list", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "timedelta.TimedeltaIndexing.time_intersection": {"min_run_count": 2, "version": "1c46a6ab1c5b09bc6d07ba2352d3bded72c4f3e38aef853c4119be71d98516ef", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_intersection", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Concat.time_union": {"min_run_count": 2, "version": "557e5f173d84bfd5245b71be3e03fb32bd56c4d33f5befa7f96fc94bbcfc9194", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list('aabbcd') * N).astype('category')\n    \n        self.a = pd.Categorical(list('aabbcd') * N)\n        self.b = pd.Categorical(list('bbcdjk') * N)", "number": 0, "name": "categoricals.Concat.time_union", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Correlation.time_corrwith_rows": {"min_run_count": 2, "version": "23e43857849029fd2f8abde76b72abeea2d7298f2ca387454e87b2c3b7945bea", "processes": 2, "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["method", "use_bottleneck"], "timeout": 60.0, "code": "class Correlation:\n    def time_corrwith_rows(self, method, use_bottleneck):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "number": 0, "name": "stat_ops.Correlation.time_corrwith_rows", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Datetime.time_is_dates_only": {"min_run_count": 2, "version": "b8a951d14fbec7a5d5945302136b94cc11e801a6433f639ee719a94708743572", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Datetime:\n    def time_is_dates_only(self):\n        self.dr._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datetime:\n    def setup(self):\n        self.dr = date_range('20000101', freq='D', periods=10000)", "number": 0, "name": "index_object.Datetime.time_is_dates_only", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.ToCoo.time_sparse_series_to_coo": {"min_run_count": 2, "version": "ffbdf30089599781adbce3bd847aa83fc748cb200d8bfe3535fcaf455c965b64", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToCoo:\n    def time_sparse_series_to_coo(self):\n        self.ss.to_coo(row_levels=[0, 1],\n                       column_levels=[2, 3],\n                       sort_labels=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n        s.index = MultiIndex.from_product([range(10)] * 4)\n        self.ss = s.to_sparse()", "number": 0, "name": "sparse.ToCoo.time_sparse_series_to_coo", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IndexAppend.time_append_obj_list": {"min_run_count": 2, "version": "f8551feb1646d6669519eabeb2447116679f19811ff8a28df5fe062bd91096ed", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "number": 0, "name": "index_object.IndexAppend.time_append_obj_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.GroupByMethods.time_dtype_as_field": {"min_run_count": 2, "version": "db95a420f534cc884f83444347b4b056fc14e16347ad5643519206ade1013a57", "processes": 2, "params": [["'int'", "'float'", "'object'", "'datetime'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'ffill'", "'first'", "'head'", "'last'", "'mad'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype", "method", "application"], "timeout": 60.0, "code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application):\n        if method in method_blacklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups)\n        values = rng.take(np.random.randint(0, ngroups, size=size))\n        if dtype == 'int':\n            key = np.random.randint(0, size, size=size)\n        elif dtype == 'float':\n            key = np.concatenate([np.random.random(ngroups) * 0.1,\n                                  np.random.random(ngroups) * 10.0])\n        elif dtype == 'object':\n            key = ['foo'] * size\n        elif dtype == 'datetime':\n            key = date_range('1/1/2011', periods=size, freq='s')\n    \n        df = DataFrame({'values': values, 'key': key})\n    \n        if application == 'transform':\n            if method == 'describe':\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\n                'key')['values'].transform(method)\n            self.as_field_method = lambda: df.groupby(\n                'values')['key'].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby('key')['values'], method)\n            self.as_field_method = getattr(df.groupby('values')['key'], method)", "number": 0, "name": "groupby.GroupByMethods.time_dtype_as_field", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.parsers.ConcatDateCols.time_check_concat": {"min_run_count": 2, "version": "45a8be00920e0509b2cce19e068dcf781b2b572524694a34fe9423cd15af14d8", "processes": 2, "params": [["1234567890", "'AAAA'"], ["1", "2"]], "type": "time", "warmup_time": -1, "param_names": ["value", "dim"], "timeout": 60.0, "code": "class ConcatDateCols:\n    def time_check_concat(self, value, dim):\n        _concat_date_cols(self.object)\n\n    def setup(self, value, dim):\n        count_elem = 10000\n        if dim == 1:\n            self.object = (np.array([value] * count_elem),)\n        if dim == 2:\n            self.object = (np.array([value] * count_elem),\n                           np.array([value] * count_elem))", "number": 0, "name": "io.parsers.ConcatDateCols.time_check_concat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_int": {"min_run_count": 2, "version": "8434314c7e4a58ab4943126d48db7f2c963f479996e722c14bf383967d6ba9d6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {"timeout": 60.0, "code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self):\n        with open(self.fname, \"w\") as f:\n            for i in range(self.num_rows):\n                f.write(\"{i}\\n\".format(i=i))", "version": "a0783c26fe897f62c481e4f911fedcfb5a385cfa7e3db45752737cfb08c77ee0", "params": [], "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks", "param_names": [], "unit": "bytes", "type": "memory"}, "io.json.ToJSONMem.peakmem_float": {"timeout": 60.0, "code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames['float']\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\n            'int': df,\n            'float': df.astype(float),\n        }\n    \n        return frames", "version": "1d38b13de3dca134bd03dead25ee0c5ddd0a9d5b3a5cce2eb0112f06ec04a907", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/io/json.py:129", "params": [], "name": "io.json.ToJSONMem.peakmem_float", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "reshape.GetDummies.time_get_dummies_1d": {"min_run_count": 2, "version": "3fde81390ce986dd764fe063f89412ccab1903267331730a0e37583abc5b8ef1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(np.random.choice(categories, size=1000000),\n                      dtype=pd.api.types.CategoricalDtype(categories))\n        self.s = s", "number": 0, "name": "reshape.GetDummies.time_get_dummies_1d", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInForObjects.time_isin_nans": {"min_run_count": 2, "version": "7f55341294add4db6feb6f374372084e929cc6776afdab36ebd8a46aba138899", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInForObjects:\n    def time_isin_nans(self):\n        # if nan-objects are different objects,\n        # this has the potential to trigger O(n^2) running time\n        self.s_nans.isin(self.vals_nans)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10**4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10**4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10**5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10**5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10**5,\n                                    dtype=np.float)).astype(np.object)\n        self.vals_long_floats = np.arange(10**5,\n                                          dtype=np.float).astype(np.object)", "number": 0, "name": "series_methods.IsInForObjects.time_isin_nans", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Range.time_min": {"min_run_count": 2, "version": "ee83fb26c76677283242edf3c9a621f53b11e8ce1f6909ea90dbc27ecc7c914a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**7, step=3)\n        self.idx_dec = RangeIndex(start=10**7, stop=-1, step=-3)", "number": 0, "name": "index_object.Range.time_min", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Equals.time_frame_nonunique_unequal": {"min_run_count": 2, "version": "8d1c1760cdeccd70f9e716a5ecb6d1618d728dfdf8ddeb2d0593d1eda69deb75", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame('foo', index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = ['A'] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "number": 0, "name": "frame_methods.Equals.time_frame_nonunique_unequal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffestDatetimeArithmetic.time_apply": {"min_run_count": 2, "version": "5c573929a3de5d5fa13905c202d891b1903395c8430c240dce551518c9191ddb", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffestDatetimeArithmetic:\n    def time_apply(self, offset):\n        offset.apply(self.date)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64('2011-01-01 09:00Z')", "number": 0, "name": "offset.OffestDatetimeArithmetic.time_apply", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Dropna.time_dropna": {"min_run_count": 2, "version": "8536d8529de5880a812156d53337faf260daee89f8f5e337d1eaa1c2c7fcc201", "processes": 2, "params": [["'all'", "'any'"], ["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["how", "axis"], "timeout": 60.0, "code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.ix[50:1000, 20:50] = np.nan\n        self.df.ix[2000:3000] = np.nan\n        self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed['foo'] = 'bar'", "number": 0, "name": "frame_methods.Dropna.time_dropna", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Fillna.time_frame_fillna": {"min_run_count": 2, "version": "7dcf12633de089958156ed6dc74812a3fb114da3adf3e4ebcd39cb9da424baf8", "processes": 2, "params": [["True", "False"], ["'pad'", "'bfill'"]], "type": "time", "warmup_time": -1, "param_names": ["inplace", "method"], "timeout": 60.0, "code": "class Fillna:\n    def time_frame_fillna(self, inplace, method):\n        self.df.fillna(inplace=inplace, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, method):\n        values = np.random.randn(10000, 100)\n        values[::2] = np.nan\n        self.df = DataFrame(values)", "number": 0, "name": "frame_methods.Fillna.time_frame_fillna", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.AddOverflowArray.time_add_overflow_both_arg_nan": {"min_run_count": 2, "version": "ffa5b7aee7136154b1d8c1ac52465a27aa0681d9fe1b4c11451aec95e33c7859", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AddOverflowArray:\n    def time_add_overflow_both_arg_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, arr_mask=self.arr_nan_1,\n                             b_mask=self.arr_nan_2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "number": 0, "name": "binary_ops.AddOverflowArray.time_add_overflow_both_arg_nan", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.GetDummies.time_get_dummies_1d_sparse": {"min_run_count": 2, "version": "76b59a23f22b6f1ffead9f2d3c48d3205ab7091153af7031cac11508f616a23d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(np.random.choice(categories, size=1000000),\n                      dtype=pd.api.types.CategoricalDtype(categories))\n        self.s = s", "number": 0, "name": "reshape.GetDummies.time_get_dummies_1d_sparse", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Categories.time_groupby_ordered_sort": {"min_run_count": 2, "version": "a960f29ec49934d00c79a0b185c6bc8a90809be46f8fc4a5173eb352aa86cdd6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Categories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby('a')['b'].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {'a': Categorical(np.random.randint(10000, size=N)),\n                'b': arr}\n        self.df = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(10000, size=N),\n                                 ordered=True),\n                'b': arr}\n        self.df_ordered = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(100, size=N),\n                                 categories=np.arange(10000)),\n                'b': arr}\n        self.df_extra_cat = DataFrame(data)", "number": 0, "name": "groupby.Categories.time_groupby_ordered_sort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Nth.time_series_nth": {"min_run_count": 2, "version": "ca595a91d18eb78f64687018a0d41f33d17bcd12247a4b24f1aa935f1889c743", "processes": 2, "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df['values'].groupby(self.df['key']).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == 'datetime':\n            values = date_range('1/1/2011', periods=N, freq='s')\n        elif dtype == 'object':\n            values = ['foo'] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({'key': key, 'values': values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "number": 0, "name": "groupby.Nth.time_series_nth", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_fastpath": {"min_run_count": 2, "version": "8b18dfad9e11f79947d6fa914899076553265d0f00e0dde6de7cc08185fae788", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_fastpath(self):\n        pd.Categorical(self.codes, self.cat_idx, fastpath=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_fastpath", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ToCSV.time_frame": {"min_run_count": 2, "version": "a51e5d4d76b27afdaa7d987c0a998795059038c82fe8025780bfe0195986d8cb", "processes": 2, "params": [["'wide'", "'long'", "'mixed'"]], "type": "time", "warmup_time": -1, "param_names": ["kind"], "timeout": 60.0, "code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame({'A': np.arange(50000),\n                                'B': np.arange(50000) + 1.,\n                                'C': np.arange(50000) + 2.,\n                                'D': np.arange(50000) + 3.})\n        mixed_frame = DataFrame({'float': np.random.randn(5000),\n                                 'int': np.random.randn(5000).astype(int),\n                                 'bool': (np.arange(5000) % 2) == 0,\n                                 'datetime': date_range('2001',\n                                                        freq='s',\n                                                        periods=5000),\n                                 'object': ['foo'] * 5000})\n        mixed_frame.loc[30:500, 'float'] = np.nan\n        data = {'wide': wide_frame,\n                'long': long_frame,\n                'mixed': mixed_frame}\n        self.df = data[kind]", "number": 0, "name": "io.csv.ToCSV.time_frame", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_boolean_series": {"min_run_count": 2, "version": "0f5fa20b04af4201e2c087e0e2ec089b2cf8af0e5d35b892121cfd6f79ac3142", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_boolean_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.Factorize.time_factorize": {"min_run_count": 2, "version": "fa4293bfe28e214c9011bc7eec53cb7efd2f09d6f7ffd6e39c934ab83bbd4640", "processes": 2, "params": [["None", "'Asia/Tokyo'"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class Factorize:\n    def time_factorize(self, tz):\n        self.dti.factorize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, tz):\n        N = 100000\n        self.dti = date_range('2011-01-01', freq='H', periods=N, tz=tz)\n        self.dti = self.dti.repeat(5)", "number": 0, "name": "timeseries.Factorize.time_factorize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.SimpleReshape.time_unstack": {"min_run_count": 2, "version": "6965052dc2246b737b7e8054b0d25cc100eb4fb93dcb4b8764cc52d872564fbb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100),\n                  np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "number": 0, "name": "reshape.SimpleReshape.time_unstack", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {"min_run_count": 2, "version": "c2dec0281e2a8aaa28fc950a09b0c35653511b7b79219cee258be49327b0c15c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select('table_mixed')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.NSort.time_nsmallest_two_columns": {"min_run_count": 2, "version": "e7f8591801b2064e1e3f6ffbb79d694caf315671435edff95e0ad5e6714ef584", "processes": 2, "params": [["'first'", "'last'", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["keep"], "timeout": 60.0, "code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, ['A', 'B'], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3),\n                            columns=list('ABC'))", "number": 0, "name": "frame_methods.NSort.time_nsmallest_two_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {"min_run_count": 2, "version": "c33bbc4022786bf938e8f885379d65cbd49b4974387336de68b642225ce695b1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp('2017-08-25 08:16:14')", "number": 0, "name": "timestamp.TimestampConstruction.time_parse_iso8601_no_tz", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.ToTimedelta.time_convert_string_seconds": {"min_run_count": 2, "version": "04574063ba03eff516b6339b608329684ea0f7f0706826947ad036c9bfb9f780", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append('{0} days'.format(i))\n            self.str_seconds.append('00:00:{0:02d}'.format(i))", "number": 0, "name": "timedelta.ToTimedelta.time_convert_string_seconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Count.time_count_level_mixed_dtypes_multi": {"min_run_count": 2, "version": "03f15973360b96a57b443b8da8464a54418a44ce813b742a8e2ecfe673275434", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Count:\n    def time_count_level_mixed_dtypes_multi(self, axis):\n        self.df_mixed.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.ix[50:1000, 20:50] = np.nan\n        self.df.ix[2000:3000] = np.nan\n        self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed['foo'] = 'bar'\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns,\n                                                  self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays([self.df_mixed.index,\n                                                      self.df_mixed.index])\n        self.df_mixed.columns = MultiIndex.from_arrays([self.df_mixed.columns,\n                                                        self.df_mixed.columns])", "number": 0, "name": "frame_methods.Count.time_count_level_mixed_dtypes_multi", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.MultiColumn.time_col_select_lambda_sum": {"min_run_count": 2, "version": "8497236caa01444cab3301a58be3bc9e1ae534216f527c6beb4c5f7048ce701e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby(['key1', 'key2'])['data1'].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame({'key1': key1,\n                        'key2': key2,\n                        'data1': np.random.randn(N),\n                        'data2': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:259", "number": 0, "name": "groupby.MultiColumn.time_col_select_lambda_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_get_loc": {"min_run_count": 2, "version": "94d4ac03b6fbc7639e67be8c49d4736b042039e5ebd3d8eef1ca7e9dd516926b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.LevelAlign.time_align_level": {"min_run_count": 2, "version": "47b2ceb6050b798d1ca376603f507172e40e6a51f005c9c92295a531a9234913", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[np.arange(10).repeat(10000),\n                   np.tile(np.arange(100).repeat(100), 10),\n                   np.tile(np.tile(np.arange(100), 100), 10)])\n        self.df = DataFrame(np.random.randn(len(self.index), 4),\n                            index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4),\n                                  index=self.index.levels[1])", "number": 0, "name": "reindex.LevelAlign.time_align_level", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_floor": {"min_run_count": 2, "version": "d7b4f173f692cdfd5aeedec3386ff2e70b251eeb1649e6381fc65f6a76942a22", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor('5T')\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_floor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Merge.time_merge_dataframe_integer_2key": {"min_run_count": 2, "version": "c40822634837ce0b4df9e8474cfbcc64306d4d8184dc2483fca0d978311dea24", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame({'key': key, 'key2': key2,\n                               'value': np.random.randn(80000)})\n        self.right = DataFrame({'key': indices[2000:],\n                                'key2': indices2[2000:],\n                                'value2': np.random.randn(8000)})\n    \n        self.df = DataFrame({'key1': np.tile(np.arange(500).repeat(10), 2),\n                             'key2': np.tile(np.arange(250).repeat(10), 4),\n                             'value': np.random.randn(10000)})\n        self.df2 = DataFrame({'key1': np.arange(500),\n                              'value2': np.random.randn(500)})\n        self.df3 = self.df[:5000]", "number": 0, "name": "join_merge.Merge.time_merge_dataframe_integer_2key", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelDatetimeFields.time_datetime_field_year": {"min_run_count": 2, "version": "5f1a8a07b5c319b419da192c9941ff2ff239057fbed19d4e9c155ed8d535857b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        self.dti = date_range('1900-01-01', periods=N, freq='T')\n        self.period = self.dti.to_period('D')", "number": 0, "name": "gil.ParallelDatetimeFields.time_datetime_field_year", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_start": {"min_run_count": 2, "version": "c6cd8fb6f75fc22734093112d97c93f260915c8c2a1ec2c360cd972bf14d9945", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_start", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_loc_array": {"min_run_count": 2, "version": "adb3dd4cd0a2678878415ef49c99cdab545663accc005e439968e16429856df7", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_loc_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ToCSVDatetime.time_frame_date_formatting": {"min_run_count": 2, "version": "0dc645756cee538da53667680e8584b2fab6cbb005e0405c021772b1ea03a4c0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format='%Y%m%d')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range('1/1/2000', periods=1000)\n        self.data = DataFrame(rng, index=rng)", "number": 0, "name": "io.csv.ToCSVDatetime.time_frame_date_formatting", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {"min_run_count": 2, "version": "58274aecd32e02048373c9d6eb90207389903cabd8f05dbef5aa4e1ea0ba5b8a", "processes": 2, "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["connection", "dtype"], "timeout": 60.0, "code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {'sqlalchemy': create_engine('sqlite:///:memory:'),\n               'sqlite': sqlite3.connect(':memory:')}\n        self.table_name = 'test_type'\n        self.query_col = 'SELECT {} FROM {}'.format(dtype, self.table_name)\n        self.con = con[connection]\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelDatetimeFields.time_period_to_datetime": {"min_run_count": 2, "version": "721e95fcc745d81c62a61b52a94e5ba43e86ac8c70c43ea0928e5a9bbee245a9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        self.dti = date_range('1900-01-01', periods=N, freq='T')\n        self.period = self.dti.to_period('D')", "number": 0, "name": "gil.ParallelDatetimeFields.time_period_to_datetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_lower": {"min_run_count": 2, "version": "1016730e7c846faa006c349924e2c5e52ae7756107d7fac96109cc5c84db5878", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_lower(self):\n        self.s.str.lower()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_lower", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Range.time_get_loc_dec": {"min_run_count": 2, "version": "10c34ad9915eeeb0982bdf6f8035717a612a54b29f70a0240bd4c02ea2af1db1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**7, step=3)\n        self.idx_dec = RangeIndex(start=10**7, stop=-1, step=-3)", "number": 0, "name": "index_object.Range.time_get_loc_dec", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.GroupByMethods.time_dtype_as_group": {"min_run_count": 2, "version": "4e11d67ab6783d75f6aa21ec6204b5b548dfc35afabacb54b0720163d3c233f0", "processes": 2, "params": [["'int'", "'float'", "'object'", "'datetime'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'ffill'", "'first'", "'head'", "'last'", "'mad'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype", "method", "application"], "timeout": 60.0, "code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application):\n        if method in method_blacklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups)\n        values = rng.take(np.random.randint(0, ngroups, size=size))\n        if dtype == 'int':\n            key = np.random.randint(0, size, size=size)\n        elif dtype == 'float':\n            key = np.concatenate([np.random.random(ngroups) * 0.1,\n                                  np.random.random(ngroups) * 10.0])\n        elif dtype == 'object':\n            key = ['foo'] * size\n        elif dtype == 'datetime':\n            key = date_range('1/1/2011', periods=size, freq='s')\n    \n        df = DataFrame({'values': values, 'key': key})\n    \n        if application == 'transform':\n            if method == 'describe':\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\n                'key')['values'].transform(method)\n            self.as_field_method = lambda: df.groupby(\n                'values')['key'].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby('key')['values'], method)\n            self.as_field_method = getattr(df.groupby('values')['key'], method)", "number": 0, "name": "groupby.GroupByMethods.time_dtype_as_group", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.RemoveCategories.time_remove_categories": {"min_run_count": 2, "version": "cec521f5900ba525b0edcd4021b1b872c064d610964e577ce4e5306d670e2401", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = ['s{:04d}'.format(i) for i in np.random.randint(0, n // 10,\n                                                              size=n)]\n        self.ts = pd.Series(arr).astype('category')", "number": 0, "name": "categoricals.RemoveCategories.time_remove_categories", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Isnull.time_isnull": {"min_run_count": 2, "version": "7c825d2cd8a959fe3540eda1d2834df1c2b127c8c333c48f7845aa29618112a0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array([NaT, np.nan, None, np.datetime64('NaT'),\n                           np.timedelta64('NaT'), 0, 1, 2.0, '', 'abcd'])\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "number": 0, "name": "frame_methods.Isnull.time_isnull", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Duplicated.time_duplicated": {"min_run_count": 2, "version": "dcb7e9272d1de6d7e72e532ddac1d2b35289bf534e87b42ed3c80cc89511b29c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [np.arange(n),\n                  tm.makeStringIndex(n).values,\n                  1000 + np.arange(n)]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)", "number": 0, "name": "multiindex_object.Duplicated.time_duplicated", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_qcut_datetime": {"min_run_count": 2, "version": "9ff36d5d2d268d71df84703a43ff374a058b5dff597046d8c6ee9fddb7ec52cb", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_qcut_datetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_raw_read_first": {"min_run_count": 2, "version": "b70da7312157e5d3fe3bf7ce260063cbc585caaee0eb97c05732eab91c647958", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_raw_read_first", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_normalize": {"min_run_count": 2, "version": "31eff8c687a439b0b4b3ae784a4bd18704a4a0353e917ed529c1ea3e03e00766", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_normalize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Correlation.time_corrwith_cols": {"min_run_count": 2, "version": "e47f875c5452333ada698603ed3943c870747fc71d1162d4300c4b5cf5428766", "processes": 2, "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["method", "use_bottleneck"], "timeout": 60.0, "code": "class Correlation:\n    def time_corrwith_cols(self, method, use_bottleneck):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "number": 0, "name": "stat_ops.Correlation.time_corrwith_cols", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.TzLocalize.time_infer_dst": {"min_run_count": 2, "version": "47ffb6811da27a909b347cc6d2f428f25709cd3c56b56120a168a039cf72ec97", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous='infer')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(start='10/29/2000 1:00:00',\n                             end='10/29/2000 1:59:59', freq='S')\n        self.index = date_range(start='10/29/2000',\n                                end='10/29/2000 00:59:59', freq='S')\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(date_range(start='10/29/2000 2:00:00',\n                                                  end='10/29/2000 3:00:00',\n                                                  freq='S'))", "number": 0, "name": "timeseries.TzLocalize.time_infer_dst", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelDatetimeFields.time_datetime_field_normalize": {"min_run_count": 2, "version": "42d69224d424650650174072f5f82685fe0f8ef57698c72ff1a35b4875feb23a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        self.dti = date_range('1900-01-01', periods=N, freq='T')\n        self.period = self.dti.to_period('D')", "number": 0, "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.PivotTable.time_pivot_table_margins": {"min_run_count": 2, "version": "076a68203243fec76504914a4d7fe813ca78c05234d5d34d03c9d10bcbadba3e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index='key1', columns=['key2', 'key3'],\n                            margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame({'key1': fac1.take(ind1),\n                             'key2': fac2.take(ind2),\n                             'key3': fac2.take(ind2),\n                             'value1': np.random.randn(N),\n                             'value2': np.random.randn(N),\n                             'value3': np.random.randn(N)})\n        self.df2 = DataFrame({'col1': list('abcde'), 'col2': list('fghij'),\n                              'col3': [1, 2, 3, 4, 5]})\n        self.df2.col1 = self.df2.col1.astype('category')\n        self.df2.col2 = self.df2.col2.astype('category')", "number": 0, "name": "reshape.PivotTable.time_pivot_table_margins", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadUint64Integers.time_read_uint64_na_values": {"min_run_count": 2, "version": "958374034fc9107ec86da0a9ce0a4f3cd7432c131b17d5b3e56af83a42380b14", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(self.data(self.data1), header=None, names=['foo'],\n                 na_values=self.na_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype('uint64') + 2**63\n        self.data1 = StringIO('\\n'.join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO('\\n'.join(arr.astype(str).tolist()))", "number": 0, "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {"min_run_count": 2, "version": "e03f0bc2e6562f82c347219a1482798e577fad85eaea4c932769696b32c0c1de", "processes": 2, "params": [["False", "True"]], "type": "time", "warmup_time": -1, "param_names": ["cache_dates"], "timeout": 60.0, "code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(self.data(self.StringIO_input),\n                      dtype={'date': str}, names=['date'])\n        to_datetime(df['date'], cache=cache_dates, format='%d-%m-%Y')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = '12-02-2010\\n' * count_elem\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "replace.Convert.time_replace": {"min_run_count": 2, "version": "0b201f8acce513c0216f2554831cf18e9546b6a3ab1a40cb6cb930f55e33d903", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["'Timestamp'", "'Timedelta'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor", "replace_data"], "timeout": 60.0, "code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10**3\n        data = {'Series': pd.Series(np.random.randint(N, size=N)),\n                'DataFrame': pd.DataFrame({'A': np.random.randint(N, size=N),\n                                           'B': np.random.randint(N, size=N)})}\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]", "number": 0, "name": "replace.Convert.time_replace", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Append.time_append_mixed": {"min_run_count": 2, "version": "3ccebbc61d34450da13498c9626e5d337475a30e46d660d253c5bb81e8c837f0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Append:\n    def time_append_mixed(self):\n        self.mdf1.append(self.mdf2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4),\n                             columns=['A', 'B', 'C', 'D'])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1['obj1'] = 'bar'\n        self.mdf1['obj2'] = 'bar'\n        self.mdf1['int1'] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index", "number": 0, "name": "join_merge.Append.time_append_mixed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_parse_dateutil": {"min_run_count": 2, "version": "87d2da27f45c1fea5a63f4e323e02fa9af558c07c62cc7d2dce5ea9bb3fba2be", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp('2017/08/25 08:16:14 AM')", "number": 0, "name": "timestamp.TimestampConstruction.time_parse_dateutil", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.MethodLookup.time_lookup_iloc": {"min_run_count": 2, "version": "8964b2421e6b4b74545350fae7ce591768d80f855cd1182bcfbcda2882780356", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:282", "number": 0, "name": "indexing.MethodLookup.time_lookup_iloc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.WideToLong.time_wide_to_long_big": {"min_run_count": 2, "version": "1512117820ce2d737b82341934d9b527d2b8316858a8efb1bbb04e2c39740721", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i='id', j='year')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list('ABCD')\n        yrvars = [l + str(num)\n                  for l, num in product(self.letters, range(1, nyrs + 1))]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)),\n                            columns=columns)\n        self.df['id'] = self.df.index", "number": 0, "name": "reshape.WideToLong.time_wide_to_long_big", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Timeseries.time_series_timestamp_compare": {"min_run_count": 2, "version": "d30494219984e2855c90da4cb9672d362cc0416e60c2d985eb359c2bb9096912", "processes": 2, "params": [["None", "'US/Eastern'"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range('20010101', periods=N, freq='T', tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range('20010101', periods=N, freq='s', tz=tz))", "number": 0, "name": "binary_ops.Timeseries.time_series_timestamp_compare", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.AsOf.time_asof_nan": {"min_run_count": 2, "version": "dcf0f4026aa4939b7c85138b60cb3cda62e311889071ab765316d9a20f763334", "processes": 2, "params": [["'DataFrame'", "'Series'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor"], "timeout": 60.0, "code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start='1/1/1990', periods=N, freq='53s')\n        data = {'DataFrame': DataFrame(np.random.randn(N, M)),\n                'Series': Series(np.random.randn(N))}\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start='1/1/1990', periods=N * 10, freq='5s')\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "number": 0, "name": "timeseries.AsOf.time_asof_nan", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffsetSeriesArithmetic.time_add_offset": {"min_run_count": 2, "version": "0c5649ff742c5732c734177ffafee4ee0a502a4e128fc157c733d077705ad535", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffsetSeriesArithmetic:\n    def time_add_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.data + offset\n\n    def setup(self, offset):\n        N = 1000\n        rng = pd.date_range(start='1/1/2000', periods=N, freq='T')\n        self.data = pd.Series(rng)", "number": 0, "name": "offset.OffsetSeriesArithmetic.time_add_offset", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_write_store": {"min_run_count": 2, "version": "ad6f9368e9ef555aea1e7822645835de2b12d137c3d95d8666592db1a627cb51", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put('fixed_write', self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_write_store", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_align": {"min_run_count": 2, "version": "5c5edfa2dc8b0cff933da78104d1b3830569456857d4deb7c3f224b976dd3deb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({'a': self.series, 'b': self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_align", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {"min_run_count": 2, "version": "a0e5e9090205efd4b2b0eaae96ef388c13f2755cbcd2e6d6055c789e521e8f26", "processes": 2, "params": [["'scalar-string'", "'scalar-int'", "'list-string'", "'array-string'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "number": 0, "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_union": {"min_run_count": 2, "version": "8db66af67fa5d031c97c8cddd9302240b82353596965a9586712470f9645bae4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_union", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.TransformBools.time_transform_mean": {"min_run_count": 2, "version": "fbd7789cba058d7b04612329c42b63613ca44729465b31dad8b0bc408e964b4d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df['signal'].groupby(self.g).transform(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({'signal': np.random.rand(N)})", "number": 0, "name": "groupby.TransformBools.time_transform_mean", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops.time_frame_comparison": {"min_run_count": 2, "version": "e004d6a4268a6a7e05ddc028327ad06efd80783bfb64b1618195980b0029e970", "processes": 2, "params": [["True", "False"], ["'default'", "1"]], "type": "time", "warmup_time": -1, "param_names": ["use_numexpr", "threads"], "timeout": 60.0, "code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != 'default':\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "number": 0, "name": "binary_ops.Ops.time_frame_comparison", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.MultiColumn.time_lambda_sum": {"min_run_count": 2, "version": "22c4e1d09d3bd0ada748f7c4650cdf3d073f9f9fbe646874464c67d8be01da95", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby(['key1', 'key2']).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame({'key1': key1,\n                        'key2': key2,\n                        'data1': np.random.randn(N),\n                        'data2': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:259", "number": 0, "name": "groupby.MultiColumn.time_lambda_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.stata.Stata.time_write_stata": {"min_run_count": 2, "version": "9e01a0804040ebaf4ba9fed79f1ac4f6d5371c101a35c1edd285ed5e2c8d24fd", "processes": 2, "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "type": "time", "warmup_time": -1, "param_names": ["convert_dates"], "timeout": 60.0, "code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = '__test__.dta'\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(self.N)\n        self.df['int8_'] = np.random.randint(np.iinfo(np.int8).min,\n                                             np.iinfo(np.int8).max - 27, N)\n        self.df['int16_'] = np.random.randint(np.iinfo(np.int16).min,\n                                              np.iinfo(np.int16).max - 27, N)\n        self.df['int32_'] = np.random.randint(np.iinfo(np.int32).min,\n                                              np.iinfo(np.int32).max - 27, N)\n        self.df['float32_'] = np.array(np.random.randn(N),\n                                       dtype=np.float32)\n        self.convert_dates = {'index': convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)", "number": 0, "name": "io.stata.Stata.time_write_stata", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_pad": {"min_run_count": 2, "version": "3386b8e938a59426c5f8eef8f13586205546de699c1a90eadfbe7d1da1283cbd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_pad(self):\n        self.s.str.pad(100, side='both')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_pad", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_datetimes": {"min_run_count": 2, "version": "ba69c725255526d292bebaa784e962b2d02497f3da54a9d333a74ea21cd20301", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_datetimes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeAsof.time_by_int": {"min_run_count": 2, "version": "116164631818e17151c21b79d12f054f2703515519a792656e530608b36ac098", "processes": 2, "params": [["'backward'", "'forward'", "'nearest'"]], "type": "time", "warmup_time": -1, "param_names": ["direction"], "timeout": 60.0, "code": "class MergeAsof:\n    def time_by_int(self, direction):\n        merge_asof(self.df1c, self.df2c, on='time', by='key2',\n                   direction=direction)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {'time': np.random.randint(0, one_count / 20, one_count),\n             'key': np.random.choice(list(string.ascii_uppercase), one_count),\n             'key2': np.random.randint(0, 25, one_count),\n             'value1': np.random.randn(one_count)})\n        df2 = DataFrame(\n            {'time': np.random.randint(0, two_count / 20, two_count),\n             'key': np.random.choice(list(string.ascii_uppercase), two_count),\n             'key2': np.random.randint(0, 25, two_count),\n             'value2': np.random.randn(two_count)})\n    \n        df1 = df1.sort_values('time')\n        df2 = df2.sort_values('time')\n    \n        df1['time32'] = np.int32(df1.time)\n        df2['time32'] = np.int32(df2.time)\n    \n        self.df1a = df1[['time', 'value1']]\n        self.df2a = df2[['time', 'value2']]\n        self.df1b = df1[['time', 'key', 'value1']]\n        self.df2b = df2[['time', 'key', 'value2']]\n        self.df1c = df1[['time', 'key2', 'value1']]\n        self.df2c = df2[['time', 'key2', 'value2']]\n        self.df1d = df1[['time32', 'value1']]\n        self.df2d = df2[['time32', 'value2']]\n        self.df1e = df1[['time', 'key', 'key2', 'value1']]\n        self.df2e = df2[['time', 'key', 'key2', 'value2']]", "number": 0, "name": "join_merge.MergeAsof.time_by_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Integer.time_is_monotonic": {"min_run_count": 2, "version": "a3287b5095a83fb876800e46e8e874614d73f0a066c9613158b66b6e7e150fdc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product([np.arange(1000),\n                                               np.arange(1000)],\n                                              names=['one', 'two'])\n        self.obj_index = np.array([(0, 10), (0, 11), (0, 12),\n                                   (0, 13), (0, 14), (0, 15),\n                                   (0, 16), (0, 17), (0, 18),\n                                   (0, 19)], dtype=object)", "number": 0, "name": "multiindex_object.Integer.time_is_monotonic", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.SortIndex.time_sort_index": {"min_run_count": 2, "version": "1427e2399524717961df855bf1cc30ca194b754f9c34964eee2b871e3717ba01", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["monotonic"], "timeout": 60.0, "code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start='1/1/2000', periods=N, freq='s')\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "number": 0, "name": "timeseries.SortIndex.time_sort_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsIn.time_isin": {"min_run_count": 2, "version": "b3d9cc6d75609adf9a495651078bae70dba81ee46f78f04ad04375e508a17bb7", "processes": 2, "params": [["'int64'", "'uint64'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class IsIn:\n    def time_isin(self, dtypes):\n        self.s.isin(self.values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsIn:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(1, 10, 100000)).astype(dtype)\n        self.values = [1, 2]", "number": 0, "name": "series_methods.IsIn.time_isin", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_to_time": {"min_run_count": 2, "version": "830184b9880e0fa4bbc1ba9471b19fb43fde22b0fe6502c5afcb850766470b57", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_to_time", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {"min_run_count": 2, "version": "6927b0c3ce4fa9564b7dc028cec1b02e5ecc0175b39c71642afb62403554686e", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.DateInferOps.time_subtract_datetimes": {"min_run_count": 2, "version": "b9e3c4374820522e86816a57bae20f0ce63761265b5107cb8dfc4168183f223e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df['datetime64'] - df['datetime64']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({'datetime64': np.arange(N).astype('datetime64[ms]')})\n        df['timedelta'] = df['datetime64'] - df['datetime64']\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:36", "number": 0, "name": "inference.DateInferOps.time_subtract_datetimes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.Fillna.time_float_32": {"min_run_count": 2, "version": "3d3ea087b84995daeddb931128d2c9d9597d5b37fc455092bd6e146ed0b8f27d", "processes": 2, "params": [["'pad'", "'backfill'"]], "type": "time", "warmup_time": -1, "param_names": ["method"], "timeout": 60.0, "code": "class Fillna:\n    def time_float_32(self, method):\n        self.ts_float32.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range('1/1/2000', periods=N, freq='1min')\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype('float32')", "number": 0, "name": "reindex.Fillna.time_float_32", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffestDatetimeArithmetic.time_subtract_10": {"min_run_count": 2, "version": "85dd562e03034557d2983c362475bd30140cb070f2d6d158d7b2cfc9761adb45", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64('2011-01-01 09:00Z')", "number": 0, "name": "offset.OffestDatetimeArithmetic.time_subtract_10", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Align.time_series_align_int64_index": {"min_run_count": 2, "version": "d2d4aa33d4703d23542f4ff884a8e4ab83a68daf8d2c9c7e2539ec6de73274d2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64('now').view('i8') + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "number": 0, "name": "join_merge.Align.time_series_align_int64_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.Dropna.time_dropna": {"min_run_count": 2, "version": "aba45ea737e4b2107e8abb774036c56a9e14a9e9d2fdafbe994b41b03774c845", "processes": 2, "params": [["'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10**6\n        data = {'int': np.random.randint(1, 10, N),\n                'datetime': date_range('2000-01-01', freq='S', periods=N)}\n        self.s = Series(data[dtype])\n        if dtype == 'datetime':\n            self.s[np.random.randint(1, N, 100)] = NaT", "number": 0, "name": "series_methods.Dropna.time_dropna", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_series_dot": {"min_run_count": 2, "version": "8ec2f7f7a202dd239f8102bc681d93f5142571836729ca32651f415ee47b3bde", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_series_dot", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IntervalIndexMethod.time_intersection_duplicate": {"min_run_count": 2, "version": "187cac6341a7ddc4bb1c69f8ba5e0adf8e5793d2ce9aa148ccb9a37211ebe253", "processes": 2, "params": [["1000", "100000"]], "type": "time", "warmup_time": -1, "param_names": ["param1"], "timeout": 60.0, "code": "class IntervalIndexMethod:\n    def time_intersection_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "number": 0, "name": "index_object.IntervalIndexMethod.time_intersection_duplicate", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_np_timedelta": {"min_run_count": 2, "version": "824c1d95cc84b91638a3c4197850cbd87899550de14a283e468d3c36bd39c8f3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(np.timedelta64(1, 'ms'))", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_np_timedelta", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_microsecond": {"min_run_count": 2, "version": "1c1ba44d7bf34991083fe5819445d690850f65fd6909baf8d59663e7e5ad5c7b", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_microsecond(self, tz, freq):\n        self.ts.microsecond\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_microsecond", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Correlation.time_corr_series": {"min_run_count": 2, "version": "0f81e50689cf06ff698f5a471a2d463322cc8960d7ef292043a28c062fbf0829", "processes": 2, "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["method", "use_bottleneck"], "timeout": 60.0, "code": "class Correlation:\n    def time_corr_series(self, method, use_bottleneck):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "number": 0, "name": "stat_ops.Correlation.time_corr_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_float_int_str_lines": {"min_run_count": 2, "version": "672d346e09538a8a461353c9d903abd095887c9b308c7b6e9309138c2804d4a2", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_float_int_str_lines(self, orient):\n        self.df_int_float_str.to_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_float_int_str_lines", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.mem_itertuples_raw_to_list": {"timeout": 120, "code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "0bd32dbb85b7f7d9a1105695390519c465473ac413643cedff2f67a1a5d47b2a", "params": [], "name": "frame_methods.Iteration.mem_itertuples_raw_to_list", "param_names": [], "unit": "bytes", "type": "memory"}, "groupby.MultiColumn.time_cython_sum": {"min_run_count": 2, "version": "b30342d5274564ee422244546363479d0bbdd74710aff6566bfb84a8ab71a174", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby(['key1', 'key2']).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame({'key1': key1,\n                        'key2': key2,\n                        'data1': np.random.randn(N),\n                        'data2': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:259", "number": 0, "name": "groupby.MultiColumn.time_cython_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_get_loc_non_unique": {"min_run_count": 2, "version": "e71c030131394210c2e5ba4708c2ac713361879184961c62ece3bb00ad19ca6f", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_get_loc_non_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Apply.time_scalar_function_single_col": {"min_run_count": 2, "version": "eedcf755e056df514a7c7a7f36607a141d0fd90fec8d2eb5652f726ca6b240b5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_scalar_function_single_col(self, df):\n        df.groupby('key').apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10**4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame({'key': labels,\n                        'key2': labels2,\n                        'value1': np.random.randn(N),\n                        'value2': ['foo', 'bar', 'baz', 'qux'] * (N // 4)\n                        })\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:35", "number": 0, "name": "groupby.Apply.time_scalar_function_single_col", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ResampleSeries.time_resample": {"min_run_count": 2, "version": "1269c5e7490778a5bdac3ce9116ecd233f6fa31e545ca45e68211234b98688fd", "processes": 2, "params": [["'period'", "'datetime'"], ["'5min'", "'1D'"], ["'mean'", "'ohlc'"]], "type": "time", "warmup_time": -1, "param_names": ["index", "freq", "method"], "timeout": 60.0, "code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {'period': period_range(start='1/1/2000',\n                                          end='1/1/2001',\n                                          freq='T'),\n                   'datetime': date_range(start='1/1/2000',\n                                          end='1/1/2001',\n                                          freq='T')}\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)", "number": 0, "name": "timeseries.ResampleSeries.time_resample", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_write_store_table": {"min_run_count": 2, "version": "3c92648901bf711fa5ba194474f8bbba9e88fdfe43e943db07fb43adab51cf19", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append('table_write', self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.AddOverflowArray.time_add_overflow_arr_rev": {"min_run_count": 2, "version": "37d64e6ce5731f6238a6236739568e2763acf65c4e72eda2a3a9162425fb14f0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AddOverflowArray:\n    def time_add_overflow_arr_rev(self):\n        checked_add_with_arr(self.arr, self.arr_rev)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "number": 0, "name": "binary_ops.AddOverflowArray.time_add_overflow_arr_rev", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_translate": {"min_run_count": 2, "version": "2a9129d87d29197e085d5ccf71790332e8e1a6dec4fd1e96e8ab8642399d3810", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_translate(self):\n        self.s.str.translate({'A': '\\x01\\x01'})\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_translate", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.SparseDataFrameConstructor.time_constructor": {"min_run_count": 2, "version": "09358dfde098be0ae778136fbee1ca703389380030273be26452803e28863057", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SparseDataFrameConstructor:\n    def time_constructor(self):\n        SparseDataFrame(columns=self.arr, index=self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.arr = np.arange(N)\n        self.sparse = scipy.sparse.rand(N, N, 0.005)\n        self.dict = dict(zip(range(N), itertools.repeat([0])))", "number": 0, "name": "sparse.SparseDataFrameConstructor.time_constructor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInFloat64.time_isin_many_different": {"min_run_count": 2, "version": "cfae13e0dd2ee397f2ed5b2e69a197694f4ee405163fe956ceff7b01b54c0d48", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInFloat64:\n    def time_isin_many_different(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.many_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10**6, dtype=np.float64)\n        self.few_different_values = np.zeros(10**7, dtype=np.float64)\n        self.only_nans_values = np.full(10**7, np.nan, dtype=np.float64)", "number": 0, "name": "series_methods.IsInFloat64.time_isin_many_different", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Categories.time_groupby_sort": {"min_run_count": 2, "version": "8b037bf4190cf19006f1586a47220ecbe042367843541f94f6645965cb98fb9e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Categories:\n    def time_groupby_sort(self):\n        self.df.groupby('a')['b'].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {'a': Categorical(np.random.randint(10000, size=N)),\n                'b': arr}\n        self.df = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(10000, size=N),\n                                 ordered=True),\n                'b': arr}\n        self.df_ordered = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(100, size=N),\n                                 categories=np.arange(10000)),\n                'b': arr}\n        self.df_extra_cat = DataFrame(data)", "number": 0, "name": "groupby.Categories.time_groupby_sort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IntervalIndexMethod.time_is_unique": {"min_run_count": 2, "version": "2edec0afd6678bab18a2141f493154c6064a094b2ca07fd7a71e8b811b2a5ff1", "processes": 2, "params": [["1000", "100000"]], "type": "time", "warmup_time": -1, "param_names": ["param1"], "timeout": 60.0, "code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "number": 0, "name": "index_object.IntervalIndexMethod.time_is_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_fromordinal": {"min_run_count": 2, "version": "8558b46ef8e615bdb4e39a24bb46d841af38c3ac7f1dee29558e7836c5f1f325", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)", "number": 0, "name": "timestamp.TimestampConstruction.time_fromordinal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IntervalIndexMethod.time_intersection": {"min_run_count": 2, "version": "939fa21709b43d146e14708f07937d7604f92aa6d2be66745499407c7a5bf7f6", "processes": 2, "params": [["1000", "100000"]], "type": "time", "warmup_time": -1, "param_names": ["param1"], "timeout": 60.0, "code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "number": 0, "name": "index_object.IntervalIndexMethod.time_intersection", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Repr.time_html_repr_trunc_si": {"min_run_count": 2, "version": "0625c38f50ef3e2614a975c3b97cfa8b69d5ba7babc9417f10f946020fd6ddfe", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "number": 0, "name": "frame_methods.Repr.time_html_repr_trunc_si", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_query_store_table": {"min_run_count": 2, "version": "aca458a89b9943e78dc9f1d65f55b3cc67a3a373c025bf59915a392a98b283b4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select('table', where=\"index > self.start and \"\n                                         \"index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.Lookup.time_lookup_and_cleanup": {"min_run_count": 2, "version": "06a0323584102febfee091acb992363d67213fb1c161d252b75eb389b85875f3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start='1/1/2000', periods=N, freq='S')\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]", "number": 0, "name": "timeseries.Lookup.time_lookup_and_cleanup", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Integer.time_get_indexer": {"min_run_count": 2, "version": "9a1a6cb27c6887a5ca06e4169c75e5fa59cb1a0a667c6125182383e741ff7580", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product([np.arange(1000),\n                                               np.arange(1000)],\n                                              names=['one', 'two'])\n        self.obj_index = np.array([(0, 10), (0, 11), (0, 12),\n                                   (0, 13), (0, 14), (0, 15),\n                                   (0, 16), (0, 17), (0, 18),\n                                   (0, 19)], dtype=object)", "number": 0, "name": "multiindex_object.Integer.time_get_indexer", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_center": {"min_run_count": 2, "version": "32d4cf3b07569eaa01b63db2cbbba25f2da2484578ee62a761128c8e53de5e04", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_center(self):\n        self.s.str.center(100)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_center", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodIndexConstructor.time_from_date_range": {"min_run_count": 2, "version": "92e2635885ff593b135cb8864680326f4f9877f53e0cb0718534fa71e69f8bbf", "processes": 2, "params": [["'D'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["freq", "is_offset"], "timeout": 60.0, "code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range('1985', periods=1000)\n        self.rng2 = date_range('1985', periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = date_range('1/1/2000', periods=1000,\n                                     freq=freq).strftime('%Y%m%d').map(int)\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "number": 0, "name": "period.PeriodIndexConstructor.time_from_date_range", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples_start": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "57ab55e1674f03fa1802c36fbed2a469d94aa728e6c5ef78e8744f20fe4d2367", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples_start", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "timeseries.Iteration.time_iter": {"min_run_count": 2, "version": "d4e780126dd4dd5f3ee8023e8109422ea533d09292debb42f9712325a9e79a17", "processes": 2, "params": [["<function date_range at 0x7f559e1e7950>", "<function period_range at 0x7f559e0fa510>"]], "type": "time", "warmup_time": -1, "param_names": ["time_index"], "timeout": 60.0, "code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        self.idx = time_index(start='20140101', freq='T', periods=N)\n        self.exit = 10000", "number": 0, "name": "timeseries.Iteration.time_iter", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_quarter_end": {"min_run_count": 2, "version": "3eb0a0557fc90258d3bb9e7796771092f38381009a636b0772c0fc2dd0e3bf62", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz, freq):\n        self.ts.is_quarter_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_quarter_end", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.ToHTML.time_to_html_mixed": {"min_run_count": 2, "version": "2b509a2a2e9de6bdd6ee381508994ceb789cb4b1405b7d7fff91a555026f4066", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range('2000', periods=nrows)\n        self.df2[1] = range(nrows)", "number": 0, "name": "frame_methods.ToHTML.time_to_html_mixed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {"min_run_count": 2, "version": "aeae5b2c0c5a1d85b30db323e81ebd1717a215043af4564aa1e9a29444d2d128", "processes": 2, "params": [["False", "True"]], "type": "time", "warmup_time": -1, "param_names": ["cache_dates"], "timeout": 60.0, "code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(self.data(self.StringIO_input),\n                      dtype={'date': str}, names=['date'])\n        to_datetime(df['date'], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = '12-02-2010\\n' * count_elem\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {"min_run_count": 2, "version": "d05101a8657458534c5ce0b687217139c0ba5fc879980f4d1f0125b9614481d7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array(['foo', 'bar', 'baz'], dtype=object)\n        self.s = Series([Timestamp('20110101'), Timestamp('20120101'),\n                         Timestamp('20130101')] * N * 10)", "number": 0, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffestDatetimeArithmetic.time_add_10": {"min_run_count": 2, "version": "a1f8542352b024c0daa9f0c0888499cd757e1a271fcb6eb6bdd8eb5b4b321a71", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64('2011-01-01 09:00Z')", "number": 0, "name": "offset.OffestDatetimeArithmetic.time_add_10", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "eval.Eval.time_and": {"min_run_count": 2, "version": "fa2fa44a20c83ee9dc23b398f63dbfc9d39ee60ff9dcf7599cad21a71e0002f9", "processes": 2, "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["engine", "threads"], "timeout": 60.0, "code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval('(self.df > 0) & (self.df2 > 0) & '\n                '(self.df3 > 0) & (self.df4 > 0)', engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "number": 0, "name": "eval.Eval.time_and", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Apply.time_apply_pass_thru": {"min_run_count": 2, "version": "9c49eb29fa9f5e4992916b0b8b438f31dc833f7e1ffcb25dcedc37741da0b03a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Apply.time_apply_pass_thru", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaProperties.time_timedelta_microseconds": {"min_run_count": 2, "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:83", "number": 0, "name": "timedelta.TimedeltaProperties.time_timedelta_microseconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.SearchSorted.time_searchsorted": {"min_run_count": 2, "version": "5d81d6e14f7e40f59b87bea9fd05a4acc74a2f74605badc6b3a5d2669195182f", "processes": 2, "params": [["'int8'", "'int16'", "'int32'", "'int64'", "'uint8'", "'uint16'", "'uint32'", "'uint64'", "'float16'", "'float32'", "'float64'", "'str'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = '2' if dtype == 'str' else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10**5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)", "number": 0, "name": "series_methods.SearchSorted.time_searchsorted", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Concat.time_concat": {"min_run_count": 2, "version": "54edba42bde703de38922f2489d056611ede65dc5f67b281d0a5092c75a6c0cd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list('aabbcd') * N).astype('category')\n    \n        self.a = pd.Categorical(list('aabbcd') * N)\n        self.b = pd.Categorical(list('bbcdjk') * N)", "number": 0, "name": "categoricals.Concat.time_concat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Rank.time_rank_int_cat": {"min_run_count": 2, "version": "49c70c199d408ef2c9c34badd7b481693f3e7c7a025311466bc023211fc8bbfe", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = self.s_str.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_str_cat_ordered = self.s_str.astype('category',\n                                                       ordered=True)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = self.s_int.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_int_cat_ordered = self.s_int.astype('category',\n                                                       ordered=True)", "number": 0, "name": "categoricals.Rank.time_rank_int_cat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {"min_run_count": 2, "version": "6318f7d19fff83012f59d45663c46e0c4f5a0a5e873f21522f7afe9d0dd6f811", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format='%Y%m%d')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start='1/1/2000', periods=10000, freq='D')\n        self.stringsD = Series(rng.strftime('%Y%m%d'))", "number": 0, "name": "timeseries.ToDatetimeYYYYMMDD.time_format_YYYYMMDD", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.pickle.Pickle.time_write_pickle": {"min_run_count": 2, "version": "3c714f1e33bc9eddecbb06d625c2bf05747c40a441d226e9cc3bc5752b9226ef", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = '__test__.pkl'\n        N = 100000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "number": 0, "name": "io.pickle.Pickle.time_write_pickle", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Range.time_min_trivial": {"min_run_count": 2, "version": "648086d23485f0a8287f4d3b255b1ba789c972854845211a2086251486935626", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**7, step=3)\n        self.idx_dec = RangeIndex(start=10**7, stop=-1, step=-3)", "number": 0, "name": "index_object.Range.time_min_trivial", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromRecords.time_frame_from_records_generator": {"min_run_count": 2, "version": "eec7b09b4fa409f895b70cac11929c08947074b5e92dfb4b844dc4f349e04474", "processes": 2, "params": [["None", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["nrows"], "timeout": 60.0, "code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))", "number": 0, "name": "frame_ctor.FromRecords.time_frame_from_records_generator", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.SeriesConstructor.time_constructor": {"min_run_count": 2, "version": "5ee029f9161ed3d5079a20931f66002235dd528b2608f554a8265ffc6c80bf72", "processes": 2, "params": [["None", "'dict'"]], "type": "time", "warmup_time": -1, "param_names": ["data"], "timeout": 60.0, "code": "class SeriesConstructor:\n    def time_constructor(self, data):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self, data):\n        self.idx = date_range(start=datetime(2015, 10, 26),\n                              end=datetime(2016, 1, 1),\n                              freq='50s')\n        dict_data = dict(zip(self.idx, range(len(self.idx))))\n        self.data = None if data is None else dict_data", "number": 0, "name": "series_methods.SeriesConstructor.time_constructor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.excel.Excel.time_write_excel": {"min_run_count": 2, "version": "d6c2e1a00861144db741bf708348f6e272c68551d64c120074187ab6f3702a4e", "processes": 2, "params": [["'openpyxl'", "'xlsxwriter'", "'xlwt'"]], "type": "time", "warmup_time": -1, "param_names": ["engine"], "timeout": 60.0, "code": "class Excel:\n    def time_write_excel(self, engine):\n        bio_write = BytesIO()\n        bio_write.seek(0)\n        writer_write = ExcelWriter(bio_write, engine=engine)\n        self.df.to_excel(writer_write, sheet_name='Sheet1')\n        writer_write.save()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Excel:\n    def setup(self, engine):\n        N = 2000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.bio_read = BytesIO()\n        self.writer_read = ExcelWriter(self.bio_read, engine=engine)\n        self.df.to_excel(self.writer_read, sheet_name='Sheet1')\n        self.writer_read.save()\n        self.bio_read.seek(0)", "number": 0, "name": "io.excel.Excel.time_write_excel", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_reindex": {"min_run_count": 2, "version": "6e6b35b66648b105318f565d0656aae9bb676b9a0fdabd14830ae3e3278e904e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_reindex", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.CategoricalSlicing.time_getitem_bool_array": {"min_run_count": 2, "version": "45c94210074a0bc47c5d75d6692baef1d4ec9077fd9dac15cc4bcc27fb4f3658", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = ['a', 'b', 'c']\n        values = [0] * N + [1] * N + [2] * N\n        if index == 'monotonic_incr':\n            self.data = pd.Categorical.from_codes(values,\n                                                  categories=categories)\n        elif index == 'monotonic_decr':\n            self.data = pd.Categorical.from_codes(list(reversed(values)),\n                                                  categories=categories)\n        elif index == 'non_monotonic':\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N,\n                                                  categories=categories)\n        else:\n            raise ValueError('Invalid index param: {}'.format(index))\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = 'b'", "number": 0, "name": "categoricals.CategoricalSlicing.time_getitem_bool_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.SparseDataFrameConstructor.time_from_dict": {"min_run_count": 2, "version": "082bfccc552c77dbbc67f64c01489aaefc81f42a5ce01825fd21bdb51db492ef", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SparseDataFrameConstructor:\n    def time_from_dict(self):\n        SparseDataFrame(self.dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.arr = np.arange(N)\n        self.sparse = scipy.sparse.rand(N, N, 0.005)\n        self.dict = dict(zip(range(N), itertools.repeat([0])))", "number": 0, "name": "sparse.SparseDataFrameConstructor.time_from_dict", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_getitem_list": {"min_run_count": 2, "version": "14183da92e20060acd256bf80467ceb0d8c45a376ac25612d3aed26c07b91b67", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_getitem_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.TransformNaN.time_first": {"min_run_count": 2, "version": "c7b7cb8404e5fc9612baeda09553cfd3d73af1adc934118a406382016d193afe", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby('key').transform('first')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame({'key': np.repeat(np.arange(1000), 10),\n                                  'B': np.nan,\n                                  'C': np.nan})\n        self.df_nans.loc[4::10, 'B':'C'] = 5", "number": 0, "name": "groupby.TransformNaN.time_first", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Ops.time_divide": {"min_run_count": 2, "version": "d1572d91001bc657b4e77615b7fd51f67fafa5df4b4df41d5ba067abec8a2619", "processes": 2, "params": [["'float'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Ops:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {'int': 'makeIntIndex', 'float': 'makeFloatIndex'}\n        self.index = getattr(tm, indexes[dtype])(N)", "number": 0, "name": "index_object.Ops.time_divide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_delta_int_tstamp_lines": {"min_run_count": 2, "version": "59b4cd755e1a64adead66f3a3da5d9af3e51eb4813354a239cee5abc98f5c098", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_delta_int_tstamp_lines(self, orient):\n        self.df_td_int_ts.to_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_delta_int_tstamp_lines", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Transform.time_transform_multi_key1": {"min_run_count": 2, "version": "d33275d012f56d1a745f36424b9764cbd02b7614e4a93966f7707a9947436211", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby(['jim', 'joe'])['jolie'].transform('max')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(levels=[np.arange(n1), tm.makeStringIndex(n2)],\n                           codes=[np.repeat(range(n1), n2).tolist(),\n                                  list(range(n2)) * n1],\n                           names=['lev1', 'lev2'])\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=['col1', 'col20', 'col3'])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(np.random.randint(1, n, (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df2 = self.df1.copy()\n        self.df2['jim'] = self.df2['joe']\n    \n        self.df3 = DataFrame(np.random.randint(1, (n / 10), (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df4 = self.df3.copy()\n        self.df4['jim'] = self.df4['joe']", "number": 0, "name": "groupby.Transform.time_transform_multi_key1", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {"min_run_count": 2, "version": "cac278a7f08f9abcc8e7b9cb003bd007a45c9aa6ae4b6736e8f33c36044d2d43", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col['A']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=['A'])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "number": 0, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples_raw_start": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "f8a6b768a1333ef06db3d3e221c6eb8aabfdc82252c6782f0148502b6788fb7f", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples_raw_start", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "reshape.Crosstab.time_crosstab": {"min_run_count": 2, "version": "86fd034fa1b941080d7841907ea0056f45ad5bd284875ef45b6aeb67a31eb558", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "number": 0, "name": "reshape.Crosstab.time_crosstab", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Concat.time_concat_small_frames": {"min_run_count": 2, "version": "a36a07a98999e740c775044f9e30589a234b4602d43a4ae0ed88137b90e92964", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:- i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame({'A': range(N)},\n                       index=date_range('20130101', periods=N, freq='s'))\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "number": 0, "name": "join_merge.Concat.time_concat_small_frames", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_count": {"min_run_count": 2, "version": "4a363b2982eced282102edc6a2a9dab1020afdca585c9dc319059830a4c2d8de", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_count(self):\n        self.s.str.count('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_count", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.stata.StataMissing.time_read_stata": {"min_run_count": 2, "version": "c3922bbd2493683bb282e1552c6ff675b65624bcf09b0d8d078acceb24c7337e", "processes": 2, "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "type": "time", "warmup_time": -1, "param_names": ["convert_dates"], "timeout": 60.0, "code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df['missing_{0}'.format(i)] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)", "number": 0, "name": "io.stata.StataMissing.time_read_stata", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {"min_run_count": 2, "version": "df9ae1f6ff777803bb1e02da2f935c5511a6cf8b6bf876575aad20d6b29fca36", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Dummies.time_get_dummies": {"min_run_count": 2, "version": "26457f2661eeecbd4eda0b010187ccb8728f05a61b5b106a855fb05c80e69855", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Dummies:\n    def time_get_dummies(self):\n        self.s.str.get_dummies('|')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5)).str.join('|')", "number": 0, "name": "strings.Dummies.time_get_dummies", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Reindex.time_reindex_both_axes": {"min_run_count": 2, "version": "bfd76f928ab3b15545aafee1c914914d73f294f6474f84a0cf63e8d981361e96", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Reindex.time_reindex_both_axes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.IntervalIndexing.time_loc_list": {"min_run_count": 2, "version": "53a67c0ae3f4a03fb6ddb93ef70355a41aaab9b4eb41712bf564868bb0ecb3c9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:220", "number": 0, "name": "indexing.IntervalIndexing.time_loc_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_iso_format": {"min_run_count": 2, "version": "5467d3e0a01d178a42069878d48c440e75871d74c3dc4239ca0c2a0624b2e81d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta('P4DT12H30M5S')", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_iso_format", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Lookup.time_frame_fancy_lookup_all": {"min_run_count": 2, "version": "fee09094b3edf5a8da05a5a374219a109fe241b261ea3c25ecd0558afa7c4c66", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Lookup:\n    def time_frame_fancy_lookup_all(self):\n        self.df.lookup(self.row_labels_all, self.col_labels_all)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8),\n                            columns=list('abcdefgh'))\n        self.df['foo'] = 'bar'\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype='object')\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype='object')", "number": 0, "name": "frame_methods.Lookup.time_frame_fancy_lookup_all", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Rank.time_rank_int_cat_ordered": {"min_run_count": 2, "version": "8e1256ed29b8b321bb0301eaf02c5922f2e32046c0ac1fb1098554504a276eca", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = self.s_str.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_str_cat_ordered = self.s_str.astype('category',\n                                                       ordered=True)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = self.s_int.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_int_cat_ordered = self.s_int.astype('category',\n                                                       ordered=True)", "number": 0, "name": "categoricals.Rank.time_rank_int_cat_ordered", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.DropDuplicates.time_series_drop_dups_string": {"min_run_count": 2, "version": "fda975124c90b8c6574041781783dfb5d5083336617ab7cfd002d9cf1adf1423", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame({'key1': key1, 'key2': key2,\n                             'value': np.random.randn(N * K)})\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({'key1': key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10),\n                                                   dtype=bool))", "number": 0, "name": "reindex.DropDuplicates.time_series_drop_dups_string", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInForObjects.time_isin_long_series_long_values_floats": {"min_run_count": 2, "version": "220cd8e3973e5afd8e593d244bbaa2d7a66e57a3f040eee30d3f0a8d6dc3def8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInForObjects:\n    def time_isin_long_series_long_values_floats(self):\n        # no dominating part\n        self.s_long_floats.isin(self.vals_long_floats)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10**4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10**4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10**5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10**5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10**5,\n                                    dtype=np.float)).astype(np.object)\n        self.vals_long_floats = np.arange(10**5,\n                                          dtype=np.float).astype(np.object)", "number": 0, "name": "series_methods.IsInForObjects.time_isin_long_series_long_values_floats", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.AsOf.time_asof_single": {"min_run_count": 2, "version": "d0f86f5f0634f8fb36c190c00f56c50bac735cc239488fad5558dcc5f5e597d4", "processes": 2, "params": [["'DataFrame'", "'Series'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor"], "timeout": 60.0, "code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start='1/1/1990', periods=N, freq='53s')\n        data = {'DataFrame': DataFrame(np.random.randn(N, M)),\n                'Series': Series(np.random.randn(N))}\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start='1/1/1990', periods=N * 10, freq='5s')\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "number": 0, "name": "timeseries.AsOf.time_asof_single", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.GetLoc.time_large_get_loc": {"min_run_count": 2, "version": "d1e4b2bab87b40d2ccd56a6bf92e1e2d5516371b82da684c0bcfef717eccc14c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, 'Z'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=['one', 'two', 'three'])\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list('A')],\n            names=['one', 'two', 'three'])\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list('A'), list('A')],\n            names=['one', 'two', 'three'])", "number": 0, "name": "multiindex_object.GetLoc.time_large_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_int_div_by_zero": {"min_run_count": 2, "version": "4f1fe81da4ef57f9843ce9b7c248e59682fa370dd6fed901cfc1774f88b64248", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_int_div_by_zero", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_store_info": {"min_run_count": 2, "version": "ea89a5cebd937eb3f618cb6e9610263cb9624b58a8023de7d830257f3bd6bab4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_store_info", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Isnull.time_isnull_floats_no_null": {"min_run_count": 2, "version": "c7de48d4c6f70974ba7b38f6d73ae415c450cf2677506cbc106fb1353b8c8a4d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array([NaT, np.nan, None, np.datetime64('NaT'),\n                           np.timedelta64('NaT'), 0, 1, 2.0, '', 'abcd'])\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "number": 0, "name": "frame_methods.Isnull.time_isnull_floats_no_null", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_replace_None": {"min_run_count": 2, "version": "daa572d0d4c19502aeb9f64d68aaa07b06766ca2187a06094dba09bb256b82b4", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_replace_None", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_series_int": {"min_run_count": 2, "version": "495bed9e1cd5c0dc88dc033f9281b005b7823ebc1c5a1f496d115aa25d81eeac", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df['ints'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_series_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "eval.Query.time_query_with_boolean_selection": {"min_run_count": 2, "version": "d8573e15bd358480af33bbf29eb616fe5e762cdcc2c3f31f860f3acad68a381f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query('(a >= @self.min_val) & (a <= @self.max_val)')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range('20010101', periods=N, freq='T')\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({'a': np.random.randn(N), 'dates': index},\n                               index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "number": 0, "name": "eval.Query.time_query_with_boolean_selection", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Values.time_datetime_level_values_sliced": {"min_run_count": 2, "version": "f4e057d03047f03fce123774465cc73f72f6faa935b0a0f4658668bb99f03357", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start='1/1/2012', periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/multiindex_object.py:115", "number": 0, "name": "multiindex_object.Values.time_datetime_level_values_sliced", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.NSort.time_nlargest": {"min_run_count": 2, "version": "253c5ac019c9236c18146b346c88bc19e56f04eb4c5d86ec0da4cd51188b900a", "processes": 2, "params": [["'first'", "'last'", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["keep"], "timeout": 60.0, "code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "number": 0, "name": "series_methods.NSort.time_nlargest", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeAsof.time_multiby": {"min_run_count": 2, "version": "c27dc4556f61acfa03d2d58164f2a66e700710eb31394e8c9decb5cd8da8190a", "processes": 2, "params": [["'backward'", "'forward'", "'nearest'"]], "type": "time", "warmup_time": -1, "param_names": ["direction"], "timeout": 60.0, "code": "class MergeAsof:\n    def time_multiby(self, direction):\n        merge_asof(self.df1e, self.df2e, on='time', by=['key', 'key2'],\n                   direction=direction)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {'time': np.random.randint(0, one_count / 20, one_count),\n             'key': np.random.choice(list(string.ascii_uppercase), one_count),\n             'key2': np.random.randint(0, 25, one_count),\n             'value1': np.random.randn(one_count)})\n        df2 = DataFrame(\n            {'time': np.random.randint(0, two_count / 20, two_count),\n             'key': np.random.choice(list(string.ascii_uppercase), two_count),\n             'key2': np.random.randint(0, 25, two_count),\n             'value2': np.random.randn(two_count)})\n    \n        df1 = df1.sort_values('time')\n        df2 = df2.sort_values('time')\n    \n        df1['time32'] = np.int32(df1.time)\n        df2['time32'] = np.int32(df2.time)\n    \n        self.df1a = df1[['time', 'value1']]\n        self.df2a = df2[['time', 'value2']]\n        self.df1b = df1[['time', 'key', 'value1']]\n        self.df2b = df2[['time', 'key', 'value2']]\n        self.df1c = df1[['time', 'key2', 'value1']]\n        self.df2c = df2[['time', 'key2', 'value2']]\n        self.df1d = df1[['time32', 'value1']]\n        self.df2d = df2[['time32', 'value2']]\n        self.df1e = df1[['time', 'key', 'key2', 'value1']]\n        self.df2e = df2[['time', 'key', 'key2', 'value2']]", "number": 0, "name": "join_merge.MergeAsof.time_multiby", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_join": {"min_run_count": 2, "version": "67978f92289cab44d3474c25409d36f3e858f3ef0f95467814a04c8e07ae5548", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_join(self):\n        self.s.str.join(' ')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_join", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops.time_frame_multi_and": {"min_run_count": 2, "version": "c1afcb2dd345b9d7baaa58d67814758ccfc0ba23b4a45771196db8117b375580", "processes": 2, "params": [["True", "False"], ["'default'", "1"]], "type": "time", "warmup_time": -1, "param_names": ["use_numexpr", "threads"], "timeout": 60.0, "code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != 'default':\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "number": 0, "name": "binary_ops.Ops.time_frame_multi_and", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_components": {"min_run_count": 2, "version": "46141c82dc69925cf2939543559756c2039efbb15369ecc4c70ca9bf10c5b472", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(days=1, hours=2, minutes=3, seconds=4, milliseconds=5,\n                  microseconds=6, nanoseconds=7)", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_components", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_with_nan": {"min_run_count": 2, "version": "851e51fdd4b12e48c592a113dd16a212925ceee02fc168848a1cd720ba08e73a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_with_nan", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Factorize.time_factorize": {"min_run_count": 2, "version": "17e84d20ae22646706df1b39a3caf905be01dad69d2bb9703388c538cfff12a2", "processes": 2, "params": [["True", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "type": "time", "warmup_time": -1, "param_names": ["sort", "dtype"], "timeout": 60.0, "code": "class Factorize:\n    def time_factorize(self, sort, dtype):\n        self.idx.factorize(sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, sort, dtype):\n        N = 10**5\n        data = {'int': pd.Int64Index(np.arange(N).repeat(5)),\n                'uint': pd.UInt64Index(np.arange(N).repeat(5)),\n                'float': pd.Float64Index(np.random.randn(N).repeat(5)),\n                'string': tm.makeStringIndex(N).repeat(5)}\n        self.idx = data[dtype]", "number": 0, "name": "algorithms.Factorize.time_factorize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_float_int_lines": {"min_run_count": 2, "version": "7501aa3a133b768ba09e097205d6cf7af08ea6aebe4c2c1983a874a2714f6b13", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_float_int_lines(self, orient):\n        self.df_int_floats.to_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_float_int_lines", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IntervalIndexMethod.time_monotonic_inc": {"min_run_count": 2, "version": "6b8f6fcddf2a59a7e379c0e62500817c2b0ac535161102dfedcf3ee1a8eeca37", "processes": 2, "params": [["1000", "100000"]], "type": "time", "warmup_time": -1, "param_names": ["param1"], "timeout": 60.0, "code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "number": 0, "name": "index_object.IntervalIndexMethod.time_monotonic_inc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_reindex_missing": {"min_run_count": 2, "version": "0008f1576f7b1408418439bd8296d38bc490e82051e87120f5e85ebea89f7e5b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex(['a', 'b', 'c', 'd'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_reindex_missing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelDatetimeFields.time_datetime_to_period": {"min_run_count": 2, "version": "60eeb8fa28518b0985b81adea662433ba7ca3a02597466c7fcdca608516a679a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period('S')\n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        self.dti = date_range('1900-01-01', periods=N, freq='T')\n        self.period = self.dti.to_period('D')", "number": 0, "name": "gil.ParallelDatetimeFields.time_datetime_to_period", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Rename.time_rename_both_axes": {"min_run_count": 2, "version": "008fb24ef2b2b1cefb935ece7f1839bad417c9a52fbf22e05c681cac6f5c91d3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Rename.time_rename_both_axes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_rpartition": {"min_run_count": 2, "version": "8293a784587893ec71f5ae4ef8e6ce1dde2d27bfb0cd46fe69db76ed736bf8ac", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_rpartition(self):\n        self.s.str.rpartition('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_rpartition", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.DatetimeAccessor.time_timedelta_seconds": {"min_run_count": 2, "version": "7702b1e726bbd121123f09f86c5afa4fe38d7fd98032738aaccd0750ecf3fb4b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range('1 days', periods=N, freq='h'))\n        return series", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:102", "number": 0, "name": "timedelta.DatetimeAccessor.time_timedelta_seconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_raw_tuples": {"min_run_count": 2, "version": "18fcd4d3c4ecdb5f4437deda8e7e21745a73cd04a48f4e6518b8a46d8b8417ea", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_raw_tuples", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_float_int": {"min_run_count": 2, "version": "15d4ef22dbb8ba52827749177d06d42548dcf7a3b876d0205e03928a5cb3a2c3", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_float_int(self, orient):\n        self.df_int_floats.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_float_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_loc_slice": {"min_run_count": 2, "version": "aac26788616f85fd4c636cfc419c79da7f78ea59a1183c95b6ebff14009d9cea", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_loc_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Rename.time_rename_single": {"min_run_count": 2, "version": "0d75a9f8bf427e0bc8cd91f0985adaf5300b41ada031723e8693916e5eaffece", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Rename.time_rename_single", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeCategoricals.time_merge_cat": {"min_run_count": 2, "version": "1b42e76edeb29253a753cb67c895a235ddaa3ba2c176ae9d031cf0a1874680f5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on='X')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {'X': np.random.choice(range(0, 10), size=(10000,)),\n             'Y': np.random.choice(['one', 'two', 'three'], size=(10000,))})\n    \n        self.right_object = DataFrame(\n            {'X': np.random.choice(range(0, 10), size=(10000,)),\n             'Z': np.random.choice(['jjj', 'kkk', 'sss'], size=(10000,))})\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object['Y'].astype('category'))\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object['Z'].astype('category'))", "number": 0, "name": "join_merge.MergeCategoricals.time_merge_cat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "eval.Query.time_query_datetime_column": {"min_run_count": 2, "version": "7f574c06d532200bc1c09d1312e3dc404f873357333db642961135220c73534a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query('dates < @self.ts')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range('20010101', periods=N, freq='T')\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({'a': np.random.randn(N), 'dates': index},\n                               index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "number": 0, "name": "eval.Query.time_query_datetime_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Timeseries.time_timestamp_series_compare": {"min_run_count": 2, "version": "6bff964fde49797d192fd5394da4fe320bb9570c23c37e8e9beaee91b0e1a50d", "processes": 2, "params": [["None", "'US/Eastern'"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range('20010101', periods=N, freq='T', tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range('20010101', periods=N, freq='s', tz=tz))", "number": 0, "name": "binary_ops.Timeseries.time_timestamp_series_compare", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.NSort.time_nsmallest": {"min_run_count": 2, "version": "91f7a9783802ebb8d4430865643ddc60d047d6480337c2525bf11ce778093519", "processes": 2, "params": [["'first'", "'last'", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["keep"], "timeout": 60.0, "code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "number": 0, "name": "series_methods.NSort.time_nsmallest", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_ix_scalar": {"min_run_count": 2, "version": "e2d2dd6014f0776ceadf483ff01150ccd79b6afacec929e1f08442587c83c6d6", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_ix_scalar(self, index, index_structure):\n        self.data.ix[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_ix_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_fromtimestamp": {"min_run_count": 2, "version": "4afd2da54b515083d180740e9f4a4d2fd4d3c965f1d92457517630372009379b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)", "number": 0, "name": "timestamp.TimestampConstruction.time_fromtimestamp", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Isin.time_isin_categorical": {"min_run_count": 2, "version": "12f2f45ad6ae954fc4fdeb729a584f750408f5e973b7b100d78cbf831a87a4d0", "processes": 2, "params": [["'object'", "'int64'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Isin:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        np.random.seed(1234)\n        n = 5 * 10**5\n        sample_size = 100\n        arr = [i for i in np.random.randint(0, n // 10, size=n)]\n        if dtype == 'object':\n            arr = ['s{:04d}'.format(i) for i in arr]\n        self.sample = np.random.choice(arr, sample_size)\n        self.series = pd.Series(arr).astype('category')", "number": 0, "name": "categoricals.Isin.time_isin_categorical", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Range.time_get_loc_inc": {"min_run_count": 2, "version": "e2341b925248a9c26b6d628dec67cf02c673cc605c393c54ea03f7cef89a5643", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**7, step=3)\n        self.idx_dec = RangeIndex(start=10**7, stop=-1, step=-3)", "number": 0, "name": "index_object.Range.time_get_loc_inc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.Pairwise.time_pairwise": {"min_run_count": 2, "version": "07b2c6235f07bca8cc85c9f440ec676c59c5fb73f79b87ed561a6ca877d72ec4", "processes": 2, "params": [["10", "1000", "None"], ["'corr'", "'cov'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["window", "method", "pairwise"], "timeout": 60.0, "code": "class Pairwise:\n    def time_pairwise(self, window, method, pairwise):\n        if window is None:\n            r = self.df.expanding()\n        else:\n            r = self.df.rolling(window=window)\n        getattr(r, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, window, method, pairwise):\n        N = 10**4\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)", "number": 0, "name": "rolling.Pairwise.time_pairwise", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_leap_year": {"min_run_count": 2, "version": "c629f2deb766760d07e0194518b8d34fedcec2f7be15910ba5e47b390eceaf38", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_leap_year(self, tz, freq):\n        self.ts.is_leap_year\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_leap_year", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeCache.time_dup_string_dates_and_format": {"min_run_count": 2, "version": "0a3cfe3cf072127219ca5ab88017dabc582dd8ab0eff89e9095d1e73d049c913", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["cache"], "timeout": 60.0, "code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format='%Y-%m-%d', cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = ['2000-02-11'] * N\n        self.dup_string_with_tz = ['2000-02-11 15:00:00-0800'] * N", "number": 0, "name": "timeseries.ToDatetimeCache.time_dup_string_dates_and_format", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_unit": {"min_run_count": 2, "version": "cac5d8f3b4efa3e7a5a23990b66ab6d34a0b2ff2054083adfc2fb1d7ad37ce64", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit='d')", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_unit", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameNumericIndexing.time_loc_dups": {"min_run_count": 2, "version": "65132c2abbdc4a03cc6b29c6b764e744ab6184801cf20aa904a3410de6ec74dd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "number": 0, "name": "indexing.DataFrameNumericIndexing.time_loc_dups", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "dtypes.Dtypes.time_pandas_dtype": {"min_run_count": 2, "version": "c636a90f2e83bdd77f2d6ee44d53f3f544eae867d47edcc9aa01c5fac4e847c1", "processes": 2, "params": [["dtype('int64')", "dtype('int32')", "dtype('uint32')", "dtype('uint64')", "dtype('float32')", "dtype('float64')", "dtype('int16')", "dtype('int8')", "dtype('uint16')", "dtype('uint8')", "dtype('<M8')", "dtype('<m8')", "dtype('O')", "<class 'pandas.core.arrays.integer.Int8Dtype'>", "<class 'pandas.core.arrays.integer.Int16Dtype'>", "<class 'pandas.core.arrays.integer.Int32Dtype'>", "<class 'pandas.core.arrays.integer.Int64Dtype'>", "<class 'pandas.core.arrays.integer.UInt8Dtype'>", "<class 'pandas.core.arrays.integer.UInt16Dtype'>", "<class 'pandas.core.arrays.integer.UInt32Dtype'>", "<class 'pandas.core.arrays.integer.UInt64Dtype'>", "<class 'pandas.core.dtypes.dtypes.CategoricalDtype'>", "<class 'pandas.core.dtypes.dtypes.IntervalDtype'>", "datetime64[ns, UTC]", "period[D]", "'int64'", "'int32'", "'uint32'", "'uint64'", "'float32'", "'float64'", "'int16'", "'int8'", "'uint16'", "'uint8'", "'datetime64'", "'timedelta64'", "'object'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'category'", "'interval'", "'datetime64[ns, UTC]'", "'period[D]'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "number": 0, "name": "dtypes.Dtypes.time_pandas_dtype", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeFormatQuarters.time_infer_quarter": {"min_run_count": 2, "version": "2b9b5ec7c140800d1c969e315f51bfa1aa3bdc16ea3da01884d37d06bbce361e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series(['2Q2005', '2Q05', '2005Q1', '05Q1'] * 10000)", "number": 0, "name": "timeseries.ToDatetimeFormatQuarters.time_infer_quarter", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_series_loc": {"min_run_count": 2, "version": "b23f09ac08416f9fdfd6b246ba7741de220c3c22cb71f3897df7166e6cf7dede", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_series_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Contains.time_contains": {"min_run_count": 2, "version": "16a728ee9c477ada791f425cd1aa45112f819557c235d2090d01bcdb595ad0a0", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["regex"], "timeout": 60.0, "code": "class Contains:\n    def time_contains(self, regex):\n        self.s.str.contains('A', regex=regex)\n\n    def setup(self, regex):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Contains.time_contains", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_wrap": {"min_run_count": 2, "version": "703b76bfc042168ee22dcddb5c0fd1a421ba297f00db6e72de2d63281e95c995", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_wrap(self):\n        self.s.str.wrap(10)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_wrap", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "1ff047e8107a332d4d93b9287b6baf44599cb1b8a56ab8754adb124fea8a8912", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {"min_run_count": 2, "version": "86a26e4e610dfcbc2ce1759b96a1e5711e4c367dbab790a1700193db97d8d57a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10**4\n        self.iterables = [tm.makeStringIndex(N), range(20)]", "number": 0, "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromLists.time_frame_from_lists": {"min_run_count": 2, "version": "ecc9fafaf46e3b4df6b1bd6c73e6d0ae6b3ad3827d21ffb65c5ff6424c0490a2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [[j for j in range(M)] for i in range(N)]", "number": 0, "name": "frame_ctor.FromLists.time_frame_from_lists", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.SparseSeriesToFrame.time_series_to_frame": {"min_run_count": 2, "version": "71e714beac4253a89d43ae878fbaeab14ad338d212cb33f02f0013d2c85df857", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        SparseDataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range('1/1/2000', periods=N, freq='T')\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = SparseSeries(data, index=idx)", "number": 0, "name": "sparse.SparseSeriesToFrame.time_series_to_frame", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.MaskBool.time_frame_mask_bools": {"min_run_count": 2, "version": "53396c27fe51bab040f207946d8fb824d0e5193a4a546c2a956b13c6471a17bc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "number": 0, "name": "frame_methods.MaskBool.time_frame_mask_bools", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {"min_run_count": 2, "version": "67292769b370303a93f9e1e80f20acbc941c5a3281e53bf67937c0a9f33ca77b", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.DropDuplicates.time_frame_drop_dups_int": {"min_run_count": 2, "version": "8bcefcc1a3a3f489f6a4f17b2b1b92641777d647525709ba8c2b060d94cdae29", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame({'key1': key1, 'key2': key2,\n                             'value': np.random.randn(N * K)})\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({'key1': key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10),\n                                                   dtype=bool))", "number": 0, "name": "reindex.DropDuplicates.time_frame_drop_dups_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodUnaryMethods.time_now": {"min_run_count": 2, "version": "1ea8cd2ab2e06f634efcce9713c1dae71a1a00e7ba5f52ee566dd01c9d084365", "processes": 2, "params": [["'M'", "'min'"]], "type": "time", "warmup_time": -1, "param_names": ["freq"], "timeout": 60.0, "code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period('2012-06-01', freq=freq)", "number": 0, "name": "period.PeriodUnaryMethods.time_now", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.FrameOps.time_op": {"min_run_count": 2, "version": "3322289ae23b18b7b27404bb4422ca539c911d44150a670216eb3be01e9d6f33", "processes": 2, "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"], ["0", "1"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["op", "dtype", "axis", "use_bottleneck"], "timeout": 60.0, "code": "class FrameOps:\n    def time_op(self, op, dtype, axis, use_bottleneck):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis, use_bottleneck):\n        df = pd.DataFrame(np.random.randn(100000, 4)).astype(dtype)\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df_func = getattr(df, op)", "number": 0, "name": "stat_ops.FrameOps.time_op", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_string": {"min_run_count": 2, "version": "585a1c98e3143a3117106ac775298f3dcec81f54e0ec6e29c6384c9eacd0d2ff", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta('1 days')", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_string", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelReadCSV.time_read_csv": {"min_run_count": 2, "version": "684782d392f3d8c6df493bd021d16091e4ec7e4d38ddbc708cc8d62822f5289b", "processes": 2, "params": [["'float'", "'object'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        rows = 10000\n        cols = 50\n        data = {'float': DataFrame(np.random.randn(rows, cols)),\n                'datetime': DataFrame(np.random.randn(rows, cols),\n                                      index=date_range('1/1/2000',\n                                                       periods=rows)),\n                'object': DataFrame('foo',\n                                    index=range(rows),\n                                    columns=['object%03d'.format(i)\n                                             for i in range(5)])}\n    \n        self.fname = '__test_{}__.csv'.format(dtype)\n        df = data[dtype]\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n        self.parallel_read_csv = parallel_read_csv", "number": 1, "name": "gil.ParallelReadCSV.time_read_csv", "sample_time": 0.01, "unit": "seconds", "repeat": 5}, "reshape.Pivot.time_reshape_pivot_time_series": {"min_run_count": 2, "version": "ddbe5faed01aacbc647be43eb092bd2487807edf57a2b269415568c97ca674c1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot('date', 'variable', 'value')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range('1/1/2000', periods=N, freq='h')\n        data = {'value': np.random.randn(N * 50),\n                'variable': np.arange(50).repeat(N),\n                'date': np.tile(index.values, 50)}\n        self.df = DataFrame(data)", "number": 0, "name": "reshape.Pivot.time_reshape_pivot_time_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Encode.time_encode_decode": {"min_run_count": 2, "version": "775853eb502bed07a303fb9ca9d03c24795c30237328c1d52c02460472292d6e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode('utf-8').str.decode('utf-8')\n\n    def setup(self):\n        self.ser = Series(tm.makeUnicodeIndex())", "number": 0, "name": "strings.Encode.time_encode_decode", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Ops.time_subtract": {"min_run_count": 2, "version": "41898eee5380586c22225a5edfd7266917bd651742d358194baf574398532154", "processes": 2, "params": [["'float'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Ops:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {'int': 'makeIntIndex', 'float': 'makeFloatIndex'}\n        self.index = getattr(tm, indexes[dtype])(N)", "number": 0, "name": "index_object.Ops.time_subtract", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_unique": {"min_run_count": 2, "version": "a66db44e796bcd3d2012b95374540eab6f88e5921aad25f2acf8d3d7c93d5f51", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor": {"min_run_count": 2, "version": "1b5c2a98b39a5f1b4ad821f9dddc6cd42d49f2cbe7776fa872f204a9d6c89cc3", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.InsertColumns.time_insert": {"min_run_count": 2, "version": "2cda60fb4db30edfa550b5508c242921890ff01753dfa6b5004cb181b3827594", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class InsertColumns:\n    def time_insert(self):\n        np.random.seed(1234)\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N),\n                           allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))", "number": 0, "name": "indexing.InsertColumns.time_insert", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameNumericIndexing.time_loc": {"min_run_count": 2, "version": "38ba16b6a15d8ccaba376f2efaf127505173abbe9de65e3da7e7b31e37e900f8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameNumericIndexing:\n    def time_loc(self):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "number": 0, "name": "indexing.DataFrameNumericIndexing.time_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeFormat.time_no_exact": {"min_run_count": 2, "version": "ae5cc3b91d21efc57b724414ee19bef83088750fbf1e44aaa3d42013af3858ff", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format='%d%b%y', exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        self.s = Series(['19MAY11', '19MAY11:00:00:00'] * 100000)\n        self.s2 = self.s.str.replace(':\\\\S+$', '')", "number": 0, "name": "timeseries.ToDatetimeFormat.time_no_exact", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSONMem.peakmem_int": {"timeout": 60.0, "code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames['int']\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\n            'int': df,\n            'float': df.astype(float),\n        }\n    \n        return frames", "version": "7a1b0f3ba99cc842a269d95c3517c061d731b820f993d67091151a2eb5250f4d", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/io/json.py:129", "params": [], "name": "io.json.ToJSONMem.peakmem_int", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "offset.ApplyIndex.time_apply_index": {"min_run_count": 2, "version": "b52c54f928ef5924eb65ed30e6172c13dbab3280875d9f5ca9d5aa81a9fb7503", "processes": 2, "params": [["<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        offset.apply_index(self.rng)\n\n    def setup(self, offset):\n        N = 10000\n        self.rng = pd.date_range(start='1/1/2000', periods=N, freq='T')", "number": 0, "name": "offset.ApplyIndex.time_apply_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {"min_run_count": 2, "version": "36b606c13f61e9b58ac5eef6609d9760ce69cc1c0149dc9967153d600298b101", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.pickle.Pickle.time_read_pickle": {"min_run_count": 2, "version": "174c53b4fe7214cc175309c99360bf7e166cf957fe9f927c1c545327dfcafe18", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = '__test__.pkl'\n        N = 100000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "number": 0, "name": "io.pickle.Pickle.time_read_pickle", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {"min_run_count": 2, "version": "6cda491cbf81896c15b0298ef9d0212fbc2b0e149e2e6df57a373089a84e9f8c", "processes": 2, "params": [["'string'", "'datetime'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indexes = {'string': tm.makeStringIndex(N),\n                   'datetime': date_range('1900', periods=N, freq='s')}\n        index = indexes[index]\n        if index_structure == 'nonunique_monotonic_inc':\n            index = index.insert(item=index[2], loc=2)[:-1]\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]", "number": 0, "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Rank.time_rank_int": {"min_run_count": 2, "version": "7824b1ce0e69e6c6465302d641b3360b9631a83e3b03971e8a921292124b34f9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = self.s_str.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_str_cat_ordered = self.s_str.astype('category',\n                                                       ordered=True)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = self.s_int.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_int_cat_ordered = self.s_int.astype('category',\n                                                       ordered=True)", "number": 0, "name": "categoricals.Rank.time_rank_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IndexAppend.time_append_int_list": {"min_run_count": 2, "version": "84bdbae116c9d458d7aa0d0e3c60241c8b4084e00781ce5957f485786bc7135b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "number": 0, "name": "index_object.IndexAppend.time_append_int_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.CategoricalSlicing.time_getitem_scalar": {"min_run_count": 2, "version": "7f5f5189cdbbc2ea9ce1b13fb7b3472a519b229c89070e3290b2ba930909a68b", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = ['a', 'b', 'c']\n        values = [0] * N + [1] * N + [2] * N\n        if index == 'monotonic_incr':\n            self.data = pd.Categorical.from_codes(values,\n                                                  categories=categories)\n        elif index == 'monotonic_decr':\n            self.data = pd.Categorical.from_codes(list(reversed(values)),\n                                                  categories=categories)\n        elif index == 'non_monotonic':\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N,\n                                                  categories=categories)\n        else:\n            raise ValueError('Invalid index param: {}'.format(index))\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = 'b'", "number": 0, "name": "categoricals.CategoricalSlicing.time_getitem_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.ToNumeric.time_from_numeric_str": {"min_run_count": 2, "version": "fe0f3479b6ccb9d1587fa384baa90e42bf9bd89459e6e1b609c1c72927376760", "processes": 2, "params": [["'ignore'", "'coerce'"]], "type": "time", "warmup_time": -1, "param_names": ["errors"], "timeout": 60.0, "code": "class ToNumeric:\n    def time_from_numeric_str(self, errors):\n        to_numeric(self.numstr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype('str')\n        self.str = Series(tm.makeStringIndex(N))", "number": 0, "name": "inference.ToNumeric.time_from_numeric_str", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "attrs_caching.DataFrameAttributes.time_set_index": {"min_run_count": 2, "version": "419269e3a9cd0e10128bbb97214df797a349d4c774c362be4e57cc055d1db0ad", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "number": 0, "name": "attrs_caching.DataFrameAttributes.time_set_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.SparseIndex.time_unstack": {"min_run_count": 2, "version": "4a452facc222e218c806d24e8eeec9b110bde75db8ba1c6905137dde871bd83c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame({'A': np.random.randint(50, size=NUM_ROWS),\n                             'B': np.random.randint(50, size=NUM_ROWS),\n                             'C': np.random.randint(-10, 10, size=NUM_ROWS),\n                             'D': np.random.randint(-10, 10, size=NUM_ROWS),\n                             'E': np.random.randint(10, size=NUM_ROWS),\n                             'F': np.random.randn(NUM_ROWS)})\n        self.df = self.df.set_index(['A', 'B', 'C', 'D', 'E'])", "number": 0, "name": "reshape.SparseIndex.time_unstack", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {"min_run_count": 2, "version": "7998e3eec400317041ad6877a81d629e8889824eca22e9f2f3018c0c44ee4d8c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(datetime.timedelta(days=1, seconds=1))", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_datetime_timedelta", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {"min_run_count": 2, "version": "1adef46ddb98abdee0da95e399a519b8aee3bde846cd7580d40da559a07853c9", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list('a' * N + 'b' * N + 'c' * N))\n        self.s = pd.Series(self.c)", "number": 0, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_intersection": {"min_run_count": 2, "version": "61159821a1df476e4e1e260d2aa9150bc248f2ad6e23d7428431d74837b3c974", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_intersection", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadUint64Integers.time_read_uint64": {"min_run_count": 2, "version": "10871b7bbefd9ca77426cf486b2f85a1d1205c3dc20bf218602cc10e48c6f40d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=['foo'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype('uint64') + 2**63\n        self.data1 = StringIO('\\n'.join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO('\\n'.join(arr.astype(str).tolist()))", "number": 0, "name": "io.csv.ReadUint64Integers.time_read_uint64", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.ReindexMethod.time_reindex_method": {"min_run_count": 2, "version": "31c1290c84ea9e725ea2f0a252bdd8437c8ac887c5bb95466e8c5f2f5ed47f08", "processes": 2, "params": [["'pad'", "'backfill'"], ["<function date_range at 0x7f559e1e7950>", "<function period_range at 0x7f559e0fa510>"]], "type": "time", "warmup_time": -1, "param_names": ["method", "constructor"], "timeout": 60.0, "code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor('1/1/2000', periods=N, freq='1min')\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]", "number": 0, "name": "reindex.ReindexMethod.time_reindex_method", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Ops.time_multiply": {"min_run_count": 2, "version": "fbe318977c4bd543511dcd1aeb4e8fda82a291666a58e31c16bfe1d55fb0839f", "processes": 2, "params": [["'float'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Ops:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {'int': 'makeIntIndex', 'float': 'makeFloatIndex'}\n        self.index = getattr(tm, indexes[dtype])(N)", "number": 0, "name": "index_object.Ops.time_multiply", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.ConcatDataFrames.time_c_ordered": {"min_run_count": 2, "version": "966d095359a18353687c39f7638a9dae933ca66b4c84d9271b16008e087afda7", "processes": 2, "params": [["0", "1"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["axis", "ignore_index"], "timeout": 60.0, "code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200),\n                            dtype=np.float32, order='C'))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200),\n                            dtype=np.float32, order='F'))\n        self.frame_f = [frame_f] * 20", "number": 0, "name": "join_merge.ConcatDataFrames.time_c_ordered", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.IntervalIndexing.time_loc_scalar": {"min_run_count": 2, "version": "3727b780fbb12d812e665dcc2f04f1833e4fa43f9b2be7586340a83331e9535a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:220", "number": 0, "name": "indexing.IntervalIndexing.time_loc_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {"min_run_count": 2, "version": "0e612bb1dfd484a2cda8cd8c63770c7ed2241957ffea874b136811f5de0dd618", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {"min_run_count": 2, "version": "6c4854fd25051123c0417d033d3e1fb1f176c73cbec1be6b6b3dd0efda842165", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=['foo'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype('uint64') + 2**63\n        self.data1 = StringIO('\\n'.join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO('\\n'.join(arr.astype(str).tolist()))", "number": 0, "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_get": {"min_run_count": 2, "version": "da43ce2ad29ded292f1bb95004f0d3b7810c271028932791864c6d8836c9644a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_get(self):\n        self.s.str.get(0)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_get", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.mem_itertuples_start": {"timeout": 120, "code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "a50608242728aedb0a2109c2389e6feb83329d3735d07af30e9b293e6c13d715", "params": [], "name": "frame_methods.Iteration.mem_itertuples_start", "param_names": [], "unit": "bytes", "type": "memory"}, "multiindex_object.CategoricalLevel.time_categorical_level": {"min_run_count": 2, "version": "5f9095f582fc60dac9b408c77db3ee614ce9c10dc94db4471b83552d9bb4d616", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index(['a', 'b'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n    \n        self.df = DataFrame({\n            'a': np.arange(1_000_000, dtype=np.int32),\n            'b': np.arange(1_000_000, dtype=np.int64),\n            'c': np.arange(1_000_000, dtype=float),\n        }).astype({'a': 'category', 'b': 'category'})", "number": 0, "name": "multiindex_object.CategoricalLevel.time_categorical_level", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Repeat.time_repeat": {"min_run_count": 2, "version": "6e420fa6b32e4f90191ac035a1889c0e89625a4e7fe705fe273fd13126088857", "processes": 2, "params": [["'int'", "'array'"]], "type": "time", "warmup_time": -1, "param_names": ["repeats"], "timeout": 60.0, "code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10**5\n        self.s = Series(tm.makeStringIndex(N))\n        repeat = {'int': 1, 'array': np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]", "number": 0, "name": "strings.Repeat.time_repeat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.JoinNonUnique.time_join_non_unique_equal": {"min_run_count": 2, "version": "63b727d12a5c19199d4697ec58d0d53f0e77ffd4e307bc36d878b8d72e20102f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range('01-Jan-2013', '23-Jan-2013', freq='T')\n        daily_dates = date_index.to_period('D').to_timestamp('S', 'S')\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype('timedelta64[ns]')\n        self.fracofday = self.fracofday.astype(np.float64) / 86400000000000.0\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq='D')\n        self.temp = Series(1.0, index)[self.fracofday.index]", "number": 0, "name": "join_merge.JoinNonUnique.time_join_non_unique_equal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Transform.time_transform_lambda_max": {"min_run_count": 2, "version": "eb9430a37ec2cb950d80cc3de1d385b84edd67a823b11b8f5422b907a5efc15f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level='lev1').transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(levels=[np.arange(n1), tm.makeStringIndex(n2)],\n                           codes=[np.repeat(range(n1), n2).tolist(),\n                                  list(range(n2)) * n1],\n                           names=['lev1', 'lev2'])\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=['col1', 'col20', 'col3'])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(np.random.randint(1, n, (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df2 = self.df1.copy()\n        self.df2['jim'] = self.df2['joe']\n    \n        self.df3 = DataFrame(np.random.randint(1, (n / 10), (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df4 = self.df3.copy()\n        self.df4['jim'] = self.df4['joe']", "number": 0, "name": "groupby.Transform.time_transform_lambda_max", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.MultiIndexing.time_frame_ix": {"min_run_count": 2, "version": "650122f789d76776c8616d398d38e3aca2bdcf01661cb6cd18c8a5f408340849", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiIndexing:\n    def time_frame_ix(self):\n        self.df.ix[999]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        self.mdt = DataFrame({'A': np.random.choice(range(10000, 45000, 1000),\n                                                    n),\n                              'B': np.random.choice(range(10, 400), n),\n                              'C': np.random.choice(range(1, 150), n),\n                              'D': np.random.choice(range(10000, 45000), n),\n                              'x': np.random.choice(range(400), n),\n                              'y': np.random.choice(range(25), n)})\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index(['A', 'B', 'C', 'D']).sort_index()", "number": 0, "name": "indexing.MultiIndexing.time_frame_ix", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVParseDates.time_baseline": {"min_run_count": 2, "version": "163abf8fb1aa0c75aca7b47de2399f61b854398d1f2cf366ae4409ee989d5a51", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadCSVParseDates:\n    def time_baseline(self):\n        read_csv(self.data(self.StringIO_input), sep=',', header=None,\n                 parse_dates=[1],\n                 names=list(string.digits[:9]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = ['KORD,19990127'] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ReadCSVParseDates.time_baseline", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelFactorize.time_loop": {"min_run_count": 2, "version": "540867a4e0cc98aa69b4f0ee2b8d35a18265da3da0b78d0c79e30f68b51690ff", "processes": 2, "params": [["2", "4", "8"]], "type": "time", "warmup_time": -1, "param_names": ["threads"], "timeout": 60.0, "code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n        self.loop = loop", "number": 1, "name": "gil.ParallelFactorize.time_loop", "sample_time": 0.01, "unit": "seconds", "repeat": 5}, "series_methods.Clip.time_clip": {"min_run_count": 2, "version": "ccfa17d1178249cacc78c3dfa6dbb3851850815c5d14df41a39789ff6adfea2b", "processes": 2, "params": [["50", "1000", "100000"]], "type": "time", "warmup_time": -1, "param_names": ["n"], "timeout": 60.0, "code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))", "number": 0, "name": "series_methods.Clip.time_clip", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_iteritems": {"min_run_count": 2, "version": "a9766bb905746261d5d05399664959f3b058a34503ebfe588fe02788ab4d05e6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_iteritems(self):\n        # (monitor no-copying behaviour)\n        if hasattr(self.df, '_item_cache'):\n            self.df._item_cache.clear()\n        for name, col in self.df.iteritems():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_iteritems", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {"min_run_count": 2, "version": "fe631b2ac9170b9e03d17c499437dfdd17ebe61e4764874c8ccac79db80f7e31", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        self.df.get_dtype_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "number": 0, "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Join.time_join_dataframe_index_multi": {"min_run_count": 2, "version": "02d7044dcb5b6796625f25a0beb50a80d2a54b367ee8e63dc52dc0269bee7151", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=['key1', 'key2'], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2],\n                            codes=[codes1, codes2])\n        self.df_multi = DataFrame(np.random.randn(len(index2), 4),\n                                  index=index2,\n                                  columns=['A', 'B', 'C', 'D'])\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame({'data1': np.random.randn(100000),\n                             'data2': np.random.randn(100000),\n                             'key1': self.key1,\n                             'key2': self.key2})\n    \n        self.df_key1 = DataFrame(np.random.randn(len(level1), 4),\n                                 index=level1,\n                                 columns=['A', 'B', 'C', 'D'])\n        self.df_key2 = DataFrame(np.random.randn(len(level2), 4),\n                                 index=level2,\n                                 columns=['A', 'B', 'C', 'D'])\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "number": 0, "name": "join_merge.Join.time_join_dataframe_index_multi", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {"min_run_count": 2, "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:83", "number": 0, "name": "timedelta.TimedeltaProperties.time_timedelta_nanoseconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Concat.time_concat_mixed_ndims": {"min_run_count": 2, "version": "760a8614dd304a0d215e4d6708a17702897f7d218a878bfaa2f364735bd9f231", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:- i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame({'A': range(N)},\n                       index=date_range('20130101', periods=N, freq='s'))\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "number": 0, "name": "join_merge.Concat.time_concat_mixed_ndims", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.AsOf.time_asof": {"min_run_count": 2, "version": "14566d259984d06411a7edbbf7921b7c820be03e8a9253f1a4a79ced0a1a4c45", "processes": 2, "params": [["'DataFrame'", "'Series'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor"], "timeout": 60.0, "code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start='1/1/1990', periods=N, freq='53s')\n        data = {'DataFrame': DataFrame(np.random.randn(N, M)),\n                'Series': Series(np.random.randn(N))}\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start='1/1/1990', periods=N * 10, freq='5s')\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "number": 0, "name": "timeseries.AsOf.time_asof", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_store_repr": {"min_run_count": 2, "version": "9912f3411e894ab801478b17a2ea421e28722535e5e6d75183e2d10902f6da1e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_store_repr", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.SparseArrayConstructor.time_sparse_array": {"min_run_count": 2, "version": "0ed244edb1c2d382bed4bd2433ffb775e119dc6831ae5695e5fa930fb84dcd10", "processes": 2, "params": [["0.1", "0.01"], ["0", "nan"], ["<class 'numpy.int64'>", "<class 'numpy.float64'>", "<class 'object'>"]], "type": "time", "warmup_time": -1, "param_names": ["dense_proportion", "fill_value", "dtype"], "timeout": 60.0, "code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10**6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)", "number": 0, "name": "sparse.SparseArrayConstructor.time_sparse_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_regular": {"min_run_count": 2, "version": "0488354e564dc5810a3aad2bd3d32a2ef74d634451c30b96978fef93ee7565dc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_regular", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaProperties.time_timedelta_seconds": {"min_run_count": 2, "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:83", "number": 0, "name": "timedelta.TimedeltaProperties.time_timedelta_seconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.ValueCounts.time_value_counts": {"min_run_count": 2, "version": "899e9a50ddf1ddfa517d78088b0d49dfcf8ad793c12915d36ace5e2ae657e7b1", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["dropna"], "timeout": 60.0, "code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10**5\n        arr = ['s{:04d}'.format(i) for i in np.random.randint(0, n // 10,\n                                                              size=n)]\n        self.ts = pd.Series(arr).astype('category')", "number": 0, "name": "categoricals.ValueCounts.time_value_counts", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.DatetimeAccessor.time_timedelta_microseconds": {"min_run_count": 2, "version": "62f562b7b411d7b9985954a612452e667dc72440264a6a099e83c11bf685d772", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range('1 days', periods=N, freq='h'))\n        return series", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:102", "number": 0, "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.SeriesOps.time_op": {"min_run_count": 2, "version": "a74f74b1fe0ee8f8708e190d73fa7db76aeb86e20b3208e3438c035264bd25df", "processes": 2, "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["op", "dtype", "use_bottleneck"], "timeout": 60.0, "code": "class SeriesOps:\n    def time_op(self, op, dtype, use_bottleneck):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype, use_bottleneck):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.s_func = getattr(s, op)", "number": 0, "name": "stat_ops.SeriesOps.time_op", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_loc_scalar": {"min_run_count": 2, "version": "459aad21b9aa9bee71ba17a46cbf3da54dd382e6c208908f212f42837e40f116", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_loc_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.mem_itertuples_read_first": {"timeout": 120, "code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "1d93c30d7b81ce1f32b9e31024a1553762a63d6ee176f19209bbc410026d0c6f", "params": [], "name": "frame_methods.Iteration.mem_itertuples_read_first", "param_names": [], "unit": "bytes", "type": "memory"}, "io.json.ToJSON.time_float_int_str": {"min_run_count": 2, "version": "89af1cc576e644d1c461e572abaa5e57e956b90981a9de2223a34d08f3ddfd39", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_float_int_str(self, orient):\n        self.df_int_float_str.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_float_int_str", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {"min_run_count": 2, "version": "e40ad16a6e0660493e8b36ca0a5c90d17a1a08717f525058767d7a4bf26f63c2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array(['foo', 'bar', 'baz'], dtype=object)\n        self.s = Series([Timestamp('20110101'), Timestamp('20120101'),\n                         Timestamp('20130101')] * N * 10)", "number": 0, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_startswith": {"min_run_count": 2, "version": "2948f78117c675c4369c235ffe1a4f1b77de8ce8e83a3b6efd02dad674112d36", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_startswith(self):\n        self.s.str.startswith('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_startswith", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.mem_itertuples_to_list": {"timeout": 120, "code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "871991183725148ad158de73bbb70e8e6bcf9ecf8125ae2b9ba46185855792af", "params": [], "name": "frame_methods.Iteration.mem_itertuples_to_list", "param_names": [], "unit": "bytes", "type": "memory"}, "gil.ParallelFactorize.time_parallel": {"min_run_count": 2, "version": "487a5b4e768b90d124eaa8671dd8fa2725d4c931bd9c132e485bfc555d872754", "processes": 2, "params": [["2", "4", "8"]], "type": "time", "warmup_time": -1, "param_names": ["threads"], "timeout": 60.0, "code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n        self.loop = loop", "number": 1, "name": "gil.ParallelFactorize.time_parallel", "sample_time": 0.01, "unit": "seconds", "repeat": 5}, "timeseries.Iteration.time_iter_preexit": {"min_run_count": 2, "version": "e10e97026648002e5bdce83666729070584d5fa1856bf26ad6972564a7cf308a", "processes": 2, "params": [["<function date_range at 0x7f559e1e7950>", "<function period_range at 0x7f559e0fa510>"]], "type": "time", "warmup_time": -1, "param_names": ["time_index"], "timeout": 60.0, "code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        self.idx = time_index(start='20140101', freq='T', periods=N)\n        self.exit = 10000", "number": 0, "name": "timeseries.Iteration.time_iter_preexit", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_loc_list_like": {"min_run_count": 2, "version": "09070abc3c4b19f96b6f3d7c6bd466a583f11b60c9d57e418fc5e28814e09e0b", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_loc_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Categories.time_groupby_extra_cat_sort": {"min_run_count": 2, "version": "7bdfb87b9f3baba0871f709291315e871eef47d4a35180966cbcb47ff6c7ad7b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Categories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby('a')['b'].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {'a': Categorical(np.random.randint(10000, size=N)),\n                'b': arr}\n        self.df = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(10000, size=N),\n                                 ordered=True),\n                'b': arr}\n        self.df_ordered = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(100, size=N),\n                                 categories=np.arange(10000)),\n                'b': arr}\n        self.df_extra_cat = DataFrame(data)", "number": 0, "name": "groupby.Categories.time_groupby_extra_cat_sort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_getitem_slice": {"min_run_count": 2, "version": "193c47c6f9bd364cb801b9119597f238c7ec254d26c9cae13c31f321d5ae0526", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[:self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_getitem_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_extract": {"min_run_count": 2, "version": "5f30f05d2066b81afa9f071394bb32c8c825e78da2d0b7ace492baa7853c7e0e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_extract(self):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract('(\\\\w*)A(\\\\w*)')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_extract", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Merge.time_merge_2intkey": {"min_run_count": 2, "version": "88ff8d6050178090d6225b33002948ea681ed81a709ea8f3cf277dd893986e07", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame({'key': key, 'key2': key2,\n                               'value': np.random.randn(80000)})\n        self.right = DataFrame({'key': indices[2000:],\n                                'key2': indices2[2000:],\n                                'value2': np.random.randn(8000)})\n    \n        self.df = DataFrame({'key1': np.tile(np.arange(500).repeat(10), 2),\n                             'key2': np.tile(np.arange(250).repeat(10), 4),\n                             'value': np.random.randn(10000)})\n        self.df2 = DataFrame({'key1': np.arange(500),\n                              'value2': np.random.randn(500)})\n        self.df3 = self.df[:5000]", "number": 0, "name": "join_merge.Merge.time_merge_2intkey", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Categories.time_groupby_extra_cat_nosort": {"min_run_count": 2, "version": "c5ed50aa92b3dc7e2ded4d32555b61096dd854c4db610920a9b74b2c69259ffb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Categories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby('a', sort=False)['b'].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {'a': Categorical(np.random.randint(10000, size=N)),\n                'b': arr}\n        self.df = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(10000, size=N),\n                                 ordered=True),\n                'b': arr}\n        self.df_ordered = DataFrame(data)\n        data = {'a': Categorical(np.random.randint(100, size=N),\n                                 categories=np.arange(10000)),\n                'b': arr}\n        self.df_extra_cat = DataFrame(data)", "number": 0, "name": "groupby.Categories.time_groupby_extra_cat_nosort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_shape": {"min_run_count": 2, "version": "e94d04e368e1d5f056ec527250d8140b4091e478bf9aba06c2ecb712dded0922", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_shape(self):\n        self.index.shape\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_shape", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Apply.time_apply_lambda_mean": {"min_run_count": 2, "version": "05eec5cd429d72dc43c027cd58cd6b1456b80d173339dbf56eff2fbf8c9c3080", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Apply.time_apply_lambda_mean", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVCategorical.time_convert_direct": {"min_run_count": 2, "version": "9c2bad5a8fe09c53d4e882b302094fe0f5148a8bbbba024e71bd1918a78f918d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadCSVCategorical:\n    def time_convert_direct(self):\n        read_csv(self.fname, dtype='category')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self):\n        N = 100000\n        group1 = ['aaaaaaaa', 'bbbbbbb', 'cccccccc', 'dddddddd', 'eeeeeeee']\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list('abc'))\n        df.to_csv(self.fname, index=False)", "number": 0, "name": "io.csv.ReadCSVCategorical.time_convert_direct", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ResampleDatetetime64.time_resample": {"min_run_count": 2, "version": "8961f0925899e8aa3f39a2648fcc06c9248e258cf9520b4e68da1404366d1bab", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample('1S').last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(start='2000-01-01 00:00:00',\n                          end='2000-01-01 10:00:00', freq='555000U')\n        self.dt_ts = Series(5, rng3, dtype='datetime64[ns]')", "number": 0, "name": "timeseries.ResampleDatetetime64.time_resample", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_series_dates": {"min_run_count": 2, "version": "3c203518055c87a85292b7dd01200a51cb2791ea40ffb42c8a471ba80398ba6d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df['dates'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_series_dates", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Equals.time_frame_object_unequal": {"min_run_count": 2, "version": "6d3804b0a9ff054d4092caf421b86b7b3e8c8ca5158d19cbcac4ae3f2ead77e2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame('foo', index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = ['A'] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "number": 0, "name": "frame_methods.Equals.time_frame_object_unequal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_iterrows": {"min_run_count": 2, "version": "de7a41e2c389e20f7451e85671c7d2a15a1260b72c592166134da6016c796baf", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_iterrows", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {"min_run_count": 2, "version": "d5400dc0d94976d63493c7da448125ca3055fadccff8ea8243658b441551122d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put('fixed_mixed_write', self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeISO8601.time_iso8601": {"min_run_count": 2, "version": "f81525325bd7ca94cfcf0bd1a705fb580c3d351f151401cb879e557459d3649b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start='1/1/2000', periods=20000, freq='H')\n        self.strings = rng.strftime('%Y-%m-%d %H:%M:%S').tolist()\n        self.strings_nosep = rng.strftime('%Y%m%d %H:%M:%S').tolist()\n        self.strings_tz_space = [x.strftime('%Y-%m-%d %H:%M:%S') + ' -0800'\n                                 for x in rng]", "number": 0, "name": "timeseries.ToDatetimeISO8601.time_iso8601", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.NSort.time_nsmallest_one_column": {"min_run_count": 2, "version": "aeb0cb016fb5bcd6e1c5f0a26db0dbe2810623cb40538f72a246f9a65c838456", "processes": 2, "params": [["'first'", "'last'", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["keep"], "timeout": 60.0, "code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, 'A', keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3),\n                            columns=list('ABC'))", "number": 0, "name": "frame_methods.NSort.time_nsmallest_one_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.FrameMultiIndexOps.time_op": {"min_run_count": 2, "version": "7a02b6c9b0898859119f9d80b2d3d48b14316bb14c49ae26349820239c8faf26", "processes": 2, "params": [["0", "1", "[0, 1]"], ["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"]], "type": "time", "warmup_time": -1, "param_names": ["level", "op"], "timeout": 60.0, "code": "class FrameMultiIndexOps:\n    def time_op(self, level, op):\n        self.df_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [np.arange(10).repeat(10000),\n                 np.tile(np.arange(100).repeat(100), 10),\n                 np.tile(np.tile(np.arange(100), 100), 10)]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)", "number": 0, "name": "stat_ops.FrameMultiIndexOps.time_op", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Ops.time_modulo": {"min_run_count": 2, "version": "7b0d3bc4902d1ab217eea02f9acc7a040ccfd95a902985d9784e18195925125b", "processes": 2, "params": [["'float'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Ops:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {'int': 'makeIntIndex', 'float': 'makeFloatIndex'}\n        self.index = getattr(tm, indexes[dtype])(N)", "number": 0, "name": "index_object.Ops.time_modulo", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.AsOf.time_asof_single_early": {"min_run_count": 2, "version": "26fdf4f13acd40141629ae409ef7ffe8de4356c3e3b0f3665aac22b846494ff9", "processes": 2, "params": [["'DataFrame'", "'Series'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor"], "timeout": 60.0, "code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start='1/1/1990', periods=N, freq='53s')\n        data = {'DataFrame': DataFrame(np.random.randn(N, M)),\n                'Series': Series(np.random.randn(N))}\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start='1/1/1990', periods=N * 10, freq='5s')\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "number": 0, "name": "timeseries.AsOf.time_asof_single_early", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "eval.Query.time_query_datetime_index": {"min_run_count": 2, "version": "d370eb4bd3209aad117060c0ce201121e4b43db77d7b5ff71958dbaa60e7ac82", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query('index < @self.ts')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range('20010101', periods=N, freq='T')\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({'a': np.random.randn(N), 'dates': index},\n                               index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "number": 0, "name": "eval.Query.time_query_datetime_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Repr.time_frame_repr_wide": {"min_run_count": 2, "version": "fb568593c4b33a8ed38975470fe6b29f317e157c2bff6ad7e3194854ce3bbbf0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "number": 0, "name": "frame_methods.Repr.time_frame_repr_wide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.SimpleReshape.time_stack": {"min_run_count": 2, "version": "c50bbef88a825dd9c95a802eb46657e5491f84dc77cbe5b94ef3efde38494ebd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100),\n                  np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "number": 0, "name": "reshape.SimpleReshape.time_stack", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.MultiColumn.time_col_select_numpy_sum": {"min_run_count": 2, "version": "a39e40c9bb078a85f4721de9d99d1219e1c4b12ba1a4b01ba543054645e56e2d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiColumn:\n    def time_col_select_numpy_sum(self, df):\n        df.groupby(['key1', 'key2'])['data1'].agg(np.sum)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame({'key1': key1,\n                        'key2': key2,\n                        'data1': np.random.randn(N),\n                        'data2': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:259", "number": 0, "name": "groupby.MultiColumn.time_col_select_numpy_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_ix_array": {"min_run_count": 2, "version": "c16395bcb770e28b971ec79774ebcda156e9229fdd5a74e21403b8ff15e5ee9d", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_ix_array(self, index, index_structure):\n        self.data.ix[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_ix_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {"min_run_count": 2, "version": "8b01debc304c393b2140b60aba18ca0d06e08daa1e8e42686c1704930acf7ba6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, 'a', None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1,\n                        index=date_range(\"2012-01-01\", freq='s',\n                                         periods=int(1e6)))", "number": 0, "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.AggFunctions.time_different_numpy_functions": {"min_run_count": 2, "version": "74b9aeb665606b565451e9a7430defa0132612011c3e6aa9f2fc357dee23133b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AggFunctions:\n    def time_different_numpy_functions(self, df):\n        df.groupby(['key1', 'key2']).agg({'value1': np.mean,\n                                          'value2': np.var,\n                                          'value3': np.sum})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        df = DataFrame({'key1': fac1.take(np.random.randint(0, 3, size=N)),\n                        'key2': fac2.take(np.random.randint(0, 2, size=N)),\n                        'value1': np.random.randn(N),\n                        'value2': np.random.randn(N),\n                        'value3': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:214", "number": 0, "name": "groupby.AggFunctions.time_different_numpy_functions", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameNumericIndexing.time_bool_indexer": {"min_run_count": 2, "version": "6de0b2afadd58cd7b2f09554a7b46ae628d905f4231710a150204d724b6d0e3c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "number": 0, "name": "indexing.DataFrameNumericIndexing.time_bool_indexer", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Datelike.time_sum": {"min_run_count": 2, "version": "058c00fd3b930873443aacfa52674259a7dd89af3a73c61561fbebe60f2daed7", "processes": 2, "params": [["'period_range'", "'date_range'", "'date_range_tz'"]], "type": "time", "warmup_time": -1, "param_names": ["grouper"], "timeout": 60.0, "code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10**4\n        rng_map = {'period_range': period_range,\n                   'date_range': date_range,\n                   'date_range_tz': partial(date_range, tz='US/Central')}\n        self.grouper = rng_map[grouper]('1900-01-01', freq='D', periods=N)\n        self.df = DataFrame(np.random.randn(10**4, 2))", "number": 0, "name": "groupby.Datelike.time_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_to_date": {"min_run_count": 2, "version": "6ab4c878895e962146997f3fac4395704b71fbc3357549978c8f25ef0b1723d3", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_to_date", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Reindex.time_reindex_upcast": {"min_run_count": 2, "version": "56875106d618da2c9dfbc22e56bcb2472718e62b09dadb39238878bba22cc373", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {c: {0: np.random.randint(0, 2, N).astype(np.bool_),\n                 1: np.random.randint(0, N, N).astype(np.int16),\n                 2: np.random.randint(0, N, N).astype(np.int32),\n                 3: np.random.randint(0, N, N).astype(np.int64)}\n                [np.random.randint(0, 4)] for c in range(N)})", "number": 0, "name": "frame_methods.Reindex.time_reindex_upcast", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_existing_categorical": {"min_run_count": 2, "version": "f8e2aaf4ead6c04dae781679489b03b4b8383fa717bed094cad08f6508bcf0d5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_existing_categorical", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Transform.time_transform_multi_key2": {"min_run_count": 2, "version": "5d4492d555c068acb081464ab1cc3a2c545b3ef24431270b2b724d7291e29550", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby(['jim', 'joe'])['jolie'].transform('max')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(levels=[np.arange(n1), tm.makeStringIndex(n2)],\n                           codes=[np.repeat(range(n1), n2).tolist(),\n                                  list(range(n2)) * n1],\n                           names=['lev1', 'lev2'])\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=['col1', 'col20', 'col3'])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(np.random.randint(1, n, (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df2 = self.df1.copy()\n        self.df2['jim'] = self.df2['joe']\n    \n        self.df3 = DataFrame(np.random.randint(1, (n / 10), (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df4 = self.df3.copy()\n        self.df4['jim'] = self.df4['joe']", "number": 0, "name": "groupby.Transform.time_transform_multi_key2", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops.time_frame_add": {"min_run_count": 2, "version": "a967814f650c42792f4d23c5b91787e255bd428db5ed34d038f03fe0db9db6ef", "processes": 2, "params": [["True", "False"], ["'default'", "1"]], "type": "time", "warmup_time": -1, "param_names": ["use_numexpr", "threads"], "timeout": 60.0, "code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != 'default':\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "number": 0, "name": "binary_ops.Ops.time_frame_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDF.time_read_hdf": {"min_run_count": 2, "version": "884e46642c149e830680262890d4d2ad245ea7f12c875bba7919a7adf8fd40a8", "processes": 2, "params": [["'table'", "'fixed'"]], "type": "time", "warmup_time": -1, "param_names": ["format"], "timeout": 60.0, "code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, 'df')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = '__test__.h5'\n        N = 100000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, 'df', format=format)", "number": 0, "name": "io.hdf.HDF.time_read_hdf", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.CategoricalSlicing.time_getitem_list_like": {"min_run_count": 2, "version": "96688d641a7bf4b366b57f5b86f5ac2693be6349aa604a679da0de1b798818a7", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = ['a', 'b', 'c']\n        values = [0] * N + [1] * N + [2] * N\n        if index == 'monotonic_incr':\n            self.data = pd.Categorical.from_codes(values,\n                                                  categories=categories)\n        elif index == 'monotonic_decr':\n            self.data = pd.Categorical.from_codes(list(reversed(values)),\n                                                  categories=categories)\n        elif index == 'non_monotonic':\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N,\n                                                  categories=categories)\n        else:\n            raise ValueError('Invalid index param: {}'.format(index))\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = 'b'", "number": 0, "name": "categoricals.CategoricalSlicing.time_getitem_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_parse_iso8601_tz": {"min_run_count": 2, "version": "dc1d1644ed45d352146ab1799bbaf41cc6325ec31974a87e5632d6a2d43c5106", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp('2017-08-25 08:16:14-0500')", "number": 0, "name": "timestamp.TimestampConstruction.time_parse_iso8601_tz", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.Dir.time_dir_strings": {"min_run_count": 2, "version": "e116c6dea26d05ccd39e54ddeab3096a69ba2e18e7daaa811e0cb3114cf2e9b6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=tm.makeStringIndex(10000))", "number": 0, "name": "series_methods.Dir.time_dir_strings", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeISO8601.time_iso8601_nosep": {"min_run_count": 2, "version": "e2a30c14fd636df157f0be8f04d06ea9e9862dcbbd60a89297b50558814e3ad8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start='1/1/2000', periods=20000, freq='H')\n        self.strings = rng.strftime('%Y-%m-%d %H:%M:%S').tolist()\n        self.strings_nosep = rng.strftime('%Y%m%d %H:%M:%S').tolist()\n        self.strings_tz_space = [x.strftime('%Y-%m-%d %H:%M:%S') + ' -0800'\n                                 for x in rng]", "number": 0, "name": "timeseries.ToDatetimeISO8601.time_iso8601_nosep", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.msgpack.MSGPack.time_write_msgpack": {"min_run_count": 2, "version": "0ce12719540e3a61c1c989a1a182530cad41d9e58c935e6fac388e18dc457489", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MSGPack:\n    def time_write_msgpack(self):\n        self.df.to_msgpack(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MSGPack:\n    def setup(self):\n        self.fname = '__test__.msg'\n        N = 100000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.df.to_msgpack(self.fname)", "number": 0, "name": "io.msgpack.MSGPack.time_write_msgpack", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.NumericInferOps.time_subtract": {"min_run_count": 2, "version": "17d6516d1182f13f0c274932bb0f6ef68f1beeeb5f2a3e1dc251b028ca9c9d31", "processes": 2, "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df['A'] - self.df['B']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame({'A': np.arange(N).astype(dtype),\n                             'B': np.arange(N).astype(dtype)})", "number": 0, "name": "inference.NumericInferOps.time_subtract", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInFloat64.time_isin_nan_values": {"min_run_count": 2, "version": "9cdb5ccf494f98ce5d7f5ca8e2bd6b67f2d1c76ac9030139a71df53bcd6f8508", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInFloat64:\n    def time_isin_nan_values(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.few_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10**6, dtype=np.float64)\n        self.few_different_values = np.zeros(10**7, dtype=np.float64)\n        self.only_nans_values = np.full(10**7, np.nan, dtype=np.float64)", "number": 0, "name": "series_methods.IsInFloat64.time_isin_nan_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_tz_convert": {"min_run_count": 2, "version": "c6469dbbebd6ea8c156a92506ad7c8066346c9ae6e13f72a8565df382213c3e4", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_tz_convert", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops.time_frame_mult": {"min_run_count": 2, "version": "3f4c6de9242e06877904488892f69260a75753e831f0b42da107bce2ccc3d6b4", "processes": 2, "params": [["True", "False"], ["'default'", "1"]], "type": "time", "warmup_time": -1, "param_names": ["use_numexpr", "threads"], "timeout": 60.0, "code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != 'default':\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "number": 0, "name": "binary_ops.Ops.time_frame_mult", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaProperties.time_timedelta_days": {"min_run_count": 2, "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:83", "number": 0, "name": "timedelta.TimedeltaProperties.time_timedelta_days", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.NSort.time_nlargest_one_column": {"min_run_count": 2, "version": "928d95d3d87487022ae109e1ee4a913b6f1e35cb126ed2413a046aa217d82655", "processes": 2, "params": [["'first'", "'last'", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["keep"], "timeout": 60.0, "code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, 'A', keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3),\n                            columns=list('ABC'))", "number": 0, "name": "frame_methods.NSort.time_nlargest_one_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDicts.time_nested_dict_index_columns": {"min_run_count": 2, "version": "89153b4718819e685f1711532b54f4a603ad4009c93f67bcd9fa3320a8babb26", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index,\n                          columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient='records')\n        self.data2 = {i: {j: float(j) for j in range(100)}\n                      for i in range(2000)}", "number": 0, "name": "frame_ctor.FromDicts.time_nested_dict_index_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Int64.time_overflow": {"min_run_count": 2, "version": "8c262318170ae4fe38bf55c9623c5501992c69d9b9d04af4c0e608b35804d6e4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list('abcde')\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df['jim'], self.df['joe'] = np.random.randn(2, len(self.df)) * 10", "number": 0, "name": "groupby.Int64.time_overflow", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.VariableWindowMethods.time_rolling": {"min_run_count": 2, "version": "222de5737ccf6bd59c532243a2d0a0606f2e89ca7a945e03d64436ca99d7f5b9", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "type": "time", "warmup_time": -1, "param_names": ["contructor", "window", "dtype", "method"], "timeout": 60.0, "code": "class Methods:\n    def time_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range('2017-01-01', periods=N, freq='5s')\n        self.roll = getattr(pd, constructor)(arr, index=index).rolling(window)", "number": 0, "name": "rolling.VariableWindowMethods.time_rolling", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.ToTimedelta.time_convert_string_days": {"min_run_count": 2, "version": "350c2d58f281c6e096fb11463da6139974738d164b8f1d9897e00eddd298a743", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append('{0} days'.format(i))\n            self.str_seconds.append('00:00:{0:02d}'.format(i))", "number": 0, "name": "timedelta.ToTimedelta.time_convert_string_days", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_endswith": {"min_run_count": 2, "version": "aea7cd3c4b343379748e78d3052105457f87b5a4e567c94d9e2c3f9ae6890b3a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_endswith(self):\n        self.s.str.endswith('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_endswith", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.Reindex.time_reindex_multiindex": {"min_run_count": 2, "version": "442fd6a6c5a8169d8f6c49fdee2448355296b446b19b88588d4a9ae6bfa49acb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Reindex:\n    def time_reindex_multiindex(self):\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start='1/1/1970', periods=10000, freq='1min')\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng,\n                            columns=range(10))\n        self.df['foo'] = 'bar'\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(index=range(10000),\n                             data=np.random.rand(10000, 30), columns=range(30))\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "number": 0, "name": "reindex.Reindex.time_reindex_multiindex", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_ix_list_like": {"min_run_count": 2, "version": "37278b1c104678f311130673845d957bf581c6b19be0a205d26f270d3ed8cb52", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_ix_list_like(self, index, index_structure):\n        self.data.ix[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_ix_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_slice": {"min_run_count": 2, "version": "dfd963b2212881b37f6ba7969a924dfc5251948fd66d30e8707b19206920c552", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {"min_run_count": 2, "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7", "processes": 2, "params": [["'2Q2005'", "'0.0'", "'10000'"]], "type": "time", "warmup_time": -1, "param_names": ["value"], "timeout": 60.0, "code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000", "number": 0, "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_get_loc": {"min_run_count": 2, "version": "0ed52566b74fa9e799b549e0294d64bee81d0af2315342171aa8530e610614b8", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.DateInferOps.time_timedelta_plus_datetime": {"min_run_count": 2, "version": "5bf92353ca0a4fa5778c8a28888c1b17aad07bfd57c652e251ab54f5ca7f4a43", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df['timedelta'] + df['datetime64']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({'datetime64': np.arange(N).astype('datetime64[ms]')})\n        df['timedelta'] = df['datetime64'] - df['datetime64']\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:36", "number": 0, "name": "inference.DateInferOps.time_timedelta_plus_datetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ReadJSONLines.peakmem_read_json_lines": {"timeout": 60.0, "code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {'int': np.arange(N),\n                   'datetime': date_range('20000101', periods=N, freq='H')}\n        df = DataFrame(np.random.randn(N, 5),\n                       columns=['float_{}'.format(i) for i in range(5)],\n                       index=indexes[index])\n        df.to_json(self.fname, orient='records', lines=True)", "version": "c6820f7b5cfca0f673f1912bdc490c39ffa3ce8c97bf3a631d572636bf9ba73e", "params": [["'int'", "'datetime'"]], "name": "io.json.ReadJSONLines.peakmem_read_json_lines", "param_names": ["index"], "unit": "bytes", "type": "peakmemory"}, "frame_methods.Describe.time_series_describe": {"min_run_count": 2, "version": "92d3d617f5efc3dfa2ab1c26c8a446348ed9f8a993000a22997322ffd54c6a17", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Describe:\n    def time_series_describe(self):\n        self.df['a'].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame({\n            'a': np.random.randint(0, 100, int(1e6)),\n            'b': np.random.randint(0, 100, int(1e6)),\n            'c': np.random.randint(0, 100, int(1e6))\n        })", "number": 0, "name": "frame_methods.Describe.time_series_describe", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_quarter_start": {"min_run_count": 2, "version": "25facb07c91c005927c552808d7f0cede99e05201cbc4ff75a8d02145d39d84c", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz, freq):\n        self.ts.is_quarter_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_quarter_start", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples_raw_start": {"min_run_count": 2, "version": "28625850f004e3530c35859abc062bd95d56d5106f36102e5fcd17b35d5f692c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples_raw_start", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_dayofyear": {"min_run_count": 2, "version": "e22e03f078c0ae7b5def52bd4ecb750eca2cd1ddb60ee187ed59a71f184a1f0f", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_dayofyear(self, tz, freq):\n        self.ts.dayofyear\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_dayofyear", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.Map.time_map": {"min_run_count": 2, "version": "30d0991a6cd745a52153612e4a9a133f393c549eb42cb5da40cfd5d92931e1a3", "processes": 2, "params": [["'dict'", "'Series'", "'lambda'"], ["'object'", "'category'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["m", "a"], "timeout": 60.0, "code": "class Map:\n    def time_map(self, mapper, *args, **kwargs):\n        self.s.map(self.map_data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == 'Series':\n            self.map_data = map_data\n        elif mapper == 'dict':\n            self.map_data = map_data.to_dict()\n        elif mapper == 'lambda':\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)", "number": 0, "name": "series_methods.Map.time_map", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.IntervalIndexing.time_getitem_scalar": {"min_run_count": 2, "version": "a5ed39d9e010bebebaedde8c09666f2e8ad83c8ecc321854014b0126a9262ef4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:220", "number": 0, "name": "indexing.IntervalIndexing.time_getitem_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Slice.time_vector_slice": {"min_run_count": 2, "version": "730434ea6857a3295bc0db1b93a5f99ed716061d30fe2c802a81d2b1de329861", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series(['abcdefg', np.nan] * 500000)", "number": 0, "name": "strings.Slice.time_vector_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.DropDuplicates.time_frame_drop_dups_bool": {"min_run_count": 2, "version": "cd0a05f658edda2e8f8205144df4c880e26e5a113aa0a18897f48e524f154573", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame({'key1': key1, 'key2': key2,\n                             'value': np.random.randn(N * K)})\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({'key1': key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10),\n                                                   dtype=bool))", "number": 0, "name": "reindex.DropDuplicates.time_frame_drop_dups_bool", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaConstructor.time_from_missing": {"min_run_count": 2, "version": "d92e628691e316b2ada118fafbc25f550a8072d23e4cf276a01d8f7e10b12e1f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta('nat')", "number": 0, "name": "timedelta.TimedeltaConstructor.time_from_missing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Duplicated.time_frame_duplicated": {"min_run_count": 2, "version": "bd7cb98a5a015c31da2515f8b8919a2dfbd333eaa692d6567aec742a070a7d0e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = (1 << 20)\n        t = date_range('2015-01-01', freq='S', periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame({'a': np.random.randint(-1 << 8, 1 << 8, n),\n                             'b': np.random.choice(t, n),\n                             'c': np.random.choice(xs, n)})\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "number": 0, "name": "frame_methods.Duplicated.time_frame_duplicated", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {"min_run_count": 2, "version": "2bbe9983ef48e574cb3c545f1a3b32939b65a012b4e8a0522ebedc1303325c5b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(self.table_name, self.con, columns=['datetime_string'],\n                       parse_dates=['datetime_string'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = 'test'\n        self.con = create_engine('sqlite:///:memory:')\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_replace": {"min_run_count": 2, "version": "7260737fc6fd2ea84f48227c96e391e308281ed7b53c8a1c5739ff6cb0574e11", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_replace(self):\n        self.s.str.replace('A', '\\x01\\x01')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_replace", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_getitem_list_like": {"min_run_count": 2, "version": "ab68dfa7f9d06a071c31620fa2f122aefd23c9c076ef778fa9b65785b2e6db34", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_to_pydatetime": {"min_run_count": 2, "version": "de8712e7b23d2f9cca428630043e7fad07297c1f17b685d97d86e15732af76fe", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_to_pydatetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ReadJSONLines.time_read_json_lines": {"min_run_count": 2, "version": "d6c1a814a4596aaa9af0c141bb911ab0ae1cb40476c11e24ea6a7fdff8cfc033", "processes": 2, "params": [["'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {'int': np.arange(N),\n                   'datetime': date_range('20000101', periods=N, freq='H')}\n        df = DataFrame(np.random.randn(N, 5),\n                       columns=['float_{}'.format(i) for i in range(5)],\n                       index=indexes[index])\n        df.to_json(self.fname, orient='records', lines=True)", "number": 0, "name": "io.json.ReadJSONLines.time_read_json_lines", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_read_store": {"min_run_count": 2, "version": "cd0474ba38ffcd30224d7d884eb4a0951b42ffcdd71471f694251e54a19f6c37", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get('fixed')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_read_store", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Apply.time_apply_ref_by_name": {"min_run_count": 2, "version": "5a00e865c055689fc7fe0e074da1361053a5af6856fc27db0a6f602410a45c1a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x['A'] + x['B'], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Apply.time_apply_ref_by_name", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameStringIndexing.time_boolean_rows_object": {"min_run_count": 2, "version": "191a535625de4f304976d77984b19508ba2942f326dd5510b8af3647c39f5beb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        self.df = DataFrame(np.random.randn(1000, 30), index=index,\n                            columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "number": 0, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.LibFastZip.time_lib_fast_zip": {"min_run_count": 2, "version": "76fdb90c052b51d11271496acb9a6821f878a7773f3c672274559b2ae5dacd7c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class LibFastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LibFastZip:\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)", "number": 0, "name": "reindex.LibFastZip.time_lib_fast_zip", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_series_loc": {"min_run_count": 2, "version": "b1ef809dbc72ebf757ca925ffecd23c3d31cc8b8b6fb1e3d021cdf513eb7b8a7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_series_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.ReadSQLTable.time_read_sql_table_all": {"min_run_count": 2, "version": "2d992c346b21c6347c332017f9a9d234558ceca432e3ac3c9f887ce62662da5a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = 'test'\n        self.con = create_engine('sqlite:///:memory:')\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.ReadSQLTable.time_read_sql_table_all", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.DatetimeAccessor.time_timedelta_days": {"min_run_count": 2, "version": "6c433dbbd4112cc286d6433e3eeedc6a84c2d5cc1976bc85cc35e286e0bf85ee", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range('1 days', periods=N, freq='h'))\n        return series", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:102", "number": 0, "name": "timedelta.DatetimeAccessor.time_timedelta_days", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.InsertColumns.time_assign_with_setitem": {"min_run_count": 2, "version": "3068315c0a3b3f85e2f6e4858fde4e7b5b173bc19f9b27bd5ab7ca1123d69a81", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        np.random.seed(1234)\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))", "number": 0, "name": "indexing.InsertColumns.time_assign_with_setitem", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_series_string": {"min_run_count": 2, "version": "55b9249d7e653a841ef57ff5e61814714853fbe00fcd8948cfe15117f3dcb648", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df['strings'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_series_string", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_get_loc": {"min_run_count": 2, "version": "b235eee029945afb8f6d60303fb9aaf5774cfc9f3461e33e8451a8582655d2bd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVComment.time_comment": {"min_run_count": 2, "version": "1281ec78b5fb3689e8c4bc1d856b2e261d1164f87ebf49b31461479c3fece69c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadCSVComment:\n    def time_comment(self):\n        read_csv(self.data(self.StringIO_input), comment='#',\n                 header=None, names=list('abc'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self):\n        data = ['A,B,C'] + (['1,2,3 # comment'] * 100000)\n        self.StringIO_input = StringIO('\\n'.join(data))", "number": 0, "name": "io.csv.ReadCSVComment.time_comment", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Equals.time_frame_float_equal": {"min_run_count": 2, "version": "41737bb7dd382b24f416fe2ee5ef513392bfaf699345b185a39105b9621ee2f3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame('foo', index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = ['A'] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "number": 0, "name": "frame_methods.Equals.time_frame_float_equal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.NumericInferOps.time_add": {"min_run_count": 2, "version": "4e86042b9b3244cf06673fc208f2248d2df365fdb6e7390b99834193fc7ddfb6", "processes": 2, "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df['A'] + self.df['B']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame({'A': np.arange(N).astype(dtype),\n                             'B': np.arange(N).astype(dtype)})", "number": 0, "name": "inference.NumericInferOps.time_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.PivotTable.time_pivot_table": {"min_run_count": 2, "version": "7495f332e7c713ae8ecf53ac0166d9a8d0d71a72634f0036fe9452c21f7cf933", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index='key1', columns=['key2', 'key3'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame({'key1': fac1.take(ind1),\n                             'key2': fac2.take(ind2),\n                             'key3': fac2.take(ind2),\n                             'value1': np.random.randn(N),\n                             'value2': np.random.randn(N),\n                             'value3': np.random.randn(N)})\n        self.df2 = DataFrame({'col1': list('abcde'), 'col2': list('fghij'),\n                              'col3': [1, 2, 3, 4, 5]})\n        self.df2.col1 = self.df2.col1.astype('category')\n        self.df2.col2 = self.df2.col2.astype('category')", "number": 0, "name": "reshape.PivotTable.time_pivot_table", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameStringIndexing.time_get_value": {"min_run_count": 2, "version": "c9770373db73484365edb35818f470e10974c9544c6771215a13b662944d2d39", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameStringIndexing:\n    def time_get_value(self):\n        with warnings.catch_warnings(record=True):\n            self.df.get_value(self.idx_scalar, self.col_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        self.df = DataFrame(np.random.randn(1000, 30), index=index,\n                            columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "number": 0, "name": "indexing.DataFrameStringIndexing.time_get_value", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_findall": {"min_run_count": 2, "version": "b99ec44f7e03df44d3a9d6cbb43e6b82877c51ccf2438678a057af7aab0842da", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_findall(self):\n        self.s.str.findall('[A-Z]+')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_findall", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Timeseries.time_timestamp_ops_diff_with_shift": {"min_run_count": 2, "version": "5a619423cafeea72dbefaac48cc2e2847501a5baa01193e5debc3ef5c3c2353f", "processes": 2, "params": [["None", "'US/Eastern'"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range('20010101', periods=N, freq='T', tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range('20010101', periods=N, freq='s', tz=tz))", "number": 0, "name": "binary_ops.Timeseries.time_timestamp_ops_diff_with_shift", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Float32.time_sum": {"min_run_count": 2, "version": "b7b34c4d7007b366b21f859e754b7910f98028b3922cfdea9dc0310aee3bc803", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Float32:\n    def time_sum(self):\n        self.df.groupby(['a'])['b'].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame(dict(a=arr, b=arr))", "number": 0, "name": "groupby.Float32.time_sum", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Interpolate.time_interpolate": {"min_run_count": 2, "version": "eb78959447327ef561fad189cc9e4b877977b63a673db8b848cfba0ad2a60df3", "processes": 2, "params": [["None", "'infer'"]], "type": "time", "warmup_time": -1, "param_names": ["downcast"], "timeout": 60.0, "code": "class Interpolate:\n    def time_interpolate(self, downcast):\n        self.df.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        self.df = DataFrame(np.random.randn(N, 100))\n        self.df.values[::2] = np.nan\n    \n        self.df2 = DataFrame({'A': np.arange(0, N),\n                              'B': np.random.randint(0, 100, N),\n                              'C': np.random.randn(N),\n                              'D': np.random.randn(N)})\n        self.df2.loc[1::5, 'A'] = np.nan\n        self.df2.loc[1::5, 'C'] = np.nan", "number": 0, "name": "frame_methods.Interpolate.time_interpolate", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.TimeseriesPlotting.time_plot_irregular": {"min_run_count": 2, "version": "8daf432abc06a172ae04b01aa16d90beaaa8e43fffec5592847f2ad72484b39c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range('1/1/1975', periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(np.concatenate((idx.values[0:10],\n                                                      idx.values[12:])))\n        self.df2 = DataFrame(np.random.randn(len(idx_irregular), M),\n                             index=idx_irregular)", "number": 0, "name": "plotting.TimeseriesPlotting.time_plot_irregular", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodIndexConstructor.time_from_ints": {"min_run_count": 2, "version": "ab166f539255244bf81c53dddc6b9b851a451aa02549d30087221b860a028076", "processes": 2, "params": [["'D'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["freq", "is_offset"], "timeout": 60.0, "code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range('1985', periods=1000)\n        self.rng2 = date_range('1985', periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = date_range('1/1/2000', periods=1000,\n                                     freq=freq).strftime('%Y%m%d').map(int)\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "number": 0, "name": "period.PeriodIndexConstructor.time_from_ints", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Concat.time_concat_empty_left": {"min_run_count": 2, "version": "3136a64205e342b45335a5e7cd62ec303a19d3099c332f0ffb0f60c90443c214", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:- i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame({'A': range(N)},\n                       index=date_range('20130101', periods=N, freq='s'))\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "number": 0, "name": "join_merge.Concat.time_concat_empty_left", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Cat.time_cat": {"min_run_count": 2, "version": "8996a66ece049adad39c28d957749ea8fbb713a4e457c74d5b80c0928f4afcce", "processes": 2, "params": [["0", "3"], ["None", "','"], ["None", "'-'"], ["0.0", "0.001", "0.15"]], "type": "time", "warmup_time": -1, "param_names": ["other_cols", "sep", "na_rep", "na_frac"], "timeout": 60.0, "code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10 ** 5\n        mask_gen = lambda: np.random.choice([True, False], N,\n                                            p=[1 - na_frac, na_frac])\n        self.s = Series(tm.makeStringIndex(N)).where(mask_gen())\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame({i: tm.makeStringIndex(N).where(mask_gen())\n                                     for i in range(other_cols)})", "number": 0, "name": "strings.Cat.time_cat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeCache.time_dup_seconds_and_unit": {"min_run_count": 2, "version": "74d91726c487c8e954088ad1983cac486896be2ad6a671dd12a992c0a692ee3f", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["cache"], "timeout": 60.0, "code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit='s', cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = ['2000-02-11'] * N\n        self.dup_string_with_tz = ['2000-02-11 15:00:00-0800'] * N", "number": 0, "name": "timeseries.ToDatetimeCache.time_dup_seconds_and_unit", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_tz_localize": {"min_run_count": 2, "version": "d37c395d7f06f086285fa60911570a3bbc00cc7b525e316019027278f7f9f5fe", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_tz_localize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.GroupStrings.time_multi_columns": {"min_run_count": 2, "version": "72bab48f65e0c6b5bf6567ec20166af5555a3697ef0b2319f2e04133de7d3870", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list('abcd')).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10**5\n        alpha = list(map(''.join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list('abcd'))\n        self.df['joe'] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)", "number": 0, "name": "groupby.GroupStrings.time_multi_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_month_end": {"min_run_count": 2, "version": "20a7912ba82cf8cdaafd33057bbc7aabeb986825f80814c14b555d551af41827", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_month_end(self, tz, freq):\n        self.ts.is_month_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_month_end", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeAsof.time_by_object": {"min_run_count": 2, "version": "266d2c5578af21df690de35fa670a334ccce0bea744607ab0667874a22ff83f6", "processes": 2, "params": [["'backward'", "'forward'", "'nearest'"]], "type": "time", "warmup_time": -1, "param_names": ["direction"], "timeout": 60.0, "code": "class MergeAsof:\n    def time_by_object(self, direction):\n        merge_asof(self.df1b, self.df2b, on='time', by='key',\n                   direction=direction)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {'time': np.random.randint(0, one_count / 20, one_count),\n             'key': np.random.choice(list(string.ascii_uppercase), one_count),\n             'key2': np.random.randint(0, 25, one_count),\n             'value1': np.random.randn(one_count)})\n        df2 = DataFrame(\n            {'time': np.random.randint(0, two_count / 20, two_count),\n             'key': np.random.choice(list(string.ascii_uppercase), two_count),\n             'key2': np.random.randint(0, 25, two_count),\n             'value2': np.random.randn(two_count)})\n    \n        df1 = df1.sort_values('time')\n        df2 = df2.sort_values('time')\n    \n        df1['time32'] = np.int32(df1.time)\n        df2['time32'] = np.int32(df2.time)\n    \n        self.df1a = df1[['time', 'value1']]\n        self.df2a = df2[['time', 'value2']]\n        self.df1b = df1[['time', 'key', 'value1']]\n        self.df2b = df2[['time', 'key', 'value2']]\n        self.df1c = df1[['time', 'key2', 'value1']]\n        self.df2c = df2[['time', 'key2', 'value2']]\n        self.df1d = df1[['time32', 'value1']]\n        self.df2d = df2[['time32', 'value2']]\n        self.df1e = df1[['time', 'key', 'key2', 'value1']]\n        self.df2e = df2[['time', 'key', 'key2', 'value2']]", "number": 0, "name": "join_merge.MergeAsof.time_by_object", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.All.time_all": {"min_run_count": 2, "version": "7cf91eee3405a4280498c10610f41e4019e807417ef41f8e55834e33f3499569", "processes": 2, "params": [["1000", "1000000"], ["'fast'", "'slow'"]], "type": "time", "warmup_time": -1, "param_names": ["N", "case"], "timeout": 60.0, "code": "class All:\n    def time_all(self, N, case):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case):\n        val = case != 'fast'\n        self.s = Series([val] * N)", "number": 0, "name": "series_methods.All.time_all", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_is_year_start": {"min_run_count": 2, "version": "3da4a807a317257b8eb98980b25d9f669aeee4a8120c5889e49acab2376abe94", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_is_year_start(self, tz, freq):\n        self.ts.is_year_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_is_year_start", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelDatetimeFields.time_datetime_field_day": {"min_run_count": 2, "version": "f5c6884dd12f0c856ed434c1d16a959054ee1e7feec7db46489a30fdff7cd5ae", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        self.dti = date_range('1900-01-01', periods=N, freq='T')\n        self.period = self.dti.to_period('D')", "number": 0, "name": "gil.ParallelDatetimeFields.time_datetime_field_day", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_iloc_slice": {"min_run_count": 2, "version": "f7938132abdb0df08450b5f3b5df5ff9e4515479adab9b69cb723846f2e93c15", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_iloc_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ParseDateComparison.time_read_csv_dayfirst": {"min_run_count": 2, "version": "30075c96d77a1f6c227019d013c7e1fd12327cdb13b5e1ddd497d282ea5a9fe8", "processes": 2, "params": [["False", "True"]], "type": "time", "warmup_time": -1, "param_names": ["cache_dates"], "timeout": 60.0, "code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        read_csv(self.data(self.StringIO_input), sep=',', header=None,\n                 names=['Date'], parse_dates=['Date'], cache_dates=cache_dates,\n                 dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = '12-02-2010\\n' * count_elem\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "replace.FillNa.time_fillna": {"min_run_count": 2, "version": "e7cc3988a1106da0c11b033728231cd03b868c74aa222541d3d456fa97c9fbb3", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range('1/1/2000', periods=N, freq='min')\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "number": 0, "name": "replace.FillNa.time_fillna", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.AggFunctions.time_different_python_functions_multicol": {"min_run_count": 2, "version": "bd847d6507165e578a4b36b24198d75b6b6a7ddca1325c8a7d872d9c04d7faf5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AggFunctions:\n    def time_different_python_functions_multicol(self, df):\n        df.groupby(['key1', 'key2']).agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        df = DataFrame({'key1': fac1.take(np.random.randint(0, 3, size=N)),\n                        'key2': fac2.take(np.random.randint(0, 2, size=N)),\n                        'value1': np.random.randn(N),\n                        'value2': np.random.randn(N),\n                        'value3': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:214", "number": 0, "name": "groupby.AggFunctions.time_different_python_functions_multicol", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.msgpack.MSGPack.time_read_msgpack": {"min_run_count": 2, "version": "28bb95bf1a680076cd392b889727bb251e773be6e1ddf421dc131be7be203872", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MSGPack:\n    def time_read_msgpack(self):\n        read_msgpack(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MSGPack:\n    def setup(self):\n        self.fname = '__test__.msg'\n        N = 100000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.df.to_msgpack(self.fname)", "number": 0, "name": "io.msgpack.MSGPack.time_read_msgpack", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_shape": {"min_run_count": 2, "version": "a11a6d1f4201feb1e4d2c7d439eb7b4e8115cb3ec7652344a7bde622cda5a110", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_shape(self):\n        self.index.shape\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_shape", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "replace.ReplaceDict.time_replace_series": {"min_run_count": 2, "version": "d4f030a6aecddbcf1a387d9b372f56f93a25b62690f982be3b7566b8479b8cc3", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10**5\n        start_value = 10**5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10**3))", "number": 0, "name": "replace.ReplaceDict.time_replace_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Rank.time_rank": {"min_run_count": 2, "version": "9e87afa473f86391f71a4582e9a68e9a482b72d6376d8fe2cb5c78677e5ac31b", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["constructor", "pct"], "timeout": 60.0, "code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "number": 0, "name": "stat_ops.Rank.time_rank", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Join.time_join_dataframe_index_single_key_small": {"min_run_count": 2, "version": "d4b440ee02d9b0a437640681f779f6f1ec162cbf6cfd72e632dea81c0f805c14", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on='key1', sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2],\n                            codes=[codes1, codes2])\n        self.df_multi = DataFrame(np.random.randn(len(index2), 4),\n                                  index=index2,\n                                  columns=['A', 'B', 'C', 'D'])\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame({'data1': np.random.randn(100000),\n                             'data2': np.random.randn(100000),\n                             'key1': self.key1,\n                             'key2': self.key2})\n    \n        self.df_key1 = DataFrame(np.random.randn(len(level1), 4),\n                                 index=level1,\n                                 columns=['A', 'B', 'C', 'D'])\n        self.df_key2 = DataFrame(np.random.randn(len(level2), 4),\n                                 index=level2,\n                                 columns=['A', 'B', 'C', 'D'])\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "number": 0, "name": "join_merge.Join.time_join_dataframe_index_single_key_small", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_floats_with_int_idex_lines": {"min_run_count": 2, "version": "811e673b7fe0c7d9015283b08a593907fdf34ce3d1564cff92d3fb6c82fc186d", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_floats_with_int_idex_lines(self, orient):\n        self.df.to_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_floats_with_int_idex_lines", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameStringIndexing.time_boolean_rows": {"min_run_count": 2, "version": "3b25e83d733ca3aba0368a59e4d6844efc4b9a49194df5a140e79a3153bdf89d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        self.df = DataFrame(np.random.randn(1000, 30), index=index,\n                            columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "number": 0, "name": "indexing.DataFrameStringIndexing.time_boolean_rows", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.AggFunctions.time_different_python_functions_singlecol": {"min_run_count": 2, "version": "3ca2f23007922b6148e88c0b5af43ded558a2e7c567592d5ebca8a1d24d4ff90", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AggFunctions:\n    def time_different_python_functions_singlecol(self, df):\n        df.groupby('key1').agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        df = DataFrame({'key1': fac1.take(np.random.randint(0, 3, size=N)),\n                        'key2': fac2.take(np.random.randint(0, 2, size=N)),\n                        'value1': np.random.randn(N),\n                        'value2': np.random.randn(N),\n                        'value3': np.random.randn(N)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:214", "number": 0, "name": "groupby.AggFunctions.time_different_python_functions_singlecol", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Split.time_split": {"min_run_count": 2, "version": "39dbba32a923fcd2b969617c94c6a01ca7767261d8391b83d56ceed1519b14c3", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["expand"], "timeout": 60.0, "code": "class Split:\n    def time_split(self, expand):\n        self.s.str.split('--', expand=expand)\n\n    def setup(self, expand):\n        self.s = Series(tm.makeStringIndex(10**5)).str.join('--')", "number": 0, "name": "strings.Split.time_split", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.EWMMethods.time_ewm": {"min_run_count": 2, "version": "ffb0f227a5546b1cd426985449713132c78173eb856f49e1becee6b6e0ad0aa0", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'mean'", "'std'"]], "type": "time", "warmup_time": -1, "param_names": ["contructor", "window", "dtype", "method"], "timeout": 60.0, "code": "class EWMMethods:\n    def time_ewm(self, constructor, window, dtype, method):\n        getattr(self.ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.ewm = getattr(pd, constructor)(arr).ewm(halflife=window)", "number": 0, "name": "rolling.EWMMethods.time_ewm", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {"min_run_count": 2, "version": "08cecf6decb11d4b745c61accb4953e09730304807576265e480c01ea6514671", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list('a' * N + 'b' * N + 'c' * N))\n        self.s = pd.Series(self.c)", "number": 0, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.CountMultiInt.time_multi_int_nunique": {"min_run_count": 2, "version": "6529b756e6d899d427ec4236384887b11546c4ae7d46b65660a727b8b7a6f4fc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby(['key1', 'key2']).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame({'key1': np.random.randint(0, 500, size=n),\n                        'key2': np.random.randint(0, 100, size=n),\n                        'ints': np.random.randint(0, 1000, size=n),\n                        'ints2': np.random.randint(0, 1000, size=n)})\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:197", "number": 0, "name": "groupby.CountMultiInt.time_multi_int_nunique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_getitem_list_like": {"min_run_count": 2, "version": "109d91dc3387565c60697c4e5f2e81f5dbe4283a6eecb9a9fb771d6e1a7e4dc5", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_getitem_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_getitem_lists": {"min_run_count": 2, "version": "0c4088513d6679dba4f2f2d088ebf4fd6efdc2f8846f8645c90ab0342c678066", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_getitem_lists", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_week": {"min_run_count": 2, "version": "dd11ca85a17cda758b11fb2eb1e21afc67aaf4d5a63af3e0013039b82db327ea", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_week(self, tz, freq):\n        self.ts.week\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_week", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {"min_run_count": 2, "version": "01284d8ea7765da6a2ec8df6237246209e4af5851d6cf0efc762bb565659ef4a", "processes": 2, "params": [["True", "False"], ["'custom'", "'iso8601'", "'ymd'"]], "type": "time", "warmup_time": -1, "param_names": ["infer_datetime_format", "format"], "timeout": 60.0, "code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, infer_datetime_format, format):\n        read_csv(self.data(self.StringIO_input),\n                 header=None, names=['foo'], parse_dates=['foo'],\n                 infer_datetime_format=infer_datetime_format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, infer_datetime_format, format):\n        rng = date_range('1/1/2000', periods=1000)\n        formats = {'custom': '%m/%d/%Y %H:%M:%S.%f',\n                   'iso8601': '%Y-%m-%d %H:%M:%S',\n                   'ymd': '%Y%m%d'}\n        dt_format = formats[format]\n        self.StringIO_input = StringIO('\\n'.join(\n                                       rng.strftime(dt_format).tolist()))", "number": 0, "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.SQL.time_read_sql_query": {"min_run_count": 2, "version": "ec2c049ce0151cd2ae07974ac44afd8838224238374c6bb3c55980fd4d563e15", "processes": 2, "params": [["'sqlalchemy'", "'sqlite'"]], "type": "time", "warmup_time": -1, "param_names": ["connection"], "timeout": 60.0, "code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {'sqlalchemy': create_engine('sqlite:///:memory:'),\n               'sqlite': sqlite3.connect(':memory:')}\n        self.table_name = 'test_type'\n        self.query_all = 'SELECT * FROM {}'.format(self.table_name)\n        self.con = con[connection]\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.SQL.time_read_sql_query", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {"min_run_count": 2, "version": "dc7a0dccf11260e719788a24237abd5a87a4306f6586870bf7c0a6759b713c30", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10**6\n        self.dti = date_range('1900-01-01', periods=N, freq='T')\n        self.period = self.dti.to_period('D')", "number": 0, "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.PivotTable.time_pivot_table_categorical_observed": {"min_run_count": 2, "version": "a1a1e8832880e5c6ed8911eade249d1abdd1c3a0cd831224bceaf429c1fa4fea", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(index='col1', values='col3', columns='col2',\n                             aggfunc=np.sum, fill_value=0, observed=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame({'key1': fac1.take(ind1),\n                             'key2': fac2.take(ind2),\n                             'key3': fac2.take(ind2),\n                             'value1': np.random.randn(N),\n                             'value2': np.random.randn(N),\n                             'value3': np.random.randn(N)})\n        self.df2 = DataFrame({'col1': list('abcde'), 'col2': list('fghij'),\n                              'col3': [1, 2, 3, 4, 5]})\n        self.df2.col1 = self.df2.col1.astype('category')\n        self.df2.col2 = self.df2.col2.astype('category')", "number": 0, "name": "reshape.PivotTable.time_pivot_table_categorical_observed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.TimedeltaIndexing.time_shallow_copy": {"min_run_count": 2, "version": "fae2d34018da9950a946b7e19dfb0f23e450bbc4f1b80821b2a422a14fcb7d83", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\n    def setup(self):\n        self.index = timedelta_range(start='1985', periods=1000, freq='D')\n        self.index2 = timedelta_range(start='1986', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "number": 0, "name": "timedelta.TimedeltaIndexing.time_shallow_copy", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.Arithmetic.time_make_union": {"min_run_count": 2, "version": "c32d2523758a9c25bf283543c78d7916c428a4d0883b4286dc3b5eb67435b8d3", "processes": 2, "params": [["0.1", "0.01"], ["0", "nan"]], "type": "time", "warmup_time": -1, "param_names": ["dense_proportion", "fill_value"], "timeout": 60.0, "code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "number": 0, "name": "sparse.Arithmetic.time_make_union", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_cut_timedelta": {"min_run_count": 2, "version": "18507088c996eb1e87d930f69f1aaac070bc890aea238f10177dfbb0effbdf9f", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_cut_timedelta", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_shape": {"min_run_count": 2, "version": "e65a17bd51c98f221ed9a4321d37f4f6d0c03aff5f7310f062bd42e8c80bb479", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_shape(self):\n        self.index.shape\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_shape", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_parse_now": {"min_run_count": 2, "version": "552a4bb08152927466f12bef880a9dd1cd434e65da7303039c64588b66e53854", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp('now')", "number": 0, "name": "timestamp.TimestampConstruction.time_parse_now", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVSkipRows.time_skipprows": {"min_run_count": 2, "version": "3dcb7bed8d524639322e4dce53b5c1ecfa0fe939f644c13bd5b82d9201dd83ac", "processes": 2, "params": [["None", "10000"]], "type": "time", "warmup_time": -1, "param_names": ["skiprows"], "timeout": 60.0, "code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows):\n        read_csv(self.fname, skiprows=skiprows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows):\n        N = 20000\n        index = tm.makeStringIndex(N)\n        df = DataFrame({'float1': np.random.randn(N),\n                        'float2': np.random.randn(N),\n                        'string1': ['foo'] * N,\n                        'bool1': [True] * N,\n                        'int1': np.random.randint(0, N, size=N)},\n                       index=index)\n        df.to_csv(self.fname)", "number": 0, "name": "io.csv.ReadCSVSkipRows.time_skipprows", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInForObjects.time_isin_long_series_long_values": {"min_run_count": 2, "version": "4a5ebefa368348dccf8861f12f69f1689735edc6858ae7b587a1a473ae54fd22", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInForObjects:\n    def time_isin_long_series_long_values(self):\n        # no dominating part\n        self.s_long.isin(self.vals_long)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10**4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10**4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10**5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10**5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10**5,\n                                    dtype=np.float)).astype(np.object)\n        self.vals_long_floats = np.arange(10**5,\n                                          dtype=np.float).astype(np.object)", "number": 0, "name": "series_methods.IsInForObjects.time_isin_long_series_long_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.Fillna.time_reindexed": {"min_run_count": 2, "version": "3cef4797895c790f23d5bc196305a53c7c7ca65546bff281875932af639e51cb", "processes": 2, "params": [["'pad'", "'backfill'"]], "type": "time", "warmup_time": -1, "param_names": ["method"], "timeout": 60.0, "code": "class Fillna:\n    def time_reindexed(self, method):\n        self.ts_reindexed.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range('1/1/2000', periods=N, freq='1min')\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype('float32')", "number": 0, "name": "reindex.Fillna.time_reindexed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Equals.time_frame_nonunique_equal": {"min_run_count": 2, "version": "ac153ac4d2ee746b0332a7f96d35ef6e8fd1e9dea1d66cb8b605a72af205175c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame('foo', index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = ['A'] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "number": 0, "name": "frame_methods.Equals.time_frame_nonunique_equal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.NanOps.time_func": {"min_run_count": 2, "version": "41743d399f9f3a98d72e1e375ec978c9fdb05b5710e2e89bf68122cf86350c1c", "processes": 2, "params": [["'var'", "'mean'", "'median'", "'max'", "'min'", "'sum'", "'std'", "'sem'", "'argmax'", "'skew'", "'kurt'", "'prod'"], ["1000", "1000000"], ["'int8'", "'int32'", "'int64'", "'float64'"]], "type": "time", "warmup_time": -1, "param_names": ["func", "N", "dtype"], "timeout": 60.0, "code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        self.s = Series([1] * N, dtype=dtype)\n        self.func = getattr(self.s, func)", "number": 0, "name": "series_methods.NanOps.time_func", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_frame": {"min_run_count": 2, "version": "b73fc6b6dcf4dd72c6070e8a9bc20eca0aef0f5f43b7eee4c18396787837272a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_frame", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.SeriesMultiIndexOps.time_op": {"min_run_count": 2, "version": "6eecbe0090e2c19b90053211bcb8fa21140857c76262f10ea1f725d7e7ebe247", "processes": 2, "params": [["0", "1", "[0, 1]"], ["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"]], "type": "time", "warmup_time": -1, "param_names": ["level", "op"], "timeout": 60.0, "code": "class SeriesMultiIndexOps:\n    def time_op(self, level, op):\n        self.s_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [np.arange(10).repeat(10000),\n                 np.tile(np.arange(100).repeat(100), 10),\n                 np.tile(np.tile(np.arange(100), 100), 10)]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)", "number": 0, "name": "stat_ops.SeriesMultiIndexOps.time_op", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_get_loc_sorted": {"min_run_count": 2, "version": "f640df7e6848e65b823be5ba87d0eff43813a7218a942ee1bc9c1a6c91e9c7e8", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_get_loc_sorted", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.FactorizeUnique.time_factorize": {"min_run_count": 2, "version": "67b2c73709a493f77c5adad12154f40b72f9508732397313008535af17bbaf4d", "processes": 2, "params": [["True", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "type": "time", "warmup_time": -1, "param_names": ["sort", "dtype"], "timeout": 60.0, "code": "class FactorizeUnique:\n    def time_factorize(self, sort, dtype):\n        self.idx.factorize(sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FactorizeUnique:\n    def setup(self, sort, dtype):\n        N = 10**5\n        data = {'int': pd.Int64Index(np.arange(N)),\n                'uint': pd.UInt64Index(np.arange(N)),\n                'float': pd.Float64Index(np.arange(N)),\n                'string': tm.makeStringIndex(N)}\n        self.idx = data[dtype]\n        assert self.idx.is_unique", "number": 0, "name": "algorithms.FactorizeUnique.time_factorize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {"min_run_count": 2, "version": "ddb503e22a337533428693787f1291b8aec9955bb0da27064acf632d32f2e0c5", "processes": 2, "params": [["'string'", "'datetime'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indexes = {'string': tm.makeStringIndex(N),\n                   'datetime': date_range('1900', periods=N, freq='s')}\n        index = indexes[index]\n        if index_structure == 'nonunique_monotonic_inc':\n            index = index.insert(item=index[2], loc=2)[:-1]\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]", "number": 0, "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.SortValues.time_frame_sort_values": {"min_run_count": 2, "version": "30b9cab23d4086f9bc592d2552b245f1c4a602bb764919da1a64312e4cac1de3", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["ascending"], "timeout": 60.0, "code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by='A', ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list('AB'))", "number": 0, "name": "frame_methods.SortValues.time_frame_sort_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Dtypes.time_frame_dtypes": {"min_run_count": 2, "version": "1eca85c37df3c0fa5ffab4f92c77a0352a28513588025f23251dda0c36027ac3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))", "number": 0, "name": "frame_methods.Dtypes.time_frame_dtypes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeNONISO8601.time_same_offset": {"min_run_count": 2, "version": "3726aaca4c6271f6c3567243e4428fbf98dd6da3c30b900afda8c3a916f85f18", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = int(N / 2)\n        ts_string_1 = 'March 1, 2018 12:00:00+0400'\n        ts_string_2 = 'March 1, 2018 12:00:00+0500'\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "number": 0, "name": "timeseries.ToDatetimeNONISO8601.time_same_offset", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples_raw": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "16f616c07f7c163721029dcb2b6db98b6d7eb1c184e01621fc61cd5503d44601", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples_raw", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "eval.Eval.time_chained_cmp": {"min_run_count": 2, "version": "2fbfdc9826fa2addbc192f7a297fb5b276f8f9a09957f1ca69413a9c025684dd", "processes": 2, "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["engine", "threads"], "timeout": 60.0, "code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval('self.df < self.df2 < self.df3 < self.df4', engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "number": 0, "name": "eval.Eval.time_chained_cmp", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_all_nan": {"min_run_count": 2, "version": "56ef562290a5036cd22f05d18d6a96888a9d055e23d5b7bed9818d022a0e473a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_all_nan", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeAsof.time_on_int": {"min_run_count": 2, "version": "86747e9181f5059e3ecac0e1365cff4e7eb8a5bac9b25c9ab7453cc32660cdbe", "processes": 2, "params": [["'backward'", "'forward'", "'nearest'"]], "type": "time", "warmup_time": -1, "param_names": ["direction"], "timeout": 60.0, "code": "class MergeAsof:\n    def time_on_int(self, direction):\n        merge_asof(self.df1a, self.df2a, on='time', direction=direction)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {'time': np.random.randint(0, one_count / 20, one_count),\n             'key': np.random.choice(list(string.ascii_uppercase), one_count),\n             'key2': np.random.randint(0, 25, one_count),\n             'value1': np.random.randn(one_count)})\n        df2 = DataFrame(\n            {'time': np.random.randint(0, two_count / 20, two_count),\n             'key': np.random.choice(list(string.ascii_uppercase), two_count),\n             'key2': np.random.randint(0, 25, two_count),\n             'value2': np.random.randn(two_count)})\n    \n        df1 = df1.sort_values('time')\n        df2 = df2.sort_values('time')\n    \n        df1['time32'] = np.int32(df1.time)\n        df2['time32'] = np.int32(df2.time)\n    \n        self.df1a = df1[['time', 'value1']]\n        self.df2a = df2[['time', 'value2']]\n        self.df1b = df1[['time', 'key', 'value1']]\n        self.df2b = df2[['time', 'key', 'value2']]\n        self.df1c = df1[['time', 'key2', 'value1']]\n        self.df2c = df2[['time', 'key2', 'value2']]\n        self.df1d = df1[['time32', 'value1']]\n        self.df2d = df2[['time32', 'value2']]\n        self.df1e = df1[['time', 'key', 'key2', 'value1']]\n        self.df2e = df2[['time', 'key', 'key2', 'value2']]", "number": 0, "name": "join_merge.MergeAsof.time_on_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.GetLoc.time_string_get_loc": {"min_run_count": 2, "version": "e63b856ff1402aa7e225016343f3e22c572a8c641711cd566fb623558d3e3799", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, 'A', 'A'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=['one', 'two', 'three'])\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list('A')],\n            names=['one', 'two', 'three'])\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list('A'), list('A')],\n            names=['one', 'two', 'three'])", "number": 0, "name": "multiindex_object.GetLoc.time_string_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Nth.time_frame_nth": {"min_run_count": 2, "version": "3d1f275a6c22e1140c8a56f950adf62864f6e573025a383a134b708a6dc17e45", "processes": 2, "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby('key').nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == 'datetime':\n            values = date_range('1/1/2011', periods=N, freq='s')\n        elif dtype == 'object':\n            values = ['foo'] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({'key': key, 'values': values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "number": 0, "name": "groupby.Nth.time_frame_nth", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {"min_run_count": 2, "version": "b923b4a3cba801a645615459d8565c817cb016035f447ab31ba81680b1cfcf6e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append('table_mixed_write', self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.FromCoo.time_sparse_series_from_coo": {"min_run_count": 2, "version": "738927096487e14107142a966b040386240f5533a4f7afac600f6f3f163e323a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        SparseSeries.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(([3.0, 1.0, 2.0],\n                                               ([1, 0, 0], [0, 2, 3])),\n                                              shape=(100, 100))", "number": 0, "name": "sparse.FromCoo.time_sparse_series_from_coo", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Nth.time_series_nth_all": {"min_run_count": 2, "version": "0d7f45209bddaff12d3a2b2bb72883e32e434e7490c3e060138249afb8bc189b", "processes": 2, "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df['values'].groupby(self.df['key']).nth(0, dropna='all')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == 'datetime':\n            values = date_range('1/1/2011', periods=N, freq='s')\n        elif dtype == 'object':\n            values = ['foo'] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({'key': key, 'values': values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "number": 0, "name": "groupby.Nth.time_series_nth_all", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sas.SAS.time_read_msgpack": {"min_run_count": 2, "version": "8074df5b56a0cada53b2d604946cc825cb92090118fd775b0c83c963cca33c2f", "processes": 2, "params": [["'sas7bdat'", "'xport'"]], "type": "time", "warmup_time": -1, "param_names": ["format"], "timeout": 60.0, "code": "class SAS:\n    def time_read_msgpack(self, format):\n        read_sas(self.f, format=format)\n\n    def setup(self, format):\n        # Read files that are located in 'pandas/io/tests/sas/data'\n        files = {'sas7bdat': 'test1.sas7bdat', 'xport': 'paxraw_d_short.xpt'}\n        file = files[format]\n        paths = [os.path.dirname(__file__), '..', '..', '..', 'pandas',\n                 'tests', 'io', 'sas', 'data', file]\n        self.f = os.path.join(*paths)", "number": 0, "name": "io.sas.SAS.time_read_msgpack", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {"min_run_count": 2, "version": "c0c53285aae872d71ae124704892ff1f3035af11d5653201e6c4f433826bb9ee", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range('1 days', periods=N, freq='h'))\n        return series", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:102", "number": 0, "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {"min_run_count": 2, "version": "e7b166572b4184ccee40c8995384e6afcecf0ee2254b263b747309e1b1174465", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select('table_wide')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.SQL.time_to_sql_dataframe": {"min_run_count": 2, "version": "b30f2cf4a229543192082947a1bdd4b0e013e6ee5abab226cf4bf2aee9376aff", "processes": 2, "params": [["'sqlalchemy'", "'sqlite'"]], "type": "time", "warmup_time": -1, "param_names": ["connection"], "timeout": 60.0, "code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql('test1', self.con, if_exists='replace')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {'sqlalchemy': create_engine('sqlite:///:memory:'),\n               'sqlite': sqlite3.connect(':memory:')}\n        self.table_name = 'test_type'\n        self.query_all = 'SELECT * FROM {}'.format(self.table_name)\n        self.con = con[connection]\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.SQL.time_to_sql_dataframe", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_series_categorical": {"min_run_count": 2, "version": "cf695fc3bb4de1f04ef1153f85912ae9d1f89fb18e3a7f70b7da3298c76d56e0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df['categories'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_series_categorical", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {"timeout": 120, "code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "version": "df6c0f3085283c0d4fa61b7483691791066c66142ea3ae8dbbbc965d54141945", "params": [], "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list", "param_names": [], "unit": "bytes", "type": "peakmemory"}, "timeseries.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {"min_run_count": 2, "version": "139934def27b5e5f5fd3ef99381e4a36c3f19a2dd15c2ad71f99184ad715b78c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start='1/1/2000', periods=20000, freq='H')\n        self.strings = rng.strftime('%Y-%m-%d %H:%M:%S').tolist()\n        self.strings_nosep = rng.strftime('%Y%m%d %H:%M:%S').tolist()\n        self.strings_tz_space = [x.strftime('%Y-%m-%d %H:%M:%S') + ' -0800'\n                                 for x in rng]", "number": 0, "name": "timeseries.ToDatetimeISO8601.time_iso8601_tz_spaceformat", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {"min_run_count": 2, "version": "60de75d6792155c27f8e49ad45f1e4021f7d479abecbdb6c71575648a4ddd8be", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["sort"], "timeout": 60.0, "code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on='key2', sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2],\n                            codes=[codes1, codes2])\n        self.df_multi = DataFrame(np.random.randn(len(index2), 4),\n                                  index=index2,\n                                  columns=['A', 'B', 'C', 'D'])\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame({'data1': np.random.randn(100000),\n                             'data2': np.random.randn(100000),\n                             'key1': self.key1,\n                             'key2': self.key2})\n    \n        self.df_key1 = DataFrame(np.random.randn(len(level1), 4),\n                                 index=level1,\n                                 columns=['A', 'B', 'C', 'D'])\n        self.df_key2 = DataFrame(np.random.randn(len(level2), 4),\n                                 index=level2,\n                                 columns=['A', 'B', 'C', 'D'])\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "number": 0, "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeCache.time_dup_string_tzoffset_dates": {"min_run_count": 2, "version": "01f74d66de617b3a5656038b3f5ecc915a9909eae00791ca4eea7992d5e814ed", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["cache"], "timeout": 60.0, "code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = ['2000-02-11'] * N\n        self.dup_string_with_tz = ['2000-02-11 15:00:00-0800'] * N", "number": 0, "name": "timeseries.ToDatetimeCache.time_dup_string_tzoffset_dates", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Interpolate.time_interpolate_some_good": {"min_run_count": 2, "version": "d15dbc7a2841b27db0ea28e6cdca512d2f9e8c38c444a78ecdca113753d13ead", "processes": 2, "params": [["None", "'infer'"]], "type": "time", "warmup_time": -1, "param_names": ["downcast"], "timeout": 60.0, "code": "class Interpolate:\n    def time_interpolate_some_good(self, downcast):\n        self.df2.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        self.df = DataFrame(np.random.randn(N, 100))\n        self.df.values[::2] = np.nan\n    \n        self.df2 = DataFrame({'A': np.arange(0, N),\n                              'B': np.random.randint(0, 100, N),\n                              'C': np.random.randn(N),\n                              'D': np.random.randn(N)})\n        self.df2.loc[1::5, 'A'] = np.nan\n        self.df2.loc[1::5, 'C'] = np.nan", "number": 0, "name": "frame_methods.Interpolate.time_interpolate_some_good", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.GetNumericData.time_frame_get_numeric_data": {"min_run_count": 2, "version": "4f28db13d6e80c935aa3667e418ed5c50bc6bf1a6f598d0e6713c656bb70e4d2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df['foo'] = 'bar'\n        self.df['bar'] = 'baz'\n        self.df = self.df._consolidate()", "number": 0, "name": "frame_methods.GetNumericData.time_frame_get_numeric_data", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_match": {"min_run_count": 2, "version": "df29690b09f6c4e5a19531ecbd676b06e94b94bd5c3b8178eafb5b37897dc7bc", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_match(self):\n        self.s.str.match('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_match", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {"min_run_count": 2, "version": "235ba443e264661a750b2961330450dc35b3483a165436f1e2f551dddd74562a", "processes": 2, "params": [["'all'", "'any'"], ["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["how", "axis"], "timeout": 60.0, "code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.ix[50:1000, 20:50] = np.nan\n        self.df.ix[2000:3000] = np.nan\n        self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed['foo'] = 'bar'", "number": 0, "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_floats_with_dt_index_lines": {"min_run_count": 2, "version": "b5452be311046379d848a1db8d9f6babd08fb30872531ded885b9cd532f63000", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_floats_with_dt_index_lines(self, orient):\n        self.df_date_idx.to_json(self.fname, orient='records', lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_floats_with_dt_index_lines", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Ops.time_add": {"min_run_count": 2, "version": "cd2c046e6c9cd407be6141875de615b8e069a684dfdf19701caac9e5e6c6e6e0", "processes": 2, "params": [["'float'", "'int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Ops:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {'int': 'makeIntIndex', 'float': 'makeFloatIndex'}\n        self.index = getattr(tm, indexes[dtype])(N)", "number": 0, "name": "index_object.Ops.time_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {"min_run_count": 2, "version": "1fd248b919c99a70e0bb70ac6b7f0dc0e5e3d3381a4d9f161563b2d7aba5869e", "processes": 2, "params": [["'nan'", "'0'", "''"]], "type": "time", "warmup_time": -1, "param_names": ["bad_date_value"], "timeout": 60.0, "code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(self.data(self.StringIO_input),\n                 header=None, names=['foo', 'bar'], parse_dates=['foo'],\n                 infer_datetime_format=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO(('%s,\\n' % bad_date_value) * 50000)", "number": 0, "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_unique": {"min_run_count": 2, "version": "989a076152a96fc7322afd6e2a7b66b230ede6cfc4c1c95ba35f2e4cdb809ca0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_unique", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Duplicated.time_frame_duplicated_wide": {"min_run_count": 2, "version": "3d400b9cafd66d0ab18844236a553bf2b9dddd4afb9e4990ba3e0ee7a45cdbc3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = (1 << 20)\n        t = date_range('2015-01-01', freq='S', periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame({'a': np.random.randint(-1 << 8, 1 << 8, n),\n                             'b': np.random.choice(t, n),\n                             'c': np.random.choice(xs, n)})\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "number": 0, "name": "frame_methods.Duplicated.time_frame_duplicated_wide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.PivotTable.time_pivot_table_agg": {"min_run_count": 2, "version": "4d482dbf9e0b2dbbe2f2f2250903e91430b5040361504164f99f8e5454f64105", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(index='key1', columns=['key2', 'key3'],\n                            aggfunc=['sum', 'mean'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame({'key1': fac1.take(ind1),\n                             'key2': fac2.take(ind2),\n                             'key3': fac2.take(ind2),\n                             'value1': np.random.randn(N),\n                             'value2': np.random.randn(N),\n                             'value3': np.random.randn(N)})\n        self.df2 = DataFrame({'col1': list('abcde'), 'col2': list('fghij'),\n                              'col3': [1, 2, 3, 4, 5]})\n        self.df2.col1 = self.df2.col1.astype('category')\n        self.df2.col2 = self.df2.col2.astype('category')", "number": 0, "name": "reshape.PivotTable.time_pivot_table_agg", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Size.time_category_size": {"min_run_count": 2, "version": "ca366f279da5c1240c8285951ba1b5c3ac622fd407c8bffa498f1808e421f136", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype('timedelta64[ns]')\n        dates = np.datetime64('now') + offsets\n        self.df = DataFrame({'key1': np.random.randint(0, 500, size=n),\n                             'key2': np.random.randint(0, 100, size=n),\n                             'value1': np.random.randn(n),\n                             'value2': np.random.randn(n),\n                             'value3': np.random.randn(n),\n                             'dates': dates})\n        self.draws = Series(np.random.randn(n))\n        labels = Series(['foo', 'bar', 'baz', 'qux'] * (n // 4))\n        self.cats = labels.astype('category')", "number": 0, "name": "groupby.Size.time_category_size", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_cut_int": {"min_run_count": 2, "version": "84547efae393eebb251ba4b7479d19553e958cc5d7594afd94ed2c268f9fcd7e", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_cut_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Isnull.time_isnull_obj": {"min_run_count": 2, "version": "869c55213cc5bc3d949b00efc3ab5ce2c3dbb220695bd49f2a8644d72dedea8e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array([NaT, np.nan, None, np.datetime64('NaT'),\n                           np.timedelta64('NaT'), 0, 1, 2.0, '', 'abcd'])\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "number": 0, "name": "frame_methods.Isnull.time_isnull_obj", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Quantile.time_frame_quantile": {"min_run_count": 2, "version": "5ca27dfca4a3c1cd1d709cb9f7314eeb2548c050a75ed22a6644c9d29f6c50e5", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Quantile.time_frame_quantile", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeISO8601.time_iso8601_format_no_sep": {"min_run_count": 2, "version": "10d9a7317bec693b378ab8dd30b7df28c7abf653d1cc0106d5f099e453c8c1c8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format='%Y%m%d %H:%M:%S')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start='1/1/2000', periods=20000, freq='H')\n        self.strings = rng.strftime('%Y-%m-%d %H:%M:%S').tolist()\n        self.strings_nosep = rng.strftime('%Y%m%d %H:%M:%S').tolist()\n        self.strings_tz_space = [x.strftime('%Y-%m-%d %H:%M:%S') + ' -0800'\n                                 for x in rng]", "number": 0, "name": "timeseries.ToDatetimeISO8601.time_iso8601_format_no_sep", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.NumericInferOps.time_modulo": {"min_run_count": 2, "version": "7cd7679ae7c09b65c42330616d0781b1bd071db1cd904ff81a59cfcf99652c02", "processes": 2, "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df['A'] % self.df['B']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame({'A': np.arange(N).astype(dtype),\n                             'B': np.arange(N).astype(dtype)})", "number": 0, "name": "inference.NumericInferOps.time_modulo", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDicts.time_nested_dict_columns": {"min_run_count": 2, "version": "8874bf3d45e75068dbf8e0233ff4333d463e35d373ead89530f21f5a7ad53933", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index,\n                          columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient='records')\n        self.data2 = {i: {j: float(j) for j in range(100)}\n                      for i in range(2000)}", "number": 0, "name": "frame_ctor.FromDicts.time_nested_dict_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.AsOf.time_asof_nan_single": {"min_run_count": 2, "version": "2560ffc2ac0f265798e1551b306c15b3929a29267be8daa70bab6b8f47f396f2", "processes": 2, "params": [["'DataFrame'", "'Series'"]], "type": "time", "warmup_time": -1, "param_names": ["constructor"], "timeout": 60.0, "code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start='1/1/1990', periods=N, freq='53s')\n        data = {'DataFrame': DataFrame(np.random.randn(N, M)),\n                'Series': Series(np.random.randn(N))}\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start='1/1/1990', periods=N * 10, freq='5s')\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "number": 0, "name": "timeseries.AsOf.time_asof_nan_single", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.ArithmeticBlock.time_division": {"min_run_count": 2, "version": "ba976a8f84c70face0f6cf3fbd57176994b3facf73f966450631f5650e58b798", "processes": 2, "params": [["nan", "0"]], "type": "time", "warmup_time": -1, "param_names": ["fill_value"], "timeout": 60.0, "code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)\n        self.arr2 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)", "number": 0, "name": "sparse.ArithmeticBlock.time_division", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.ConcatDataFrames.time_f_ordered": {"min_run_count": 2, "version": "6270ced745de3a466bb8e01497178c250bf103aa26a8bd4926b76e870c8d8bc5", "processes": 2, "params": [["0", "1"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["axis", "ignore_index"], "timeout": 60.0, "code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200),\n                            dtype=np.float32, order='C'))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200),\n                            dtype=np.float32, order='F'))\n        self.frame_f = [frame_f] * 20", "number": 0, "name": "join_merge.ConcatDataFrames.time_f_ordered", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {"min_run_count": 2, "version": "a2a1a7f44f3b4ad7e0bc20311b69854774889dd8c2691f50843d36169f8c05d7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select('table_wide', where=\"index > self.start_wide and \"\n                                              \"index < self.stop_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "replace.FillNa.time_replace": {"min_run_count": 2, "version": "e9ead9b00e47573db5ba625918c2378a575771fb539e28ce29ed2103934d1235", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range('1/1/2000', periods=N, freq='min')\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "number": 0, "name": "replace.FillNa.time_replace", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.DataFramePeriodColumn.time_setitem_period_column": {"min_run_count": 2, "version": "0d631ff4706e89d208c23f901276e8b9c35501d5a64645f834cadbaedaacbdd5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df['col'] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start='1/1/1990', freq='S', periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "number": 0, "name": "period.DataFramePeriodColumn.time_setitem_period_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Float64IndexMethod.time_get_loc": {"min_run_count": 2, "version": "717e6a136bc8af946792fa946550ad5e4bef98b9fdb2fedec255480da8bb1021", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100000\n        a = np.arange(N)\n        self.ind = Float64Index(a * 4.8000000418824129e-08)", "number": 0, "name": "index_object.Float64IndexMethod.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_getitem_array": {"min_run_count": 2, "version": "9a9c0443f381e71f9bbd395e5800e0b9dca934b8091fcab746a36c35ad6530ad", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_getitem_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Nth.time_frame_nth_any": {"min_run_count": 2, "version": "c19c244515157914bec9d62dfb58acc61aff465008ff114c8275a03a61e5777f", "processes": 2, "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby('key').nth(0, dropna='any')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == 'datetime':\n            values = date_range('1/1/2011', periods=N, freq='s')\n        elif dtype == 'object':\n            values = ['foo'] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({'key': key, 'values': values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "number": 0, "name": "groupby.Nth.time_frame_nth_any", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.I8Merge.time_i8merge": {"min_run_count": 2, "version": "1daa9d5d2782c93d98f8009ccfc21a9acf42bea4bf899bcde236fa9fad741cca", "processes": 2, "params": [["'inner'", "'outer'", "'left'", "'right'"]], "type": "time", "warmup_time": -1, "param_names": ["how"], "timeout": 60.0, "code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10**6\n        self.left = DataFrame(np.random.randint(low, high, (n, 7)),\n                              columns=list('ABCDEFG'))\n        self.left['left'] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({'left': 'right'}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right['right'] *= -1", "number": 0, "name": "join_merge.I8Merge.time_i8merge", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.stata.Stata.time_read_stata": {"min_run_count": 2, "version": "7dd9e44200ca8f6169b1c1c4a2c85f6de764f8303d304bd791ee19b2a292de9e", "processes": 2, "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "type": "time", "warmup_time": -1, "param_names": ["convert_dates"], "timeout": 60.0, "code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = '__test__.dta'\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(self.N)\n        self.df['int8_'] = np.random.randint(np.iinfo(np.int8).min,\n                                             np.iinfo(np.int8).max - 27, N)\n        self.df['int16_'] = np.random.randint(np.iinfo(np.int16).min,\n                                              np.iinfo(np.int16).max - 27, N)\n        self.df['int32_'] = np.random.randint(np.iinfo(np.int32).min,\n                                              np.iinfo(np.int32).max - 27, N)\n        self.df['float32_'] = np.array(np.random.randn(N),\n                                       dtype=np.float32)\n        self.convert_dates = {'index': convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)", "number": 0, "name": "io.stata.Stata.time_read_stata", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Size.time_multi_size": {"min_run_count": 2, "version": "4b2a4a290b00a30072d62722354d6148b14e2b45cfd9093e3c7fa2776edbb779", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby(['key1', 'key2']).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype('timedelta64[ns]')\n        dates = np.datetime64('now') + offsets\n        self.df = DataFrame({'key1': np.random.randint(0, 500, size=n),\n                             'key2': np.random.randint(0, 100, size=n),\n                             'value1': np.random.randn(n),\n                             'value2': np.random.randn(n),\n                             'value3': np.random.randn(n),\n                             'dates': dates})\n        self.draws = Series(np.random.randn(n))\n        labels = Series(['foo', 'bar', 'baz', 'qux'] * (n // 4))\n        self.cats = labels.astype('category')", "number": 0, "name": "groupby.Size.time_multi_size", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_qcut_timedelta": {"min_run_count": 2, "version": "0fd148ac141970c2a39fe8dd9d32eaf183bb1833e86dc250571ee7034c47f96c", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_qcut_timedelta", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns": {"min_run_count": 2, "version": "fd5395e2918bfb6197bb8ea2c8f7eab4af26cefd1650be7fc1ff4b377c76f766", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SortIndexByColumns:\n    def time_frame_sort_values_by_columns(self):\n        self.df.sort_values(by=['key1', 'key2'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndexByColumns:\n    def setup(self):\n        N = 10000\n        K = 10\n        self.df = DataFrame({'key1': tm.makeStringIndex(N).values.repeat(K),\n                             'key2': tm.makeStringIndex(N).values.repeat(K),\n                             'value': np.random.randn(N * K)})", "number": 0, "name": "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInForObjects.time_isin_long_series_short_values": {"min_run_count": 2, "version": "1c3f6c63fed9d4a9e14fea38e4dee54ea1afe69a6ec0ee3d112445af99044ac2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInForObjects:\n    def time_isin_long_series_short_values(self):\n        # running time dominated by look-up\n        self.s_long.isin(self.vals_short)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10**4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10**4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10**5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10**5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10**5,\n                                    dtype=np.float)).astype(np.object)\n        self.vals_long_floats = np.arange(10**5,\n                                          dtype=np.float).astype(np.object)", "number": 0, "name": "series_methods.IsInForObjects.time_isin_long_series_short_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.Align.time_align_series_irregular_string": {"min_run_count": 2, "version": "277b232ca56df50176d8d03929aa6d237e054156fa74fea40dea2e49f59f6d82", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = tm.makeStringIndex(n)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(np.random.randn(subsample_size),\n                        index=np.random.choice(indices, subsample_size,\n                                               replace=False))", "number": 0, "name": "reindex.Align.time_align_series_irregular_string", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_get": {"min_run_count": 2, "version": "470b7d7abff71c79a760487770ffe613d314c03989d2ae2550e68cc0869685ea", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_get", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Nth.time_series_nth_any": {"min_run_count": 2, "version": "0c9adec497b2730fc3b7b0c0ee9cdedb7b09539b4b8eafdf380fb4c074e15335", "processes": 2, "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df['values'].groupby(self.df['key']).nth(0, dropna='any')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == 'datetime':\n            values = date_range('1/1/2011', periods=N, freq='s')\n        elif dtype == 'object':\n            values = ['foo'] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({'key': key, 'values': values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "number": 0, "name": "groupby.Nth.time_series_nth_any", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_iloc_list_like": {"min_run_count": 2, "version": "a558e065957d077e195452c33d726d7a68961c0ffb2f27473ccef46d6b0aefd7", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_iloc_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Apply.time_copy_overhead_single_col": {"min_run_count": 2, "version": "7fd3b41a0191db3071a19b0aa53f6c74ccfd8389b7c07827ee05e8f475dda9f7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_copy_overhead_single_col(self, df):\n        df.groupby('key').apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10**4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame({'key': labels,\n                        'key2': labels2,\n                        'value1': np.random.randn(N),\n                        'value2': ['foo', 'bar', 'baz', 'qux'] * (N // 4)\n                        })\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:35", "number": 0, "name": "groupby.Apply.time_copy_overhead_single_col", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.DropDuplicates.time_frame_drop_dups": {"min_run_count": 2, "version": "65fc1bf59b5906c89be80e95831360e1bcfa18a20ee681195e243b991f520cf7", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates(['key1', 'key2'], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame({'key1': key1, 'key2': key2,\n                             'value': np.random.randn(N * K)})\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({'key1': key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10),\n                                                   dtype=bool))", "number": 0, "name": "reindex.DropDuplicates.time_frame_drop_dups", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_get_loc_non_unique_sorted": {"min_run_count": 2, "version": "60dbf93cea5b01ed7d513fcb64e8d98bfe5ff3c2ddfaa517f2d7c775bca8fe5e", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_get_loc_non_unique_sorted", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.CategoricalSlicing.time_getitem_slice": {"min_run_count": 2, "version": "2c1b86de308be1962d948de5418223535e7bb800bc0ee8598f7d9cf5b505cc8c", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[:self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = ['a', 'b', 'c']\n        values = [0] * N + [1] * N + [2] * N\n        if index == 'monotonic_incr':\n            self.data = pd.Categorical.from_codes(values,\n                                                  categories=categories)\n        elif index == 'monotonic_decr':\n            self.data = pd.Categorical.from_codes(list(reversed(values)),\n                                                  categories=categories)\n        elif index == 'non_monotonic':\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N,\n                                                  categories=categories)\n        else:\n            raise ValueError('Invalid index param: {}'.format(index))\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = 'b'", "number": 0, "name": "categoricals.CategoricalSlicing.time_getitem_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDF.time_write_hdf": {"min_run_count": 2, "version": "c361ca283d7c437daaef267cf52a56cb20ea37aef8d136b44aec8bd582a02c6a", "processes": 2, "params": [["'table'", "'fixed'"]], "type": "time", "warmup_time": -1, "param_names": ["format"], "timeout": 60.0, "code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, 'df', format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = '__test__.h5'\n        N = 100000\n        C = 5\n        self.df = DataFrame(np.random.randn(N, C),\n                            columns=['float{}'.format(i) for i in range(C)],\n                            index=date_range('20000101', periods=N, freq='H'))\n        self.df['object'] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, 'df', format=format)", "number": 0, "name": "io.hdf.HDF.time_write_hdf", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.DropDuplicates.time_frame_drop_dups_na": {"min_run_count": 2, "version": "d8f413ab6a48cdf5247691ce7e82693f651ce0671a5c97e2d8530b2118ab6160", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["inplace"], "timeout": 60.0, "code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates(['key1', 'key2'], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame({'key1': key1, 'key2': key2,\n                             'value': np.random.randn(N * K)})\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({'key1': key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10),\n                                                   dtype=bool))", "number": 0, "name": "reindex.DropDuplicates.time_frame_drop_dups_na", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Repr.time_rendering": {"min_run_count": 2, "version": "cbee0f9affea494b9a2dc356ad907f1454630219aced01823c128e8c3f7cd063", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series(['s1234']).astype('category')", "number": 0, "name": "categoricals.Repr.time_rendering", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "plotting.SeriesPlotting.time_series_plot": {"min_run_count": 2, "version": "a91dce790d3db655fc8192788f414459800741eee4eba98d9423b4b016fb33f7", "processes": 2, "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'"]], "type": "time", "warmup_time": -1, "param_names": ["kind"], "timeout": 60.0, "code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in ['bar', 'barh', 'pie']:\n            n = 100\n        elif kind in ['kde']:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in ['area', 'pie']:\n            self.s = self.s.abs()", "number": 0, "name": "plotting.SeriesPlotting.time_series_plot", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reindex.LevelAlign.time_reindex_level": {"min_run_count": 2, "version": "30bd93f3b900a376d0898dc177ee435c3b4aec97057b5cbdfbae7620da5b99eb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[np.arange(10).repeat(10000),\n                   np.tile(np.arange(100).repeat(100), 10),\n                   np.tile(np.tile(np.arange(100), 100), 10)])\n        self.df = DataFrame(np.random.randn(len(self.index), 4),\n                            index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4),\n                                  index=self.index.levels[1])", "number": 0, "name": "reindex.LevelAlign.time_reindex_level", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "inference.NumericInferOps.time_multiply": {"min_run_count": 2, "version": "983b0da750ea677a8e9d8c5ca5ebc8a69b12a7bc1524e9f0ceca5adb64e47978", "processes": 2, "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df['A'] * self.df['B']\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame({'A': np.arange(N).astype(dtype),\n                             'B': np.arange(N).astype(dtype)})", "number": 0, "name": "inference.NumericInferOps.time_multiply", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodProperties.time_property": {"min_run_count": 2, "version": "7e1a349986c03a4c285bf870d7bef6a12afe24851a8c18753bd6b4586f823106", "processes": 2, "params": [["'M'", "'min'"], ["'year'", "'month'", "'day'", "'hour'", "'minute'", "'second'", "'is_leap_year'", "'quarter'", "'qyear'", "'week'", "'daysinmonth'", "'dayofweek'", "'dayofyear'", "'start_time'", "'end_time'"]], "type": "time", "warmup_time": -1, "param_names": ["freq", "attr"], "timeout": 60.0, "code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period('2012-06-01', freq=freq)", "number": 0, "name": "period.PeriodProperties.time_property", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodIndexConstructor.time_from_pydatetime": {"min_run_count": 2, "version": "53fdcd420a531ed678dc7fbc6b125ab19c5477a3589b718aa0c27f458dc8db8a", "processes": 2, "params": [["'D'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["freq", "is_offset"], "timeout": 60.0, "code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range('1985', periods=1000)\n        self.rng2 = date_range('1985', periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = date_range('1/1/2000', periods=1000,\n                                     freq=freq).strftime('%Y%m%d').map(int)\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "number": 0, "name": "period.PeriodIndexConstructor.time_from_pydatetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.SparseDataFrameConstructor.time_from_scipy": {"min_run_count": 2, "version": "21c5192bed05626ca1106fed0e1dac52546e4ae49d1825761dd213bb4c33ddfb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        SparseDataFrame(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.arr = np.arange(N)\n        self.sparse = scipy.sparse.rand(N, N, 0.005)\n        self.dict = dict(zip(range(N), itertools.repeat([0])))", "number": 0, "name": "sparse.SparseDataFrameConstructor.time_from_scipy", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_quarter": {"min_run_count": 2, "version": "4e6f8a10ae81808591ed74cf0a87dec146a08c259c8ee45998848750bd59c6cb", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_quarter(self, tz, freq):\n        self.ts.quarter\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_quarter", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_read_store_table": {"min_run_count": 2, "version": "2c6913c4c8462c4c54b8de9e811dfcad6dfd1e77ddc331499132bb2dad2ca63c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select('table')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Ops2.time_frame_int_mod": {"min_run_count": 2, "version": "473d611481a4380a118f142a864255a8cb9c1f75a12e30e002dabafe8ab653d6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                  np.iinfo(np.int16).max,\n                                                  size=(N, N)))\n        self.df2_int = DataFrame(np.random.randint(np.iinfo(np.int16).min,\n                                                   np.iinfo(np.int16).max,\n                                                   size=(N, N)))\n    \n        self.s = Series(np.random.randn(N))", "number": 0, "name": "binary_ops.Ops2.time_frame_int_mod", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Concat.time_concat_series": {"min_run_count": 2, "version": "ba0a0eac3f9dabbd249d706599e19c43ef36e4c8980bc25eab99ff6537287507", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:- i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame({'A': range(N)},\n                       index=date_range('20130101', periods=N, freq='s'))\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "number": 0, "name": "join_merge.Concat.time_concat_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.Append.time_append_homogenous": {"min_run_count": 2, "version": "b89dd6ad6eae22c13800c035479c9c58a011031981ec9d2212c57aa708a9d26e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Append:\n    def time_append_homogenous(self):\n        self.df1.append(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4),\n                             columns=['A', 'B', 'C', 'D'])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1['obj1'] = 'bar'\n        self.mdf1['obj2'] = 'bar'\n        self.mdf1['int1'] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index", "number": 0, "name": "join_merge.Append.time_append_homogenous", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {"min_run_count": 2, "version": "922131e71b6c5200ab6bbf1cc7283e1a8a9ed9573d84a27b37c203f76c053fb0", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append('table_dc_write', self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_ceil": {"min_run_count": 2, "version": "c9ce7a78149f2b026cb3ca9bef835b9bdf869a3d1a39d02145447e20cf9c9953", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil('5T')\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_ceil", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Algorithms.time_value_counts": {"min_run_count": 2, "version": "4eb62e54fffe1f0e01f7b68117f900e2fdd07643c04f19a0727271f323cb3914", "processes": 2, "params": [["'index'", "'series'"]], "type": "time", "warmup_time": -1, "param_names": ["typ"], "timeout": 60.0, "code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [Period('2011-01', freq='M'), Period('2011-02', freq='M'),\n                Period('2011-03', freq='M'), Period('2011-04', freq='M')]\n    \n        if typ == 'index':\n            self.vector = PeriodIndex(data * 1000, freq='M')\n        elif typ == 'series':\n            self.vector = Series(data * 1000)", "number": 0, "name": "period.Algorithms.time_value_counts", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeFormat.time_exact": {"min_run_count": 2, "version": "a52b08b718b5e121c16dbc359abbb8389718d9445a1868b961cba1004a37ca5d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format='%d%b%y')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        self.s = Series(['19MAY11', '19MAY11:00:00:00'] * 100000)\n        self.s2 = self.s.str.replace(':\\\\S+$', '')", "number": 0, "name": "timeseries.ToDatetimeFormat.time_exact", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_rfind": {"min_run_count": 2, "version": "b3012e7022b35fc1154ff7611a91e7da89524435fd04c538f30ad666c775f902", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_rfind(self):\n        self.s.str.rfind('[A-Z]+')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_rfind", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeCategoricals.time_merge_object": {"min_run_count": 2, "version": "ef40dcca7fc69edfad7aa851bfaed9366c626265309232413474024209bc6fa5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on='X')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {'X': np.random.choice(range(0, 10), size=(10000,)),\n             'Y': np.random.choice(['one', 'two', 'three'], size=(10000,))})\n    \n        self.right_object = DataFrame(\n            {'X': np.random.choice(range(0, 10), size=(10000,)),\n             'Z': np.random.choice(['jjj', 'kkk', 'sss'], size=(10000,))})\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object['Y'].astype('category'))\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object['Z'].astype('category'))", "number": 0, "name": "join_merge.MergeCategoricals.time_merge_object", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_shallow_copy": {"min_run_count": 2, "version": "291be44fdbad2d2994b1463179d1a204c149b8b5f2732aff8bb716f9d185d22d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_shallow_copy", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_to_pydatetime": {"min_run_count": 2, "version": "3aff1a961d6cd2ab95d7393f42b93bc1f39b35a4b75b1b690f38965f4c048243", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_to_pydatetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Describe.time_dataframe_describe": {"min_run_count": 2, "version": "15552907c28f688e36b76b8da59723b4435f1af8aa5e4df43d906a61aa0dc2c3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame({\n            'a': np.random.randint(0, 100, int(1e6)),\n            'b': np.random.randint(0, 100, int(1e6)),\n            'c': np.random.randint(0, 100, int(1e6))\n        })", "number": 0, "name": "frame_methods.Describe.time_dataframe_describe", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing_engines.ObjectEngineIndexing.time_get_loc": {"min_run_count": 2, "version": "68f0069411e524ac798f1368d7a6ca3c1ace79965502965ac9b87c9cce008691", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc('b')\n\n    def setup(self, index_type):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        arr = {\n            'monotonic_incr': np.array(values, dtype=object),\n            'monotonic_decr': np.array(list(reversed(values)), dtype=object),\n            'non_monotonic': np.array(list('abc') * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(lambda: arr, len(arr))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc('b')", "number": 0, "name": "indexing_engines.ObjectEngineIndexing.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.RankWithTies.time_rank_ties": {"min_run_count": 2, "version": "0cb57f2d63901ee1d41610ef48a944745906d64d151d19a7d019aba367817c6b", "processes": 2, "params": [["'float64'", "'float32'", "'int64'", "'datetime64'"], ["'first'", "'average'", "'dense'", "'min'", "'max'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype", "tie_method"], "timeout": 60.0, "code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby('key').rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10**4\n        if dtype == 'datetime64':\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.array([1] * N, dtype=dtype)\n        self.df = DataFrame({'values': data, 'key': ['foo'] * N})", "number": 0, "name": "groupby.RankWithTies.time_rank_ties", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_ix_slice": {"min_run_count": 2, "version": "c4a4fcad4f08771ac04ddabaf9456da5a136199fd3b9b27ffd7db2c94456fd1f", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_ix_slice(self, index, index_structure):\n        self.data.ix[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_ix_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_intersection": {"min_run_count": 2, "version": "c32d297b72af2489f47e7092f6e911394396590ff53b46109d97252fe426ffdd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_intersection", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.ArithmeticBlock.time_make_union": {"min_run_count": 2, "version": "41c7ee25d6a4e9101df0965167dbb2c3f8fa677faa6ae140b33edd2f03b748a5", "processes": 2, "params": [["nan", "0"]], "type": "time", "warmup_time": -1, "param_names": ["fill_value"], "timeout": 60.0, "code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)\n        self.arr2 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)", "number": 0, "name": "sparse.ArithmeticBlock.time_make_union", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_weekday_name": {"min_run_count": 2, "version": "878bbec822a24300eb9c8c3d14c60e225ca9e007eee3e014be83f24919f84f4c", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_weekday_name(self, tz, freq):\n        self.ts.day_name\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_weekday_name", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Quantile.time_quantile": {"min_run_count": 2, "version": "178e4b752debb9c2a8ef30e20577bf0656d1fb1e253266237196fd02c462dd4c", "processes": 2, "params": [["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"], ["'float'", "'int'", "'uint'"]], "type": "time", "warmup_time": -1, "param_names": ["quantile", "interpolation", "dtype"], "timeout": 60.0, "code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.idx.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10**5\n        data = {'int': np.arange(N),\n                'uint': np.arange(N).astype(np.uint64),\n                'float': np.random.randn(N)}\n        self.idx = pd.Series(data[dtype].repeat(5))", "number": 0, "name": "algorithms.Quantile.time_quantile", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_shallow_copy": {"min_run_count": 2, "version": "bc7e4ac0a278aadcdf8627771d49b978a0e230af408cb5097f2fed207b3778d3", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_shallow_copy", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Transform.time_transform_multi_key4": {"min_run_count": 2, "version": "51885c433e06a246d7e48699f6afd68c8f8422875cc478cbb14a31d1e3c9777d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby(['jim', 'joe'])['jolie'].transform('max')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(levels=[np.arange(n1), tm.makeStringIndex(n2)],\n                           codes=[np.repeat(range(n1), n2).tolist(),\n                                  list(range(n2)) * n1],\n                           names=['lev1', 'lev2'])\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=['col1', 'col20', 'col3'])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(np.random.randint(1, n, (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df2 = self.df1.copy()\n        self.df2['jim'] = self.df2['joe']\n    \n        self.df3 = DataFrame(np.random.randint(1, (n / 10), (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df4 = self.df3.copy()\n        self.df4['jim'] = self.df4['joe']", "number": 0, "name": "groupby.Transform.time_transform_multi_key4", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Duplicated.time_duplicated": {"min_run_count": 2, "version": "d1d401588c30b95db07bb559b7c7703837a8d999a10cafb92ee43a2ca891a447", "processes": 2, "params": [["'first'", "'last'", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "type": "time", "warmup_time": -1, "param_names": ["keep", "dtype"], "timeout": 60.0, "code": "class Duplicated:\n    def time_duplicated(self, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, keep, dtype):\n        N = 10**5\n        data = {'int': pd.Int64Index(np.arange(N).repeat(5)),\n                'uint': pd.UInt64Index(np.arange(N).repeat(5)),\n                'float': pd.Float64Index(np.random.randn(N).repeat(5)),\n                'string': tm.makeStringIndex(N).repeat(5)}\n        self.idx = data[dtype]\n        # cache is_unique\n        self.idx.is_unique", "number": 0, "name": "algorithms.Duplicated.time_duplicated", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVConcatDatetime.time_read_csv": {"min_run_count": 2, "version": "c5531bc6297e942a0dfdb40d2d998299620be9db9a9e33c59a3f6591ec155125", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(self.data(self.StringIO_input),\n                 header=None, names=['foo'], parse_dates=['foo'],\n                 infer_datetime_format=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range('1/1/2000', periods=50000, freq='S')\n        self.StringIO_input = StringIO('\\n'.join(\n                                       rng.strftime(self.iso8601).tolist()))", "number": 0, "name": "io.csv.ReadCSVConcatDatetime.time_read_csv", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.Timeseries.time_timestamp_ops_diff": {"min_run_count": 2, "version": "dfeccabdb5bd2a97282e7da3437da400e5cb6237cc51a70c1fd6c0b6df2024c1", "processes": 2, "params": [["None", "'US/Eastern'"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range('20010101', periods=N, freq='T', tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range('20010101', periods=N, freq='s', tz=tz))", "number": 0, "name": "binary_ops.Timeseries.time_timestamp_ops_diff", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_strip": {"min_run_count": 2, "version": "933983163a3e74bfe19f441a9d0de46f7eed1913927f32f4af0cf3b915674a5e", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_strip(self):\n        self.s.str.strip('A')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_strip", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {"min_run_count": 2, "version": "a09aa667e962193df729171b73bf5ea094df41cdd3983b2a970b03fdaa4bf049", "processes": 2, "params": [["'string'", "'datetime'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indexes = {'string': tm.makeStringIndex(N),\n                   'datetime': date_range('1900', periods=N, freq='s')}\n        index = indexes[index]\n        if index_structure == 'nonunique_monotonic_inc':\n            index = index.insert(item=index[2], loc=2)[:-1]\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]", "number": 0, "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Shift.time_shift": {"min_run_count": 2, "version": "395684e7863d6ac7ba645245929a877db93acae804ce3111495aa5b0f1a8209a", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))", "number": 0, "name": "frame_methods.Shift.time_shift", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameNumericIndexing.time_iloc_dups": {"min_run_count": 2, "version": "57a810caa20e61e3f3257bed744e297d7bda5a4a486a895b41eacc16b8e02b54", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "number": 0, "name": "indexing.DataFrameNumericIndexing.time_iloc_dups", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "series_methods.IsInFloat64.time_isin_few_different": {"min_run_count": 2, "version": "905bcd41500875c8ca8bd41ffe29e1c5150ef340e18da6112a86ce23af2fb70b", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IsInFloat64:\n    def time_isin_few_different(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.few_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10**6, dtype=np.float64)\n        self.few_different_values = np.zeros(10**7, dtype=np.float64)\n        self.only_nans_values = np.full(10**7, np.nan, dtype=np.float64)", "number": 0, "name": "series_methods.IsInFloat64.time_isin_few_different", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.NSort.time_nlargest_two_columns": {"min_run_count": 2, "version": "5f437e27806105143ea45fd979f0d451988db355ad2151211cd1d2f887db3cdd", "processes": 2, "params": [["'first'", "'last'", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["keep"], "timeout": 60.0, "code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, ['A', 'B'], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3),\n                            columns=list('ABC'))", "number": 0, "name": "frame_methods.NSort.time_nlargest_two_columns", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Repr.time_repr_tall": {"min_run_count": 2, "version": "f32bf0352558e8826294895745a574c3f76d158504f298372a9f26190ec8aba7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "number": 0, "name": "frame_methods.Repr.time_repr_tall", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.CategoricalIndexIndexing.time_getitem_scalar": {"min_run_count": 2, "version": "52cee43b71fe77c8467563ca1d97ee525621e5834ac0e705e85e1ced75b65633", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list('a' * N + 'b' * N + 'c' * N)\n        indices = {\n            'monotonic_incr': CategoricalIndex(values),\n            'monotonic_decr': CategoricalIndex(reversed(values)),\n            'non_monotonic': CategoricalIndex(list('abc' * N))}\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = 'b'\n        self.cat_list = ['a', 'c']", "number": 0, "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ToDatetimeNONISO8601.time_different_offset": {"min_run_count": 2, "version": "44ee19e6876c886fffce02eff0ba1fa1eca2b69e1601ef4cbfe3a0d085c26958", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = int(N / 2)\n        ts_string_1 = 'March 1, 2018 12:00:00+0400'\n        ts_string_2 = 'March 1, 2018 12:00:00+0500'\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "number": 0, "name": "timeseries.ToDatetimeNONISO8601.time_different_offset", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timedelta.ToTimedeltaErrors.time_convert": {"min_run_count": 2, "version": "cde1b5e91cdbca24377efd93f023e61a72939f4693d927aaed9cc97177d6d2e7", "processes": 2, "params": [["'coerce'", "'ignore'"]], "type": "time", "warmup_time": -1, "param_names": ["errors"], "timeout": 60.0, "code": "class ToTimedeltaErrors:\n    def time_convert(self, errors):\n        to_timedelta(self.arr, errors=errors)\n\n    def setup(self, errors):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = ['{0} days'.format(i) for i in ints]\n        self.arr[-1] = 'apple'", "number": 0, "name": "timedelta.ToTimedeltaErrors.time_convert", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.CategoricalSlicing.time_getitem_list": {"min_run_count": 2, "version": "fea9dcb64635b5f9107fb21a7107ff62eb3b8689987e7cc984cade2e21ead27b", "processes": 2, "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["index"], "timeout": 60.0, "code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = ['a', 'b', 'c']\n        values = [0] * N + [1] * N + [2] * N\n        if index == 'monotonic_incr':\n            self.data = pd.Categorical.from_codes(values,\n                                                  categories=categories)\n        elif index == 'monotonic_decr':\n            self.data = pd.Categorical.from_codes(list(reversed(values)),\n                                                  categories=categories)\n        elif index == 'non_monotonic':\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N,\n                                                  categories=categories)\n        else:\n            raise ValueError('Invalid index param: {}'.format(index))\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = 'b'", "number": 0, "name": "categoricals.CategoricalSlicing.time_getitem_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {"min_run_count": 2, "version": "a73846c324dad5886347dc5054ddbee48420469c395265420327f572a083a578", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get('fixed_mixed')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ResampleDataFrame.time_method": {"min_run_count": 2, "version": "65cd727d59ffcfe48483d7b1de916fdd5125d76bc83aae7182a47b919dd87907", "processes": 2, "params": [["'max'", "'mean'", "'min'"]], "type": "time", "warmup_time": -1, "param_names": ["method"], "timeout": 60.0, "code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start='20130101', periods=100000, freq='50L')\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample('1s'), method)", "number": 0, "name": "timeseries.ResampleDataFrame.time_method", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_replace_tz": {"min_run_count": 2, "version": "c65597209c380c038f9c5e700ca0a6d7b0675d3f5cdcd94b685e2611784a0ad8", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=pytz.timezone('US/Eastern'))\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_replace_tz", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeIndex.time_get": {"min_run_count": 2, "version": "db73ee6bac0bec459d01b6da3b65f61e96ac73756b2c8db680a65113a073ab9a", "processes": 2, "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "type": "time", "warmup_time": -1, "param_names": ["index_type"], "timeout": 60.0, "code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {'dst': date_range(start='10/29/2000 1:00:00',\n                                     end='10/29/2000 1:59:59', freq='S'),\n                   'repeated': date_range(start='2000',\n                                          periods=N / 10,\n                                          freq='s').repeat(10),\n                   'tz_aware': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz='US/Eastern'),\n                   'tz_local': date_range(start='2000',\n                                          periods=N,\n                                          freq='s',\n                                          tz=dateutil.tz.tzlocal()),\n                   'tz_naive': date_range(start='2000',\n                                          periods=N,\n                                          freq='s')}\n        self.index = dtidxes[index_type]", "number": 0, "name": "timeseries.DatetimeIndex.time_get", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.PivotTable.time_pivot_table_categorical": {"min_run_count": 2, "version": "22488df0b81a0881381d3f16a7821512bd2f4fc9d6c422c6cf67591f5986ae22", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(index='col1', values='col3', columns='col2',\n                             aggfunc=np.sum, fill_value=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame({'key1': fac1.take(ind1),\n                             'key2': fac2.take(ind2),\n                             'key3': fac2.take(ind2),\n                             'value1': np.random.randn(N),\n                             'value2': np.random.randn(N),\n                             'value3': np.random.randn(N)})\n        self.df2 = DataFrame({'col1': list('abcde'), 'col2': list('fghij'),\n                              'col3': [1, 2, 3, 4, 5]})\n        self.df2.col1 = self.df2.col1.astype('category')\n        self.df2.col2 = self.df2.col2.astype('category')", "number": 0, "name": "reshape.PivotTable.time_pivot_table_categorical", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Crosstab.time_crosstab_normalize": {"min_run_count": 2, "version": "6e949f5407716901971c931d6630520223ae1abdb4b91892a3d59dc39466f5de", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "number": 0, "name": "reshape.Crosstab.time_crosstab_normalize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.AddOverflowArray.time_add_overflow_b_mask_nan": {"min_run_count": 2, "version": "a8bb386cb2d8dde5d4bdf7164b8cefc8ae18e66aa2c5eda099c43d6f96c89cde", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AddOverflowArray:\n    def time_add_overflow_b_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed,\n                             b_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "number": 0, "name": "binary_ops.AddOverflowArray.time_add_overflow_b_mask_nan", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.Sortlevel.time_sortlevel_zero": {"min_run_count": 2, "version": "20cdb905dae7e8e53bb628e678157bd748a3a9e901f5ae3fca89641a194d7cfa", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [np.repeat(np.random.randint(low, high, (n // k)), k)\n                for k in [11, 7, 5, 3, 1]]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "number": 0, "name": "multiindex_object.Sortlevel.time_sortlevel_zero", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodUnaryMethods.time_to_timestamp": {"min_run_count": 2, "version": "5eb7512a7562372fe37b53fdb7083d2390a27804bbfda5838bc31f668b17a6b0", "processes": 2, "params": [["'M'", "'min'"]], "type": "time", "warmup_time": -1, "param_names": ["freq"], "timeout": 60.0, "code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period('2012-06-01', freq=freq)", "number": 0, "name": "period.PeriodUnaryMethods.time_to_timestamp", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.json.ToJSON.time_delta_int_tstamp": {"min_run_count": 2, "version": "a026ac9eb3ca332c1580a8b29127db128ed7ccfd6246f9dc7fb343923b4a67b8", "processes": 2, "params": [["'split'", "'columns'", "'index'"]], "type": "time", "warmup_time": -1, "param_names": ["orient"], "timeout": 60.0, "code": "class ToJSON:\n    def time_delta_int_tstamp(self, orient):\n        self.df_td_int_ts.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, lines_orient):\n        N = 10**5\n        ncols = 5\n        index = date_range('20000101', periods=N, freq='H')\n        timedeltas = timedelta_range(start=1, periods=N, freq='s')\n        datetimes = date_range(start=1, periods=N, freq='s')\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame({'td_1': timedeltas,\n                                       'td_2': timedeltas,\n                                       'int_1': ints,\n                                       'int_2': ints,\n                                       'ts_1': datetimes,\n                                       'ts_2': datetimes},\n                                      index=index)\n        self.df_int_floats = DataFrame({'int_1': ints,\n                                        'int_2': ints,\n                                        'int_3': ints,\n                                        'float_1': floats,\n                                        'float_2': floats,\n                                        'float_3': floats},\n                                       index=index)\n        self.df_int_float_str = DataFrame({'int_1': ints,\n                                           'int_2': ints,\n                                           'float_1': floats,\n                                           'float_2': floats,\n                                           'str_1': strings,\n                                           'str_2': strings},\n                                          index=index)", "number": 0, "name": "io.json.ToJSON.time_delta_int_tstamp", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromDicts.time_nested_dict": {"min_run_count": 2, "version": "f31f3adcc1ca169b79f438c21765c7c6804b2038fe888ca4760d062624239aa5", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index,\n                          columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient='records')\n        self.data2 = {i: {j: float(j) for j in range(100)}\n                      for i in range(2000)}", "number": 0, "name": "frame_ctor.FromDicts.time_nested_dict", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.DatetimeAccessor.time_dt_accessor_time": {"min_run_count": 2, "version": "e77880f2340abf6e3b721be5efdd815a54f7b108e80a45c511c76ffd572a8549", "processes": 2, "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(\n            date_range(start='1/1/2000', periods=N, freq='T', tz=tz)\n        )", "number": 0, "name": "timeseries.DatetimeAccessor.time_dt_accessor_time", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.DataFramePeriodColumn.time_set_index": {"min_run_count": 2, "version": "b2a0fc97c8aa5243bf699c3fd6c88459c42224c84e01f58f04cbe7fb895c21ed", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df['col2'] = self.rng\n        self.df.set_index('col2', append=True)\n\n    def setup(self):\n        self.rng = period_range(start='1/1/1990', freq='S', periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "number": 0, "name": "period.DataFramePeriodColumn.time_set_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.Arithmetic.time_divide": {"min_run_count": 2, "version": "62acf2bf00dabfbdf78eeef0404bfbcf41caaf1e544245dd370815f75f135b5a", "processes": 2, "params": [["0.1", "0.01"], ["0", "nan"]], "type": "time", "warmup_time": -1, "param_names": ["dense_proportion", "fill_value"], "timeout": 60.0, "code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "number": 0, "name": "sparse.Arithmetic.time_divide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVFloatPrecision.time_read_csv": {"min_run_count": 2, "version": "13d9adeb0705df21c30ef75055da269532bdaeda80f6269f0f916fcb5fae4d56", "processes": 2, "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "type": "time", "warmup_time": -1, "param_names": ["sep", "decimal", "float_precision"], "timeout": 60.0, "code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(self.data(self.StringIO_input), sep=sep, header=None,\n                 names=list('abc'), float_precision=float_precision)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [''.join(random.choice(string.digits) for _ in range(28))\n                  for _ in range(15)]\n        rows = sep.join(['0{}'.format(decimal) + '{}'] * 3) + '\\n'\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampConstruction.time_parse_today": {"min_run_count": 2, "version": "923fd8e80970e1e55c73c1891365911e5d2a4a57b4c907237547f43209ca26ce", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp('today')", "number": 0, "name": "timestamp.TimestampConstruction.time_parse_today", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.ArithmeticBlock.time_intersect": {"min_run_count": 2, "version": "1c0239990fc8134f0e8b98f89ecd4d12d03713a9be9073016bf262e9d639461c", "processes": 2, "params": [["nan", "0"]], "type": "time", "warmup_time": -1, "param_names": ["fill_value"], "timeout": 60.0, "code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)\n        self.arr2 = self.make_block_array(length=N, num_blocks=1000,\n                                          block_size=10, fill_value=fill_value)", "number": 0, "name": "sparse.ArithmeticBlock.time_intersect", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.SumBools.time_groupby_sum_booleans": {"min_run_count": 2, "version": "197a2bf6aca645d8f51604cdbf9bd8813c7f038daf6c763d2fefc640611e6d43", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby('ii').sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({'ii': range(N),\n                             'bb': [True] * N})", "number": 0, "name": "groupby.SumBools.time_groupby_sum_booleans", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "algorithms.Hashing.time_series_timedeltas": {"min_run_count": 2, "version": "5e146fd3016008cbdbbd4b8c8886130ad6b2d64eeafb4550ab43f59a79f6cf70", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df['timedeltas'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {'strings': pd.Series(tm.makeStringIndex(10000).take(\n                np.random.randint(0, 10000, size=N))),\n             'floats': np.random.randn(N),\n             'ints': np.arange(N),\n             'dates': pd.date_range('20110101', freq='s', periods=N),\n             'timedeltas': pd.timedelta_range('1 day', freq='s', periods=N)})\n        df['categories'] = df['strings'].astype('category')\n        df.iloc[10:20] = np.nan\n        return df", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:91", "number": 0, "name": "algorithms.Hashing.time_series_timedeltas", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "eval.Eval.time_add": {"min_run_count": 2, "version": "aa96fd9dc20763e19c09aa4e70aa963675cbf0ce5e2168d0cc9a07716fbdde51", "processes": 2, "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["engine", "threads"], "timeout": 60.0, "code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval('self.df + self.df2 + self.df3 + self.df4', engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "number": 0, "name": "eval.Eval.time_add", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.IndexAppend.time_append_range_list": {"min_run_count": 2, "version": "27559b03a1f8d22f5b568f9f42f26f762810d1ec943e6cff4cdd670eed65714f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "number": 0, "name": "index_object.IndexAppend.time_append_range_list", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {"min_run_count": 2, "version": "03825a029602e1e16ab095e8280a57286cdabbdcce7ad037820f5e1ee6802605", "processes": 2, "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["connection", "dtype"], "timeout": 60.0, "code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql('test1', self.con, if_exists='replace')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {'sqlalchemy': create_engine('sqlite:///:memory:'),\n               'sqlite': sqlite3.connect(':memory:')}\n        self.table_name = 'test_type'\n        self.query_col = 'SELECT {} FROM {}'.format(dtype, self.table_name)\n        self.con = con[connection]\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {"min_run_count": 2, "version": "a8f5ac7a1db1946834361015958b333df13334a355dee46f0ce66e1b6900cceb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(lambda x: {'first': x.values[0],\n                                                        'last': x.values[-1]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))", "number": 0, "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.ToString.time_to_string_floats": {"min_run_count": 2, "version": "35ba9d12bdf34f2d470d8cdd3bec022ad580be8c77b8ff412859229dd04409cd", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))", "number": 0, "name": "frame_methods.ToString.time_to_string_floats", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameStringIndexing.time_ix": {"min_run_count": 2, "version": "76f06fe5ffefa8a6a72333c188c628a8e33a6c011c76adddd85dec8383f01dee", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameStringIndexing:\n    def time_ix(self):\n        self.df.ix[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        self.df = DataFrame(np.random.randn(1000, 30), index=index,\n                            columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "number": 0, "name": "indexing.DataFrameStringIndexing.time_ix", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Apply.time_apply_axis_1": {"min_run_count": 2, "version": "1f1647107fcdd0c0a7cc194e4f42c0204f0c21a910e2031247274facb9a72ff4", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list('ABC'))", "number": 0, "name": "frame_methods.Apply.time_apply_axis_1", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Indexing.time_sort_values": {"min_run_count": 2, "version": "529c92615d61ea96da2ece71ffd7a229c7c1d64d8483c4cbe9c53ac72028187f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "number": 0, "name": "categoricals.Indexing.time_sort_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Nth.time_groupby_nth_all": {"min_run_count": 2, "version": "77a76e83823c92e23bbe0016bd6cacb5ca7a7670a0699900fd410eb8b804d31d", "processes": 2, "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby('key').nth(0, dropna='all')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == 'datetime':\n            values = date_range('1/1/2011', periods=N, freq='s')\n        elif dtype == 'object':\n            values = ['foo'] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({'key': key, 'values': values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "number": 0, "name": "groupby.Nth.time_groupby_nth_all", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_iteritems_cached": {"min_run_count": 2, "version": "ffca822677e7f239144d637e4f7ea0547590e48d6bc4b55897b80d523fed99f2", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_iteritems_cached(self):\n        for name, col in self.df.iteritems():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_iteritems_cached", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_qcut_int": {"min_run_count": 2, "version": "6d81b43b33387eaf663f305713d6aca7a76865cf2d036fdc083b7c21f56e772f", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_qcut_int", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.SetDisjoint.time_datetime_difference_disjoint": {"min_run_count": 2, "version": "c803b3e673aadfec4e8fd39b183d2957c7a6490bbd3480ee95f0f2fc659c6eeb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10**5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))", "number": 0, "name": "index_object.SetDisjoint.time_datetime_difference_disjoint", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Iteration.time_itertuples": {"min_run_count": 2, "version": "86611b2db5f40a2c02ef7cf8c53407ee8979ae13e1069c6ff43c90531a718fc7", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120, "code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(np.random.randn(N, 5 * N),\n                             columns=['C' + str(c) for c in range(N * 5)])\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "number": 0, "name": "frame_methods.Iteration.time_itertuples", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_normalize": {"min_run_count": 2, "version": "b8b893f7173149c06d041b063deee106c442d7d8977c1da4536b7a665f8006e8", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_normalize(self):\n        self.s.str.normalize('NFC')\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_normalize", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "index_object.Indexing.time_boolean_array": {"min_run_count": 2, "version": "894333180fb8605be08f51de3401a473f469f847f96110d8f6f098c55fc47177", "processes": 2, "params": [["'String'", "'Float'", "'Int'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, 'make{}Index'.format(dtype))(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (self.sorted[:half].append(self.sorted[:half])\n                                  .sort_values())\n        self.key = self.sorted[N // 4]", "number": 0, "name": "index_object.Indexing.time_boolean_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Groups.time_series_groups": {"min_run_count": 2, "version": "58e4051d38b6f289951a72643762c510bed812fb15af2933877458c4ae1512cd", "processes": 2, "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "type": "time", "warmup_time": -1, "param_names": ["key"], "timeout": 60.0, "code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {'int64_small': Series(np.random.randint(0, 100, size=size)),\n                'int64_large': Series(np.random.randint(0, 10000, size=size)),\n                'object_small': Series(\n                    tm.makeStringIndex(100).take(\n                        np.random.randint(0, 100, size=size))),\n                'object_large': Series(\n                    tm.makeStringIndex(10000).take(\n                        np.random.randint(0, 10000, size=size)))}\n        return data", "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:70", "number": 0, "name": "groupby.Groups.time_series_groups", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {"min_run_count": 2, "version": "d1dada77e1f756edf25a86efb38547a7ebb72cbd6708b003b78a7405917bfe51", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append('table_wide_write', self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame({'float1': np.random.randn(N),\n                             'float2': np.random.randn(N)},\n                            index=index)\n        self.df_mixed = DataFrame({'float1': np.random.randn(N),\n                                   'float2': np.random.randn(N),\n                                   'string1': ['foo'] * N,\n                                   'bool1': [True] * N,\n                                   'int1': np.random.randint(0, N, size=N)},\n                                  index=index)\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame({'float1': np.random.randn(N),\n                              'float2': np.random.randn(N)},\n                             index=date_range('1/1/2000', periods=N))\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(np.random.randn(N, 100),\n                                  index=date_range('1/1/2000', periods=N))\n        self.df_dc = DataFrame(np.random.randn(N, 10),\n                               columns=['C%03d' % i for i in range(10)])\n    \n        self.fname = '__test__.h5'\n    \n        self.store = HDFStore(self.fname)\n        self.store.put('fixed', self.df)\n        self.store.put('fixed_mixed', self.df_mixed)\n        self.store.append('table', self.df2)\n        self.store.append('table_mixed', self.df_mixed)\n        self.store.append('table_wide', self.df_wide)\n        self.store.append('table_wide2', self.df_wide2)", "number": 0, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Count.time_count_level_multi": {"min_run_count": 2, "version": "250bbdfa8d02b35b929b32d5b356f37d7a63478c32fb2cea48d935bb34993113", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class Count:\n    def time_count_level_multi(self, axis):\n        self.df.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.ix[50:1000, 20:50] = np.nan\n        self.df.ix[2000:3000] = np.nan\n        self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed['foo'] = 'bar'\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns,\n                                                  self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays([self.df_mixed.index,\n                                                      self.df_mixed.index])\n        self.df_mixed.columns = MultiIndex.from_arrays([self.df_mixed.columns,\n                                                        self.df_mixed.columns])", "number": 0, "name": "frame_methods.Count.time_count_level_multi", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_days_in_month": {"min_run_count": 2, "version": "4a6c42c2c2bc98bf5c16d99dd0e45379d5313993d1d6aaff30a464a1a86742c3", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_days_in_month(self, tz, freq):\n        self.ts.days_in_month\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_days_in_month", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Rank.time_rank_string_cat_ordered": {"min_run_count": 2, "version": "e4d30acbfa64a74e03ed4c3cfceac368bfbbfdaa1dc8b619e5b3407e08b1c80c", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = self.s_str.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_str_cat_ordered = self.s_str.astype('category',\n                                                       ordered=True)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = self.s_int.astype('category')\n        with warnings.catch_warnings(record=True):\n            self.s_int_cat_ordered = self.s_int.astype('category',\n                                                       ordered=True)", "number": 0, "name": "categoricals.Rank.time_rank_string_cat_ordered", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "binary_ops.AddOverflowArray.time_add_overflow_arr_mask_nan": {"min_run_count": 2, "version": "a9d04fe6490f525b6162096c08513af5b22d78747bcbc99a775e95a150100884", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AddOverflowArray:\n    def time_add_overflow_arr_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, arr_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "number": 0, "name": "binary_ops.AddOverflowArray.time_add_overflow_arr_mask_nan", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.GetLoc.time_med_get_loc_warm": {"min_run_count": 2, "version": "fd4b0bef6cf932db7a1e3a686c322bf693965be331a2ac86d81d61ad024aee14", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, 'A'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=['one', 'two', 'three'])\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list('A')],\n            names=['one', 'two', 'three'])\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list('A'), list('A')],\n            names=['one', 'two', 'three'])", "number": 0, "name": "multiindex_object.GetLoc.time_med_get_loc_warm", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NonNumericSeriesIndexing.time_get_value": {"min_run_count": 2, "version": "c9b4e06adc5ca4108771eaca56256f9c56b7c59c7d4b1be566b915c495d489bd", "processes": 2, "params": [["'string'", "'datetime'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NonNumericSeriesIndexing:\n    def time_get_value(self, index, index_structure):\n        with warnings.catch_warnings(record=True):\n            self.s.get_value(self.lbl)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indexes = {'string': tm.makeStringIndex(N),\n                   'datetime': date_range('1900', periods=N, freq='s')}\n        index = indexes[index]\n        if index_structure == 'nonunique_monotonic_inc':\n            index = index.insert(item=index[2], loc=2)[:-1]\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]", "number": 0, "name": "indexing.NonNumericSeriesIndexing.time_get_value", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "eval.Eval.time_mult": {"min_run_count": 2, "version": "e0ee7ed56aaa8785613e3f6d8f863c24835e928023f845ee5669fa52883e0ea2", "processes": 2, "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "type": "time", "warmup_time": -1, "param_names": ["engine", "threads"], "timeout": 60.0, "code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval('self.df * self.df2 * self.df3 * self.df4', engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "number": 0, "name": "eval.Eval.time_mult", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.SumMultiLevel.time_groupby_sum_multiindex": {"min_run_count": 2, "version": "2e04f60dfdfc037bd85a6ce279e9091eb1e4c718674c31038759d678f12a5887", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 120.0, "code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame({'A': list(range(N)) * 2,\n                             'B': range(N * 2),\n                             'C': 1}).set_index(['A', 'B'])", "number": 0, "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.DataFrameNumericIndexing.time_iloc": {"min_run_count": 2, "version": "19c77440ecbc85666fb74478b31bd63f2e4087850ad61df0a33ea2d3bba11395", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class DataFrameNumericIndexing:\n    def time_iloc(self):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "number": 0, "name": "indexing.DataFrameNumericIndexing.time_iloc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "sparse.Arithmetic.time_intersect": {"min_run_count": 2, "version": "0eb0a2d52dc54a715bbc5783e6cfb7ccc9612c7c48947b7a6545b38f93339d66", "processes": 2, "params": [["0.1", "0.01"], ["0", "nan"]], "type": "time", "warmup_time": -1, "param_names": ["dense_proportion", "fill_value"], "timeout": 60.0, "code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "number": 0, "name": "sparse.Arithmetic.time_intersect", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {"min_run_count": 2, "version": "4dd475ac0a96111b205b967b6c716e28db7b5fce5308ce0799d63a7f0a6a214b", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["do_cache"], "timeout": 60.0, "code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache):\n        # kwds setting here is used to avoid breaking tests in\n        # previous version of pandas, because this is api changes\n        kwds = {}\n        if 'cache_dates' in _parser_defaults:\n            kwds['cache_dates'] = do_cache\n        read_csv(self.data(self.StringIO_input), header=None,\n                 parse_dates=[0], **kwds)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache):\n        data = ('\\n'.join('10/{}'.format(year)\n                for year in range(2000, 2100)) + '\\n') * 10\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_freqstr": {"min_run_count": 2, "version": "7290af331db9fd0eb57d1f43a923d28c8107ea39f0962e3f9dd0b2eefd026a63", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_freqstr(self, tz, freq):\n        self.ts.freqstr\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_freqstr", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "categoricals.Constructor.time_from_codes_all_int8": {"min_run_count": 2, "version": "7c7df96a0237ecd319ce68e009c4d9d60b9e3304b7f287b1526de5210c6f04b6", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list('abcde')\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(pd.date_range('1995-01-01 00:00:00',\n                                                 periods=N / 10,\n                                                 freq='s'))\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, 'int8')\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "number": 0, "name": "categoricals.Constructor.time_from_codes_all_int8", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_ctor.FromSeries.time_mi_series": {"min_run_count": 2, "version": "31cd15987aceabc0ef946bd94b0df86240ada3c11a2d7a04358bc512d7920595", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)", "number": 0, "name": "frame_ctor.FromSeries.time_mi_series", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {"min_run_count": 2, "version": "c3848bca338831c462005678c0f8a4508553e97f845e00632edda8776cc15407", "processes": 2, "params": [["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "type": "time", "warmup_time": -1, "param_names": ["dtype"], "timeout": 60.0, "code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = 'test'\n        self.con = create_engine('sqlite:///:memory:')\n        self.df = DataFrame({'float': np.random.randn(N),\n                             'float_with_nan': np.random.randn(N),\n                             'string': ['foo'] * N,\n                             'bool': [True] * N,\n                             'int': np.random.randint(0, N, size=N),\n                             'datetime': date_range('2000-01-01',\n                                                    periods=N,\n                                                    freq='s')},\n                            index=tm.makeStringIndex(N))\n        self.df.loc[1000:3000, 'float_with_nan'] = np.nan\n        self.df['datetime_string'] = self.df['datetime'].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists='replace')", "number": 0, "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "rolling.ExpandingMethods.time_expanding": {"min_run_count": 2, "version": "d1d5f6979147d3d2df3bfb418cef7cfc9e0cb6bfe5f2ff76e94ffc1f1323870c", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "type": "time", "warmup_time": -1, "param_names": ["contructor", "window", "dtype"], "timeout": 60.0, "code": "class ExpandingMethods:\n    def time_expanding(self, constructor, dtype, method):\n        getattr(self.expanding, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ExpandingMethods:\n    def setup(self, constructor, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.expanding = getattr(pd, constructor)(arr).expanding()", "number": 0, "name": "rolling.ExpandingMethods.time_expanding", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_get_loc": {"min_run_count": 2, "version": "385a2281cf557837cf49e78bab438d74990a91d194ebad5165c975449489f682", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "strings.Methods.time_len": {"min_run_count": 2, "version": "cb628df45dfedf98d84770fdd6612006d03759a5ebd6c91c3566bb7dd6d92f74", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Methods:\n    def time_len(self):\n        self.s.str.len()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10**5))", "number": 0, "name": "strings.Methods.time_len", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NumericSeriesIndexing.time_iloc_array": {"min_run_count": 2, "version": "c6952100cd0bc9a96b05b9d92afc90d505f086381d22272f897c7bc94ab53cbc", "processes": 2, "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indices = {\n            'unique_monotonic_inc': index(range(N)),\n            'nonunique_monotonic_inc': index(\n                list(range(55)) + [54] + list(range(55, N - 1))),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "number": 0, "name": "indexing.NumericSeriesIndexing.time_iloc_array", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "join_merge.MergeAsof.time_on_int32": {"min_run_count": 2, "version": "1c8c6829d38fc0c9950a4314d04b3f4e88bfb66518ab0a6f4827fe20c3f3757a", "processes": 2, "params": [["'backward'", "'forward'", "'nearest'"]], "type": "time", "warmup_time": -1, "param_names": ["direction"], "timeout": 60.0, "code": "class MergeAsof:\n    def time_on_int32(self, direction):\n        merge_asof(self.df1d, self.df2d, on='time32', direction=direction)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {'time': np.random.randint(0, one_count / 20, one_count),\n             'key': np.random.choice(list(string.ascii_uppercase), one_count),\n             'key2': np.random.randint(0, 25, one_count),\n             'value1': np.random.randn(one_count)})\n        df2 = DataFrame(\n            {'time': np.random.randint(0, two_count / 20, two_count),\n             'key': np.random.choice(list(string.ascii_uppercase), two_count),\n             'key2': np.random.randint(0, 25, two_count),\n             'value2': np.random.randn(two_count)})\n    \n        df1 = df1.sort_values('time')\n        df2 = df2.sort_values('time')\n    \n        df1['time32'] = np.int32(df1.time)\n        df2['time32'] = np.int32(df2.time)\n    \n        self.df1a = df1[['time', 'value1']]\n        self.df2a = df2[['time', 'value2']]\n        self.df1b = df1[['time', 'key', 'value1']]\n        self.df2b = df2[['time', 'key', 'value2']]\n        self.df1c = df1[['time', 'key2', 'value1']]\n        self.df2c = df2[['time', 'key2', 'value2']]\n        self.df1d = df1[['time32', 'value1']]\n        self.df2d = df2[['time32', 'value2']]\n        self.df1e = df1[['time', 'key', 'key2', 'value1']]\n        self.df2e = df2[['time', 'key', 'key2', 'value2']]", "number": 0, "name": "join_merge.MergeAsof.time_on_int32", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "groupby.Transform.time_transform_ufunc_max": {"min_run_count": 2, "version": "74f119c5d42cf7a8c5f87ace569da1ad5790234d87b0aa22c43820c2f610c88a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Transform:\n    def time_transform_ufunc_max(self):\n        self.df.groupby(level='lev1').transform(np.max)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(levels=[np.arange(n1), tm.makeStringIndex(n2)],\n                           codes=[np.repeat(range(n1), n2).tolist(),\n                                  list(range(n2)) * n1],\n                           names=['lev1', 'lev2'])\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=['col1', 'col20', 'col3'])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(np.random.randint(1, n, (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df2 = self.df1.copy()\n        self.df2['jim'] = self.df2['joe']\n    \n        self.df3 = DataFrame(np.random.randint(1, (n / 10), (n, 3)),\n                             columns=['jim', 'joe', 'jolie'])\n        self.df4 = self.df3.copy()\n        self.df4['jim'] = self.df4['joe']", "number": 0, "name": "groupby.Transform.time_transform_ufunc_max", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Crosstab.time_crosstab_normalize_margins": {"min_run_count": 2, "version": "ba47015ba4cecb12e2b9d3f44bac88ebddb8eda83bfd1a89380805e55ec4b719", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "number": 0, "name": "reshape.Crosstab.time_crosstab_normalize_margins", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.MaskBool.time_frame_mask_floats": {"min_run_count": 2, "version": "8ab2826673211a03105b29836d30048ce03a984a5717e2b7be1add61ab6fe617", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "number": 0, "name": "frame_methods.MaskBool.time_frame_mask_floats", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing_engines.NumericEngineIndexing.time_get_loc": {"min_run_count": 2, "version": "616f704e7a6d722f1ff6b1a5ef4ecc75886ac26f6322727d911e7e7887d6878e", "processes": 2, "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "type": "time", "warmup_time": -1, "param_names": ["engine_and_dtype", "index_type"], "timeout": 60.0, "code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type):\n        self.data.get_loc(2)\n\n    def setup(self, engine_and_dtype, index_type):\n        engine, dtype = engine_and_dtype\n        N = 10**5\n        values = list([1] * N + [2] * N + [3] * N)\n        arr = {\n            'monotonic_incr': np.array(values, dtype=dtype),\n            'monotonic_decr': np.array(list(reversed(values)),\n                                       dtype=dtype),\n            'non_monotonic': np.array([1, 2, 3] * N, dtype=dtype),\n        }[index_type]\n    \n        self.data = engine(lambda: arr, len(arr))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)", "number": 0, "name": "indexing_engines.NumericEngineIndexing.time_get_loc", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {"min_run_count": 2, "version": "bf14755681421148a1b50da917f36ba6707e1c38dab9f7044bf7fdc337d7a23c", "processes": 2, "params": [["'mY'", "'mdY'", "'hm'"]], "type": "time", "warmup_time": -1, "param_names": ["value"], "timeout": 60.0, "code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value):\n        read_csv(self.data(self.StringIO_input), sep=',', header=None,\n                 names=['Date'], parse_dates=['Date'])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)", "number": 0, "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_dayofweek": {"min_run_count": 2, "version": "925fee7502aea81bcd356960db01f74d17592a5226861cbed26819304624236e", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_dayofweek(self, tz, freq):\n        self.ts.dayofweek\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_dayofweek", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampProperties.time_month_name": {"min_run_count": 2, "version": "dc1479304652ed6a7af6278fc111870afd9eae1053fbb2cf71b94654f6c8e327", "processes": 2, "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "type": "time", "warmup_time": -1, "param_names": ["tz", "freq"], "timeout": 60.0, "code": "class TimestampProperties:\n    def time_month_name(self, tz, freq):\n        self.ts.month_name()\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp('2017-08-25 08:16:14', tzinfo=tz, freq=freq)", "number": 0, "name": "timestamp.TimestampProperties.time_month_name", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Isnull.time_isnull_strngs": {"min_run_count": 2, "version": "fdf3479469a2f1bb557385d6776abae001a2b0c0f94db8efd8d21f741cde8249", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array([NaT, np.nan, None, np.datetime64('NaT'),\n                           np.timedelta64('NaT'), 0, 1, 2.0, '', 'abcd'])\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "number": 0, "name": "frame_methods.Isnull.time_isnull_strngs", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.ResetIndex.time_reest_datetimeindex": {"min_run_count": 2, "version": "d948ba554dc72cdbe5f7aefa5bc576f44f49490696348741a5108119135dd42a", "processes": 2, "params": [["None", "'US/Eastern'"]], "type": "time", "warmup_time": -1, "param_names": ["t"], "timeout": 60.0, "code": "class ResetIndex:\n    def time_reest_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start='1/1/2000', periods=1000, freq='H', tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)", "number": 0, "name": "timeseries.ResetIndex.time_reest_datetimeindex", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "io.stata.StataMissing.time_write_stata": {"min_run_count": 2, "version": "7937dd4468e1b76e036dac0bf763fb971b88dec3f2ccf4b34e42bcd64c7a648f", "processes": 2, "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "type": "time", "warmup_time": -1, "param_names": ["convert_dates"], "timeout": 60.0, "code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df['missing_{0}'.format(i)] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)", "number": 0, "name": "io.stata.StataMissing.time_write_stata", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "stat_ops.Rank.time_average_old": {"min_run_count": 2, "version": "7f3fcf5067799694afbf461d0cfd299d144da5ba70ae6e28800c292c88bd8be0", "processes": 2, "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["constructor", "pct"], "timeout": 60.0, "code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "number": 0, "name": "stat_ops.Rank.time_average_old", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Cut.time_cut_datetime": {"min_run_count": 2, "version": "349f621e34ba51118d530b74f6bc91b1c16b15b3ed33f1909d4f325ced3770d9", "processes": 2, "params": [["4", "10", "1000"]], "type": "time", "warmup_time": -1, "param_names": ["bins"], "timeout": 60.0, "code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(np.random.randint(N, size=N),\n                                          dtype='timedelta64[ns]')\n        self.datetime_series = pd.Series(np.random.randint(N, size=N),\n                                         dtype='datetime64[ns]')", "number": 0, "name": "reshape.Cut.time_cut_datetime", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {"min_run_count": 2, "version": "30a9cd33082a4ba2ae7d79048c64c4d6111d4ba4e666f3a275216ae6adfb4ddb", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df['date'] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range('1/1/2000', periods=N, freq='H')\n        self.df = DataFrame(np.random.randn(N, 1), columns=['A'], index=idx)", "number": 0, "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodIndexConstructor.time_from_ints_daily": {"min_run_count": 2, "version": "8585c8bfce48cb48d220f8dab1e8e81b1afe0f6a6a326cef89d9c27e68c0c06f", "processes": 2, "params": [["'D'"], ["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["freq", "is_offset"], "timeout": 60.0, "code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range('1985', periods=1000)\n        self.rng2 = date_range('1985', periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = date_range('1/1/2000', periods=1000,\n                                     freq=freq).strftime('%Y%m%d').map(int)\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "number": 0, "name": "period.PeriodIndexConstructor.time_from_ints_daily", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timeseries.SortIndex.time_get_slice": {"min_run_count": 2, "version": "6314737a369472fa41d9676bf9a73ba5f1d5a9ce54eacf9a1bbb03de1779ce55", "processes": 2, "params": [["True", "False"]], "type": "time", "warmup_time": -1, "param_names": ["monotonic"], "timeout": 60.0, "code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start='1/1/2000', periods=N, freq='s')\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "number": 0, "name": "timeseries.SortIndex.time_get_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "offset.OffsetDatetimeIndexArithmetic.time_add_offset": {"min_run_count": 2, "version": "1daca016e9dd503c96088620a97efbbee1f9706f0881b5751e4250f96888d75b", "processes": 2, "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "type": "time", "warmup_time": -1, "param_names": ["offset"], "timeout": 60.0, "code": "class OffsetDatetimeIndexArithmetic:\n    def time_add_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.data + offset\n\n    def setup(self, offset):\n        N = 1000\n        self.data = pd.date_range(start='1/1/2000', periods=N, freq='T')", "number": 0, "name": "offset.OffsetDatetimeIndexArithmetic.time_add_offset", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.Indexing.time_align": {"min_run_count": 2, "version": "70c32a64ad80f195aa3d8d9f9c50f83f815eecf9140302b86f57e58d5335e97f", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Indexing:\n    def time_align(self):\n        DataFrame({'a': self.series, 'b': self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start='1985', periods=1000, freq='D')\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "number": 0, "name": "period.Indexing.time_align", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {"min_run_count": 2, "version": "c5ca1a1701e15d99d1e222acd582a974c7264c653857b9a784369522456b3484", "processes": 2, "params": [["'string'", "'datetime'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "type": "time", "warmup_time": -1, "param_names": ["index_dtype", "index_structure"], "timeout": 60.0, "code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[:self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        indexes = {'string': tm.makeStringIndex(N),\n                   'datetime': date_range('1900', periods=N, freq='s')}\n        index = indexes[index]\n        if index_structure == 'nonunique_monotonic_inc':\n            index = index.insert(item=index[2], loc=2)[:-1]\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]", "number": 0, "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "multiindex_object.GetLoc.time_small_get_loc_warm": {"min_run_count": 2, "version": "5da677be3bfbb13de077ee7f51b13ce3f48a6044ad536fef746afbe2dfe38f80", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, 'A', 'A'))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=['one', 'two', 'three'])\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list('A')],\n            names=['one', 'two', 'three'])\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list('A'), list('A')],\n            names=['one', 'two', 'three'])", "number": 0, "name": "multiindex_object.GetLoc.time_small_get_loc_warm", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "period.PeriodUnaryMethods.time_asfreq": {"min_run_count": 2, "version": "323a380c11b49b4181f8c75d6c01d93f4d3522728b2636ad83d8fd48e0229d24", "processes": 2, "params": [["'M'", "'min'"]], "type": "time", "warmup_time": -1, "param_names": ["freq"], "timeout": 60.0, "code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq('A')\n\n    def setup(self, freq):\n        self.per = Period('2012-06-01', freq=freq)", "number": 0, "name": "period.PeriodUnaryMethods.time_asfreq", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "timestamp.TimestampOps.time_to_julian_date": {"min_run_count": 2, "version": "b7c0fdcb2cd42560f7dfef466d259dd49b20847a2fe87cd5faaed4510b8659a2", "processes": 2, "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "type": "time", "warmup_time": -1, "param_names": ["tz"], "timeout": 60.0, "code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp('2017-08-25 08:16:14', tz=tz)", "number": 0, "name": "timestamp.TimestampOps.time_to_julian_date", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.XS.time_frame_xs": {"min_run_count": 2, "version": "84890573485c33234a2850a3e31fed6e497b5bc95e53ed13e087bd5dd59f462f", "processes": 2, "params": [["0", "1"]], "type": "time", "warmup_time": -1, "param_names": ["axis"], "timeout": 60.0, "code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10**4\n        self.df = DataFrame(np.random.randn(self.N, self.N))", "number": 0, "name": "frame_methods.XS.time_frame_xs", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "frame_methods.Equals.time_frame_float_unequal": {"min_run_count": 2, "version": "427c8c79cfa2add003777bc94bbf91752f0086708c8f10ac9df56caf7fdfeee1", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame('foo', index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = ['A'] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "number": 0, "name": "frame_methods.Equals.time_frame_float_unequal", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "indexing.MultiIndexing.time_series_ix": {"min_run_count": 2, "version": "da7961b0e259b4f39a246eaee1ff718cb3cbfd66780955335cb6ddb53f37a87a", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class MultiIndexing:\n    def time_series_ix(self):\n        self.s.ix[999]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        self.mdt = DataFrame({'A': np.random.choice(range(10000, 45000, 1000),\n                                                    n),\n                              'B': np.random.choice(range(10, 400), n),\n                              'C': np.random.choice(range(1, 150), n),\n                              'D': np.random.choice(range(10000, 45000), n),\n                              'x': np.random.choice(range(400), n),\n                              'y': np.random.choice(range(25), n)})\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index(['A', 'B', 'C', 'D']).sort_index()", "number": 0, "name": "indexing.MultiIndexing.time_series_ix", "sample_time": 0.01, "unit": "seconds", "repeat": 0}, "reshape.Crosstab.time_crosstab_values": {"min_run_count": 2, "version": "974a224c940083c1217f073d3d8de1a892e2b302d5499088c9490d3b419bfd7d", "processes": 2, "params": [], "type": "time", "warmup_time": -1, "param_names": [], "timeout": 60.0, "code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc='sum')\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array(['A', 'B', 'C'], dtype='O')\n        fac2 = np.array(['one', 'two'], dtype='O')\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "number": 0, "name": "reshape.Crosstab.time_crosstab_values", "sample_time": 0.01, "unit": "seconds", "repeat": 0}}, "revision_to_date": {"16384": 1511648019000, "8203": 1388896303000, "16399": 1511744366000, "16400": 1511782007000, "16401": 1511782093000, "16402": 1511782496000, "16403": 1511782581000, "16405": 1511818862000, "16406": 1511861737000, "16407": 1511867783000, "16408": 1511868267000, "16409": 1511868580000, "16410": 1511914960000, "16411": 1511952647000, "16412": 1511956925000, "16413": 1511960292000, "16414": 1511961840000, "16415": 1512029638000, "16416": 1512050159000, "16417": 1512051981000, "16418": 1512054702000, "16419": 1512090315000, "16420": 1512090418000, "16421": 1512127829000, "16422": 1512146719000, "16423": 1512154741000, "16424": 1512154961000, "16425": 1512155722000, "16426": 1512236076000, "16427": 1512236581000, "2738": 1336151422000, "16437": 1512386849000, "16438": 1512387344000, "16439": 1512387446000, "16440": 1512387519000, "16441": 1512392154000, "16442": 1512418411000, "16443": 1512433434000, "16444": 1512465536000, "16445": 1512472521000, "1342": 1322277354000, "16455": 1512559116000, "16456": 1512559606000, "16457": 1512559655000, "16458": 1512559753000, "16459": 1512560266000, "16463": 1512608774000, "16464": 1512609554000, "16465": 1512609648000, "16466": 1512644617000, "16467": 1512644925000, "12373": 1438722943000, "16475": 1512730262000, "16476": 1512731503000, "16477": 1512731578000, "16478": 1512732366000, "16479": 1512736857000, "16480": 1512779224000, "16481": 1512831386000, "16482": 1512832354000, "16483": 1512833866000, "16484": 1512834616000, "16485": 1512914797000, "104": 1262713712000, "4203": 1352225986000, "16498": 1512982454000, "16499": 1512989820000, "16500": 1512990379000, "16501": 1512990518000, "16502": 1512991424000, "17770": 1528919960000, "19819": 1552425131000, "8327": 1389878709000, "14360": 1476559541000, "4249": 1352505519000, "19373": 1546700133000, "15964": 1505775013000, "4289": 1352940069000, "19148": 1544925552000, "16590": 1513041658000, "19149": 1544926106000, "208": 1285906928000, "18829": 1542498440000, "16601": 1513047512000, "16604": 1513047803000, "16606": 1513050947000, "16607": 1513071306000, "16608": 1513076118000, "16609": 1513116198000, "16610": 1513129661000, "16611": 1513130264000, "16612": 1513130564000, "16615": 1513175815000, "16616": 1513176133000, "16617": 1513251034000, "16618": 1513251409000, "16619": 1513254882000, "16620": 1513299786000, "16621": 1513302336000, "16622": 1513337523000, "16623": 1513359904000, "16624": 1513382086000, "16625": 1513382214000, "16626": 1513420966000, "16627": 1513421018000, "16628": 1513599164000, "16629": 1513599245000, "16630": 1513599368000, "16631": 1513600449000, "16632": 1513602000000, "10964": 1415541672000, "3418": 1340991466000, "8234": 1389186315000, "16638": 1513681943000, "16639": 1513682467000, "16640": 1513682810000, "16641": 1513683238000, "16642": 1513687679000, "16643": 1513692503000, "16644": 1513694464000, "16645": 1513697627000, "16646": 1513731420000, "16647": 1513773407000, "16648": 1513779803000, "16649": 1513793396000, "16650": 1513810560000, "16651": 1513822102000, "16652": 1513863811000, "4374": 1353646198000, "16666": 1513870257000, "16667": 1513877096000, "16668": 1513890999000, "16669": 1513952057000, "16670": 1513952920000, "288": 1298163988000, "16676": 1514059483000, "16677": 1514061285000, "16678": 1514061388000, "16679": 1514061795000, "16680": 1514062222000, "16681": 1514274924000, "16682": 1514275775000, "16683": 1514275917000, "16688": 1514326406000, "16689": 1514326494000, "16690": 1514362631000, "16691": 1514366580000, "16692": 1514367162000, "16698": 1514406422000, "16699": 1514410442000, "16700": 1514461068000, "16701": 1514464123000, "16702": 1514464288000, "17569": 1525812240000, "16705": 1514481722000, "16706": 1514507152000, "16707": 1514508814000, "16708": 1514550565000, "16709": 1514552748000, "16717": 1514570467000, "16718": 1514584136000, "16725": 1514637096000, "16726": 1514637428000, "16727": 1514640824000, "17842": 1530052049000, "16735": 1514663812000, "16736": 1514671924000, "16737": 1514673682000, "16738": 1514674081000, "16739": 1514676058000, "16740": 1514677762000, "16741": 1514731433000, "16742": 1514731764000, "16743": 1514732053000, "16744": 1514741170000, "16745": 1514816137000, "16746": 1514892058000, "16747": 1514892229000, "16751": 1514978194000, "16752": 1514978250000, "16753": 1514978420000, "16754": 1514979693000, "16755": 1514982321000, "16756": 1515023690000, "16757": 1515023791000, "16758": 1515025668000, "16759": 1515045170000, "16760": 1515075306000, "16763": 1515111860000, "16764": 1515112324000, "16765": 1515112519000, "16766": 1515113130000, "16767": 1515113599000, "16772": 1515179782000, "16773": 1515184879000, "16774": 1515190719000, "16775": 1515195259000, "16776": 1515195445000, "15085": 1489770715000, "16784": 1515260262000, "16785": 1515286089000, "16786": 1515286130000, "16787": 1515292667000, "16788": 1515292828000, "16791": 1515341390000, "16792": 1515363146000, "16793": 1515363418000, "16794": 1515363572000, "16795": 1515363753000, "16797": 1515439812000, "4510": 1354157877000, "16799": 1515502422000, "16800": 1515502442000, "16801": 1515502467000, "15771": 1500634859000, "16807": 1515589103000, "8616": 1391083269000, "16809": 1515589225000, "16810": 1515589249000, "16811": 1515589331000, "16812": 1515619682000, "16813": 1515668952000, "16814": 1515670333000, "16815": 1515676913000, "12722": 1441988415000, "16821": 1515757232000, "16822": 1515757338000, "16823": 1515757520000, "16824": 1515757593000, "16825": 1515757740000, "16826": 1515854855000, "12731": 1442049754000, "16828": 1515939022000, "16829": 1515965245000, "16830": 1516025484000, "16831": 1516025861000, "15776": 1500699521000, "16835": 1516061676000, "16836": 1516061928000, "16837": 1516063396000, "16838": 1516063643000, "16839": 1516101460000, "16840": 1516147168000, "16841": 1516148041000, "16842": 1516148130000, "16843": 1516189604000, "15778": 1500749977000, "16846": 1516235566000, "16847": 1516236123000, "16848": 1516236557000, "16849": 1516236787000, "16850": 1516273788000, "19875": 1553167425000, "16852": 1516352262000, "16853": 1516359708000, "16854": 1516359872000, "16855": 1516361555000, "16856": 1516398632000, "473": 1308971823000, "19877": 1553253754000, "16865": 1516557456000, "16866": 1516563014000, "16867": 1516573686000, "16868": 1516619514000, "16869": 1516619686000, "16870": 1516665595000, "16871": 1516666249000, "16872": 1516705256000, "16873": 1516706410000, "16874": 1516707411000, "15783": 1500857218000, "16879": 1516788403000, "16880": 1516792205000, "16881": 1516842473000, "16882": 1516842611000, "16883": 1516843741000, "16884": 1516881284000, "16885": 1516881544000, "16886": 1516881716000, "16887": 1516961517000, "16888": 1516965517000, "16889": 1516965825000, "16890": 1516967647000, "16891": 1517015202000, "16892": 1517015350000, "16893": 1517015415000, "16894": 1517015544000, "16895": 1517016020000, "16896": 1517070805000, "16897": 1517072123000, "16898": 1517072193000, "16899": 1517140384000, "16900": 1517229779000, "16903": 1517261949000, "16904": 1517270372000, "19884": 1553372009000, "16906": 1517312196000, "16907": 1517312236000, "16909": 1517395733000, "16910": 1517397425000, "16911": 1517398221000, "16912": 1517398452000, "16913": 1517400914000, "19886": 1553452450000, "15839": 1502397817000, "16921": 1517489696000, "16922": 1517490557000, "16923": 1517490942000, "16924": 1517491595000, "16925": 1517492239000, "4638": 1354900852000, "19888": 1553464138000, "15793": 1501048475000, "15794": 1501064963000, "15796": 1501112629000, "19893": 1553556272000, "12867": 1443887330000, "16970": 1518053522000, "19895": 1553559902000, "16972": 1518088839000, "589": 1311458440000, "16974": 1518089524000, "16975": 1518179132000, "16976": 1518179342000, "16977": 1518192677000, "16978": 1518209621000, "19897": 1553575113000, "16986": 1518282520000, "16987": 1518288495000, "16988": 1518297157000, "16989": 1518307490000, "16990": 1518310162000, "12896": 1444306718000, "15803": 1501455242000, "16997": 1518387874000, "16998": 1518435213000, "16999": 1518437171000, "17000": 1518480775000, "15804": 1501611556000, "17002": 1518533454000, "17003": 1518548502000, "17004": 1518558074000, "17006": 1518606346000, "8815": 1392348296000, "17008": 1518606799000, "17009": 1518607611000, "17010": 1518607880000, "4723": 1355269526000, "17012": 1518649934000, "17013": 1518682651000, "17014": 1518683769000, "17015": 1518685232000, "17016": 1518697871000, "17017": 1518805312000, "19903": 1553637077000, "19904": 1553687453000, "17857": 1530233148000, "19906": 1553719483000, "17859": 1530237660000, "19908": 1553777294000, "19909": 1553792097000, "4770": 1355447463000, "15814": 1501722187000, "15815": 1501722307000, "19229": 1545953714000, "15816": 1501762038000, "694": 1313620812000, "15817": 1501778246000, "15818": 1501794365000, "15136": 1490535679000, "15819": 1501832693000, "4816": 1355762888000, "15823": 1502103958000, "15824": 1502110613000, "15825": 1502111436000, "19922": 1553973677000, "19938": 1554382301000, "15827": 1502144313000, "19924": 1553997795000, "15829": 1502235008000, "19926": 1554055234000, "14074": 1469053087000, "15833": 1502277876000, "15834": 1502309967000, "798": 1315255505000, "19931": 1554217392000, "19932": 1554218769000, "15837": 1502361459000, "15772": 1500634898000, "19934": 1554323134000, "13114": 1447846614000, "19935": 1554323298000, "9020": 1393855836000, "19936": 1554323500000, "15841": 1502410737000, "19941": 1554392522000, "4941": 1357446804000, "15843": 1502447013000, "13531": 1455378460000, "15844": 1502447773000, "862": 1315859521000, "3557": 1343003671000, "874": 1316017084000, "13165": 1448038103000, "15853": 1502829759000, "915": 1316984686000, "15854": 1502837094000, "17625": 1526944276000, "15855": 1502916749000, "5022": 1358831994000, "15856": 1502964652000, "933": 1317048249000, "17905": 1530709180000, "19954": 1554461444000, "15859": 1503017554000, "15860": 1503070040000, "10399": 1408461173000, "15861": 1503142025000, "16808": 1515589117000, "15862": 1503161465000, "19959": 1554672538000, "19960": 1554679160000, "981": 1317617173000, "15865": 1503264343000, "5082": 1360531241000, "19962": 1554808817000, "15867": 1503302199000, "15868": 1503303290000, "13291": 1450897740000, "19965": 1554877220000, "19966": 1554901182000, "1029": 1318197429000, "1033": 1318267521000, "17421": 1522290697000, "9230": 1396563043000, "17423": 1522334348000, "17424": 1522340616000, "17425": 1522354203000, "17001": 1518481163000, "17430": 1522446996000, "17431": 1522510046000, "17432": 1522512081000, "17433": 1522512179000, "17434": 1522512252000, "17435": 1522514252000, "17436": 1522590020000, "17437": 1522590145000, "17438": 1522597795000, "17439": 1522604824000, "17440": 1522676129000, "17441": 1522708712000, "17444": 1522738843000, "17445": 1522738950000, "17446": 1522760415000, "17447": 1522783330000, "17448": 1522783418000, "17449": 1522869619000, "17450": 1523260898000, "17451": 1523268143000, "17452": 1523298838000, "17453": 1523339652000, "17454": 1523413592000, "17455": 1523413794000, "17456": 1523441147000, "17457": 1523562549000, "17458": 1523620049000, "17459": 1523639629000, "17462": 1523712924000, "17463": 1523713303000, "17464": 1523716320000, "17465": 1523749652000, "17466": 1523750310000, "17467": 1523817524000, "17468": 1523818233000, "19978": 1555106403000, "17470": 1523819014000, "17471": 1523823920000, "17472": 1523874606000, "17473": 1523874794000, "17474": 1523874875000, "17475": 1523874979000, "17476": 1523890443000, "17477": 1523951612000, "17478": 1523961102000, "17479": 1523961253000, "17480": 1524041522000, "17481": 1524132454000, "17482": 1524132768000, "17483": 1524132932000, "17484": 1524141800000, "17485": 1524184513000, "19981": 1555301135000, "17492": 1524334454000, "17493": 1524335034000, "17494": 1524349587000, "17495": 1524406937000, "17496": 1524408825000, "17497": 1524487782000, "17498": 1524491956000, "17499": 1524492383000, "17500": 1524510313000, "17501": 1524533728000, "20223": 1559403297000, "15313": 1492832004000, "17511": 1524566322000, "17512": 1524569374000, "17513": 1524573826000, "17514": 1524597208000, "17515": 1524619680000, "17516": 1524659897000, "17517": 1524687700000, "17518": 1524690441000, "17519": 1524704825000, "17520": 1524745094000, "17521": 1524756885000, "17522": 1524826564000, "1139": 1319248032000, "17524": 1524853758000, "17525": 1525035984000, "16132": 1508397382000, "17528": 1525089335000, "19988": 1555348159000, "17530": 1525110791000, "14527": 1479365051000, "17532": 1525134788000, "15893": 1504088384000, "17540": 1525201047000, "17541": 1525205171000, "17542": 1525256797000, "17543": 1525259615000, "13448": 1453840368000, "19308": 1546396102000, "17546": 1525272424000, "17547": 1525306788000, "17548": 1525307028000, "17549": 1525307608000, "17550": 1525342949000, "17551": 1525343831000, "17552": 1525343917000, "17553": 1525344124000, "17554": 1525428578000, "5267": 1363111718000, "17556": 1525524225000, "17557": 1525524253000, "17558": 1525524816000, "17559": 1525525145000, "17563": 1525738736000, "17564": 1525738791000, "15898": 1504175751000, "17566": 1525739428000, "17567": 1525775710000, "17568": 1525779587000, "1185": 1319509932000, "17570": 1525861358000, "17571": 1525861478000, "17572": 1525863602000, "17573": 1525879198000, "17575": 1525947982000, "17576": 1525948329000, "17577": 1525951793000, "17578": 1525976730000, "17579": 1525976868000, "17580": 1525982385000, "17581": 1526021353000, "17582": 1526039188000, "17583": 1526039628000, "17584": 1526063386000, "17585": 1526150294000, "17586": 1516249512000, "19953": 1554431294000, "20030": 1556021435000, "17596": 1526378554000, "17597": 1526392157000, "17598": 1526396861000, "17599": 1526407788000, "11808": 1430388244000, "17603": 1526415166000, "17604": 1526438450000, "17605": 1526439631000, "17606": 1526439720000, "17607": 1526440053000, "17608": 1526468972000, "17609": 1526477540000, "17610": 1526516442000, "17611": 1526516511000, "17612": 1526560934000, "17613": 1526590514000, "17614": 1526622825000, "17615": 1526751970000, "17616": 1526760498000, "17617": 1526760600000, "17618": 1526760903000, "15907": 1504699419000, "17620": 1526899073000, "17621": 1526899279000, "17622": 1526899489000, "17623": 1526900404000, "17624": 1526900763000, "15908": 1504700586000, "14543": 1481312071000, "17628": 1526984391000, "1245": 1320729617000, "17630": 1527049334000, "17631": 1527071742000, "17632": 1527173967000, "17633": 1527199905000, "17634": 1527232194000, "17635": 1527247925000, "17636": 1527282369000, "17637": 1527339793000, "17641": 1527556838000, "17642": 1527557544000, "17643": 1527557674000, "17644": 1527558174000, "17645": 1527558379000, "17646": 1527590487000, "17647": 1527714287000, "17648": 1527722866000, "13553": 1455719363000, "17651": 1527762452000, "17652": 1527782355000, "17653": 1527799492000, "17654": 1527803069000, "17655": 1527812073000, "12181": 1436186502000, "17657": 1528111282000, "17658": 1528147730000, "17659": 1528148596000, "17660": 1528174470000, "17661": 1528189442000, "17662": 1528196910000, "17663": 1528218074000, "17664": 1528270271000, "17665": 1528290923000, "17666": 1528297702000, "17672": 1528404131000, "17673": 1528406416000, "17674": 1528406468000, "17675": 1528406737000, "17676": 1528409157000, "20013": 1555784412000, "17683": 1528476876000, "17684": 1528479551000, "15918": 1504784484000, "17686": 1528500740000, "17687": 1528501203000, "15919": 1504784967000, "14909": 1486921871000, "16138": 1508506229000, "13622": 1457534291000, "17722": 1528716534000, "17723": 1528730087000, "17724": 1528761945000, "17725": 1528762529000, "17726": 1528762596000, "3637": 1344479297000, "13633": 1457732611000, "17730": 1528802917000, "17731": 1528803070000, "17732": 1528803421000, "20022": 1555863659000, "1350": 1322466345000, "15927": 1505028648000, "20231": 1559518467000, "20024": 1555864704000, "8419": 1390345599000, "15929": 1505054617000, "13657": 1458247628000, "17757": 1528821775000, "17760": 1528825328000, "15931": 1505127798000, "17766": 1528887101000, "17767": 1528887295000, "17768": 1528891958000, "17769": 1528896241000, "5482": 1364232404000, "20029": 1555994701000, "17778": 1529067078000, "17779": 1529083144000, "17780": 1529083296000, "17781": 1529083639000, "17782": 1529084014000, "17847": 1530100799000, "17786": 1529361807000, "20031": 1556021547000, "17788": 1529370194000, "17789": 1529396412000, "17790": 1529397047000, "15936": 1505212555000, "17794": 1529488221000, "17795": 1529489665000, "17796": 1529490589000, "17797": 1529490787000, "17798": 1529490909000, "20033": 1556022258000, "17800": 1529549663000, "9611": 1400269456000, "17804": 1529574432000, "17805": 1529575831000, "17806": 1529576333000, "17807": 1529576660000, "17808": 1529586343000, "9617": 1400278770000, "15940": 1505305497000, "17818": 1529708367000, "17819": 1529708499000, "17820": 1529708678000, "17821": 1529708841000, "17822": 1529710604000, "17823": 1529753278000, "1440": 1323817436000, "18672": 1541356966000, "17826": 1529938663000, "17827": 1529965343000, "17828": 1529965470000, "17829": 1529965797000, "17830": 1529965868000, "17840": 1530051581000, "17841": 1530051957000, "1458": 1324060369000, "17843": 1530052187000, "17844": 1440921488000, "17845": 1530093475000, "17846": 1530098602000, "20041": 1556204004000, "17848": 1530113355000, "15946": 1505429339000, "17855": 1530232785000, "17856": 1530232859000, "13761": 1461002864000, "17858": 1530233228000, "20043": 1556240006000, "17860": 1530274935000, "15948": 1505431779000, "15949": 1505439183000, "15950": 1505463504000, "15951": 1505469106000, "17888": 1530574306000, "17889": 1530574423000, "17890": 1530575051000, "17891": 1530575662000, "17892": 1530575927000, "17899": 1530648898000, "17900": 1530661013000, "17901": 1530661117000, "17902": 1530661169000, "17903": 1530661208000, "17904": 1530708621000, "9713": 1401450122000, "17906": 1530729713000, "5628": 1365121328000, "20053": 1556486093000, "20054": 1556498866000, "17929": 1530823764000, "17931": 1530828264000, "17932": 1530829030000, "17933": 1530830571000, "17934": 1530844495000, "17935": 1530844538000, "13843": 1462283462000, "20005": 1555624334000, "17943": 1530893926000, "17944": 1530894605000, "17946": 1530895717000, "17947": 1530902309000, "17948": 1530917871000, "15963": 1505742308000, "17958": 1530976196000, "13865": 1462973545000, "15785": 1500879472000, "20061": 1556630097000, "20062": 1556630229000, "15967": 1505852894000, "9798": 1402003509000, "20065": 1556746321000, "19869": 1553090634000, "19012": 1543613839000, "15941": 1505344736000, "20068": 1556753220000, "1632": 1325734840000, "16167": 1509212278000, "12566": 1440945959000, "5767": 1365818352000, "1678": 1325983299000, "13970": 1465954930000, "17469": 1523818647000, "5781": 1365867809000, "20242": 1559739033000, "17787": 1529361925000, "18607": 1540696453000, "17824": 1529770338000, "18135": 1533316766000, "14925": 1487254336000, "16971": 1518088632000, "15880": 1503568218000, "5863": 1366678471000, "15942": 1505344853000, "1786": 1326934583000, "19413": 1547138230000, "1812": 1327034032000, "10015": 1404121287000, "20225": 1559408638000, "16155": 1509117925000, "19421": 1547289134000, "17656": 1528105986000, "1562": 1325182613000, "19975": 1555080378000, "5980": 1368126974000, "15900": 1504268370000, "14178": 1470825394000, "315": 1303101648000, "19431": 1547423838000, "19977": 1555106289000, "1931": 1327947201000, "15886": 1503929129000, "19439": 1547561526000, "10140": 1405035967000, "17523": 1524834366000, "20251": 1559831437000, "15346": 1493550585000, "20127": 1557798053000, "19979": 1555189880000, "14283": 1473253863000, "20130": 1557843329000, "14289": 1473277332000, "20131": 1557849839000, "10199": 1405943035000, "20132": 1557853774000, "19980": 1555296603000, "20133": 1557853980000, "14306": 1473807615000, "16038": 1506860740000, "15357": 1493724388000, "14323": 1474632211000, "17799": 1529539755000, "14343": 1475416385000, "14344": 1475430051000, "3074": 1338253482000, "2066": 1328819689000, "2072": 1328826175000, "2077": 1328843532000, "14376": 1477347051000, "19905": 1553690808000, "15891": 1504026197000, "6199": 1369933955000, "14392": 1477552301000, "14393": 1477576270000, "15370": 1493909668000, "19469": 1548038792000, "17422": 1522318259000, "11528": 1426255236000, "14439": 1478171539000, "19474": 1548080491000, "14448": 1478182795000, "14463": 1479262159000, "18564": 1540384120000, "18565": 1540384393000, "18566": 1540384490000, "18567": 1540398338000, "18568": 1540407001000, "18569": 1540465591000, "18570": 1540466773000, "18571": 1540467221000, "18572": 1540467989000, "14479": 1479471947000, "15384": 1494003581000, "19986": 1555331129000, "16067": 1507115256000, "2196": 1330553078000, "15385": 1494012477000, "18586": 1540555663000, "18587": 1540556620000, "18588": 1540556643000, "18589": 1540556678000, "18590": 1540589001000, "14495": 1480068330000, "20123": 1557694464000, "18606": 1540696161000, "14511": 1480465216000, "18608": 1540696599000, "18609": 1540697204000, "18610": 1540698639000, "18620": 1540757652000, "18621": 1540765873000, "18622": 1540771026000, "18623": 1540779925000, "18624": 1540814978000, "18625": 1540839197000, "18626": 1540899725000, "18627": 1540902256000, "18628": 1540902571000, "18629": 1540903943000, "2247": 1330658997000, "14536": 1481030108000, "18635": 1541032538000, "18636": 1541032682000, "18637": 1541033432000, "18638": 1541034542000, "18639": 1541034612000, "18640": 1541073760000, "18641": 1541091949000, "18642": 1541092012000, "19491": 1548356483000, "18648": 1541168109000, "18649": 1541168566000, "18650": 1541228682000, "18651": 1541250586000, "18652": 1541250769000, "14559": 1481486262000, "18656": 1541255597000, "18657": 1541255784000, "18658": 1541256008000, "18659": 1541307681000, "15897": 1504175063000, "18663": 1541325373000, "18670": 1541345443000, "14575": 1481731842000, "2288": 1331241598000, "18673": 1541362343000, "18674": 1541363539000, "14719": 1482594798000, "18686": 1541474326000, "18687": 1541474390000, "18688": 1541474626000, "18689": 1541474849000, "18690": 1541476530000, "10501": 1410094321000, "19990": 1555399560000, "15405": 1494518848000, "19901": 1553620176000, "15899": 1504175878000, "16164": 1509157844000, "6439": 1371512776000, "3791": 1347149946000, "18739": 1541851913000, "18740": 1541886444000, "18741": 1541888014000, "2358": 1331927660000, "18745": 1541898354000, "14650": 1481930528000, "18747": 1541899698000, "18750": 1541947826000, "18751": 1541948894000, "18752": 1541949726000, "18753": 1541950842000, "18754": 1541953204000, "18757": 1541979389000, "18758": 1541981717000, "18759": 1541982118000, "18760": 1541997926000, "18761": 1542000667000, "14666": 1482166790000, "18765": 1542027880000, "18766": 1542028379000, "18767": 1542036827000, "18771": 1542041932000, "18772": 1542042171000, "10585": 1410965305000, "14682": 1482318568000, "18781": 1542116937000, "18782": 1542117045000, "18783": 1542128238000, "18784": 1542130371000, "18785": 1542131561000, "1084": 1318951906000, "14698": 1482526883000, "18796": 1542215205000, "18797": 1542228914000, "18798": 1542229017000, "18799": 1542229786000, "18800": 1542238045000, "14711": 1482576646000, "18808": 1542288405000, "18809": 1542288640000, "18810": 1542289756000, "18811": 1542298112000, "18812": 1542315264000, "18813": 1542376932000, "18814": 1542377370000, "18815": 1542378429000, "18816": 1542385426000, "18817": 1542389114000, "18825": 1542495637000, "18826": 1542496138000, "18827": 1542496453000, "18828": 1542497161000, "14733": 1482971244000, "16109": 1507858703000, "18839": 1542580319000, "18840": 1542582465000, "18841": 1542590492000, "18842": 1542590727000, "18843": 1542592852000, "14750": 1483133432000, "14765": 1483487706000, "18863": 1542679206000, "18864": 1542680247000, "18865": 1542680316000, "18866": 1542680466000, "18867": 1542680854000, "16798": 1515439929000, "18872": 1542727589000, "18873": 1542730705000, "14781": 1484084814000, "18879": 1542741523000, "15768": 1500588246000, "18893": 1542792720000, "18894": 1542796395000, "18901": 1542814669000, "18902": 1542818616000, "18904": 1542820570000, "18905": 1542828766000, "18908": 1542858898000, "14813": 1484856825000, "3494": 1342184152000, "14824": 1485012656000, "2539": 1334253112000, "14829": 1485003492000, "18926": 1542942441000, "20221": 1559400994000, "18929": 1543005909000, "18930": 1543017394000, "18931": 1543035525000, "18932": 1543074236000, "18933": 1543089646000, "2555": 1334276689000, "14845": 1485299413000, "16128": 1508285024000, "18948": 1543182656000, "18949": 1543192545000, "18950": 1543239176000, "18951": 1543240251000, "6664": 1373346771000, "14861": 1485981778000, "18962": 1543313818000, "18963": 1543321541000, "18964": 1543335445000, "18965": 1543338928000, "18966": 1543341713000, "6679": 1373414385000, "18969": 1543357635000, "2479": 1334001823000, "14877": 1486419972000, "16133": 1508408200000, "18977": 1543422144000, "16134": 1508443834000, "18982": 1543427146000, "10793": 1412642319000, "18986": 1543443737000, "18987": 1543443909000, "18988": 1543444060000, "14893": 1486735771000, "3360": 1340393682000, "16136": 1508490134000, "16137": 1508494369000, "19001": 1543512084000, "19002": 1543512164000, "19004": 1543528873000, "19005": 1543528908000, "19006": 1543529055000, "19010": 1543613622000, "19011": 1543613651000, "2628": 1335381436000, "19014": 1543623433000, "20236": 1559611429000, "19019": 1543629539000, "19021": 1543666183000, "19022": 1543707454000, "20237": 1559647422000, "14928": 1487266767000, "20238": 1559692741000, "19033": 1543778416000, "16143": 1508749143000, "14941": 1487644750000, "20240": 1559735620000, "16827": 1515867521000, "10853": 1413672736000, "16145": 1508754144000, "19876": 1553181128000, "14957": 1487966169000, "16147": 1509026257000, "20244": 1559739552000, "14973": 1488256996000, "20245": 1559760278000, "6794": 1374697106000, "16151": 1509097515000, "14989": 1488532605000, "16184": 1509446472000, "20248": 1559770674000, "15775": 1500686510000, "16153": 1509107390000, "15005": 1488715313000, "15639": 1498848651000, "19106": 1544455267000, "19107": 1544455333000, "17685": 1528479857000, "19109": 1544462650000, "19110": 1544464766000, "19111": 1544507135000, "19112": 1544536450000, "20252": 1559832605000, "19114": 1544541077000, "19115": 1544546063000, "15021": 1488978730000, "19121": 1544662270000, "19122": 1544665662000, "19123": 1544666402000, "19124": 1544666540000, "19125": 1544684979000, "15032": 1489061147000, "15037": 1489101303000, "20222": 1559401386000, "19135": 1544815902000, "19136": 1544816641000, "19137": 1544819633000, "19138": 1544823783000, "19139": 1544825477000, "17526": 1525045741000, "19146": 1544908883000, "19147": 1544923018000, "10956": 1415452422000, "15053": 1489341700000, "19150": 1544947479000, "14797": 1484496542000, "19156": 1545050575000, "19157": 1545051373000, "19158": 1545055031000, "17529": 1525100765000, "19160": 1545061662000, "19161": 1545090428000, "16905": 1517312176000, "15069": 1489681237000, "17531": 1525114914000, "16166": 1509204884000, "6887": 1375403606000, "19178": 1545222923000, "19179": 1545229737000, "19180": 1545252670000, "19181": 1545259980000, "19182": 1545260023000, "19183": 1545315905000, "19184": 1545317255000, "20264": 1559967892000, "19187": 1545410093000, "19188": 1545410182000, "19189": 1545410770000, "19190": 1545412196000, "19191": 1545412309000, "19192": 1545415930000, "19193": 1545440733000, "19194": 1545440851000, "15101": 1490031949000, "19199": 1545580026000, "19200": 1545586261000, "19201": 1545586369000, "19202": 1545606360000, "19203": 1545606499000, "19204": 1545675907000, "19205": 1545677563000, "19206": 1545679514000, "19207": 1545680975000, "19208": 1545698483000, "15117": 1490183908000, "16173": 1509320608000, "19217": 1545828510000, "19218": 1545840269000, "19219": 1545868249000, "19220": 1545868315000, "19221": 1545869175000, "8005": 1386168654000, "7983": 1385527286000, "2844": 1336861000000, "15133": 1490481734000, "19230": 1545953968000, "19231": 1545953997000, "19232": 1545956864000, "19233": 1545956942000, "11042": 1416578711000, "19235": 1546006552000, "19236": 1546006733000, "19237": 1546007243000, "19238": 1546007642000, "19239": 1546021257000, "15149": 1490636252000, "17544": 1525259813000, "17545": 1525272362000, "19256": 1546101866000, "19257": 1546102995000, "19258": 1546103030000, "19259": 1546114716000, "19260": 1546121289000, "15165": 1490875020000, "16181": 1509410723000, "20278": 1560117071000, "19270": 1546198673000, "19271": 1546199268000, "19272": 1546205869000, "19273": 1546206847000, "19274": 1546206894000, "20279": 1560117098000, "15180": 1491222263000, "19873": 1553166811000, "15196": 1491419737000, "19301": 1546366761000, "19302": 1546373206000, "19303": 1546373227000, "19304": 1546373242000, "19305": 1546373258000, "19307": 1546391757000, "15212": 1491592149000, "19309": 1546397646000, "19310": 1546397839000, "19311": 1546410335000, "8680": 1391395738000, "15646": 1498858184000, "17555": 1525428672000, "15228": 1491751731000, "19330": 1546487113000, "19331": 1546487161000, "19332": 1546505023000, "19333": 1546517924000, "19334": 1546528752000, "2951": 1337361430000, "15242": 1492082910000, "15245": 1492123659000, "18925": 1542941713000, "11156": 1417731624000, "15261": 1492351517000, "16193": 1509535533000, "20012": 1555779144000, "19370": 1546700073000, "19371": 1546700094000, "19372": 1546700115000, "15277": 1492504476000, "19374": 1546700162000, "17565": 1525739013000, "3912": 1348197360000, "11188": 1418306362000, "19383": 1546725761000, "19384": 1546726513000, "19386": 1546728466000, "19387": 1546759219000, "15293": 1492726863000, "19390": 1546790028000, "19391": 1546790628000, "19392": 1546802339000, "19393": 1546871277000, "19394": 1546877468000, "19396": 1546907277000, "19397": 1546915895000, "19398": 1546952328000, "19399": 1546952381000, "19400": 1546952869000, "19401": 1546976451000, "19402": 1546976838000, "19403": 1546976985000, "15309": 1492824507000, "19406": 1547036269000, "19407": 1547037224000, "19408": 1547049280000, "19409": 1547050910000, "19410": 1547081833000, "19411": 1547118044000, "19412": 1547131862000, "7125": 1378512651000, "19414": 1547142166000, "19415": 1547155654000, "19416": 1547210966000, "19417": 1547211088000, "19418": 1547215517000, "19419": 1547215672000, "19420": 1547215888000, "15325": 1493116514000, "15786": 1500930314000, "19428": 1547411680000, "19429": 1547423156000, "19430": 1547423565000, "19878": 1553255468000, "19432": 1547424229000, "19433": 1547472972000, "19434": 1547496419000, "19435": 1547499934000, "15341": 1493328473000, "3055": 1338223586000, "19440": 1547592795000, "19441": 1547602494000, "19442": 1547602580000, "19443": 1547603000000, "19444": 1547651934000, "19445": 1547654518000, "19446": 1547655804000, "19447": 1547674130000, "19448": 1547729321000, "19449": 1547729712000, "19450": 1547729814000, "19452": 1547814165000, "19453": 1547830415000, "19454": 1547838104000, "19455": 1547851206000, "19456": 1547861717000, "19457": 1547905304000, "19458": 1547931897000, "19459": 1547932732000, "19460": 1547933227000, "19461": 1547933375000, "19462": 1547933644000, "19465": 1548000307000, "19466": 1548009845000, "19468": 1548022494000, "15373": 1493933355000, "15378": 1493951109000, "19475": 1548099519000, "19476": 1548162242000, "19477": 1548168572000, "19478": 1548199773000, "1194": 1320196542000, "19480": 1548260544000, "19481": 1548260598000, "19482": 1548265931000, "19483": 1548268234000, "19484": 1548279435000, "15389": 1494109212000, "19488": 1548343566000, "19489": 1548348305000, "19490": 1548348534000, "19880": 1553271577000, "19492": 1548383205000, "19498": 1548426187000, "19499": 1548428076000, "19500": 1548428149000, "19501": 1548430346000, "19502": 1548451808000, "18952": 1543240761000, "17587": 1525977291000, "19510": 1548515330000, "19511": 1548516886000, "19512": 1548517342000, "19514": 1548524852000, "19515": 1548524921000, "19516": 1548558346000, "15421": 1494932560000, "15437": 1495145089000, "11353": 1423145345000, "15450": 1495527419000, "15453": 1495537639000, "3170": 1338837524000, "17595": 1526378492000, "15469": 1495668254000, "15791": 1501003665000, "19870": 1553090803000, "19883": 1553371722000, "19583": 1549228549000, "10777": 1412603691000, "926": 1317000085000, "15529": 1496198355000, "7344": 1380055037000, "3955": 1348710085000, "15545": 1496345512000, "3262": 1339519295000, "3266": 1339521874000, "15930": 1505088101000, "15561": 1496573234000, "3282": 1339692475000, "9423": 1398684037000, "15811": 1501667277000, "15587": 1496609647000, "15599": 1497107370000, "15601": 1497196148000, "15603": 1497223179000, "15606": 1497264412000, "15610": 1497395271000, "15613": 1497395865000, "15932": 1505128976000, "15617": 1497481407000, "15621": 1497537930000, "15622": 1497617178000, "15623": 1497915293000, "15624": 1497915339000, "15625": 1497915404000, "15626": 1497942731000, "15627": 1498041489000, "15628": 1498041656000, "15629": 1498042339000, "15630": 1498137431000, "15631": 1498225788000, "15632": 1498251570000, "15633": 1498548220000, "15634": 1498576929000, "15635": 1498577024000, "15636": 1498626544000, "15637": 1498627758000, "15638": 1498841592000, "15660": 1499423136000, "15640": 1498852152000, "15641": 1498853154000, "15642": 1498853479000, "15643": 1498854315000, "15644": 1498854851000, "15645": 1498856193000, "11550": 1426495793000, "15647": 1498892046000, "15648": 1498898497000, "3361": 1340394271000, "15650": 1499085595000, "17627": 1526973303000, "15652": 1499200452000, "15653": 1499200536000, "15654": 1499343818000, "15655": 1499344631000, "15656": 1499380931000, "15657": 1499381160000, "15658": 1499422635000, "15659": 1499422693000, "11564": 1427031398000, "15661": 1499429815000, "15662": 1499433032000, "17629": 1527013957000, "15664": 1499435164000, "3393": 1340820112000, "3403": 1340922642000, "15697": 1499446444000, "15699": 1499446527000, "3412": 1340986814000, "15701": 1499681570000, "15702": 1499681629000, "15703": 1499681708000, "15704": 1499682961000, "15705": 1499682992000, "15706": 1499767272000, "15707": 1499767737000, "15708": 1499769650000, "15709": 1499791179000, "15710": 1499791220000, "15711": 1499874667000, "15712": 1499973326000, "15713": 1499978148000, "15714": 1499987069000, "15715": 1500041633000, "15716": 1500061601000, "15717": 1500067228000, "15718": 1500092160000, "15719": 1500121803000, "15720": 1500124294000, "15721": 1500127104000, "15722": 1500132844000, "15723": 1500132871000, "15724": 1500133102000, "15725": 1500134261000, "15727": 1500135970000, "15728": 1500139984000, "15729": 1500142055000, "15730": 1500146074000, "15731": 1500154103000, "15732": 1500160429000, "15733": 1500152643000, "15734": 1500162182000, "15735": 1500162548000, "15736": 1500167577000, "15737": 1500168055000, "15738": 1500169376000, "15739": 1500192275000, "15740": 1500199034000, "15741": 1500218610000, "15742": 1500219072000, "15743": 1500219165000, "15744": 1500220533000, "15745": 1500272367000, "15746": 1500296354000, "15747": 1500304297000, "15748": 1500333535000, "15749": 1500334197000, "15750": 1500341502000, "15751": 1500354086000, "15752": 1500377204000, "15753": 1500393535000, "15754": 1500394083000, "15755": 1500420711000, "15756": 1500421787000, "15757": 1500425101000, "15758": 1500432717000, "15759": 1500457907000, "15760": 1500459476000, "15761": 1500459570000, "15762": 1500459772000, "15763": 1500480021000, "15764": 1500482023000, "15765": 1500533302000, "15766": 1500546995000, "15767": 1500560619000, "7576": 1381274604000, "15769": 1500633491000, "15770": 1500634229000, "19867": 1553084815000, "19868": 1553084923000, "15773": 1500635119000, "15774": 1500679511000, "19871": 1553109240000, "19872": 1553137663000, "15777": 1500749787000, "19874": 1553166845000, "15779": 1500826857000, "15780": 1500831839000, "15781": 1500831865000, "15782": 1500835074000, "19879": 1553271517000, "15784": 1500872844000, "19881": 1553284018000, "19882": 1553306932000, "15787": 1500939688000, "15788": 1500955141000, "15789": 1500977903000, "15790": 1500995842000, "19887": 1553461005000, "15792": 1501042122000, "19889": 1553467286000, "19890": 1553470444000, "15795": 1501112322000, "19892": 1553513804000, "15797": 1501112959000, "15798": 1501133456000, "15799": 1501134536000, "15800": 1501149440000, "15801": 1501365483000, "15802": 1501407805000, "19899": 1553600390000, "19900": 1553615106000, "15805": 1501618162000, "15806": 1501626780000, "15807": 1501627000000, "15808": 1501627098000, "15809": 1501627449000, "15810": 1501667219000, "19907": 1553728527000, "15812": 1501672937000, "15813": 1501722132000, "19910": 1553804380000, "19911": 1553805914000, "19912": 1553808549000, "19913": 1553861610000, "19914": 1553862042000, "19915": 1553873180000, "15820": 1502084966000, "15821": 1502102640000, "15822": 1502102766000, "16973": 1518089334000, "19920": 1553973153000, "19921": 1553973448000, "15826": 1502129047000, "19923": 1553989525000, "15828": 1502234922000, "19925": 1554046548000, "15830": 1502236139000, "15831": 1502274454000, "15832": 1502275040000, "19929": 1554119464000, "19930": 1554157665000, "15835": 1502360818000, "15836": 1502361410000, "19933": 1554239219000, "15838": 1502368366000, "3551": 1342986141000, "15840": 1502410382000, "19937": 1554341462000, "15842": 1502446966000, "19939": 1554382588000, "19940": 1554386503000, "15845": 1502559026000, "15846": 1502559183000, "15847": 1502559232000, "15848": 1502706701000, "15849": 1502734778000, "15850": 1502792969000, "15851": 1502821566000, "15852": 1502828624000, "19949": 1554425119000, "19950": 1554431118000, "19951": 1554431158000, "19952": 1554431216000, "15857": 1502964816000, "15858": 1503009577000, "19955": 1554470169000, "19956": 1554483283000, "19957": 1554526716000, "19958": 1554650755000, "15863": 1503179734000, "15864": 1503179959000, "19961": 1554739447000, "15866": 1503301844000, "19963": 1554830899000, "19964": 1554859118000, "15869": 1503304044000, "15870": 1503344390000, "19967": 1554901241000, "19968": 1554943666000, "19969": 1554997296000, "19896": 1553560122000, "19974": 1555079814000, "15879": 1503524149000, "19976": 1555088909000, "15881": 1503568998000, "15882": 1503571107000, "15883": 1503579230000, "15884": 1503692997000, "15885": 1503928685000, "19982": 1555301267000, "15888": 1504001415000, "15889": 1504011171000, "15890": 1504013018000, "19987": 1555335335000, "15892": 1504026247000, "19989": 1555361119000, "15894": 1504090204000, "15895": 1504111185000, "15896": 1504125053000, "19993": 1555415944000, "19994": 1555417061000, "19995": 1555435036000, "19996": 1555488403000, "15901": 1504277564000, "15902": 1504283760000, "15903": 1504285900000, "15904": 1504353055000, "15905": 1504567954000, "15906": 1504607431000, "20003": 1555601500000, "20004": 1555616820000, "15909": 1504709712000, "20006": 1555635834000, "20007": 1555636006000, "20008": 1555703338000, "20011": 1555779039000, "15916": 1504783692000, "15917": 1504784140000, "20014": 1555785214000, "20015": 1555785889000, "15920": 1504785393000, "15921": 1504831572000, "15922": 1504831672000, "15923": 1504832405000, "15924": 1504865105000, "15925": 1504865773000, "15926": 1504984148000, "20023": 1555864624000, "15928": 1505053192000, "20025": 1555868299000, "20026": 1555889328000, "20027": 1555947099000, "20028": 1555979974000, "15933": 1505210990000, "15934": 1505211962000, "15935": 1505212292000, "20032": 1556021787000, "15937": 1505220893000, "15938": 1505297010000, "15939": 1505297072000, "20036": 1556118320000, "20037": 1556139656000, "20038": 1556139731000, "20039": 1556139785000, "15944": 1505384083000, "15945": 1505405370000, "20042": 1556239511000, "15947": 1505429573000, "20044": 1556241162000, "20045": 1556241369000, "20046": 1556348900000, "18671": 1541346807000, "15952": 1505545210000, "15953": 1505569241000, "20050": 1556469594000, "20051": 1556469939000, "20052": 1556485043000, "15957": 1505660695000, "15958": 1505660743000, "15959": 1505683257000, "15960": 1505683588000, "15961": 1505686455000, "15962": 1505737806000, "20059": 1556629548000, "20060": 1556629636000, "15965": 1505821656000, "15966": 1505847123000, "20063": 1556637478000, "20064": 1556710951000, "3344": 1340247840000, "20066": 1556747182000, "20067": 1556747280000, "7780": 1382923129000, "20069": 1556799307000, "20070": 1556799457000, "20071": 1556816158000, "20072": 1556828646000, "20073": 1556862609000, "20074": 1556889815000, "20075": 1556895134000, "20077": 1557077658000, "20078": 1557090951000, "20079": 1557091155000, "20080": 1557091314000, "20081": 1557094800000, "19992": 1555415763000, "20087": 1557191317000, "20088": 1557192410000, "20089": 1557193024000, "20090": 1557193088000, "20091": 1557194359000, "20092": 1557202764000, "20093": 1557228479000, "20094": 1557228521000, "20095": 1557228701000, "20096": 1557251389000, "20097": 1557256670000, "11906": 1431306604000, "20099": 1557287829000, "20100": 1557289119000, "20101": 1557297163000, "20102": 1557310321000, "20103": 1557327504000, "20104": 1557405117000, "20105": 1557405394000, "20106": 1557405428000, "20107": 1557445993000, "20108": 1557524280000, "20109": 1557524394000, "20111": 1557525391000, "20119": 1557691373000, "20120": 1557693248000, "20121": 1557693932000, "20122": 1557694318000, "17007": 1518606727000, "20124": 1557765620000, "20125": 1557767823000, "20126": 1557778913000, "16031": 1506679481000, "16032": 1506679559000, "16033": 1506680195000, "16034": 1506681082000, "16035": 1506697208000, "16036": 1506785157000, "16037": 1506800032000, "20134": 1557884502000, "16039": 1506869625000, "16040": 1506869732000, "20140": 1557963081000, "20141": 1557963144000, "20142": 1557964011000, "20143": 1557965722000, "20144": 1557971259000, "16049": 1506947564000, "16050": 1506948219000, "16051": 1506951172000, "16052": 1506953442000, "16053": 1506961991000, "19902": 1553630756000, "16059": 1507028071000, "16060": 1507028150000, "16061": 1507029945000, "16062": 1507035665000, "16063": 1507054484000, "16064": 1507060147000, "16065": 1507060625000, "16066": 1507063372000, "16331": 1511270053000, "15649": 1499017138000, "16075": 1507224501000, "16076": 1507228519000, "16077": 1507228555000, "16078": 1507228588000, "16079": 1507228636000, "15651": 1499102625000, "16084": 1507290391000, "16085": 1507298902000, "16086": 1507303353000, "16087": 1507304244000, "16088": 1507304283000, "16089": 1507374178000, "12002": 1433426744000, "12923": 1444751455000, "20040": 1556144834000, "20205": 1559180956000, "20206": 1559222118000, "20207": 1559243817000, "20208": 1559245863000, "20209": 1559274036000, "20210": 1559306470000, "20211": 1559348273000, "16122": 1508113798000, "16123": 1508137145000, "16124": 1508149640000, "16125": 1508149714000, "16126": 1508156646000, "16127": 1508163923000, "20224": 1559407616000, "16129": 1508322397000, "16130": 1508322476000, "16131": 1508322616000, "20228": 1559517108000, "20229": 1559517188000, "20230": 1559517615000, "16135": 1508452018000, "20232": 1559518974000, "20233": 1559540125000, "20234": 1559562989000, "20235": 1559600260000, "16140": 1508596308000, "16141": 1508596841000, "16142": 1508748792000, "20239": 1559719328000, "16144": 1508754058000, "20241": 1559738797000, "16146": 1508932145000, "20243": 1559739274000, "16148": 1509040254000, "16149": 1509062062000, "20246": 1559761573000, "20247": 1559766645000, "16152": 1509104953000, "20249": 1559771327000, "20250": 1559831305000, "15663": 1499433106000, "16156": 1509128814000, "20253": 1559835981000, "20254": 1559842699000, "16160": 1509136891000, "16161": 1509141835000, "16162": 1509147682000, "16163": 1509151124000, "20260": 1559936699000, "20261": 1559939647000, "20262": 1559959534000, "20263": 1559967763000, "16168": 1509216576000, "16169": 1509216793000, "16170": 1509235928000, "16172": 1509313014000, "12077": 1434192334000, "16174": 1509352164000, "16175": 1509352264000, "20272": 1560029119000, "20273": 1560030250000, "20274": 1560030349000, "20275": 1560030931000, "20276": 1560036180000, "20277": 1560105771000, "16182": 1509411992000, "16183": 1509413398000, "20280": 1560117502000, "20281": 1560117596000, "12091": 1434584708000, "16190": 1509532097000, "16191": 1509532385000, "16192": 1509533598000, "3905": 1348166149000, "16194": 1509538309000, "16196": 1509621918000, "16197": 1509622010000, "16198": 1509622089000, "16199": 1509623775000, "16200": 1509623932000, "16201": 1509662962000, "16202": 1509666594000, "16203": 1509666884000, "16204": 1509670659000, "16205": 1509713303000, "16206": 1509750231000, "16215": 1509832022000, "16216": 1509856611000, "16217": 1509879126000, "16218": 1509879289000, "16219": 1509886175000, "16220": 1509908220000, "16221": 1509943184000, "16222": 1509975321000, "16223": 1509975956000, "16225": 1509990128000, "16226": 1509992308000, "16227": 1510000423000, "16228": 1510060187000, "16229": 1510061777000, "16233": 1510109966000, "16234": 1510110034000, "16235": 1510139492000, "16236": 1510142425000, "16237": 1510146042000, "16241": 1510172746000, "16242": 1510174014000, "16243": 1510228718000, "16244": 1510229471000, "16245": 1510231650000, "16249": 1510322022000, "16250": 1510322095000, "16251": 1510323273000, "16252": 1510323345000, "16253": 1510323898000, "16256": 1510344384000, "16257": 1510350077000, "16258": 1510356465000, "16259": 1510404733000, "16260": 1510405429000, "16261": 1510434036000, "16262": 1510436471000, "16263": 1510443507000, "16277": 1510573082000, "16278": 1510578306000, "16279": 1510578346000, "16280": 1510578388000, "16281": 1510578560000, "16284": 1510650835000, "16285": 1510652588000, "16286": 1510659164000, "16287": 1510664674000, "16288": 1510674007000, "16289": 1510675398000, "16290": 1510699857000, "16291": 1510745186000, "16292": 1510745274000, "16293": 1510745372000, "16297": 1510791831000, "16298": 1510791958000, "16299": 1510830835000, "16300": 1510830941000, "16301": 1510832067000, "16305": 1510879029000, "16306": 1510881103000, "16307": 1510909346000, "16308": 1510918116000, "16309": 1510922034000, "16310": 1511051446000, "16311": 1511051643000, "16312": 1511052530000, "16313": 1511054789000, "4026": 1349655420000, "16323": 1511176205000, "16324": 1511176354000, "16325": 1511176527000, "16326": 1511176856000, "16327": 1511179343000, "16328": 1511202063000, "16329": 1511224237000, "16330": 1511224872000, "8139": 1388422887000, "16332": 1511270298000, "17729": 1528794912000, "16340": 1511317330000, "16341": 1511318036000, "16342": 1511346346000, "16343": 1511349937000, "16344": 1511350121000, "19108": 1544462595000, "16347": 1511384501000, "16348": 1511391041000, "16349": 1511391148000, "16350": 1511391796000, "16351": 1511426589000, "16359": 1511453627000, "16360": 1511466063000, "16361": 1511473569000, "16362": 1511480083000, "16363": 1511524024000, "16367": 1511551633000, "16368": 1511553797000, "16369": 1511553955000, "16370": 1511554683000, "16371": 1511561822000, "4084": 1350486962000, "19113": 1544540936000, "15700": 1499530111000, "16381": 1511644394000, "16382": 1511645173000, "16383": 1511646673000}}