{"project": "pandas", "project_url": "http://pandas.pydata.org/", "show_commit_url": "https://github.com/pandas-dev/pandas/commit/", "hash_length": 8, "revision_to_hash": {"104": "138b3ef6caa3a27da268cf32d06f181dcc140f8e", "208": "49bb4b643c35271affd5e9e98677cad52f8b3fd4", "288": "4906ee79d730f77be02ec586ec7f66c95a0433da", "315": "2ad94dc4bd36dbb638d8169a841aaf74cca2120b", "473": "8720b1632eb10d665027605bd1de63e160505d2d", "589": "2134ded168d91461ccb96f66cd674d2f59048d74", "694": "dc1b32055a09d5b723932d0238bdc5fa3f583fb8", "798": "c27e09c0a541f4be51ed8724310e7b6d52d5a056", "862": "9e406c50b77949433ed8f7fd094fd30b5421a35e", "874": "645d61131ad5acf768fff906a25e9e34b53efb92", "915": "04cc1eb08c6e267b73378794c2a2ca8a9f2961cc", "926": "cdc607c8ebd05419c0c446298a89814eac817459", "933": "ba1ff88c95b081741eb28c8630aaa6b0423900e0", "981": "35c6b68facf00788e9092d1fcedd53acbf99be89", "1029": "a8b14798fe18050e486845b26370d4899f46a8b3", "1033": "549453aa779ef24a5f1942781e61da248bc6467f", "1084": "a0aa6a96d8a2456523d9f407d3f9f936f24dd7c8", "1139": "6e418a97858b771fc58255f4307271abc969487b", "1185": "8f79f7c6e01874bbf7f3b9bc38af01551c90121e", "1194": "da3e95da95e1e07acc535b8e734b9b80a0972609", "1245": "ac5f314e001dafae9b13ddcfedea7b200821db48", "1342": "010a620da89e5babc137b924dd1f632b4f6e6fee", "1350": "7912b5221accd92a6f586d1792816892f9874773", "1440": "d5fbdcc26520d1c92b5dd73bb6e9a9902756ad16", "1458": "9bb210ccfd7866cd614fb11045188e75874219b2", "1562": "c2ce8039cb77cc69525fb3249fb163d3b3914276", "1632": "2ca93a17ed4609960f0ee3b8704b8b2edca1db5b", "1678": "dfd2926502dfbc5933169767a64ccfd871d08d65", "1786": "9637b509780997019d9089ea8ed2f2f01e2755e7", "1812": "06f608182ecd516abcd140531c65e07b30293eb0", "1931": "fcb200561fa486316efda2d38a86fbc78cfae5b6", "2066": "9fea06df74c87fb606efe564e6eae67177977181", "2072": "13f5db0ac0ba5a30d64866cdbd02b9985efa6303", "2077": "abc59ab02622560f226dd32bd068857053bc96d0", "2196": "776d80c2145ce4a4df1cf5c9ad21140b09df671d", "2247": "483ca398bd20ae42dd1a9d12f972634b384d560b", "2288": "5353a7c75b16b1f9f6ded1eb0b9e4fd4fc98eeed", "2358": "4117b4fde3ffbc74a48b01f3a28f1f76b2db05fd", "2479": "cab9cab52fbdfd3305b7416d4774d10cfb52efcc", "2539": "9d0949396a8533d9fb9b0a6d0fb90a9f0ac16b23", "2555": "dfd7447e47562a941bb355af51c475823520f9e3", "2628": "f750485c264a6fdf1a69c9374673fa95c8373860", "2738": "47abe8cc8d7a66032cfc705e2696adb8cf30161f", "2844": "00a3abbde4d1d15515393d195591996b92aa7ba7", "2951": "0600425d541a26587204b33f2bdf7b738c032c51", "3055": "3c1cc3504caa08d1105a67690be196002c5f8dae", "3074": "5b98fdfeae2ef42d78242c4cca1e0959b9c710db", "3170": "092fa15d220eeeccf9da8b16b452b000d9378bdb", "3262": "fde270b20861fbf36d3063d504fb299d0b58695b", "3266": "a1d768829015796d16486cbc1e99020348901e25", "3282": "b31610d5ef4a85d029b2c2def56b9e67992cc8e8", "3344": "1c08383fc3cf24d503ae221c5d31b93899da6473", "3360": "5f5df2aa34f027d3fc83abb19cf7840ababd4557", "3361": "5d90f7d0e7e9bb53e55fdb7b70f972aa502004ed", "3393": "c91f6d1f62d02a65af78651f61f8db9a62c58b1b", "3403": "d8a0b4fd0d39dcac4fb7a2297bf25cc442e12729", "3412": "a901af2cdfe411d6aa9f9b1f6fa3223738f3e514", "3418": "f5a1bc9cda068f724d2de2ddc0da8ac2c518095b", "3494": "1c24700c3ba74419988e74319fd46e1f937c1f4d", "3551": "4e95b311bbf320d7b88edd6f8ce17194e48b8145", "3557": "23fa6f8b3d1f823dbafb64dc52e5a96fefe9236c", "3637": "39c735c67a4f8ae4203a671deaee07b060f8e201", "3791": "3a940300dc55c58dd5f1d84d6e3a0fcd27f1d310", "3905": "a2f5e56b13dff45a82c4fa068ec5edf35bece645", "3912": "e1b6e44bed02f47f59bf2d71c836f42f6e130dea", "3955": "6d9bd5a6374f1d6b4c18d3d53fc0413c82a16b49", "4026": "b5956fdc123b0208cf36fafc1b80a9671c66efbb", "4084": "023b1d4ae2e3c81b07e95736e17aa500d01928e5", "4203": "f41775415c060ba053ad8a50939ad843b87741fc", "4249": "2d576ee9b9337210a8c85f11e48177db42ecd57f", "4289": "9867f8af6e20cd2248626548f9b3f9a66b57789c", "4374": "5ecae6bd055ac4e5738c0fdc97c275bb6f539600", "4510": "8781bf4cf0b1106bec806038946707809e7edc42", "4638": "eb64630c9c62677979f7e0157344533a1a2c40f6", "4723": "78ce0ce8baef9c66bbee77083c0d12a47d5e294f", "4770": "241e630dbd3ee499fee5aebc265f269b95f9ba26", "4816": "1751bae723d336904bca81945097b3b700b11801", "4941": "a52df7d6b6013bafefe9b5429fe775fd33fee068", "5022": "31ecaa9d06f71b5d652d15441cf6b2dcc6f7e640", "5082": "ccaa428aa8872c4c3b7899901f492a348eef1f41", "5267": "7b03ff2e63c15f1545dab417b1adedcd257872c7", "5482": "a12d480b38c16bccd111af772d78b8f172e612f7", "5628": "b5840b3d5cb533e1b6a0f32e6f316de44040da7e", "5767": "258c7e3c5ec5dca7bec32308925b94267fbcff61", "5781": "e71db13f98edc715abb481e239cf321999210616", "5863": "f9eea308611152f1f7bb89981380fa5d85685f48", "5980": "4670e9f35a130078290722ff538985104f401915", "6199": "31512a2705070b3bd4f975ba087e2657c849529f", "6439": "7ea6bdc9df375bfc4d239e7948f48fd2099df3ef", "6664": "b96ab6bddd5f2e84bd88a0659c4d98154819cffc", "6679": "015e926a0d6d0b3b4fca0099dee2ca9050af4804", "6794": "8c0a34f15f8a87def3f7ad6ebdac052de44669f2", "6887": "5544b896540bac844d5e8fd6cb27e0a3d305495d", "7125": "22f04f7906b8f533cd59541c2a88788388719c8b", "7344": "efb7b0d3c56df52fc77f8618467eee5b62e8cbe0", "7576": "6f484a7e65e39e851d92ea9a76105106317989df", "7780": "6f31fd1b6c39322bbb7015b1b0e8b4a729ffc1e9", "7983": "16052e501adc3dedec3bf8cf65a7ea24300de1b1", "8005": "5a750ce760fbdcbc70f566bd52b0a13ca3cb77f2", "8139": "a5410ed841759badae2c3fe4cc71335c9dd6ad92", "8203": "2a8cd09acbe78e5b325f14082de2b0b496af2747", "8234": "db18d443dc0eac6454b864e179579619493899dc", "8327": "48c005ea761adcaf6b76a84aa94da0d35db8c6d6", "8419": "e97e2be5c11be14e1eede230d60a113946fbc965", "8616": "667c6cd760466c4e1dc2c82f56827e5b8beceb12", "8680": "d10a658673b7d2c2e7a346461c9a4bfc5233d7e1", "8815": "26312e15b2f9d9a379d97c31ce0aba3c0b4ea2e0", "9020": "47785e30d6257c6ff2987a221cf62761860782fa", "9230": "97e87b8dbd1699f5627867ff609f1aa3637971ed", "9423": "20ba83d241dd3aaa84c98daa7c9821fd313c4f22", "9611": "48729e29ff1081c7b32fc75761d0b8e2a36a2f19", "9617": "76f6cf0050025ec5a6187e17957ea9a158cc2d56", "9713": "da0f7ae362bb0ee747c3c5c141327d1d8ba161bc", "9798": "fa8a5ca1dd27c4169727070ddbdcb248002fddb4", "10015": "6f0ccafa8fd796742be127032e58b919e10ad046", "10140": "d839555f5e080a981ce5faf89b4df7dfe0924541", "10199": "7f10211d2ed7d28a5bdc89c689d90b6610bb4e83", "10399": "12a39bb05973573e5fcfcba28c3d25a76737239d", "10501": "12248ffc942acf3a224922495102462c6999c804", "10585": "605d2fcc308fb33bf5443ff069bf62806786f099", "10777": "3834259a93ab0b5540fe10fb7f77be647165c573", "10793": "8dfbe09c1443334fc3036465712195a36c773f4b", "10853": "017adeaa4b70d63fe6c788db457dc9d31562f4d6", "10956": "d8ab3415373ea42713c096a97c3d9ed5c9cb82ee", "10964": "68d483fa7db48c10f4282620f855c8c733f4ce76", "11042": "f1b270fcf5d505eebe4bf964f0541d6a43c3560e", "11156": "d5963dcf31c9fe8529b704efd72306a34eb77953", "11188": "18ea1d856d45c87fe18a41d1a267ede46e10880e", "11353": "5dc8009c401bdf29564c73d9abfcbd7928fdec50", "11528": "9e859f40c1651b38f9528aaccd211b1706cf317e", "11550": "9772a5b3890ebe5473dda012b302aa05f67b78a8", "11564": "c91bdbadfdbf9f60879ead8dd86bd1e72ca18ccf", "11808": "28b1488a35d1a916f59c251dc47e1e14baf73784", "11906": "ca9eefc3c4733f368c054e33537ff18384114b43", "12002": "24633ec81de4b960a9213cc29aecc8e731024c60", "12077": "06832891870119984c6a5404bc7f7a471f43b99c", "12091": "6b1055c765c488e6fb411eed452abf75ff8df4bb", "12181": "4a03e936426936068afb063e44393312d82d12ae", "12373": "f1719b72c46f88807dd91cf6a092c2da12e676ca", "12566": "fb42766b3eb55155d67548d364672d254be7ffb6", "12722": "9687145e06aed545c14630460d24a9693c9a0b39", "12731": "57b5fff36002217578e2340fda6631d6823aff1c", "12867": "071cffd63e4b99362c68a5e2d472b629618c50a1", "12896": "fe48704835323c140846d1bde5e1387aa0cac3d4", "12923": "c0f5cb1f1c4494155bcbb055f2df98cb911bfcdc", "13114": "89f46a5e5db4d55a99b90a00ca68bbc3da0cbb1f", "13165": "6c30cbecf8e5ae610f2a37ba821116bd9f77044d", "13291": "6b8a7211ca88cb7f2536d3546e0ccf3b4290e6b2", "13448": "d77f0724b21cb290a0daec0202f2119543644236", "13531": "9259a56c600f6ea247a9c58c00af017790fe5e21", "13553": "69baf4c30a8b404f8626728e89a4c5fd5b606a44", "13622": "e5ed87b33ab6cd9dade10df945bc5d7452310b7d", "13633": "e462ece64b7cb12fe7cad6e085f62f3bfe9785c6", "13657": "2a531131abf396d438500fcd770cae010dd83c8f", "13761": "2267bd32c3b4e6cdf50ff52306fc09d5f9a279a1", "13843": "87b0f4dc1e91571cc4dd933b7cb181b99606ad20", "13865": "f0e47a9c9350e0d8fc0fe00a1ca0237582437e9d", "13970": "eefe71e27131bc4848e549e3688ef6700b57b73a", "14074": "1ce8f8e0b8540252dac25497f29d4de66a8bea3f", "14178": "0e7ae89115e60419b807c38b9e4b8a19d4c8f830", "14283": "e88ad28c97457c8c1c8a83bf5252257c1eb802bf", "14289": "497a3bcbf6a1f97a9596278f78b9883b50a4c66f", "14306": "5e665b373393365dec03c9b55f488aee36e1b5c9", "14323": "7dedbed8988db9dc6453320383202bf97deaf14a", "14343": "b97dbd01e49f54ae6fa8df382d6f6e4c771d2bc0", "14344": "96b364a4a337b608c92dd6d5a00ceedd80c29315", "14360": "e70252b794070dc5bb4dd4e27be76d1323572d23", "14376": "13088842a7218e8e4626ab68f0c4f204f25f0ba4", "14392": "31ca7170edd1fa3cfcfd96b283d6821491324711", "14393": "e7ac84d2988284604bff781c67a50974e51afdec", "14439": "252526cc0f197fb4c6b93cad41ca7cbcc5a82ed7", "14448": "27b783986230a3d044d045604b72a51acd13b7be", "14463": "a7604fcd8e105221c5cd5d469be9a3a308325631", "14479": "dca0185388d7dce3b1f9e39955c209de1184836a", "14495": "6ad6e4e1d9251a9fddcbed80bdaad18ed07c66ae", "14511": "423c16a2ee88d82202c1e6b24a31d47ec6a04b82", "14527": "c0e13d1bccd4a783486eba8cc769db48a7875de8", "14536": "51f725f7e817df964387b3b68bdf01a07e9fb8cc", "14543": "0699c89882133a41c250abdac02796fec84512e8", "14559": "428c106a051e6adfbac94a39022e8e7d89ef4bdb", "14575": "84cad615564175119635abaea8b83b36a6550d7c", "14650": "6f4e36a0f8c3638fe5dfe7bf68af079a2f034d00", "14666": "0ac3d98fa000bc4fa33b8a3c74d087f0106c57bb", "14682": "07c83eedba7494ff293acd7d800190cc29ebb888", "14698": "6bea8275e504a594ac4fee71b5c941fb520c8b1a", "14711": "f293d6219dcad0b0f4d572a36d52c8b28f8c7b07", "14719": "825876ca7ee8ac7bea463925399c083d5f190b3e", "14733": "975a440b08cce771e286de86706fa213d6479d45", "14750": "7dd451d881964d958acbd078e8dba505906b01bf", "14765": "6eb705f5350a0eeffd9e7663d7b4bf54acb4d6af", "14781": "c71f214a7024a3a8d679f8c2eafdd4e870d7c216", "14797": "a19b0d86105a52a86e3cac4a72bb7580456faa2c", "14813": "4c65d5fc79ea435bc4e47d8af2914cba324117bd", "14824": "4515be9ca7c20783cf8ca00da3da168e00ed315f", "14829": "79b181196e897ec9bdf9771b2d9e4227721f6e1c", "14845": "64d7670d99a11ec4e263da73f2bb1335cb4290d3", "14861": "48fc9d613323ada9702a7d5c78c23eb0e8cae8a8", "14877": "bf8194a74c84c0ba3976d40cc8380df76aa32cdb", "14893": "e8840725447859531ddcc4b878266f2043fb6465", "14909": "dda3c4292b28d4dbead8bb6ae9927373aea9fe23", "14925": "f2246cfa215d01b68aebd2da4afb836d912d248d", "14928": "c7300ea9ccf6c8b4eeb5a4ae59dc2419753c9b18", "14941": "e1d54074ce8448bfcc69dc08d8a800ef9ef918ff", "14957": "3fe85afef47e9e079a0fa24f826bb6faaa2341d5", "14973": "23889d3ec8396925269210d6d5782574e61769bd", "14989": "24a2155eec4a24242cdecd9ddd7e61d02d8d6aeb", "15005": "84bbeae9f10d63fcd546c632649828621a80f64d", "15021": "8daf677b04b6797e7db894b85da7f6e5a4d356c5", "15032": "27b0ba70c7a62965af1f669f91162f01a2c7e2f5", "15037": "470c3276479925a198f38f9c0aacd745ef3a64bd", "15053": "35109568489401dd2172fb76fd38c1c212355227", "15069": "fe15466cff9184e38ecee16639c1eefaa45c3c92", "15085": "a1b118cf46dc0a92fc16f2268b07731e27ed00d3", "15101": "771e36c32f922c6a0c4a147f08fef32a011d534f", "15117": "fb7af6e257d5ca162487ea417eae675e3edbe271", "15133": "156bfd2ed5db2837fe740ec2934a782f56e99864", "15136": "10589887016f4c9280fdeec01f9fcdbe9cea4dfa", "15149": "1dab800b412be3613e8f666eb1be88458b631312", "15165": "48749ce4a774fba73ea38501cd99820537549d5a", "15180": "f49f9058d152efc9a309e01541762407e16dc953", "15196": "dbc1654fb1604b99c1b4fe31a26b5548ea623565", "15212": "c25fbde09272f369f280212e5216441d5975687c", "15228": "c3c60f0d7a782cd429e3d7115a99cdc068a6d528", "15242": "73222392f389f918272a9d96c5f623f0b13966eb", "15245": "cd35d22a04e22aa6a0ca6a98633fbe654f087960", "15261": "8daf9a7e45344dc5a247410e037dccb41b97a3db", "15277": "f53d38b94d963cff081b4fe0a1e7242e8d5eb221", "15293": "064f57fcfacaab7d45c7597552017d91ec3056a4", "15309": "f0bd908336a260cafa9d83c8244dd1a0a056f72d", "15313": "19fc8dac68e088126ffd132dc322dbf8a163ec69", "15325": "8ab8ad027a98b3219d9bbdb1cc39f7e577deed55", "15341": "669973aafdcf239c2e657601231879659ee3249c", "15346": "de8734474daddf772d97c66a9ef759e23a3d362f", "15357": "20fda2223d5121be3f8204702b5ce1e6037e5b18", "15370": "2002da33b0a755fcf7ef64b2c87ca4252f0e7df0", "15373": "a54efdd3f8ff4c9d9248c71e87679af29c856806", "15378": "a31c96d34d00dc757908b564dc93991e867d83e2", "15384": "e346c663cf76186c22f4d3b703461b1b60db280f", "15385": "e5134306bd47db9f6d0f125d2cafd0b8a789e065", "15389": "b8f6556cad57e60a4a522ff6574003b40c06f688", "15405": "1bee0357a97c2c3d79adcd5f120773d7627baca0", "15421": "42e2a87f2a8848795238de1259a3daa5612e393d", "15437": "6dcf2ed2706b00020f6a3be5530ff8dc121ba989", "15450": "e905f9ef7e28116e723b412593a4571aa78d187e", "15453": "6614e266bca32771c761e904367eff10dd4c8979", "15469": "b0a51df89e40691608bb8d9aa80f2d7e4861b9e1", "15529": "92d07992e826808cd56f0bd8fec083b510ca402d", "15545": "7b106e44286187f6b8fed2d6124c8b3c33a922e9", "15561": "50a62c17c16d24b8a20be9ef281a86bf589144f2", "15587": "2814061730893bc8122caa4e01197c699da352e6", "15599": "ceaf85233d434a226b23f891465b4abfdc602e46", "15601": "18a428da81f7fe0f41f8ec78f03a385b731bb6a3", "15603": "d915c7ec5ded5cae5292d8df1feb135432648718", "15606": "b72519e45bbfe7387e0c576c9315475aace69a2b", "15610": "466e4253ae466aaa422cc3f3b3a4143d1466158c", "15613": "3caf858b0ab0dd62126be7ca1021d71409b70d98", "15617": "b7e7fd3f17d4d2a2f87b9d169cf87143f04e5d33", "15621": "3ff845b4e81d4dde403c29908f5a9bbfe4a87788", "15622": "125c414389320dc67ecaffddc65878c01822064e", "15623": "09d8c22d9f56f4a067880a28fbb1235bcf0a1e49", "15624": "8b5e3d65bbc52b155efdc1cfcf3dc10e50691742", "15625": "196eb8e5c05952574dcdd5d0fb4d0a73e4bd6e91", "15626": "520f87b95639e4fc0344a6c6b9851b5cc5a1376b", "15627": "c38f2822786a81bc0820a0469a3163193ef688c3", "15628": "25e057654f9b9d4196ebf02961867ae26fb93547", "15629": "8a98f5ed541c87a9bf101c9331bd6cfa8f007cc9", "15630": "18f7b1ccee1c723cac7f23a16099d08c17ed0a91", "15631": "9c9d5fb64de1dda51c6ed4874bcec83dbb9e35ae", "15632": "1265c27f4bbd06e1bb75f846139a164bdadd5b31", "15633": "f6f5ce5f9ce2afc3b6f55a3228b93024b121b88f", "15634": "aade74a13bb8105328a0997eeb910a96080fac04", "15635": "65a0e642e1270791e6586c967758b362b865b6a8", "15636": "18c4f88526712c5ab97253030e1b0ad9c555c9ef", "15637": "664348c440ccb4dab3d4c420d6aaee7c688c9b0e", "15638": "85740a5b6285e529931aab7a205468e57d023b7f", "15639": "5b88d2f4c721299b44802b21f03fe08f28576fc7", "15640": "5e776fb6cf4e7b3ae0f36b480e1f4e5da154b313", "15641": "794e06032a34c62a2f8757e7d92820192301fa1e", "15642": "6ae92a8b68ec792526c3cc7eb1a4bd75663e7151", "15643": "06fc667f7a26f136b11f33a658124bf64cd57ab4", "15644": "6b729ddd740b6d2efb739757180dbbbef9b092c7", "15645": "7c27b9d99a945bd228c173eaac8042ca2f70bb72", "15646": "b2b5dc32e24cfa5ab1c37d09c4e505d4a82d171c", "15647": "9462379038c69885cf74869fff3e97c1a6d70394", "15648": "e5fd3e023c52c6756fa83604c5909cc102808fdc", "15649": "329fdaae294ae3dc45d4d7301f0f1eec2d26cb4b", "15650": "92e1cc829181f9a4cea47f6a81cec986e8ef2707", "15651": "9e55af2552664267ce27c7fc6c932acb0651c259", "15652": "04de578b173c6901e75d24647c49d6a697ceec4b", "15653": "15db50bbdbce91608c9c4c0bc1398c41a619a9be", "15654": "cc5d20f50c059f02472b029f4455b2609620374e", "15655": "7d0a98e9bfb6c59d5f1738927732ddb80013b581", "15656": "1c3752334dcec4666bb7e6d51fb718a7674849ed", "15657": "8d197ba63128a4cdbbb8627e48e7f1b4f150330c", "15658": "5cc1025a78ba316ea058ad6ea70a2104cc05345a", "15659": "f6edaeffb3de7f9787d049c67d90bf83442864bb", "15660": "500cd0f1935d89c64d93f42cbf373a1209870600", "15661": "e9e434d9ab522496ab1a6c72dbdd057c9c9e5386", "15662": "d8cd9ca5ac96b4edbb8f47c6b734c8f2513d5f01", "15663": "e832ddfc8bb6362a465de18ccdd25a42585ba2bd", "15664": "7be9db9c2ca46099723500af88850c2ef2eef0ce", "15697": "18f929fa83d2d1f335f8ccf325c05a6ce314b94d", "15699": "3a7f956c30528736beaae5784f509a76d892e229", "15700": "9c44f9b2cad863bde17c7dd061d5b5b5ccbada21", "15701": "3be2de63e4c6cfbd04671f86d07869dfc984e9ed", "15702": "a5477b760d939a1f62ab5d38c75bf9d802a2bcf3", "15703": "a43c1576ce3d94bc82f7cdd63531280ced5a9fa0", "15704": "3e20eab7ad5639810b4824790cd559367b326b0b", "15705": "f4b12d8488434d5f9a45fba1cbe7ad5a77c776ff", "15706": "114feb9290c684b5e5b3a2456307f9116372e89f", "15707": "6a85e88bee498e7e218f0eeb766f15b9d78e9eaa", "15708": "d236f31c7cfc740549b363926580ec0c94559b25", "15709": "55af1ab626baf62dbbc00c2521c20be29b819a06", "15710": "a9421af1aac906cc38d025ed5db4a2b55cb8b9bc", "15711": "9d13227345882daaa90f03078c09a9b44a18ce72", "15712": "63536f4a80a1f1f03732411d015910c55a1f9290", "15713": "25384ba459ba7de9fb9d36821f0a4ae239cc40b2", "15714": "4ca9fcd73225af9cb1dc2acc99bb494dc5f8926a", "15715": "6000c5b9624fdd8925099f215eba282bfbef87ce", "15716": "a587d568d213c62307a72d98d6913239f55844e8", "15717": "6858d0f6caa60c98acc4b6c3eaa6cd0309aedca6", "15718": "ad24759871ea43131711cfce1e5fc69c06d82956", "15719": "5f2b96bb637f6ddeec169c5ef8ad20013a03c853", "15720": "6cee09ebfd2e8fb15f3e225bd9770852a6a533d1", "15721": "80e40f81d78ade9921607a092a00b83f9d34cfd3", "15722": "61f0c5ce2eae8a548e4729ee5cc8a8633faa8316", "15723": "0e47b280ae6159dbc8817f3c7bd3e296af480c5d", "15724": "d7bf220c2daeaf86ba2e2026b4fe900d441720d8", "15725": "794fd789603e06e86456375f92489ae4de92a99a", "15727": "4c498f8451fe4c491a6f38ed9e35da3d3ab6b9b8", "15728": "7500218947bffd4915832e9037d9f48991e53ca3", "15729": "3955261c04d5b838488a45fe7b186399bcdca137", "15730": "96168ef698ac8bbccba251258ee66958359b11bf", "15731": "2cd85ca748f62d7430b30e2d9ddd036e972cc64e", "15732": "8e3d8315d63f61c1cc7a0ea9ad24cdd63b63f6b8", "15733": "4f04d0be1fe22dabaff6c0eeb6162bffb763af46", "15734": "1212fe034b7302f40bf253aedd9e3989514eeb52", "15735": "3524edb82e7945998876591813b7e77fe620ce36", "15736": "53ae390f442e745503745e5fa8ed7b06b72fd102", "15737": "01a8be3578e9d0b2a66b8318c5477e3e6cfb75f2", "15738": "148e038bfaf2a3893b52e28b6469cf5984eec794", "15739": "9c096d29a1e9a68b8151de4896b0d9684383821a", "15740": "7ffe7fc21f3dc4ca444de9c83dbf61313b6986e2", "15741": "1d1c03ef807b5ea3cd589b60ea578c88a0c1227c", "15742": "745c01265e31afb9048fe461dfd8c88ad2606702", "15743": "cbd0354d024d6d45c67fceab69f908eb51339f70", "15744": "692b5eeeff9b8e8c750f3e64db0c39dc149a73e8", "15745": "ea487fc9b197285f25b066450c46fc456db09e2a", "15746": "ec927a47e472eebb5ba7086dcc15f3dda1c832cd", "15747": "0bd871fb9634e8b73efcc1aeabb93961fbc43d53", "15748": "dc54b6bbfd1da0947f3b66d4919e4b80e3207bce", "15749": "81f8acef11e8d1e2f0ea78a7b57ee04bef1f6038", "15750": "7b9a57fc99fcd63c55b041ea7c76f5c390c12aa0", "15751": "fcb0263762a31724ba6db39bf1564569dda068a0", "15752": "9e7666dae3b3b10d987ce154a51c78bcee6e0728", "15753": "6a5e56dc9402136e74e8c818a6947fd495bcd3b2", "15754": "34210ac4d8c61ec4d695baba24d84bd7a1826af4", "15755": "a1dfb037de79e6982a0e7ccf883e5af11e9cc843", "15756": "01d7be51132b31771ff5b5c7a9c333557a902e8e", "15757": "e5de21a991408b3d3783489989201826af8ada67", "15758": "aead041fece0ef17a81218585329109e17b5deb9", "15759": "1dc93b521f54b0259c77e8079b03c6fae791dd24", "15760": "47e909dc9d619e20b139c43236efde66b52f9d11", "15761": "5a024494fef4f0afaffa85665370f884857e298d", "15762": "dd1852d59e51e28c2f9b589eefa1916ef5d9bdc9", "15763": "af5eafb5905ad9a5eaa43645716cefc684a20813", "15764": "031d7a9fe24f2799454de34a1e595ae4fa6cfc9f", "15765": "f511d8237322589c59eff8c16ffe00b8293ff4a1", "15766": "8d0c025a4584c0f2d412d060c30fe459dc90b53b", "15767": "8e582254e3bbdd717ec8193364420913a7fc786d", "15768": "7d9d6d3465d1c102c69d799161ebd9e28540acba", "15769": "a2d03d4a63147e2f56615852814de4d2f77c373c", "15770": "8f309db542c893b46e7cc6cff72638f68f5a855b", "15771": "142b5b61a0433c256511649a993b0fe1b6f64524", "15772": "869be8d6981d364d01e4000845583f1035104f2f", "15773": "4efe6560e07f28de6a1834fa90e31cef31b0fb18", "15774": "d884e51909a887119c0558146de31284a4278931", "15775": "28622c5c120d73c2cb4d2292bc0837534b4e9dfe", "15776": "c0a84b59f5b9638ddabcd49ad664fa5850f02135", "15777": "09108fae0fc7d2234bad765634213007172d4407", "15778": "ee6412aee8bbf350aea89bbafbfdfb0f8d7620ed", "15779": "8d7d3fb545b4273cf9d1a61bf7ea3bfdde8a1199", "15780": "a7eb1a775354b43a2bf82ed3a284c0538bc41583", "15781": "4ce5340fec2ec075815e0aac3d4223c2598f1d84", "15782": "811bcbcf4daf6a1118eb898e4e55320c68ec5159", "15783": "e7c10bb8d715390c95925bf20c06e98a7eb1b234", "15784": "ef3aae5ca658ccc4dd21c18485762fda52cc3957", "15785": "c55dbf067d85c3a060a6ffeff2aad24991e95eae", "15786": "1d0e6a151668ffde51270c03274b7e6f529a6132", "15787": "9e6bb42fa50df808bffd60a665bf921e49b87032", "15788": "395f712133a4f6003ec8029458ade7ab423096d0", "15789": "793020293ee1e5fa023f45c12943a4ac51cc23d0", "15790": "920a5778a6c3289e9e9e1118de710a8c755d7cb5", "15791": "13b57cd6ace5b0288431ec13e54c1066e952adea", "15792": "a7b4a9c7eed794872c5d7dcc558a10ff9f076682", "15793": "e2588d9a88805cc12754d7271356ddcc6ab22338", "15794": "f9a552dc12262d1d208f9cdc2c5ffd1731f9c361", "15795": "9de416aa1445deac056972be537846420cd0a7c6", "15796": "5c185e07f0210c148ced62d4dda3275a1ded954d", "15797": "e3b784068a654d13ede6dd4062c8a2b6c9b945c5", "15798": "3ab56bde78e85939a8c5ba73f86ddb888483d395", "15799": "c6e5bf6bfdaad8945120bd54600b3eac79de26b2", "15800": "465c59f964c8d71d8bedd16fcaa00e4328177cb1", "15801": "b03f7e52e859c5d20141a47aa4d6880a321af84d", "15802": "6b8e43688f3363ab19c8a3049e0ade70c13bd4b2", "15803": "f2b0bdc9bc4e57e101e306db7555eb7db28172e9", "15804": "7358f096ef76207b05bcce0bd02f3a45246e8b09", "15805": "ab49d1fcda17cdb5571959a0d85d5ee872638b4c", "15806": "6ac609d8b43769fd80866ebfbf0749e75dddcf04", "15807": "563fa082e32af200d98cfbc1dc30b7ea5247d5d2", "15808": "f394409b0053ffb8a24ffef34f1f758175a7ecf5", "15809": "611d29606263d12ecdcc38a2b8a790e99aa443d6", "15810": "3ed51c2b4b24c391587b78b9dd3faea8d09066e2", "15811": "f4330611ff5ac1cbb4a89c4a7dab3d0900f9e64a", "15812": "8e6b09ff3a09de58e82da6dcabbfddba61a743d6", "15813": "3fadc62e75bb09b2f39ddd2169baa182fb2ea720", "15814": "a4c0e72094622ef8b6b4d24c36e532467a00caf9", "15815": "90913306595c36facde65b6858ff94b6e6d51668", "15816": "55ae03986dab53f39c1df2b8a5e3532f89ad22be", "15817": "0c4bc059d7a99b66f0f5251d699a753c9fe81ced", "15818": "9b07ef4a5b656a1532512c270533053ee338e30d", "15819": "929c66fd74da221078a67ea7fd3dbcbe21d642e0", "15820": "dd776a9f88734ea0769ffdec83423b6ab0c7a59a", "15821": "cdabac1df8220b12d57db021b4b06d391459bed0", "15822": "3ab7d5c0a9fe8c90a5ce2dc52cb77d219e1112da", "15823": "7cc0fac9a77547d2017e70807858ba0c5be5c4ff", "15824": "cda091f85a31fd67b2b3957e77718373e92ff883", "15825": "65e04510b1576a0bfddd307f19154a44f0fb58d8", "15826": "62f464ff73c4ce3137c896b34613659cdf331075", "15827": "3c833db29b6f5977c78d1ade791a09a5b29cedb8", "15828": "e5aad1a2e31ede967c09c2c19236bed701e3c97a", "15829": "5d8319e51909870f4694b26370eb03832f56e627", "15830": "7bef6d873b8af5ee0d35ba4b42c8a4775a6b3f24", "15831": "64129d11e5a4f668378a6c8ace6cad1abd864aa3", "15832": "3e9e947b89d8edd7426bf8c748b1c6e3de5a7afb", "15833": "556effcba52f4712fed21b269e9782f1a309ea93", "15834": "073c14544436d95969258928e2554cb2fc093c99", "15835": "b82253590a66b4a35ed682bca244f668f16c3e0b", "15836": "a09db4b156cd9129fd38214e039097ae944c062c", "15837": "dbffba81914c922925e098411d0f773a759f7992", "15838": "f165b90ed27487287e1c8a0a6c4e66344b2c731d", "15839": "a2c454373b8cd2334b93a68d52104e9cbcdd3721", "15840": "d59a7b5c4ab842399d79ffac120e9a46b4c0f8fa", "15841": "989babdec1f11edd208d94eaf5806f931ecb8fc9", "15842": "236241465a0c10376d032da3c02a381f2b927246", "15843": "d11fae62ae6a9a5e712d3165c721179c31d961bd", "15844": "06850a148ad880eb2fd2564cc0ad7cae8606dd90", "15845": "a4a566531685eff6ea001bf6bd60f96791e8d076", "15846": "3ea2993a7dd3f477e2be6911d39d647b0e74d712", "15847": "330b8c1c195174f729a1d2ee6f916ebd1579217e", "15848": "0fafd4f8f7967f83845a74905d7e3ed9432807b6", "15849": "0f25426eac5c0097214df78b45125ac039c85770", "15850": "924b43359b2450cd1e6e364c468c30ee7694f0c1", "15851": "133a2087d038da035a57ab90aad557a328b3d60b", "15852": "a46e5beed5ee0c2395f11ab325eb1b71e6d23c60", "15853": "47b397309e9601640170aedd6f70486a54d638fd", "15854": "6fe68325de93a5f745ff49eac57589d33a1d53c1", "15855": "57befd18cb8ea8d641ea88a5c8ef916a09a9a1aa", "15856": "ecaac87c526f5642389dc36e6ee565fe8d21bfd7", "15857": "95f4f7dc78ac21a132b86b01c31efc5b0fdbceab", "15858": "0ee1675c51a276649e6e45af962c076c526d1c75", "15859": "24b6349c013fb9e59ea7fa4b1d40088026c32d25", "15860": "34c4ffd7c454848311f71e6869b5cad4bc132449", "15861": "7818486859d1aba53ce359b93cfc772e688958e5", "15862": "4e9c0d1f2156c656df5da4ac3f00190f0da5828b", "15863": "ab32c0a3e2033456ede23dbfeffc6adc8c4ea190", "15864": "3b02e73b856a6f8d53382bf3908f04447bf90e03", "15865": "58d872903449b8a29237288ade6227cdb280fe18", "15866": "e14431f897c7c0afd76d627ba933c07c277f8deb", "15867": "8354a1dfa9073eab1b120d39be31103fc29394bb", "15868": "91245a758ee32658c66bdecd9556f7054cd99901", "15869": "d0d28fec180ee61de17921fe5068ecde95adae8a", "15870": "91c2f1f6acde8e5f571d12716e72327747183247", "15879": "66ec5f3e616f6449ef2c88401042cf2a282234d7", "15880": "d45e12b87ce867b2df3254c386c0f17f175efbf0", "15881": "6993c1ba981554cdd8f45675db5807077a28e2c0", "15882": "62527c0f328caa4ae716328246df75a6f2b33028", "15883": "96f92eb1c696723b6465fdc273dc8406201c606a", "15884": "473a7f3c186f6b0bfd9d3ce413fb627cf7a8f111", "15885": "376483e12e4a08140d594eab86bf22423684fbcb", "15886": "36dadd70376c6033037af281a4669a360fc71cfa", "15888": "6bab9d18bef3b7fccab2830d6dad78d0fb476ed8", "15889": "9a1dfca9182c86c90fffa26579844244cfd7cd7a", "15890": "e8a1765edf91ec4d087b46b90d5e54530550029b", "15891": "0618f9950ad72f6f30283bbcf44fcdcf5918756d", "15892": "0d676a3ccf1d7aa986416a7488b941496f936d98", "15893": "b9d48e48904b0e607c4d18738df50dec744b745f", "15894": "77bfe21c7229e724d01721bb84861283baf7e9d3", "15895": "ad7d6fc0248edaf098537e5674dcc0c9dd059491", "15896": "64c8a8d6fecacb796da8265ace870a4fcab98092", "15897": "b98e688c7d483777a21fb46ec46e86b72b90e5a3", "15898": "764cf2abca9ae3d0c730c98b5103fcde5b4fd88b", "15899": "062f6f118fe4ea439ae255a8ff886a532e20ecdb", "15900": "dad39d593eacd1ee2b2465dc2ac025b0cfaffe2a", "15901": "9e425d637b0c635f1ec73407e6b45d1c53cd7fca", "15902": "f7fe4295f84937bc0fa82c9718e62ec19fc36e6a", "15903": "8351f86a0079b6b0cb95414807a2c2248530ef2c", "15904": "1981b679b0619de0765c2009684ce4abd886189d", "15905": "c2d048137c7288644e8276fed3c5a7071a80221e", "15906": "5bca6ce860f66ca6f92327086a954b9e0326a85f", "15907": "25d529905521c4710c13b9a2c189a39479c529cb", "15908": "84a39f99013f238a2e1df9ba63bdaa8a3fd00c08", "15909": "d4577911c750f2f48f760ce451d413116bed72da", "15916": "8a8a4fd74dc1dd2804d5f605fcad47e6f0fd4b60", "15917": "9dc01c4f9142908c4a7db5a3a0300685f6d43308", "15918": "aee2ae086e0972aabcb43d05fa2a404153e3b3b5", "15919": "3a291bb7170ca900cb1b886a3c0b39976a9870ef", "15920": "ee6185e2fb9461632949f3ba52a28b37a1f7296e", "15921": "46832ac8f465aa911ba79ebc1b1a4d0f6baf46f9", "15922": "9c4e4c8959853c7cda554d8e9b530efdd8ef9cb1", "15923": "7e4e8acf5b5d68b3dfadecd3ba816d4f0b9be0ce", "15924": "3ccb88c912d898b2fd8decd3d988aca264e4e820", "15925": "d6df8ea99f2574480e934aae01a1e142f935145e", "15926": "fdbc6b8f4b36f07da62fc901b19754f922ae3952", "15927": "23050dca1b404d23527132c0277f3d40dc41cab8", "15928": "c3ad501ed31e2e71ab91a201ed72779fdd597698", "15929": "e6aed2ebb7374ed2a6a7c284750d47728aec285e", "15930": "42ed4f143f8b0b386c90df9fa8a55d0f2e5a857c", "15931": "f3b6d1f91643d245d6b43b41e7c9fd1349fb8de5", "15932": "46856c3936540a47df719d10a7699eb35673e4a4", "15933": "34cc2e812f60687d2a4417ff26fc180f7c042674", "15934": "9a8427404efb3df5deda12f76352725d628adf5e", "15935": "d46b027e793e0f7b03a9372b82ac68cd35c1f35f", "15936": "e682902327bd883a207b291b0326f277b3dcdd12", "15937": "83436af8ae1ccad49b7ceac7471c060d823d10ab", "15938": "633be31adcd43fc8bfe9a9fd9e7621ff3fc8ccbd", "15939": "f6d4d7078d49503adf990f0c159eb603ca1f0c1a", "15940": "f11bbf2f505d81900cc83ce387a6a1b1d2a2f866", "15941": "eef810ef2c64be00943696b33e8bab0b4dd66e9e", "15942": "fa557f7391589f351b1260f46b3b3db22492f50b", "15944": "97abd2c9c11aeee0e3d2c58a74d85fa75062ca1f", "15945": "0097cb712a7361a69eb4f5ebb9bc13c2b8733f19", "15946": "06a6e63c317e5291eb78081e2a21bc163ddaab6e", "15947": "ad70ed4ba921360169820dabd16e4475c527479f", "15948": "94266d48e5f54287a877cf7a0e94ef740e3eda22", "15949": "9b21c5456eb4b2cdbc7f74569c4b8660ada951fe", "15950": "72c38883f09c6902863345de432d3c90a29140b3", "15951": "328c7e179b72e257e27adf92a06718fd5a40473f", "15952": "9ec157be1cc0908e3d20e099c7a36cd76d3454cc", "15953": "f5cfdbb1f4b715819aceac4b00cf18ba5f467f85", "15957": "643fc1e0670eaa9e4a332a3a87805b03f68da74c", "15958": "138be889e74ae64132249232ad90f9e4239fd1c7", "15959": "26b461bb6706fe387caf191293bf511de70291d9", "15960": "553a829bf8b433ca7c555fad527c6e0d9f020e91", "15961": "cbb090fac6a39d0e687a01b2ad1b7c136f5d92fc", "15962": "9cc33333fa035e842f35fceccde6afa71f3f1d1b", "15963": "37e23d03e1ba2298d9df05ded69028dfac0e823e", "15964": "0e85ca7f5afb26880e81ba6ff3965c8c0f27bbaf", "15965": "6630c4eddf2762d519507304ad73de189a7e0c6c", "15966": "3795272ad8987f5af22c5887fc95bb35c1b6bb69", "15967": "21a38008e3cab7a0459cce4fab4ace11379c3148", "16031": "00e52abe927150d10a72e397893bee56f4cc6505", "16032": "ffa86c5d154e7013863f94a5a72b574aa2846508", "16033": "54f6648cdebfa376c83f9fc03b53effe82df7492", "16034": "ad7d051bdfdbadc4221307d691fd55412d9d7ae8", "16035": "e2a0251d32a1467e9ab86281a31f57aca582a88f", "16036": "b8467c00f78eec73efd14f159f1ba935a65b4ee7", "16037": "030e374940a93b7920c0c2ac5c950668564c3703", "16038": "baadad7581c48b0b1c6401b7e3b32fd09e7f0863", "16039": "fd336fbea59edf6324d5c4ac8b22ed696312f50e", "16040": "7d4a260cbe6d5c1825541adcd0d5310f32a3ba42", "16049": "1a6b7ab8ecb0270227066ec7cca8a6bbcd9ddbc3", "16050": "a3d538ab72380471f5de7b8e4a3f811aa4de84af", "16051": "2310faa109bdfd9ff3ef4fc19a163d790d60c645", "16052": "def3bce010eb0eaea2580ad6b6f44c0318314296", "16053": "72c7a396fbd10559f0862e59f55a93beb52c35db", "16059": "170411ff666153fa1275c8cdba657729441d2b12", "16060": "8e89cb3e135f6ef746437211857776136747388f", "16061": "9e67f4370ebf4d63ae65878f5dde6e8371538134", "16062": "2ff1241fa794231b8317ebe96b66f71dce99e0c2", "16063": "50c1dda3f1e0c0a4e439c73ac12943536cf58806", "16064": "9ac7c51faf15bfef0756f9ab50cef3177d7fe5a8", "16065": "69024a0110fdc5d8e8a015ea2c5316826e2f80be", "16066": "81694dce171ecd93a65e32ed455612ee967d3951", "16067": "48d0460ab9acbee223bae1be699344f8fd232224", "16075": "3c1923287cf1365ef653efa4abb5c6a4c0a9bd1c", "16076": "e7bb63c4a4f4e5ca04481e4957f1c1394fdcd598", "16077": "7740a6ea71c1e414728a5f81b3e49f066fd7d69e", "16078": "7a57b83a8c1e362920e5e358c21d2a090c8706aa", "16079": "22515f58c178cdb5cd38c4e56f26dc91c7053550", "16084": "4379d04cd933fdaa2b9cbc9be4169cab2c506a92", "16085": "3b4121b5fca88a84bcc9dba56af568c8a2f901c0", "16086": "5bb693a85ef061520936a4feeea30fd382918a76", "16087": "1335090b5da9706419b60e610997c10d9a023fc8", "16088": "e63c935d5a0705f83fc726932eb82bac4c272106", "16089": "7db7f82ed34dfe9b9768f2449b291d5abd6ef60a", "16109": "c277cd76416d4e930b1f05da873b9eaf101139da", "16122": "c9876947831b8a2093d87613a83777a98dfbfcaa", "16123": "00f23ca69e8999592f1bad02c6d763df48365a97", "16124": "a2ff3f0a4d847b9798b76046db05f723c2723355", "16125": "34978a72107b3c77cf295fadbf1f5244ccb6afdf", "16126": "9092445b1b8bdc6cb031a2319ac98204b13f908c", "16127": "5bf7f9a4ff6968fd444fa7098f8dc95586591994", "16128": "a0a0f5a691e7b5f949e21034df69339e092a6a1d", "16129": "bbaa576ac691f69fde076d22587736b989ab69ef", "16130": "6691285bbf5af202483c24f62f4e68198a92f279", "16131": "5687f9e8f63c325249caabf0c8b7f0bee0a12f09", "16132": "e4573255664660441ebbcf9df163327cecd71045", "16133": "a2e54006218c824d562e43ac5092e30600f6e863", "16134": "29a9f63a567e3a28abca547f3fad07c35860c786", "16135": "51c5f4d2a20179041114fac0262ef567d0b0373f", "16136": "a441d239e159fe67915dfdcf69b347841ffa60d3", "16137": "cd477c838ffff6032128afdf591649b225086a63", "16138": "77b4bb30ed5afc95f2c264c6b25e96ea8a9a5aee", "16139": "95b422cdb3b72efc15dc7fee7cddfe68d5d6432c", "16140": "5314578d859d891427609da0698469824d81e530", "16141": "058da72fe62e9f80aa553c305bab8b501f329b7d", "16142": "e2b49ba93a662d042294c6d65572453ad613355c", "16143": "5b99ae2c0b77e7a6fc9c3bb7cbeecd42b6c80bd7", "16144": "097eb6916b84e027e216fd9f69966e271a40b30e", "16145": "e1dabf37645f0fcabeed1d845a0ada7b32415606", "16146": "36c309ed51b98e97fb64238232ecdc795040ad24", "16147": "6779ac0efb166052deced47f23e18196808439ed", "16148": "6a945180165aaf9f1657ce6f3b190963769f5fc0", "16149": "7aeccd392f0c07ecd1c8d929a0d0312fd8151971", "16151": "79498e399f271c530c658484cdf42f5ffe538ed8", "16152": "e38bd749dfb39fb25e9038bc51dbeb6ae78b63b1", "16153": "cc7abd9ee19912c165cfd8d08f95e8e3f4450ecd", "16155": "81372093f1fdc0c07e4b45ba0f47b0360fabd405", "16156": "fc1e50733ea4c372f4c9eb3a53bf35e102d5d215", "16160": "dff5109abfd1e29dcd349d04d535a9c8735219b3", "16161": "5dd2ea0b3211528ffcfe9b231ce6c00f02918153", "16162": "f39f62ec798d5bacb596aa505faef882405fedf9", "16163": "78c8e17d1aef9f2f327fd46b997c46424c961a32", "16164": "44893893db479894a156dccb28c56f7087b32e14", "16166": "1977362f2c2949811b30268bb98e7fb52f49b8cc", "16167": "39a6b8f20fe95f5b6bb91c577cf5dea81214932c", "16168": "34abef282cc7f27257ed873c60a91f69f67b36b5", "16169": "b2d0d1bfe578ce91d545bd2f806655d0bf497440", "16170": "5959ee3e133723136d4862864988a63ef3cc2a2f", "16172": "a355ed2a8c32a29c1dc93466f9b65870cac272fa", "16173": "4af9a8b6d9e164301a4183ae4e2c93e645b04ec1", "16174": "3f4089d3d74cd793b7e773fffa2f5d199bde8363", "16175": "52fe6bc15acd1598290b53195ea7fefecda5fce3", "16181": "62dd2d3e10d2b5beb93d83b5027fbe31d203a4b8", "16182": "823cfc409ac493e3d3aef1381f6200005a13e4b5", "16183": "c65a0f554b0381ac3f50762050a56bcff188ffa1", "16184": "08158c076d89177a962d00e4851649f1ef76d12f", "16190": "f62c85ad5a9c1a2c96a23a1590f416dbb43a1f69", "16191": "ff805c3f215eaa10279074c4b1ae0242d0d5dbf2", "16192": "1719437dbf0a24939e0ce7e46e0a5aa742bff773", "16193": "bc88240d9cfc35675a01267cde33442adc290b7e", "16194": "15fa4bd62c5c7ac7ac618a7e68742b7eb1f90d21", "16196": "21f9e1a47b8331e2894d0bd2d401710d78850f7b", "16197": "bb4fa658483cc0f9aa714dfc5733fe7ab7945f73", "16198": "194dbff2c3e986dc385237b7e56fe9c6d27358bc", "16199": "94bca94daf64cc6cd36705a9bfe4d6d9f8306202", "16200": "0fd3bd73e17e4123f1d334f4ebd305e33cd75fe1", "16201": "804fb99a868f09e9035cc2bd438ba1642e4e35fd", "16202": "90fb0e3c551cc121571b54c6b8615bea084bffd6", "16203": "427d2839e58db6fedab61db9cbf5a127a56a04bc", "16204": "b4375bde87afdc037056ff90e4f93b606c76e140", "16205": "27bbea7ee125f4dc19dca2a7703c9a13ca754f9b", "16206": "86e9dcc164760c5197438968151b2b852647de84", "16215": "8388a47b7b09d345f463fe5fe91f32e87f7bb550", "16216": "e1f3a70239c636e0dc05f5ee289bbd4bfb4c1436", "16217": "de299f663d3a1df063baed7656d9062b9c3b003b", "16218": "58c2f098ab13178f7cf3d3a61c9f4e0fa5d54ead", "16219": "bc69dc69b168bae59d0ed6a461f18222b8137fa1", "16220": "f7f214ba5241d84c107d318df4f85129b9ffc938", "16221": "1181622fbfc9208a906ae9e70716b83fc7b3ae5a", "16222": "9c49e648da8d90a27eba13e11fa12dcdd22bb925", "16223": "f17aa265021b084ec2b4ff9d97e75700dd24f680", "16225": "6f0ff1a6f5fdc2cc135ffffc6e54b471977d2659", "16226": "e23bd24912af10a39f86415221f293619a37e079", "16227": "c176a3c29ccabe7e471fa0b76c6cc1ceeb9bcd77", "16228": "d7c04fba56a704663108da31e064e37ad2ed60f9", "16229": "537e880d2bdb6f3e71d6b66f6489783102b70443", "16233": "d3d60f845b2f324ddc1afbf698788db1efbe145d", "16234": "93c755e0ea64b6039c8ecd55fc637d1dd67dbd6e", "16235": "079f6786f90553a6fae569354273c80d7c1e44ff", "16236": "6b29671e558df9a7ce17e67fd3c86973f9de5fd0", "16237": "535033033002592b8fce94f9365b6671baaf59ec", "16241": "4054632e151c33e8e31c201a1e4ffb5f857b0652", "16242": "8dac633142daa8d5bcd0cf77ad89b97628d474eb", "16243": "ba231d47fbb6891a8f7710b7609802cc8e702771", "16244": "8113b87e017ccce2f78fe885404840838e360033", "16245": "17e0b13095b23ade8e64434e88300b849bfadf01", "16249": "6b3641b48439922ce4c1225a1d338dfe0b1f8967", "16250": "a6345c7cd8c41842d61902801e7bef9cacb0c2d5", "16251": "150f6d41245f42596123998bacbb254b15ccbd75", "16252": "276b3c30b1c3c35dfee1e7249e887dd26d02d9de", "16253": "75c1fa01ebcfe3a61cb1ec9899729062336724a6", "16256": "d8129b49b76362ed148938bcb64e095a95aaf19a", "16257": "bbadc81fc93383bbcd264e2de7a1c1128a6b2c8e", "16258": "f68bf254a5a9503bbaef64e23bd53cd85527d20e", "16259": "b37e4f5c46a3c262015388188264bffcf93ab3f3", "16260": "3493abaa9c47e39b410752833c901fd27f5b3a76", "16261": "b36dab50a5dc7ca2d8de2b62a81014e095117771", "16262": "85e6864177af5d90c633943ee0d86b46ea5150d9", "16263": "96a527434a6138b291c1b4a782bd2793cff51f74", "16277": "4292a27e7e64dc0da6fb6dade7b8304a4251360e", "16278": "c3cfe90d8b7be9435c59f279fc933c7931f0e215", "16279": "feaa0d0a48c01ec5dbf38ef4e51964afd1700ace", "16280": "cff284258c3e7a9474e0ac49f5e7a3b75d939310", "16281": "7f4c960c7d0c100e5df9f0a3bc68401fc4eace4d", "16284": "22fcf43a22866bb4c75dd59d7f91ddf7ff2e8c2e", "16285": "7857c684c38c478190ff5b045f396d05a69c83a1", "16286": "1e30886c09b63ea33236d02f9fb3ae854387ae67", "16287": "77f10f0805651493b95a462085c9a3cd98e9197a", "16288": "ef4e30b85fa3058f0127a969ae7576f0ef3f7454", "16289": "63e8527d32aaf6afe1cd4b2a7b3bfadb088c9a72", "16290": "148ed63f9287cc55f7a2802da300b717d01cabe6", "16291": "9aaf50a367933bad65a4c46920901d58c76e569b", "16292": "fa4ebd4df50853e4cd3f3574738ba9f5964bfafc", "16293": "9c799e2c4331e5e42cfda03323eef165feb5be1a", "16297": "2a6023e83a7428eed5c705b3e606de4b32ec2d01", "16298": "54f2a5e91e90e35f7cbd15214297169831d6a6a6", "16299": "498a1e19555c41d416d0c66095d98211f1eeb4b4", "16300": "7c4ae124c2cf9a2087b0f08828c71ff1e8e4fb75", "16301": "6405919ea341877218ee78c4dae86d1d10d4b8a0", "16305": "d5c490841242e490aa4f510233847861f2ef7144", "16306": "774030cf77a2a2aaea2663c8a3bbc5470ae23c74", "16307": "d6049a0efb7c04996bc374f3747bab8fe4c84bac", "16308": "a39f967b3d6e43edc62e3feae040e22eb69f20b4", "16309": "cfad581e9a6d35c7d05d2b1f34e4a19f7ee15cc6", "16310": "fe4c34bf2053ade8e8e5f6e5b703f5d8be11b6f8", "16311": "0522dcc37899d755a3dc18a7fd1f3fc9b93a51ff", "16312": "f724066f4b3e8b402f7307a132b0d9c5e89ab60f", "16313": "1798c9df8144890f9d9b74cca9f3134ea523b201", "16323": "f85cdfd67a8bbb024f38b3a8adc9a36b8dc4ea56", "16324": "84bce214ca0b44a371a10692124990d4cb23de6a", "16325": "7aa273733b876b548aa9e853cd392f1c5ab2539f", "16326": "8486c7361a1dfa771e738346cb5bf4bf55ce0ec6", "16327": "1647a724ae5c9038cdd3cf4ebbf2273d1b6ab109", "16328": "8d04dafd48d541042613548183b62288ef7e97b3", "16329": "8512cc5f4751fff754cbf8b7f5f95e65eb7e18dc", "16330": "509e03c6b113e78935ae46707572e4bf7f7a1df5", "16331": "8efd1a0162a643c06af998bb1bc60a2cc9f5dbf6", "16332": "c4a2cd362afdfbc21cb62a8e09758226e86735c4", "16340": "b6b9f3faa16907a158676cf949b5a8191a21d42a", "16341": "103ea6fa33cbee3d9a193010016faa4cec7abf87", "16342": "c619a6746048a1b0f2dfb0119d80295b1c7e4f28", "16343": "977686801378978c54472f8ff0981b5da3ecc1d3", "16344": "d421a09e382109c1bbe064107c4024b065839de2", "16347": "dac9b43f7c12b3785250b0e7805b43421a03dc8c", "16348": "717c4a28f6a979c856642bb4d74fddecc8030efb", "16349": "bd145c8d2b14e506609b251a11bd8268582ebc85", "16350": "fedc503f0d25b04850a931398fc0556d892d69ea", "16351": "c63435207375b172db9efdd0d31f32e0da555a72", "16359": "b45325e283b16ec8869aaea407de8256fc234f33", "16360": "492040b401772e95b755f74f09b20ca236016fb5", "16361": "5e670653e50dcbbafc0ba004b16328f49925f041", "16362": "e6eac0b308af9869ee123caa8c256bd8a7cc126b", "16363": "154c41690fdc23b62aa69ad2d6774a02f6334ece", "16367": "4fce7846be56e12999fe8758abb2ea2f2794259d", "16368": "66606381317a131406220df96b5511b33559cfa4", "16369": "e728f94b1e9f16f4720b0c99d2eec2ff184c0301", "16370": "aaee541b538559f8887881ab23d2734dddd920d3", "16371": "412988ed972a929203b2e867c8fdc7fcb0e7d312", "16381": "3d4422173ee2c169afd19b6762e3b5003d8a954f", "16382": "1fab80852f90cecd852d8f89f7e963cf89d69d79", "16383": "20f65126e0de65876bf412fa4280d8725afe2260", "16384": "50f432de81078e522b12c1247376f459bb235feb", "16385": "38f41e64f4b8a0479f8835022af5e7343ccf8498", "16399": "f745e52e168790bff06a55928c3491cdea389508", "16400": "1043a46bcdebf974e1e656837e46aab9b31da5f5", "16401": "f7c79be4d5bc966a631c9876e272d19a54fd8edf", "16402": "4fd104a72a825914851820fee623fbcdf1a989a7", "16403": "262e8ff367c9291c79c4df0c2daf4713de52abc0", "16405": "88ab6934e78117359719eb09c7d580906155575d", "16406": "7463f86632571547184854faedf5ad8fa13c846e", "16407": "6148e5853460dc5325468fe3ec8f6e5c2b52b8b6", "16408": "94f3923c99ef612a953942d6c76fc605e8e5c6d9", "16409": "2a0e54bc841f27164b116135ebda4b74bae2fc4a", "16410": "32f562dbe459ee9e437da3a67631949d34531411", "16411": "48c5bfca5d95b08ce01de3b2cdb9250b6515fa5c", "16412": "d3c3c2b092b17aa720b489101d59d60aff8799da", "16413": "e459658b79c228c908c9070fadcd957cf737339d", "16414": "7627ccaf9442f4101afda69b6077e7f035e23543", "16415": "a47ad560d5ff030bb67b51feaf03d7c4b6d3e55b", "16416": "c40c8f8b3baccbd658d078816698f85e3268a781", "16417": "67c4d0f4f9f45b981d3e6cb07521f9c0bbb459d7", "16418": "5da3759b30167cd5ef5cb02f5bbfb98ac1be1103", "16419": "5cd5e3b81fc3850367bb3e25644cbe3197cdea5a", "16420": "1eedcf664cab1ca23a1d10071b2b7fb8095d0160", "16421": "d74ac70ffd44e9d00e6ffa8ecf7a1a88312e8065", "16422": "d5ffb1fc9653a47e5426121fefeccdf2be9e8c46", "16423": "f7df0ff3b4a4b391c8cf21aeeb7b11403b5515bf", "16424": "d270bbb1448ecaccbb567721c991350bac715059", "16425": "d163de70c93547035579870e2ae9008cb3640b45", "16426": "e1ba19a1fea96726f57415669b57316ba060bc1e", "16427": "0e168188811677f9de72a6a5b97253e551b6b04a", "16437": "73ed6de17ca390418d23a5698cf4db78aa8b7b80", "16438": "3e4e4b3bfc38651d728074df1eb4c42d3b033047", "16439": "02e72ecf1ce75e1fbfc6be0e8fb3568c36fa7fa3", "16440": "e99cb9c0448ed2dad3be33c22179da8a1177c65c", "16441": "2c903d594299b2441d4742e777a10e8c76557386", "16442": "a7646638d06f1ce98481b88f3505e2b4badf172c", "16443": "52fefd50f8bffa493018ba8ff8b8c46b95c94ada", "16444": "52838e609c1b2a495069964dea862a39dd067b2b", "16445": "c3c04e266cbc5e176cc6ef4dc385cdd88fda0669", "16455": "1d88cdb022da8c62dfb2c2132365a801e93bca0a", "16456": "2145e89267e3d489ba95d7bbac4e6dbd9778349b", "16457": "19ce05eb9eb0de6c0cfdd438f505293c3acde040", "16458": "330fb57a92699e907763eb2956b92984859cc09f", "16459": "fdba133336c2ec8f1269eb15e73d48797840c48b", "16463": "d9163516dfcf3b16bb1a0a212fd4f802f3839ee4", "16464": "15ad5427cbd7ae928d69825c87fc992a72dc13e7", "16465": "695e89345a46c0cab06c479c83007f5adbb70ad5", "16466": "279578c0e281a51c5e7d105abb96b70d870c9a80", "16467": "3e506a363e40d2426936a0ee570e3d56830b0d5f", "16475": "1fa55d23d83be6d8ae65fb5ac1c86834c9f142fe", "16476": "0ebdc1003e6689c2b6a9acbf7a19ff47dabd1090", "16477": "f7eb4aef42a620cb4003a38a08fed9bb1795e00e", "16478": "0229538165d9a7dc63d6fe99451c960db5977bd8", "16479": "288bf6e5e3287a8c66a7ed41050db0ebf56d7ea6", "16480": "27a64b2bb9d631ef584a941a3a3f66aebc2477f5", "16481": "e65814814c5f80df120d19f693c816c660e04a4c", "16482": "1a46dba2449c18ad7682926f4d4c165ffc54b867", "16483": "86606b2541c615821c73007dc949d2837a5af2d0", "16484": "34a8d36e45c1623d2e61671561cdbd5de36adac8", "16485": "16de5f9e6c6ffda91be323c8cc4b6c0de628cdd3", "16498": "5d9151c582bf814b460927e1822dbeaf2b01c561", "16499": "c753e1e08b01a438aaa252327de046109bf4bcfd", "16500": "38210407e1462aec987d08ba692f1040aed5c1d3", "16501": "e909ea0b2a583bcc9cfe3e759652351d7f0266cb", "16502": "2aa4aa947df59d7f0a5bd86145394f5db124250a", "16590": "38c6fc8eef863df0f23545f5678df9040431fee6", "16601": "d23fa5830e6e68dcef5814cf5927df8ff1f99723", "16604": "99d384d4f7ef6e2b6cb5a4eebea127e8bddf521b", "16606": "7bb204a05fee20c3c825e7da39ccaf39fbeb8ca5", "16607": "b70b05c620f929e8a69e022bd0a9850fa040c88e", "16608": "96439fb13e941100080a8fb5c78b7b291a2dd2fe", "16609": "d2fd22e1f995a638f1e84b0ef091eaf70e171fdc", "16610": "6a06d50bc2588801495ce1d396900064ba8001bf", "16611": "22f924b5df318f3eedaadd6eea61002d0046de13", "16612": "9705a480615201ce1e89e5385f48fde155726e8b", "16615": "54eaca88f1c725753dc8b6cf3509a177ac570ec2", "16616": "265e3272b8709a7be274321ee8b505a0e74b8e10", "16617": "34ef9eb8e9ed70b7fdbc13ed1cd9793dbfdbbb93", "16618": "76b35c6662136302d212448906c1c8bf8225fffd", "16619": "5b9b4a89c9bf6ca23aa4431973d67da6df50ced9", "16620": "6c02c9efc916e5a742fda33e5d2440897710136d", "16621": "7b4229aa1b95b2050b31cc93e38fda1a72258675", "16622": "fe900cb787949ea9f949ba72f9390dcd6c83df1d", "16623": "0303d0d6cd983758fbe5c4618ceabf1b880a95f4", "16624": "a845187755f65087129e1cd71f3900f2b1ea6db6", "16625": "c28b6249471ffddfed51d62437a65ca97766fb7f", "16626": "f5415d82f48f210fc9ccf023ecb11d97c6a7ab92", "16627": "b5f1e716d89487423bb12d6cc4e6da2b39184531", "16628": "73085773998e12e85f1044771069f63f4e8d65ad", "16629": "8e0e35447f3a66764b2ea92ca23569b30b341d43", "16630": "78dd03508494fdfa23aa1ad080dd547b001f4bbb", "16631": "fb178fc5e9793a0684d486c37d5bd8c2c54bcbf5", "16632": "7a0ee19e95e29042c3373a1d912d2db27108c828", "16638": "852c53e199d0cd14ef0f4370d7c0949deb89405f", "16639": "6747ab50acf808389b96ae5083aa172ad824e291", "16640": "26c6c19a37c4f77f173533ecd4e54f708cb06151", "16641": "b2a02bd0e022e166c45b4c03c20a00b241b59d3f", "16642": "b32dd634c8d4ee46c328e75ed949b2c237994fa7", "16643": "856d9e5b50cb79444a3586e8f88b68577bdf4221", "16644": "04db779d4c93d286bb0ab87780a85d50ec490266", "16645": "07d8c2d93af3fe24f18d6c80096275de3b6794b4", "16646": "c1af9a83f9cdfca5541c5c5ccd7c9c052b3a3c05", "16647": "15f6cdb6404a8949bc5532248de0a4a30c9a037a", "16648": "8e33a71bf0f93dc8e5140312bf2d217d47c755e4", "16649": "775099cde4a2424dfb369d79b8b6e2687e5af7f9", "16650": "ac8ac158377d60c8c8e10e6905d49d48bbe80855", "16651": "f833103a1883672751b45d94d14a3641095df672", "16652": "ff865b464d6d0edf3dad6fc8a01c0e8f0a6528ca", "16666": "75b97a70110b0d924a557bd8e7929bcf1f4509a2", "16667": "08a66e111a60b9a25fb59a0dcc691c3f1ec0ad1e", "16668": "316acbf065f5d1e30fdc7fcced3a53a2f4b14655", "16669": "eccafcc0285b9d2e46ecf5b35cf3cfc4f20dd040", "16670": "6164da24a7d3f9469fcad8b987c9c7fac1c8dd25", "16676": "b9cc8212b69b84ab75a229669b58b207c1c86544", "16677": "175cc4fe044ef26f9e978f766127bee488eaae92", "16678": "507157dbedd960d9b47d4d0fe46eb16230b170b4", "16679": "81adbe6298231bbfb9e68b6f71127941f2f036fe", "16680": "cdebcf374598e9141df7dc23bc75c9528e92c004", "16681": "e85f43222d743a696126a3beaf0603a5940138cc", "16682": "dbb41216a9bb5f1fd1592f3c32ed48ba68f094f9", "16683": "ee9c7e9b19a1fa3c4499d10885dec72f1d651832", "16688": "fb95f7f305e85d474cc44283fc642abc900e0096", "16689": "a18d7259e385732540392aab2532fa09b168207e", "16690": "674cf4ff66266f7cc6aff0261e7fcdfcfcfbcf84", "16691": "3e40255b423c4a6f3868aac47e493f8fd09dd206", "16692": "feef9041d84b3e3b7b68121d903a5ae1a4bf42b0", "16698": "80a5399e59f409749f08f2f38903e25b1c92d5e0", "16699": "e56794984f17d1651d74e6dbcdbf77fbec53d45f", "16700": "e1b638e94f80ff4cb17ac6a1f1079195a931b481", "16701": "f42ae789a5c7c15e8faf3c7b88c9db6033efa64f", "16702": "ef753900b5c3956c43068ff64d271e1332024f52", "16705": "e1d5a2738235fec22f3cfad4814e09e3e3786f8c", "16706": "7818d5168c509199c1f318855299d2a8942bb69d", "16707": "4883a432a21e65d998a57708e20196627f7c60d7", "16708": "fae79204e2b60ac1ff2b2309352ffb5d9382a017", "16709": "dedfce905e49270485d5cc84dd59a215cbb7c56f", "16717": "4d571bb34aa963bfbe367c0504881094b5403873", "16718": "84335621ad0a0d83302a80b6911d3985c00b5cee", "16725": "faeac49687d1ce1c3310bf365d402a4a2ab783bb", "16726": "c24a0d2815b717a33edc5de9d3f09eeecc810670", "16727": "e92d788bc3fc6d6248cdb84cb75beaedc458eb8d", "16735": "a00154dcfe5057cb3fd86653172e74b6893e337d", "16736": "e957dcd9a51a63bc7fdce7006df3ab1c2f802ed0", "16737": "461221dd58d7fa7fcc247a7eec0e409309e82394", "16738": "34f12654bce2c1cbeea90a0fcb2e0395824861d9", "16739": "b63453f6826992b5c068e0aeaba4456f7ae133f7", "16740": "0e3c797c4c12fa04fd745e595e822886e917b316", "16741": "ace46636f96b916a5617345e860d48da7c448465", "16742": "2030a072a454f6e00ba2b49b5cb2c5e886194df6", "16743": "beb1e69cae8a62e0836b671749a1058ce1e67515", "16744": "cfa5ea6969f4a6a63bb26937181bdd0d00f54a59", "16745": "c19bdc98fa3f856e2e6b3495bbab88b587801987", "16746": "a69742181f20f02b9a86ff1a89314efe62cdd21f", "16747": "04beec77e5a713dd90ba31dcf7ad43fd64ac55bb", "16751": "e581b140b115f634e4ce110bf8c182784650bf81", "16752": "f5fc3a035ffb05069b6c61815198f0b558c005b7", "16753": "9e4418218e17857f32df472b00714812a11ab1dc", "16754": "c8831285c5d0732a32f16c4571fea7c48224b502", "16755": "6552718d2a908a57b88354fe916609631793131e", "16756": "02fb95459f062d34985177f5cd191ffd22a427e7", "16757": "61ed3e5f8b3b53b41f13c1ba822581f2198462a8", "16758": "3198b9df59b7a0e946a37d7ede4167e1bb71d91a", "16759": "93033151a8d8aaa650a81df9f41347758bf6c393", "16760": "f9117658514ad4c31130adfc921fa098c38a6f7a", "16763": "cadbf2dce6ad84d6d059df230d908b5533277b24", "16764": "a355d5c0d224eff6b3b0155b1feffc5dcb722fa9", "16765": "77ec4e8cbc3a5249d9abe2c5ad9f1a8f955e2d0c", "16766": "acbfdf83ddb0cea63eaed0b3281e673d5094184d", "16767": "35b2aba7386619dc156ca245cab781d3aea37789", "16772": "f2d8db1acccd73340988af9ad5874252fd5c3967", "16773": "e1888f09630bdd236be1f3ec9577c275d6d67457", "16774": "821028f68fa75c0d6d341148a3ab6f08bc8d3515", "16775": "685813b82f08ebb2b48f99fbfd39ce8c1463348f", "16776": "c0e37670dd578728f988a33bc21bc173b336249a", "16784": "bbfbe48e84f40c22187879b94a7039ff06b6d21a", "16785": "e1d525cffd2751ab8d30743d31dd89ac47621682", "16786": "b1a9421de9a8c3833b1e6f3f7a39b7aef1561942", "16787": "5fb018bc477c69da1052adc1e986153f40b7ad9b", "16788": "36a71eb00ea61c4e6aef78b9ad9f865760a3cfd4", "16791": "1265f66860a1a108b835881ef41ca4e52d397b3f", "16792": "0ffcf9e52b947d9faf45e236178db1af648d4736", "16793": "6d3740bc8cb5820a967712266041e3f23f6c6e70", "16794": "3314ab16c0d14fe3bf0a9c5739dfcd0bdc84f3c6", "16795": "f6c0f8a17005e7aaffa6de1b429b2cdf9889459f", "16797": "5205283078ea574dc4d0e29aef73464f3063da89", "16798": "78147e9c84fb55a67af382a2d3a090e6b0828532", "16799": "7c8c1fd3ab44923f4ba2e61f992e2123c6a69663", "16800": "45a70121c5932b1e4300161114f691af517997e4", "16801": "23fb3392adedd3a618bbdf9ccb0ed81263fa3eb2", "16807": "7351b435975188ef0f645b2529751b2a51fc1cde", "16808": "5a926a7d1d9041749c1cd8f73e4e5e3cc5a7f360", "16809": "fabc316ecf0ebed12cd3ddc4240d3ffafc7b474e", "16810": "8badfd572a0110ee3567722d0bf001915317665f", "16811": "055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "16812": "982e11233698bc54e59be87eb257da2f33b8eb10", "16813": "a31e739a0429c776933ab8f1f32a12ca19a7a1fb", "16814": "1954a830398d33458cc686b4591869f651b0b7b4", "16815": "8acdf801c501a0ce2ac14ddd676cd248f0f32180", "16821": "499802c08c6049419266c95349dd0a5de6751c4d", "16822": "27a503958639185ca40edd8e660579aaed1f32cf", "16823": "8912efc3884133bd4141af3a8bb2faed8ae1d341", "16824": "5853b7953d6e25894fba59056652b9aab61d8beb", "16825": "8347ff8c9d8876fa46f73dbc48919a672caef1d2", "16826": "08a3d3afca2ebbb8e189c173550ec90b4a27b7d9", "16827": "04778805dd595e37e33f6ef0e02d9337a1154e09", "16828": "53be5206c97fbe09e5f10194bf170593148629e8", "16829": "787ab5556f23d2e10b798d2e58e66789d79fd4d5", "16830": "de42bee01230cd67cb0fc905788653d1b4c18ba4", "16831": "1a240f609ff6809f3eaf3cc405d5d7c50fe36d0e", "16835": "c26c49dc57990c5bf64bbb782b90524629690575", "16836": "72086101327c584d2b6f515ffacbaa062e6279bc", "16837": "eee83e23ba0c5b32e27db3faca931ddb4c9619aa", "16838": "c271d4dd0b014c41bd91048fa6e8d33c5bf27b44", "16839": "4ebdc50f250ab2fd4312f82d119e5370a5128810", "16840": "6a6bb40bdd407f37d7ca6477f0dfacac6e11a62b", "16841": "3db6f6661768d46aee04b7b29a1c798326b3b324", "16842": "04a6815f7da0f6d879725d553c7a45f47bb4a15c", "16843": "65d1b62dfe46cd5cfd80d8b1aafd633575c72ee6", "16846": "94cdc16b6357cde99ca08a2b81a3901a748f3d2a", "16847": "51d71cd2c3d37be8b5ed4fa249494b939711dca7", "16848": "6e0927ec352ac5d05332eb9b86b7a84d4a6fbde4", "16849": "d7a2e94914b7707e1c37a4524a9a7c3fef649d01", "16850": "4086e420c8c7a5f72fb9090a7d2d97045cf443bb", "16852": "93dd55ef237843b8fa6c0792b48b718bf72e2250", "16853": "0f1c9c5fd95d45bcfbfa59e5aed73c77e2e5cb22", "16854": "1c0a48c0211f9513e774e727e46f7acc7c327c01", "16855": "f0cd23ca6485940e3a6572cc4f5afdce4c3921ab", "16856": "1245f0673074316b53d1d1ee10abd6077058b133", "16865": "bcaa5da3671b2fd1b3dfca98ebd529d3525815c0", "16866": "6ba65ca8a69560d526762bdbded64b3139f66d7a", "16867": "b6acf5e784471fad52b2c74ae23fc235e5de5049", "16868": "37024923d23cf49cf44c15134df56bce977d04b5", "16869": "2952fbd556e1bc4b5fac70c727652b5419e8e096", "16870": "d409eaf22f0aa1cf4088ebbbe0b1ab8b3917973b", "16871": "9872d6757e5117dce070981141cee562f675694e", "16872": "45aa0ce963df5c766063d7f4bfc6493b852028ba", "16873": "9fdac02ebafa287471a1f406606c0c2eb54be45d", "16874": "5fdb9c0edef57da4b29a437eca84bad5f20719b7", "16879": "eb9e8233965c1b1695381a5af5b207457d8ba330", "16880": "b4662cd9cbcc81f7d55ab15323d8227b8b0803b2", "16881": "83e95e09a08b4f46643a49071edf40bbb3581e13", "16882": "e865b774e463525614d0aad1de5a783929c01a79", "16883": "250574eda5302b6941f8c766f520f67226aadad7", "16884": "0597c7939962e0460a46616eacca30cbaeb210fe", "16885": "86d9af0594ecd0ce4811f3078e405535b4ca4219", "16886": "d3f7d2a666aa824e2df98083aa5c1fd9bb63252e", "16887": "b951c0a565dca09e40a8816c6e5ff1169e0515fd", "16888": "41e02a0c28e03e104abbd455e7545ef6b2805c5d", "16889": "68cdd46139fb1e0ab2f30b223583c07610b00f45", "16890": "8a7aca9eda989243fedae4ef525ddef4511ab241", "16891": "dfc605483f514dc7becc1556dc7eac6295ae950f", "16892": "1d7b075579ace4d53fe47b13fc50c8e2795998a7", "16893": "eec7f578b79bc82e7101d4b3529c20e99c30a24f", "16894": "43f11618d89a416148843f75348d4fa64caac822", "16895": "5f6c80b5e3641ab96f747bd9967e4d58b5852814", "16896": "860c99cd6d9996383960279ab21bf9ca15d859ef", "16897": "5f79123c574b2d5817707516a827c4ee60d95355", "16898": "24d95098789c8685e7c0ce6a57982d0372ffc3e0", "16899": "8cbee356da1161c56c64f6f89cb5548bcadc3e44", "16900": "272cabb03c6720a922e63d97188640f29d92a24a", "16903": "e0d9651b2721b2a009e23b5597fa7549521538c8", "16904": "4618a0918e1bbdb40a493d8a32d46ab8c94fd0b4", "16905": "44bbd5a4d33643c9270bbefd7419f45aecaa4667", "16906": "8a567750e5d56b604411808dabf7c1c700be717a", "16907": "238499ab0a48a0ad4a2011e2ce1c6a02c86124eb", "16909": "65639e67b045a4849c47583d3b32144089a81bb4", "16910": "d9daec83341baa1ae660245d12e76999feeb8d2d", "16911": "01cbc645ec4e3858ea0a098d5afc46f22a7e3e06", "16912": "1bd7b3ad1644ad9d26ac02f507ec7cc0832377bb", "16913": "fb3b23782534c925ab7158c59dcb32c8f8390d71", "16921": "113f78886907a77fd4c73e1456833e83ee48594f", "16922": "d3851ac09d6a9121cea44aabbdc7e4f60f06b7d9", "16923": "c7688299e0621a072ae27ad480c9d35f223a08ce", "16924": "09307dd06a73b5702095987fb5868275d44cc1f7", "16925": "35812eaaecebeeee0ddf07dee4b583c4eea07785", "16970": "36f905285c0089228985cffc9f9f6c7d28789128", "16971": "8f4ad305dc3a98332cc9765200b0535669dfafa2", "16972": "432642eac39c8063d2cc06cd0175bd48463282ac", "16973": "34b86fd75d3620723d0bd6ff2a16bef6adb8b079", "16974": "b83512773ab0dd3908cf2ef5ccaddcd8e0337c64", "16975": "f30345f13974ef325118d499cf8c1033443fe6c9", "16976": "7dcc86443fd9b1aa94b6f7e4e33b6fbd0210b8db", "16977": "a214915e241ea15f3d072d54930d0e0c8f42ee10", "16978": "6485a36483884fb817800a8380a4a4197d6df4ad", "16986": "d7797b44b12f80a6f6e447b3523b820fadd85b7b", "16987": "13bd008edbbe0780600072d404fa989accb5e762", "16988": "507a2a24c6b8cfa8484c6b98ece1603c28a85519", "16989": "c0e75a59b8fd2870c55b8e15565d1f5f8be9ec00", "16990": "cd484cc525951320ee03c620f581c8bd9fa4000d", "16997": "7a5634e79f0b42ddbf602720dc184e9ce69f929c", "16998": "a2771089d87afe8104765f12a07a6cd125e532ac", "16999": "569bc7a35c06ef8eb9a121ca983ba8951399a124", "17000": "d6fe1940a5d7ea10624e1cc871a6eef13f32b382", "17001": "d9551c8ee2a09ccc4c39d2b661f199334162edb6", "17002": "df38f66b417b754afdd2b0e17282255bbf2c769e", "17003": "07137a5acdfc761c7cc30a081600e4c4f23c7d3d", "17004": "8cace882612a6f51ed05ffec43763b8f7ffc110b", "17006": "b9bd0d7fb2083b29a4943e67d6f646309449bebe", "17007": "76f175bec48d51749bbc8b48526ac0f63c01b89a", "17008": "39e7b6916b07982240bac87132848fb2665806a2", "17009": "5a20717ddc58c4d961227a482fa88f905f159bab", "17010": "d198a6efd5a3d2e7d5afb4a3cf556507c7501dd4", "17012": "6cd42ebf269436baa49159d24d2610d9506b50b6", "17013": "db55f4786f0888f19c23ad8c03b791e0ef69ffa1", "17014": "d59aad656d55a95dd5e52e8de17bd42836d2e872", "17015": "405ed25b214740f2e0457ee84007567072b6fd18", "17016": "2fdf1e256e5e0b7f1fe909629e2f0b7893c8c7c3", "17017": "44c822de8dee0bf0e1ed2e8bc15424bb323b786f", "17421": "0c4e611927772af44b02204192b29282341a5716", "17422": "93bc32b156780aadcb953f91408d90f7e97c72c0", "17423": "1bf36b0b9e64a911c83e8c2125836869e2ab37af", "17424": "14889f1bb808c7e60b4f63f28787e07400c46285", "17425": "c4b4a81f56205082ec7f12bf77766e3b74d27c37", "17430": "d7a4f5b0b40525d58ebcd51b40186c0d8af91f84", "17431": "89813f5d7acf72d88efabe93040dbae02148fe01", "17432": "14f03ce4c3d41f70c0e998023478d11475340035", "17433": "f71cd9ad53d9760a51837979a517880e746272bd", "17434": "2eefe5a8671bb25a9b5ad45f4ff5f5171d46fd44", "17435": "d2ab4076512f5571b74e6ea2936910841b10dbe2", "17436": "5d1f5abec3f4f3b614534865e50166955c42f4fc", "17437": "6a22cf786e9e09ceb8ca44b712dce4af5bbcfd65", "17438": "a77ac2bb9fc47b970378985446e6b983ac51a6b7", "17439": "4efb39f01f5880122fa38d91e12d217ef70fad9e", "17440": "fac2ef1b2095c7785006c901e941e2657571d935", "17441": "5edc5c4acde1f0d05b598825ab5c6a86fe551484", "17444": "e71c02aa533a809290c1029438f04ff50f8dd8fc", "17445": "6eda77e7245ff0555f28d84674b541c0e80436c8", "17446": "73cb32e71469cf1615907544728bb9a751089de4", "17447": "85c790082328feaaf2cb606c46beee5e6fd068c1", "17448": "aa3fefc898b2f101f3cf83f90add69857926fcbe", "17449": "6d610a4d9393c0d0335267dc3252ccabb9e51e43", "17450": "eb168b76f66756b54d65b60077c176035bba69ab", "17451": "2431641ad7882326d3d65a35319ef4093cdbae9c", "17452": "e8f206d8192b409bc39da1ba1b2c5bcd8b65cc9f", "17453": "4e6aa1c012d91d663edcfd13658a35f88a49da30", "17454": "d91b706642569aa87173c8449e2fa14e27f72c93", "17455": "fa24af91a156587e7f8d1aab27a45644b59c7e49", "17456": "2794474334cbd53315c248b605953579d010c693", "17457": "fa231e8766e02610ae5a45e4b2bc90b6c7e9ee6f", "17458": "0e42a99ecbef822885a488cd4d8d85362d5b24b2", "17459": "ad5affb6417c26bc7f3bc10668f0cf63fd867940", "17462": "2acce77d0f579dfd8733c6e9482a13d746e5f7e2", "17463": "d104ecd4eb3ec359177a99dd372ad1644b66ff19", "17464": "3885cedb884a8b22e0875d9ffbc8d28123d82b48", "17465": "ec7968d023a9edee0c8be926f008d3b91ec2d0f8", "17466": "d5d5a718254f45b4bdc386c360c830df395ec02a", "17467": "b16974ada8cd833fbeeda793d4ddfaaacc4cfb48", "17468": "e1e1e54720d98901849aa55dec3f76e8c93672fa", "17469": "0bd8a5a62b7831084fe17b40b75127d311f669bd", "17470": "7f7f3d49bba842881b5f26a4fe973a6f3eca8757", "17471": "d04b7464dcc20051ef38ac2acda580de854d3e01", "17472": "804101c8888c7c9cf33a5224489a4c75c4118fe1", "17473": "1e4e04bf47417aadaf11c7d55c206508f2899fa5", "17474": "8756f55234e4fa00a116cb105d36861f1bc6100b", "17475": "da33359b4d19c9bc25710854472cb67918611a2d", "17476": "4a344972722cc3c27250cbc8e382472b13e66bde", "17477": "6245e8c983a685a46e3b64d64aaa59afc4655ed6", "17478": "75295e16dbd449c29609ec6e3e09087df977744b", "17479": "bb095a6e96217f162544b10e9e7a46f04071fb37", "17480": "7ed1f5371601f3300c8b4592c87159fb3eaec5cd", "17481": "b9f826f46d9ec9871a00f2d2a95a0e13f520483e", "17482": "07739aadda4a9afda31fe9ab5d7b01d19f3f1199", "17483": "ede11af8d02a4ac37ed866593839024b941a8086", "17484": "78fee04e95e3c53c83c938285580c39e7761ddc8", "17485": "3e691a4cba566472bef03ef9bbaec701498670e1", "17492": "7e75e4ae7cc8a693ca25f7bfe255574b8a91fa03", "17493": "0d199e4e8bb2b9ce73a35889b49d847283fadce5", "17494": "8def64931af8a01f4af50d79a8d628fe3e63f00c", "17495": "4de2e9bc0d0a7a20232b4c41e2e5861c14bcf4b2", "17496": "0ae7e9090cee6e10ebb4124a0b7f3b30811ccc53", "17497": "ada3fa41d2d7efbbdb7747d2d030dbfdcd2231bb", "17498": "a80c7839c7389483d8c9a29d75bb07195d0651dc", "17499": "31e77b0b4129134d20cd5027dac0adb9fbd2dca0", "17500": "add3fbfbd1f3abb157398d0167bb31fa4aa00a22", "17501": "41db52730b47ff1d707004decd1214fb87e5c533", "17511": "0ae19a156e3d0307bbb5c022b40ef49186e995bc", "17512": "ce8f6e89b83af4c8632c9cb61aa78b868beeaecc", "17513": "8bee97a81764c5211d719d61a62424b1edfacd80", "17514": "d1ace10555f06061c99f478f3a757da07546bd6a", "17515": "7ec74e5f7b1f9a379b318153da88092cccb855cc", "17516": "60fe82c8a2829e831d28cf6d4b3595637c3c5802", "17517": "4aac0c8a3ffd841a6916a5b49a8c4aa55fa8b080", "17518": "21e884f556c175865320f3c25854bc9243a388fe", "17519": "630ef1649cb57a4068474baaff8c4a2b8a14b313", "17520": "e9190bf325311c717d4dfb977ccdf67fdece4db3", "17521": "6cacdde5630c593999059833b516e1fec60aaf72", "17522": "96f2f57379afab0e9050fb3f4f5be4258613740e", "17523": "2cbdd9a2cd19501c98582490e35c5402ae6de941", "17524": "563a6ad108a79b0192a25d51d743812a18e21b15", "17525": "632204359249093d1305e71183be932ceceeee78", "17526": "8ddc0fd801d794fcd7735816790dff66d1c678e2", "17528": "4afc7563895830d224ac949f571edef2f069c314", "17529": "70468dfaacf6ae3d62d1ebd29d66826c6d797e27", "17530": "d274d0b22ec3fa0048b27df7b5f349f1779a8c3f", "17531": "c8fcfcb6035d2bd76e4e83e9eabf4cfd86f74377", "17532": "f799916d0dbf35cd309a42f03fb311e446cd8021", "17540": "93e712327d5aee09cd2994519f9af45495fb5f7a", "17541": "c4da79b5b322c73d8e61d1cb98ac4ab1e2438b40", "17542": "3471b9809b6432aaab9426864b8777630a19ec7d", "17543": "f851699cf086ca7d6011061031c959bcc39d1e71", "17544": "44ccca1f3c27795322b979cf6e5dbd49422b5173", "17545": "24930465344008bc3b7e3dbcd31e66b37b3034d4", "17546": "b02c69ac7309ccf63a17471b25475bf0c0ebe3c3", "17547": "2ab37272b06b21b5bffd846c44ebc387248f5618", "17548": "3340f27e2210553b5bd7b08a3ade3d20ca3b1220", "17549": "ce4ab828d882a0c50f2f63921621ccae0d14b5ae", "17550": "d3d33524cccee1c4c9c00318e286270b5196fde3", "17551": "21f5fb1a3507cbec3b97ae9ff2a23a01bdebdcec", "17552": "cb5c86933f1e0a7f7781c7f07affb7f184c5f356", "17553": "28dbae9f306ade549eb1edd5484b3e1da758bcdb", "17554": "ec4609eecbd7fe4d46291b092bfe93f130b77ee5", "17555": "ef019faa06f762c8c203985a11108731384b2dae", "17556": "be6f11e5bb4643e44b134681f3830b13c35b1620", "17557": "c94a68c60d0f2259cd0fa55182a723b51ea5edee", "17558": "e8e6e89643bad03e50e4f5b568a3d1da560312ae", "17559": "bd4332f4bff135d4119291f66e98f76cc5f9a80e", "17563": "e0513038e6d2ada60345d4445183c3d3d6daa930", "17564": "620784f1bec8f8895937c545ff9693152483dfff", "17565": "d15c104d0596454c289ba48906a397be45dda959", "17566": "2299693d079033a0dd502ed5f59a4ad6e7a24b20", "17567": "d98f25a4771d317a34c88c1e9d9a6ab22a8f5046", "17568": "3dd90a2ae1725c5df5a328ea78fe873f6459e4df", "17569": "b3f07b2551b7eb40408ca28416ca5e21f8fb37b4", "17570": "673fe6e02d50eedd87b835723d82e509372dd7e7", "17571": "21ee836b7f1f36cdc6da0310f4ce7584b6692377", "17572": "e9782795c77b91beeebce863cd28b1b20feb16f6", "17573": "eff1faf2729fa0fb0c2d7913107201e475de33d6", "17575": "21dd192d491829d694e8ed81d9f3610382c2390d", "17576": "780b8d257575c65a875ce53cac0f23c6493c263d", "17577": "6d5d701566615b736a6c11b369bb5ab53176600c", "17578": "8e2a4a9e0b5a960b1330ab4a3c2a330120b9a458", "17579": "c30f0bbc94d420ecef4d5c0c79c3da81599ff220", "17580": "52effcb6848c05226bfdc103e28beb01d972c63f", "17581": "17a0ca172c5fbe3095644d6a491d3f11b142f961", "17582": "0e00151aafb6c1f97b6a0cd711c83b4fba53f53b", "17583": "648ca95af696266b18ded6bfc5327d0666e3ad23", "17584": "3d03fdb24b1a9c1438fe65f5242cbea5418787bf", "17585": "3283ae82bba9b3172551e699ee034941cc273c79", "17586": "1dcddba2200b89cffe97ae7a32a34cdec3a7c8fb", "17587": "a5c02d5c4225a90cda8ed7f328306bd9754d0f93", "17595": "1a9937dd6c43eec3f51d985b6d81145994999d6a", "17596": "186ce4e772c8884b5bc87ab767adc94d6870a4e0", "17597": "8aff1243a54fecf6002268d5bafe1c893067bf37", "17598": "dfb265166c51fa20c473fbb0726f11442042ee03", "17599": "3be623b8e9822a16ba3a815257731056dc384006", "17603": "3147a86e1b20571766b488a8444c74cef29729ad", "17604": "2eb5a67999552d60f7a2a9e1922549d5417d714f", "17605": "cff6e014171539aaa6415a318f47f22b5a2119f0", "17606": "d63d0152f148bafc82b0af5175a5f1d10700991a", "17607": "a327920673868db898d85ed937c1582fc6437ca2", "17608": "27581e919a4e76113e2ee0a6e1c598507ab35f0d", "17609": "501f0418c00064f5041ef156ed5a2289a9064da3", "17610": "9f40757c9c8e8cc5df4984599f7047daff6685ae", "17611": "1ee5ecf3ddbf1ce92e1a78e90a4ef07fc3cf0840", "17612": "d623ffd90f57abda2beb34d807da58ca95b3743d", "17613": "6cc5f235b083a3505eb4ca9b18cad1f3eda29f5b", "17614": "e033c0616158d3ba974456b4f84810492936b1fe", "17615": "cc8d33e00bcf7d1e0bf08f58ffae3f16d37ff118", "17616": "ed784a897047db2aab88e3cd87e62f17647289a4", "17617": "af2b6094b93ec04c5f26c16552cf339b4d037150", "17618": "bc37ea2e05019a89adaa48159b220483598d1898", "17620": "3cae0a26e7fb681dddb5cdf64a2a29c27e2c8f86", "17621": "e80cc43d9eeaec088bbbe61b4bba15e2aa993aed", "17622": "0ebbafd13b586a7f41e089edfb509127ea00b93a", "17623": "508ec3d3686338c7ddb4b5b121c677c6864b1f80", "17624": "81358e862022cedbac009985abac5135a873dde3", "17625": "ac32ce8fca6bdbc40ec1ca14e45e49d73b5176a5", "17627": "90c2237677975885a42f0d38ff59ed0f78928e7d", "17628": "791de95b7e5b7991d4ea39db68b2fc847e38d1b5", "17629": "cd04471023d7b02dfcc168e5bdfcf1d7f960e8aa", "17630": "be90d492836fa604b4b914ab6c7387752a6ba9e6", "17631": "1abfd1bfdb26e9f444b4f44ffbcd2e37026e6497", "17632": "6f1f9759ba8319736c2d51b6d05b071998f1add6", "17633": "f91e28c3fdd4e0708e4cc2ec45a96b068ed0a44b", "17634": "e0f6c2281bf803889d4ac6c7f8bdfd721715665b", "17635": "dc02831f7b267ef152c9bb6a1c8e39c652c1ac3c", "17636": "f6abb6148c8dc14e6279f31f2e620ecf52822107", "17637": "1c2844aca8e3dad7373576d5de40ee6810f7e5ad", "17641": "d30cc746f39e8d8442849cdcccc625ea4dd036d2", "17642": "a5259cc7f1ba092dccc73e0f066d5ae6ffd5ee97", "17643": "f0c2330082e71d8723ca9f3f62ccacff78669bd6", "17644": "b64e9d5bf17888667bff8f37411d71fd45603891", "17645": "b2eec25f4600ba17ef4b9d23cccbf0122da56279", "17646": "c85ab083919b59ce84c220d5baf7d34ff4a0bcf2", "17647": "4cbbcc648436ac21aed296206ace61da96aa7614", "17648": "bc9241d51bd4ad40d4863fde5ac84d13fe42b48e", "17651": "5348e06c4e9e8a03cbd0011483d2dd087e850940", "17652": "9af5fee41ddb2b13f2dd23792c3bc537795a3a63", "17653": "b237b11ba9f7e0465642fd0286b2a483289eaad0", "17654": "f1631bec96dd9a1dc4890677b9c5475d0677e102", "17655": "4274b840e64374a39a0285c2174968588753ec35", "17656": "88c3f08d9b031f6559b9db6574ec02da5f81f6a8", "17657": "cbec58eacd8e9cd94b7f42351b8de4559c250909", "17658": "686f6047312fe7671d8a5e1b2ffd1866f7c7a766", "17659": "9f95f7dbffef7752175ca9ed918314cb6f0b9b18", "17660": "b32fdc44206c38aecbbe5fdb4ed543a5d213ebb9", "17661": "15b39cdb2ee521964a00308f09d45f92be2feaf5", "17662": "67e6e6fcd19d1d89cb60abc3a78372bc85fd8e29", "17663": "7dc6f7023ce439e8ef10ef336f314b10192911c5", "17664": "dd91539c02b9afb0895b88ce7bc99c075f316795", "17665": "fbb47d67a6355a4aa77267b87300cd448a4bfc32", "17666": "0c65c57a279e755ab7093db925d1e580f9878dae", "17672": "a65e4af2a7af17c533017ebcf1227279f7423ec3", "17673": "5bbbaf6ae48681699cfbdf8f4a726661118e0dcb", "17674": "649bfae90f70e8ee7181aba31b0f0b44f09b76e6", "17675": "c460710f32193c65e33d366921f9eaf919bc8da4", "17676": "abfac97b2d22447d41bfccaa53e0a264ca34d6d4", "17683": "d79203af0552e73933e6f80f4284ac2697372eaa", "17684": "05e55aad0b6b55418cef437a5b562ed72cef3ceb", "17685": "8d5032a8c7b00d47fe5d0886145e1ad9dd17e0d3", "17686": "324b324f91021e57106ffc7937f35d54279aac5c", "17687": "415012f4f38ca0cf41717c51e49bd2349cba09a8", "17722": "7000b899038e9d6559ce80d3c018ec0ad5412efe", "17723": "480790531ffcc4329f280ddf6877d028d08e969f", "17724": "66d9b1559eb524a5cb12815e5c45d81be8967fc4", "17725": "879b15f3476d81d51f236d13684444579bafb8fd", "17726": "defdb34bafa3900069d399ce597c0abbd4a2b0cc", "17729": "d8a1feff3947cd8759c20bf3c7479014d41ee732", "17730": "e77dc7e337dbce19d26a25c9b2f9651aede5ad49", "17731": "ffffa5cbb6134d0b6c6e49d460e5735bbdd6d5a2", "17732": "92e9882d723c57b3135b17bded1a6495fec0ebda", "17757": "ab668b0a56a9f2aee959bde787e9a0af4068d7a7", "17760": "1a23779f09abc6ebf908d66ee88b973b767e2e3c", "17766": "bc4ccd7dfaceb92ac2c6dc345c1bc4489407108f", "17767": "c8f27ccd40611e15b9c8e7f75c16b41a78e9ef72", "17768": "b3744a11ccbed5bcb020c2e994a9267a2d080c84", "17769": "576d5c6b76e039a411a7cc4c0de29813e2de0149", "17770": "b5fc76954963e30b7d7dd4c30ed7363568fd01ee", "17778": "49188296a363f52784abd30f8074f20acd4d0a00", "17779": "c50a9dc20d6e5b72e07a35c2cde4a9fdaa62730a", "17780": "ec5956ed350d33ac2cee07bf9a24ea5315529443", "17781": "6c71c4586296d2861717fa541875f83bbd07ca1f", "17782": "9e982e18678c47c83ce2bb5932f844e2d9ee21f3", "17786": "076635ac3a33b819f4ae0fb1f95106bf8e4bf329", "17787": "91451cb7dbaaf6fb3f9bdfca73fe6adc2ee68cce", "17788": "6131a598a614b93e70a28b36d35819cb6081965b", "17789": "6d346576669fe7bd9c2b3c103cc8d29ef3d00cd4", "17790": "71c53f0be9b49af0fdf5c6965b2a5a217b9f7179", "17794": "cb57fa6d9602018cabfe1cc61fa3369137da9ba9", "17795": "2625759abeb78655558067d55a23c293628c3165", "17796": "89874d34f3ce7f30207fa1f8dfc082d835a3fba5", "17797": "ec2020735d72ff73e0a6a607689281aad173c702", "17798": "b36b451a74bc16d7ea64c158a3cd33fbfb504068", "17799": "506935c3482cb678b75dc7a70f48707c70b4ae79", "17800": "f91a7049d1730aa1924584a07a1265d9f57a2f35", "17804": "1c0740cf654d1e9ddba5e946305e736e3b95ecac", "17805": "6a5a565b44583ea8a5faa00aff988bfead9fd9ad", "17806": "e24da6c9f92d2b04ffb39a7fe0db85015af7ff3f", "17807": "1638331172cb260c7c642d02e5cf97373f7bcba6", "17808": "f1ffc5fae06a7294dc831887b0d76177aec9b708", "17818": "7d8626dfabef595245af44bf74d329f251ce42ca", "17819": "c6347c4c4fcc911e31cc22005fe2d42cd520b7cd", "17820": "66fea91e915ca5e3f096055f3ad0f07335483e3f", "17821": "5fdaa9717f7550c5293d421205bfa19011278396", "17822": "7bee353cd69ab846317301fdf614a94fbae50117", "17823": "eb40557a7897a6138b605b1fe5291451027ec01b", "17824": "f1aa08c4631aea435d66c161557e44f7c72a618e", "17826": "7829ad3290dc6894d24c1c853ffc4dabef50294a", "17827": "3433f1990333324d88a7e0b768921b28e921c55b", "17828": "44f7b144afa19e1ff65f36609184d133d538324a", "17829": "51d548dbe6dedfb001cdca3a65bea46b8faa5fd0", "17830": "1033e8b1195d4071253889ada60523832285354c", "17840": "9d38e0ef5842fafcc4e391abc6aba486684e6dc7", "17841": "2a7e1f297316ddbe64e1a14e235d6f08e524e7eb", "17842": "838e8dac435e1d5a08004e21c0e630a299b6dac0", "17843": "ebe480a9035095b6e72f2e8055ce7ea1e02743cd", "17844": "45e55af9cf74aede00a8b10f8922537f285a573a", "17845": "b35cb1c127aae894c2a1ee5ab2f16987b91e9000", "17846": "44c54607828f03d2b4b172838d5270e66b2a5312", "17847": "f9cc39fb1391cb05f55232367f6547ff9ea615b8", "17848": "a620e7255ce896c9185275d82172513268b1a719", "17855": "66b517c2f51ed20d4c6823272d5c2a0f47f96d84", "17856": "5afb95358efbde0ec1327378d12e9287a9ae1c6b", "17857": "a3e56f25a4f7c71a2b53ef9dc3b66000c093b084", "17858": "5c761f1c8a19ea3d87fcf365f7a2c6ae00b355f8", "17859": "0b63e81dfcd7860a8c30e0837238ff9cc7bbe88d", "17860": "dc45fbafef172e357cb5decdeab22de67160f5b7", "17888": "1af2f6cd29385b481d7d3de1e1a30cf1a64e9eb6", "17889": "be14333ab00a68a9f7fa8ea3b35ef5ff4571fd02", "17890": "823478c6eaf773cd7e1803a0353232c0b7e56af2", "17891": "8b2070a1a5e6e250b05cf7e47523c857f5e97b57", "17892": "7cd2679982138e1e7f9f1a759827647e6e521d43", "17899": "8f322149ebd2a30f2f2d48c06863cd783166fa84", "17900": "e77e428d8ee37f15471974362bd48d0863f71ae4", "17901": "0c2ab656ed2e9aad0031efb644a160fdd6bfc4f8", "17902": "0cb0886bba5805babd1f2907bf2748886f00f792", "17903": "2b136054db3b8f4c8d1aa33160c4bbe3b8ce940e", "17904": "7bb010cf1206f924cdc225f00669fda3daba758e", "17905": "62a0ebc5837a4a1f7cc925e13344be1adf1acc59", "17906": "10709762e95be2b98d68b95db93a287ee5af74d4", "17929": "bd8ba3680eae9c19221ef7200928bcef68508f4a", "17931": "9b0f560a73d11b2fa72c48d7fd16126b5137f349", "17932": "c7e4b212205b6b18cdd7f0d7c079da80b58fad82", "17933": "d24a9507ba539f455d9b90885edf098c7dc93e99", "17934": "861287bde7c04179d8b8d3fe78c3e8d38f52c55f", "17935": "04caa569e5316e1a6526f0c78142a677ca4b2ee9", "17943": "2543795597a01a485d8ff355068ee4e0debe496f", "17944": "a740b8905a8fa23ea9d80162e6cf845cbf6d4710", "17946": "3be3254c06a97ffe4b73b9a55df30422ceeca36d", "17947": "30eb48cc485bb7c7c47a4e7e26f87e469fbd8b8a", "17948": "620abc403d371446afe38fc1e63f0d90ea27b80a", "17958": "edb71fda022c6a155717e7a25679040ee0476639", "18135": "0409521665bd436a10aea7e06336066bf07ff057", "18564": "4eaaf3623725181c73c49ba92df169b778923947", "18565": "4a11eacf01dea84f9cdb69dd43b771dabe341e90", "18566": "92fd46c8bf719746b4c720bf7599d4080b319c8d", "18567": "5dd4cae70d5013925c712d0933220c03d20e0efb", "18568": "1c26375c0743a2cbdcfe14a62ad10806001cbee8", "18569": "c584ae7856cf9d6c8838b4e1c3cd2fa0bebfee98", "18570": "a20b09759f833cfd71e059319a41b9bd25a96751", "18571": "6b8e5e871dc4544db0e9a24463b1e64d1164147e", "18572": "0a2d5019dc2b8f9521879f47a197076d9cef38ce", "18586": "88a57c9cc861f066abc0caa0bb902fd827b2fa97", "18587": "48782a8f6de2564cff08517a3f6753734690b711", "18588": "5d84bc08ea7c45b0d2b3aa021a425b11531336f1", "18589": "caea25a8b91d62b30eef99aa0c523448e19cd6db", "18590": "f662c5f2a7b392ee96a43f055073c8523f8f0339", "18606": "2360f5ac758683c8f9871f94eca3a21e4f87162f", "18607": "a9ddafea8799f16a9eb80b87b63bff0642de537d", "18608": "05be7699bbf96be7965ce01f10e57afb5a4c80f6", "18609": "e14c5505ff25f245bfdd6f8bc901279dabe34a38", "18610": "62a15fa4071d0711b2b97771b981d527c1c4af10", "18620": "a26005a3481b0079f80c4f3edccb25066ede81b9", "18621": "360e7271756b4129e0dcd22ed15755a5fa0b87d0", "18622": "96d321c70e55c619ad6eab40a84e3fa166982a4c", "18623": "184bcd3386a835d058a802d18a8b6d201df4a584", "18624": "0d6cb3c21d1305d75878eee7a470bf463b6754bd", "18625": "a2e599499667b256bc5b8b13a75f0601eccfd432", "18626": "ea17df51e26ab7568f801b3936a45fea8fc76540", "18627": "da9e35883b28c83fcf55635f73c65bef89902f21", "18628": "218389ba3f741cfb32502bf6120bb8fdcade550d", "18629": "353a0f9ebfbd87642d1dd7154f25be0286cdaf93", "18635": "3b50d94e286087b82f8deaf391235fab66e5d629", "18636": "16c0bbb0e769dbc6a6d105a841c4f6e76214745f", "18637": "a4f9a44e8e348744e2dc95f243c44e9829546d5f", "18638": "d4aaf615a6cf92602ec2f755a073491b7fad6f41", "18639": "9019582c45d17035098941a666a8b6072c13a357", "18640": "6b9318c132f53fd4e2ca588c67c16249b75c3b16", "18641": "555adc2497746986e24e471beba61c40031f3cbf", "18642": "2eef8652fac582978a3828ac307b808c739932ad", "18648": "2073fc28fb0bf1ee4a094f9cda86b7852e951db5", "18649": "4f717551b8e49ecd978bb4f5a985d6f6a96d86e9", "18650": "f7f0c597f34dd7346ed736f3c588b32c35dd1556", "18651": "916d5be8076c761b4270abf8a484b00087f801dc", "18652": "ee7d856b86114cb29ce272dc85a599af8e2d3b1e", "18656": "430b17271343d7db90dca351de89fa1a1a60bb26", "18657": "528ce15557c4816bd17420442b100206222aed5e", "18658": "d78bd7a65f87022bae5021d36c8656c0ea5a7b76", "18659": "8586644429a8c0054a74e645830601419da6613f", "18663": "0aa9efa5593f87f1268e2dab5b55ee0cc4492458", "18670": "0fe97bcbf9b157288417c8a475f763824ba79e41", "18671": "aaaac86ee019675119cb0ae9c3fb7a2b7eef9959", "18672": "b9fc22db9ddd8b2aa10be4680f4c7bf1b5c50ad8", "18673": "6db8d19f6bc5a1aeed58d2c53a2c642cefcc3ca7", "18674": "24ab22f75aae1c9b9491c26e6f753814b7d6fd8e", "18686": "02abc73ef05b2554bf11e8ba8358ff36e302c6f0", "18687": "ce8e05dfa0dcb7d7b1a15d7d04f70834b17dbfa6", "18688": "6a5c34c650a4f38025ea860ecadcd7aeb5e10785", "18689": "11c0d284c60775e134b9c85a5ebd6656c7ec6626", "18690": "c6366f5c15acee213bad0d9f7a15ad69d4445a64", "18739": "8ed92efc65b51a9010bd14e0e666fc722226e50a", "18740": "b930303e111767ccb7ecb29828d33dc555195cb4", "18741": "383d0525831d7301ae4ab26bb8c2d475ee4ab72a", "18745": "274ef6ff9eeb6e0b3dc2c42e494d5c20ad454108", "18747": "2cea659a9a6a88d16e0d1fa698fb61dc6c3ce3d5", "18750": "00ca0f9cafa8528c8835d920ff24c71104690def", "18751": "4c63f3e0672be8345ad2a152f5ba506eefde8312", "18752": "43a558f551555486df3ce495c54157e64113897c", "18753": "da230304097a96d77d0cfd695a66bda6349be853", "18754": "58a59bd606911f11a4f679df18a00cfc25536c30", "18757": "592fd64363659969065896a070459ee701dce627", "18758": "bb32564c3e1a9c40fb117d87c78073ac235d884f", "18759": "dcb8b6a779874663d5cfa8b61d3a2c6896f29a0f", "18760": "8a7eceee59b7b8d0a54012a7528a9b351b96fdc4", "18761": "a092e91f3c6d77c24518dff8fd829a96d26e5007", "18765": "0bc458092c3512883bcd34f0ca0e17e650609c72", "18766": "011b79fbf73b45313b47c08b4be1fc07dcb99365", "18767": "b9ba7085983bd287ef08963bffbb5acf964db041", "18771": "c7385239340050b7643c614f52fb513f19ac0ed4", "18772": "2d4dd508fa7419a39201ad7befb287d0d72378ef", "18781": "2e1ce1a069537b1cef47ef698d1b029bc5f50cc0", "18782": "71cd230f3ce3e29760b31dfcfa391cd2c4371842", "18783": "454ecfc61891be610fbb586a7d946eb61b87f32d", "18784": "fe52d9f29416dd7d19c04ba7d47434b68c411bbd", "18785": "a197837c4067469478b13e491a21b58cb78ed165", "18796": "fcb840349caa1a922b1d15e7a8e1ab05bfeed94e", "18797": "5a04e6ec929dc46f938197484142ca72f2aa1ba2", "18798": "6d031f2b739ac1197cbb81b36cdea5f954d4e065", "18799": "e413c491e090274aad78489cc17a2e29cbd8e269", "18800": "b4b945adad587851d570e950d05a1da75c5dc76c", "18808": "ee5e79f75fece9254b716fee6e596f72ebba9a07", "18809": "e50b5fee953472c4cff6ec0df5dfb0875f5a1a2b", "18810": "8af76370a10399b539e93e2533ad7f25d77263c5", "18811": "a23f90142352b6427916292b2b9faa7bb61d07bc", "18812": "e98032db44c95325edec23292be84cebed9af867", "18813": "4a6a9187ce14d84f802c09fdef12dd2bd59e3aa5", "18814": "57347e8c7c2b8742b94903809fc988673681787d", "18815": "b92f85cf1068d9623c86240b7b708cd49f6ada3b", "18816": "b53a1a8197dbce71a5d63d28ad9170059a40ddcb", "18817": "db2066b7d31450aaa87f2efcef492162a3d08309", "18825": "f8727ce4e201994f25b7f9fbcf27916d3066d2f5", "18826": "1a42c70e532ae01c95596d071ab62dc535e2bac9", "18827": "e9aee5b5e921a1127e1d2cc57db761840675005b", "18828": "731ac60627257f94e9881cea34839d7a34899ada", "18829": "24bce1a5fdd70a66b9fb5e2f9f51631d1df6add3", "18839": "cc712c9e4325a6ec88afceb30b0142900bc18262", "18840": "84cc0fb71393b685a28afc6bfe323a782296e455", "18841": "97b612f0f95e4650778d12f20d5943efde5f8392", "18842": "e538182203fc243e0fe964883c1e53566bc93058", "18843": "0ab8eb26817191bb88b6fa45b02443c4aba04326", "18863": "34e8d52295d4403670196dcdc8b6e0f29a30411b", "18864": "295c2781049ee29952d4e2a13fb516b1d5cd9c2a", "18865": "9f17a0744440d95f56a08f2469827d0fa14d2657", "18866": "7a6ecf71e0846c0f39864da8fad90041559b06f0", "18867": "df5eeece8ed28462832ee6e762192629c446670c", "18872": "f0b2ff3c0397795c1dca976c3585eb03f1edc6dd", "18873": "01cb440f2953821418e640d163b138518f16fd50", "18879": "99df7da9ef5b3b210f3045ee19279808368def28", "18893": "3625e1e2fa886f4533a68ac839db2749539fec17", "18894": "4f16dff3d9cdcd9c4465a02df773885f8862035e", "18901": "6e932f8d5621c26ed939adbdc740e0aa4524dab6", "18902": "280781aee7b2c689a0f807ae939b59e83911d469", "18903": "8a2238cfb231ccc9745e9fe5e69e80ff39519f43", "18904": "3e01c384b532e32872053bcd71e627c69ec61cb3", "18905": "e405a105a717f55874ef8d5b4cbcdae0b8a21236", "18908": "20ae4543c1d8838f52229830bfae0cc8626801bb", "18925": "8edf972fa07aa3b761756aba87c08fea98499687", "18926": "e5c90e5e355077c4ee5245a4a72833f4e8af72b9", "18929": "94ce05d1bcc3c99e992c48cc99d0fd2726f43102", "18930": "dc0674d66c1e8cd1917a6ec28f0b5a6d3e23c5e6", "18931": "f2839fe813391140a1e08d3c5f71c04bbaf5ab56", "18932": "bea9da2ee55e741a850680f1fcb211f5ebeb4fa1", "18933": "d865e5213515cef6344f16f4c77386be9ce8f223", "18948": "209e7f5e2d3d63a043e6d9a99af77267d62761e2", "18949": "1f02bf240c3d0d3da338af868d056bfc169b28c2", "18950": "dc3323eb32d883843b49615977e139a41546cc21", "18951": "f1cee69a455a3bfbac29685d26e5e73cafe15b9e", "18952": "b7294dd3ec47dffa50f3c8bdf89aa8a01f4494f2", "18962": "448c9bc32ef49a40bef5f4c0f7d0fc055cd0d4a7", "18963": "39229473bc025b1c4fedc79962a5089949c5a296", "18964": "d53a4cc856e7fbdfd7d0db75e8e3416b0640ce98", "18965": "a215a7b7a4661b657969ecd5865609a7579de7e7", "18966": "ee283faee006abf5b879d37fe17c2db4e0fa51fd", "18969": "0e7cf4814ae8f85dc90ed6d8e24f0459be0b75e3", "18977": "2712c8ff8d46b49868ec8704fb915cfbd9cf5c7a", "18982": "30c1290610c65d53bcdd1665be3104104ca27eb2", "18986": "15f70464580d9e6223a63278117b8baaa3261c22", "18987": "440469b806a169ba7467c36ff7c565797b87a0fd", "18988": "580a0941475d856a0cde2df4ef3472404706cbba", "19001": "03658288ce478b2170819fccd8e5bdb48eceb2ce", "19002": "7653a6b43a8a302bc1d88903c8c99730a00bcc80", "19004": "87c643364acde61dac9cc1c0828f7f3056facb43", "19005": "5a91c5330d7d79e6f3fd6aa4d1a224d0ea8e2b44", "19006": "dc8d35aa53d496b651f5e1ab4cb2604e9f7236c7", "19010": "5411421799d14a12dd1762ae618c34eab469411d", "19011": "cfacd4c0167b16d7fc65ed93929de3ca23fbeb42", "19012": "bdeddb139c1f9d95a7b32095884849856994ec41", "19014": "fa547d83cc566e77ba54c1b8fe16eaba7be718e2", "19019": "5b6b346b9db57b610df2965f60753473ef16e16f", "19021": "5b0610b875476a6f3727d7e9bedb90d370c669b5", "19022": "b45eb265dd88648fb02ebb0fdcfb168364ab664e", "19033": "92d25f0da6c3b1175047cba8c900e04da68920b8", "19106": "baad046d15093ef1503e77f4f666752dfbf42397", "19107": "53899874f8c33bf00b68d270beee2640078f3cd6", "19108": "a771b471ba26e4e637d6b159691f465964e5c624", "19109": "8221ee91d15b01a190d73ea10d47af81de296c90", "19110": "91802fb0accde031c3b6aca040a8b533a193fef6", "19111": "7f753892eb6b29aaa62176cb9f00ad84c092c09a", "19112": "9f29f8824f8c0b7462ce657b60f35d4513c77c1f", "19113": "9ea8176f598a2fb61d16d8a6aa0463f22df061e2", "19114": "c994e98c0e216622ad025c0c9e28421a4a3ee6af", "19115": "f6c7f6be80c83ad9f4680fc7bcd5bf9e5b426d92", "19121": "33ca356ec63827acf09c34c296e64f28fd93dbaa", "19122": "250dd5f7336196ac6e93744b671edddb449bd9cc", "19123": "1d18430d0b55b260ab54bfaea7b9a91e3c5382ee", "19124": "b7ee8292b465aa507a37777443efbaecb07b3f57", "19125": "2f6d682a06573e0aab64ae90eeaba216f224db12", "19135": "4974758cf59e21b19fbf3b0943d896ebb223db0c", "19136": "d564c42d3dbf82aa0e9fd013466d07c2db86484b", "19137": "4efc8197e825c12b83c584902d4b93ac944f3def", "19138": "1e658f717de4b8342bcd1abe27cf018a4831d1ba", "19139": "7b0fa8e94e22aa4a491fa574bc56f8ca791f7608", "19146": "ca85a41242af245b32f6c62580b072d1685342d4", "19147": "66e9cfe86497e5e848b56e0b89c4eb0a3e8c89ec", "19148": "d9c814fd38f6ff73c53f286fdc71ca9512b81aef", "19149": "df3b045e92ad139e1b22fce1cb2056c94430f6d5", "19150": "41681c89df25e78d072c862feabe24ec715eed54", "19156": "49b51b81f8e1eec2ae6740919ba14fc143f8ac69", "19157": "66fb79853cc699ec45feee097191c58de042cf3d", "19158": "6077b886045c5fb8d16d88d85ad2f0f19be19255", "19160": "3675c29a7bf8714d3f83d1c6a854325702f81969", "19161": "216986d4691297d5cfec33b5c62be7890b9a54d7", "19178": "c230f297c279bcac536f4689a30f1894d0278d06", "19179": "14c33b0e531ba955ae20a6e37750261133e5391e", "19180": "88aebed582f5ae898aa78e8b3491c212e92c5d13", "19181": "1c37ce94d88021a03a6ada2e2cfea919bb350f7e", "19182": "f6cf7d9e2606e82fd3934e1dac8119c43f5ee643", "19183": "ff69f45f10fdd08dc901b2f671094974194fa693", "19184": "5d134ec1a9ab118abbd16157bd161783547117e6", "19187": "b36e06c704fac35224d984102bb0db50ef1a20f9", "19188": "71332c4f7b5c6f496e4e5dab75cf1e33c2400d74", "19189": "95f73c3dab1eb472d27121c09723b8abeab9eeb7", "19190": "bab279ab76125e2622cc8dc9a8e6521e88a5a1d4", "19191": "0bb3772219c5532f4c9703e4e4f2a2e844ee55d3", "19192": "8c58817bd0eaca46d7c0d0c975715ad37fe43710", "19193": "aa3d56effe18031e6377a0714a145287445a4b89", "19194": "3e0358d869f8a76b3223e8bb313a92edbaa369db", "19199": "d7bf6f2cc870c6ba5e465307c5e8271cbaab8af7", "19200": "0c593ae9b6c6b843026809ced54251014688c123", "19201": "1cd077a3077352d63c1226d554db1e46cb9d2c1a", "19202": "0d2cd533bf93260d866dc8ac3479ba3797ac6a14", "19203": "fc7bc3f74d1f5702bf66c519ad190126538a8f5b", "19204": "a71c1216f4b89884f6bcb631b84873240a38e3df", "19205": "9f62f5e6cbc153cda48b6e8b3c768916c80ad968", "19206": "195cbef27ffc2ce59bb65083801ffc6c773a1967", "19207": "6b31abdbad403255ec995603daa42ccbffec7543", "19208": "159772d0c9d49977d4b7f871c62c26e06890143a", "19217": "52a2bb490556a86c5f756465320c18977dbe1c36", "19218": "8b4b38fd7995cb59b0595f2d06cb4b984b5886a9", "19219": "1d86861681d0d4046f3d391f641c8bdfd86eb61d", "19220": "9fa063ea398b44d20f16c12ca04e533c9ca6223a", "19221": "9ed49eb936f2dcbe824a91fa1339647f052f73f3", "19229": "b66114d8cf9c5ab47fca0848807a4d78f322207c", "19230": "73801ab9cc0dee4637e52f16e571bba28e0f21c6", "19231": "24a50fc3028ff52ab37ea38911f34c05a746181c", "19232": "459ebb2ad309938e9e68ae79e3bdb312efac0ca2", "19233": "aa1549f7fd8ce81bf23296bf92fe9713aa8d6e20", "19235": "5a9f4521fa2e33cfbdaa48616471ab4d16fc3a62", "19236": "6cfa23e68f62069c4f16be80b80e6d1596a90234", "19237": "5b61eafbbf6fefe4c06eeb7b269838a2185d98ec", "19238": "ab55d05e7a12ebbccfd71511d36efa075fcfa0dc", "19239": "336b8d62e3ba184f5e9a857187f9b06e83092e2b", "19256": "70bc919316db6be6be8cce1a53dd54d34f25ff98", "19257": "6c5057258b332add112727fe40f1197ff09749d5", "19258": "aeff38d3301d4d31650f6624304259d0dfdbd69b", "19259": "41b2b18b94ade34a172483cf8307ce16bbbfc7c1", "19260": "02a97c0a150377fab02fa22580d232c8242b5baa", "19270": "0efbbc29e58bb46835b8f0cd642c87b996fa40a9", "19271": "c4ac0d68b2418e261f2fd8f3a9f8eca0d5e20474", "19272": "fce9ccfa575a4b3c88c0313f3969e1501fedf65d", "19273": "03244659485a1d5fab229bbb0a083638fac1336c", "19274": "43c4dcd45a50de04658dc78c7f2e5c62eaf6b5d2", "19301": "091cfbb053c8522acd4f851f6a93626751e77dbb", "19302": "c5af28263f7eda1bcb9c15c238141727507c8e46", "19303": "8f3aa2be78dd42fc43de6106c372c45040f025e0", "19304": "d659e7d3df1576b265037f596086b4dfc3a51d70", "19305": "945445d84daa07664dd3691142d23356a5aff70a", "19307": "71efe61b457892dbd7dce5ebba5d1cd364a8ebbd", "19308": "f67c97e16fe181573d9d3d9bbc14524d4153abdd", "19309": "48dad14953c26230fa297cfabe1d57f15b736123", "19310": "f67aa133d0332a8a1290aa775db582558163204f", "19311": "e76c90ed99efe6b2b827b10c01d759f85ece8045", "19330": "afc2c86c7d4df06ce4b82585ec93d6925b66e206", "19331": "268150f191884a554359de512ad6330977501796", "19332": "00391586e86f990804f5034c6f9894575080b4b0", "19333": "db051b94d50cec2a5f2a160b36d67716c47839c7", "19334": "479ddcb63131ed48862c2ebffb8a94411f389d83", "19370": "c6b09e418873003c6913d3ae3b60e496a44c3d59", "19371": "8730ea9ee3c76382525148b56f3b822f1194b728", "19372": "3ae422930836192aa285649e58b9a3dffbf843cc", "19373": "62a2a11d2be09bf468eab304fd876a21a9658411", "19374": "d106e9975100cd0f2080d7b1a6111f20fb64f906", "19383": "e2fb47badb6ea386ca9c468e19714dcf8c78d788", "19384": "b9d2700a548d8dcdd3e97f67c86e2f4f8f8f4cec", "19385": "2ed7adee60a29a50394f6b29e0c99a72e20e529e", "19386": "dc91f4cb03208889b98dc29c1a1fe46b979e81c7", "19387": "88ca968ff95583678f257bcad08c821e9f0f82c7", "19390": "393d0aa1dc1b2b0cd478cbded6fb13e530589c4e", "19391": "7c842b0312064bbc6bf1201ba6dbb774da90ba0d", "19392": "c4994ca56b5d6af35643bd9f20d39b090acbe5ff", "19393": "ca842cc4bab2aa9d2b48c051a597d860f38345d8", "19394": "4bf3a0e11d2e98afc9ee76dbe54a667410d0220e", "19396": "be406f316d7aa27d565894059fc609329f055972", "19397": "4e7f0747944a920278791d051ec8e587a513da2b", "19398": "fbd39d9a708b6a1b41372c7372f0a238a5a86c43", "19399": "f13859dd3f5d89f3e45ecc67f719793326099ada", "19400": "f57bd72310207b36e96604056f01cb77f0640b3b", "19401": "6bd17055ee2b6fefc77029ef082c29dee5eb03ac", "19402": "2897fca7f7c3febd13a4558827be29689d087aea", "19403": "caf462c2a7699daf4b149d49f5aeaff822700113", "19406": "9744a4de1952188114587bc43cc797448390305f", "19407": "ea8c9bf5167c6ae3740f56b9fe2ba60500c96ffb", "19408": "46a31c9944a2f6c25282f65a8bf8247abe848bc9", "19409": "decc8ce5601c32dc2313f0d2b1d611164262cae9", "19410": "d56db9d6a20b063ce27b6e8c898f0d3b5db2e175", "19411": "3f1e5940e3929577f094ea2708f94ee184e7a336", "19412": "021cbae52061b660b2251d6c4dbbfa6d2a246325", "19413": "4bd286a5ee2c15f0e9c9ef56be1474d9abee9f41", "19414": "bad02e8875e11e03d438d66e38785203549a0b87", "19415": "d46d2a5ea900c59439dff58942e79ea8b39e918d", "19416": "e2b20686464b5990594b079e15449766f85dd85a", "19417": "3fe28fcb6f4292e7d6c01ea78d6a2a21b0bac16a", "19418": "7c4efe09b7803967f75656f856138c732a888884", "19419": "c1a81fe512604ff1b241e688d145dc7628558241", "19420": "fdc4db25a9988a7b595a3756760d05a6c177123d", "19421": "33f91d8f9f2e84f2b5f3ac3f0481b691c977c427", "19428": "f160c7d7c63c11f8807ddd1e653a95821e82269d", "19429": "10a353b5ef2d9436a276c95d5ae58d778cd2a2a9", "19430": "cef5e8a1a463351b8742ed7baff7e09b8be42eaa", "19431": "306e733626b07a3bbc8f9d6e1fde6f84d9b4d579", "19432": "453fa85a8b88ca22c7b878a3fcf97e068f11b6c4", "19433": "e2bf1ff491dbdabce1590506d2b1dafca34db82e", "19434": "ff40c2f74abecd3e898eae79274b24b4745eaa0e", "19435": "6d3565a5181b3d0fb8342e69dd1d21a98ac3d380", "19439": "0bd454cdc9307d3a7e73403c49cc8350965628ce", "19440": "02b5d9f509cd20dcaf08d65844f270439767dbb4", "19441": "57a6f44868a0400dff9c62cfc7fa12fc631c4f05", "19442": "8ce64b73fa33d85fb2c900f0a6e2b6c382e49500", "19443": "5a15a37dfec62678788aba6e0d4b0dc77fe43549", "19444": "b99f8bc3ce4b0d5aa71e2caf8db5e6dc4dbc42de", "19445": "98f46f7f08e9f15374fd840507438cb237313a9e", "19446": "0bf62b31e431faa102caa926ca1ff148ede53ec9", "19447": "17a6bc56e5ab6ad3dab12d3a8b20ed69a5830b6f", "19448": "be26f6dc467a92108132b309d9fe9443bce43ef8", "19449": "9f4357b40a3d844aeff53e7cccb627277275ab73", "19450": "512830b46e678a1c6bd86cc60f54d74ff75792db", "19452": "2bbe418409d88f60daeb9e12e738cf8c9633eccc", "19453": "08f92c4c86fbb4e03d030f24ea66402f6deee6df", "19454": "ccde0a8bcf25285160a67847057ebe8847f71a3f", "19455": "a07d68582cdc49daf3e6a14a1e1fd7064670d696", "19456": "7e6ad8634ef6858664d3c9b48bb1942f23ad8890", "19457": "aa05e542bc47140123157c5854cac498c3541a8c", "19458": "bd3c001ca668906c0956abd76cc48318c9bc95ea", "19459": "e984947ab42b2c95c5acbe37cf2e24786a51980d", "19460": "1dcfc5fed3645627642a4e5c7453bdaf2809fca3", "19461": "f78790f5932e0648da4edecffbb1aeceef35432a", "19462": "f4458c18287288562b21adece524fc1b046e9724", "19465": "2d47349122a8baf61d7b33d190d0d1d54505c776", "19466": "518b237ef515a250abf5ba403563721754d39c05", "19467": "af82b2a3fe202d1ee5691e33e0a7807e6f7499f0", "19468": "01e7872b018f8ceb1c5d1217caf03d5ba4da3602", "19469": "402d5dbd455bf35b875ea3c57feeef3141eb2bf0", "19474": "6d918f07240275272999784e775b3952aeb2ecfb", "19475": "12bb6d0536b947f74b66ebe18b5f451bfdd7453f", "19476": "a49be7f4ea4773af5b801ebd9504a20e5b40b245", "19477": "853cd7031ff98737b9a50404c4a181dcda67a0be", "19478": "597f9f31639eeb5724e49bec602e15b9bf8be092", "19480": "8972ddf13f6d0ba827f99a63d4261944baf3f29f", "19481": "14eac280e1b7516714d117e65b45023dee7feee7", "19482": "4b937ff59127bf0edec8e07a667fa222bf2e3b4e", "19483": "6a745d826d9d5f5f46e208b0dad4d4ce0524defe", "19484": "2fa0835737a0e3e111e893d30ed2f25b7249fd4b", "19488": "e2c0b120eb19ecc93a70f9a9c3cb51417cb55d1f", "19489": "0a4665a5fe716c28ec2e756611b64efd32d63148", "19490": "fa12b9ecbea36a504249e74579ee2124f98bcc3f", "19491": "5761e359b65631db491349a65fc21d0da51dcc0f", "19492": "539c54f30736b4163b70f1ba903aee7a4243ab1f", "19498": "14b68eabb4b7750c04ccd3ed17247504aceae35a", "19499": "8a8a0830f5a021f7c8d272fabdfa699b4502edd3", "19500": "c8aae3540e4d22d2581e66843740fba10e9ea0b1", "19501": "83eb2428ceb6257042173582f3f436c2c887aa69", "19502": "0c4113fa0906273007cc12a4bcadff85d943dc84", "19510": "69a2c54ef4c3df06104a0528b2d59a5b7521b23f", "19511": "95415406d191eb5b0886ae107a7d01f0ef39b019", "19512": "37a224d216e8d49a05681e2c87482bd8e67385fc", "19514": "602eda47da1f560252ba4bf386875a68e561452c", "19515": "95f8dca47723192ddeed5a2f198d0521c687c9aa", "19516": "2b16e2e6c5a298396727fc2e66a60edf1eb13bf9", "19583": "1700680381bdbfbc1abe9774f96881801b24d6ca", "19819": "cb00deb94500205fcb27a33cc1d0df79a9727f8b", "19867": "27aa9d8733d20c5d96d9678dd7a0c0773ede58b7", "19868": "37d04a3d3df82c3abb80afc2ef6fcfa0b7d5df44", "19869": "4c21e5c982614436c1fcc32ef32ac83f01c0b7af", "19870": "85c3f82dff73ede6d5d961611518e007c8ba0098", "19871": "fbe25233345b750031911f0d4b0845fa115c4432", "19872": "cdfdd77b65df350386ce27142ef3babd9e5186d2", "19873": "0bf9f146f208e5df2e192569c3e34149a9317b08", "19874": "8b56ea30f185dfe9e05cbbd5e5be261388354ae8", "19875": "f39a9ce580d25c8273cff717d13a7bc8601aa339", "19876": "e31b4f46df6ab1182c16183f48df76fb4beaca0f", "19877": "aab42a2a4cf154c710d4c9e265742c00adb6b4c5", "19878": "f2bcb9f0060d030085cdbaeeb638664c6f73e636", "19879": "1f7ef05ef4e2e5b72763d8f32d79e3495c364d35", "19880": "cd057c7a3675354ffdf6fbd1939fa84b6c06ded2", "19881": "0d3e0e68cc4dbe0620008d98274d0004dbf5a734", "19882": "9e27f1298d4cd1dcfcf559937125e547c0341f0e", "19883": "2b67692bee7a9d7315eac93eca1a01950e2813a9", "19884": "6e0f9a971bcd07a4a6283dc03190b4363d42e292", "19886": "2618b218eb4fad936310dcce011acc1b79e0ed96", "19887": "72f4098ca91fb7f9051021b0f78adecec3f28fdf", "19888": "dca809b0151adb744940a727f5d82ca43f4c3ea4", "19889": "fd6681eb4eaab3c359588f1da0bcdc5bb978d851", "19890": "9821b77de692716d7c2b62db1a68cac9ffc456c3", "19892": "d8642e903cccb8fa0ea4d4477c89bbc1523b8c8e", "19893": "d37c531075322b4aa115f5f9f0cb9173773afbdc", "19895": "48d76d65261611d423754b62a7d860f5b5362faf", "19896": "51c6a05477ffb5835ee52fc0bbb26e2f64f13bf7", "19897": "324bb84c8e4c84b4103e9b2bdda2d99e8ef549db", "19899": "b878f5b5e3a8b90a75815de25815525d49673de3", "19900": "923ac2bdee409e4fa8c47414b07f52e036bb21bc", "19901": "d40446044fc240f4ec6904d12a7821f0091f3b29", "19902": "af6ccf64dab57cc90cce1582fea60fba13b2998a", "19903": "95c78d650a420eb3282d5862a088b00617e09588", "19904": "2beb1b4ccc78f16d5277a33157c7415ebd702b92", "19905": "ac318d26cdbe3d10030f4863b84a06e938da9bba", "19906": "850fbb503203f2fb9a8a1448522e02f0437b2136", "19907": "882961df6025b800b899d351c243412e799accf4", "19908": "68dd97931c364b2ce281c3ad124de21dbb6efe72", "19909": "31b4019ef290bc55855e079b2b7dddcc39a16fc4", "19910": "96a128eaa0a7425dd4285d219780ef29c2727e46", "19911": "8b9f933b221f7a1e69c2c1559cfeef5e4dca7ef8", "19912": "7721f7009249e2b1fa2647526114e7c423fef4ea", "19913": "d2d9e2df7c73df370f7985385c1dc5f3b4a56b4a", "19914": "19626d2567487f8e698174de835c28c900784ed3", "19915": "1d4c89f4d747854def6c32733383b4afa250165d", "19920": "e1aa6f3c911ff46cd19abd964cab82d400fc14c7", "19921": "3de913705283b8c6618f32693e65399458fc1bab", "19922": "f0ba498f71a9aed5b9cfda6ad6099fe9e7292cda", "19923": "819fc1525488b4da7f3d76051a85971a2e004fed", "19924": "de3a85c8404505ace0c0febc26b1fbe824f48034", "19925": "e01bcc3a28c92e39f79ae0acd13b9abbcfc5ec11", "19926": "b727c6b328c3c586ddab54baae36680a0992e961", "19929": "c7c4c94389103c017e950b37191d7c267a75fa22", "19930": "00c119c50728bee88a5e5d1538cf3a405e36997c", "19931": "485cbbb9da072e19b5bd81b1e6b7f0643b5e5bc0", "19932": "f90f4aad4589727ebb3235326970a9110aaa309f", "19933": "4814a2875d078d6e9e9300bd1f77af15ef4f0f0a", "19934": "9caf58f3ee712a26b4ac9b9a2501141844a455ce", "19935": "d591ade7b1053ce6bebb4501578474cf9544582a", "19936": "1172d61aa8cb66e76af2bfdf8a70444802b28c6b", "19937": "caad3b5e566d74d5cf0a018378d71625c30bf145", "19938": "435e2b58c8279560b5053ec0fbc1a27a1e79f2b3", "19939": "8b15dff89a0386110459bfd8ef6af96c75320439", "19940": "1679e542385ea6e4b80908b9520390420cc5c2dd", "19941": "70773d952bf52229d7214707ce6d66cee70607cb", "19949": "9fbb9e7c71cf10852b84c1f393263ee04bd790d5", "19950": "1322eb05f315802d36b3896a59e8e314d2ffcb9e", "19951": "db2d16aa671517d28f06ad3c337125f9e1fb9fd8", "19952": "77713d5791a21faf88d49ce4c2505cc2eb7f6642", "19953": "0b031306746511130f19e6af33ca317f942f862c", "19954": "fc5f292377412fa7bc824d2c2cc69f2ae45bd7f9", "19955": "fa9c7de77ab09835cd0ce883623111cd9af68811", "19956": "181f972d2f4e6bd5c8c33721175f68188cfa1a0d", "19957": "a1fee9199eba7ebf423880243936b9f1501d3d3a", "19958": "6c613c8e40c2210826bb2450803ec52658d5667c", "19959": "d2f9228b060a6a5a4d3d3cd2c573cce60f924a13", "19960": "6de813364fd4ebfd16e2794e5ac3422d3bef87e7", "19961": "0610a60d06c190cdd597480962f98b97de7b4286", "19962": "af0ecbe01a7f70461f28e9ff383ffda0246a0850", "19963": "2f6b90aaaab6814c102eb160c5a9c11bc04a092e", "19964": "9d66bdf1c6f252ba8a9f7b3298877d9c021a84c9", "19965": "2769ebf3da8d9c2869ba5811ae9409d84b0cf28a", "19966": "6bb9ab8a60b9914bfc306ca3691130d583e02656", "19967": "6d9b702a661891724e6c10dd96eb149404205c67", "19968": "e02ec8f89a743cc56a79e660b7be850448d15f61", "19969": "a07ed594ec6a5befc967fb1b18244bbeb3bc2bf1", "19974": "feefca8398c930cbbb1c636b328dbfccfa7dbc72", "19975": "22c2b73857d1035685d42b0df56f4762ffad0611", "19976": "90a85e0b154833577a4023f643d8aace0c0ae7f5", "19977": "b1340829eaf6ea8e470507329fe6e504ec99e2c5", "19978": "5a150694731d2ecce670cca65760c472338a04fa", "19979": "190a69e3d6bc3f106ef635ae18ff0fb8fdfe85c0", "19980": "4e7e7f0dd6f60556a2b3abc6078af043302ed852", "19981": "e26e2dfe6e93922830fb5fb7868b87238b85911a", "19982": "d9c9e2f01ab53de2ba4031367bc570ce66dac374", "19986": "455a2cdc4808890dd7eea41494100f48f34794d5", "19987": "7b3bf2dc6b8b00133d2cf46c1f70f2865666a13f", "19988": "b90f9db6d23f64b0ce9ff469445e1c31013a07c0", "19989": "d86553b00fe263d264bd0b2ce691724591dc7b01", "19990": "aad77394b14f1997786850e6110154d4c78faffd", "19992": "32d66e0c6c44e26831a0a369301f2d316f53a844", "19993": "4b1624edd6af26b11d59696479aae60a1c8ae7c3", "19994": "fd1c3f868d2d8f8763cf126054ebbb5ae367017a", "19995": "68b1da7f53f043b21e3f722e8872e19941a10250", "19996": "057b2423ac7d5a972a05f4ba602d49ed6a3f75be", "20003": "dd9c585e7093dd752b7b3630abc7a1e77571f39f", "20004": "1c0f8cf0546120627f4133896c1cfc510667a82d", "20005": "c18c8be779240be49872860ddbfec9bc5ef0a548", "20006": "ecbb0efaaaedd5b3a2937eb52af761a8402c67c4", "20007": "f53bb061939fb54d6c826c4db408c458d3d2a1db", "20008": "c79b7bb91236a2e4cde3782d23109ac1f5e76dce", "20011": "3face07520a50678d001987f0f57e327ab4dfb87", "20012": "3e90d436e82ffafb9df287ebd9e5052387a251c0", "20013": "c4bf97a3ed615705aac1d170569a5f162bdcc1c2", "20014": "7706741fb92a97d09c63d1858cba8558e032ce1e", "20015": "dc86509b44b3fb0cd9a1a6d6ed564b082dc50848", "20022": "84fa2ef3d17f63709805aae74b2a56b143c551da", "20023": "5fa8a3158226178655d2bd46ad65af61b88971ab", "20024": "61edc765ee3d12a2341ee667d6aee3d96be3db72", "20025": "bbcfc7fba2c730d4df18f93f7f95ad439c26c31b", "20026": "947bd7662afa8b6dc4406ec52cefc39d76d2d6cd", "20027": "fecee8ffe39446d213f425257c6de24b5a7f9021", "20028": "e134ddb727069e50bd76c319d9d220fc23ca170f", "20029": "b9e46ad1b10bce78464a07454dafd680273af6ff", "20030": "fdda543e9c3158e166291e31b50231e6ada69a36", "20031": "a13ef664aac05570eb70e5d6d28656468f6d467b", "20032": "3de4a85089c4c3647137f8c5b41390f6b490e5d6", "20033": "d74901b1a114d70244fb919e8de630fb53481b00", "20036": "b62e9aeac6b646a7d4a1f63d88dd15e347ad3719", "20037": "4d9de8dd9569be2eaa23652d00b9577d91ebfd89", "20038": "88062f75dbca929ec082295c936edd07cc912dbf", "20039": "33e05d7432e3f580d27c949a0ccd87e5bff307e2", "20040": "444ba646944c6a44490633587fc779d39b55cbfc", "20041": "3de7139db646e705050dd38402929820a3b265df", "20042": "b2b09b7fcd2cc4fd151eb2ddbdea6cb0dee81993", "20043": "77855a1e2d4a406e6dff7c629ee32c0b50c5eec4", "20044": "e464a88a90d1c4b61ac1f3f240ccc0a88347f04d", "20045": "65466f04025474c3ee1bd2f4e49a1c5e24b76f7b", "20046": "64104ec343f0770afa88f02da47b34fbe62c8281", "20050": "187630bfe314fe4428e41704f9bfc01797f7ea3a", "20051": "48ea04fe5d3ba9b618152ae83aef703dbbb2c3f4", "20052": "f572ec4d6f652a9cdb793071d182c0febda14153", "20053": "51980fe369f75e827143f21b6b26e0d6a86c8c78", "20054": "9feb3ad92cc0397a04b665803a49299ee7aa1037", "20059": "f54945ea0678742c4785b0e88a2fa99f62cafa49", "20060": "66d60239b4c43afef35035150d14a9e00e00486c", "20061": "34da8be0c0c5eb869a1f57efb76bdf97ee0667fe", "20062": "b6324be64884afdd2829e046748b7e843e338c65", "20063": "7eff62725a3988d6d4ecc9edb87441355e33d75a", "20064": "80be9b5defaff892e3362a31b44ca1479c2847b6", "20065": "d3b9d9f1350117d257d3f6832a2b5adce1b4e35b", "20066": "4df308f441f84b99d59691e7387c791cb84222c2", "20067": "c2c79399377f59375723e58b8f9ccf86cc608be7", "20068": "7fafb356549f1c52a9896429ce0241487f42bea9", "20069": "d1e4ec38576ed558f8a14664b30f8e63e00b586a", "20070": "d49ebd4191887ebf35ebedc6c1a1608ce8e9505f", "20071": "1175933e11e018a8afcb91820917d650e4774359", "20072": "0989339c2bb9ed583889ee86d584f4eb8c4362f9", "20073": "e854ccf173a195e582b965063c17eee75ef2c92c", "20074": "a8d61d39d252bb126dc7972cefb00947dd9d59d2", "20075": "f46ab96fc3f6fb2e764295b4922f5f5e2323d2d8", "20077": "8ac31233f376291c231a286b69851526552348ed", "20078": "a0c965e7b203d54633c7ea30fe8be60cecf8c3bd", "20079": "ec2846a117c098ad9bfc6f71cb77c45bac0d9cb0", "20080": "cc3b2f0a185e5e81ff219fc06f57eea92f629b2b", "20081": "71207255f32af73cd701fe4ecf56a643c925a9e1", "20087": "2e4e0b9058cf9f5a3ca81d2fb405fcd3b9317951", "20088": "ca1a36ab3a793d9a87900537de066fa676cbf237", "20089": "07cea1971902cf35b2094d06962ae0bcabe026f9", "20090": "749f456c181376e682b40f0eaa3818810bbc6f16", "20091": "5eead579fa9eebe4af8eea8fa36248737fbc39c3", "20092": "64c1127aaf01b501fcc8dc4d31d00accc712952c", "20093": "2f182aa5909df64fff79b3a4152bf2d24b3d810a", "20094": "f65742cd47d6b364a2cbf150869b282c5aa7daf0", "20095": "2bbc0c2c198374546408cb15fff447c1e306f99f", "20096": "fe98ba82c356ea47ea42ffe33f45e6be88f5658e", "20097": "20fa58d48a7788e980a084ac05196cab2cc055ac", "20099": "7bd7fab10796a8559040880098c927cf9bb0ae4c", "20100": "6d7ba051508b93fbbc80f6929ed6f2254ab7b938", "20101": "7bfbd81b44526c88bab575a6ff6d229cb89f5e1a", "20102": "23b611533a3f66eb42db23b8532adb7a14f23df2", "20103": "d024aaef04f938f30ef926e7839ac70e5311f1d1", "20104": "cf9ed41a51211027e313261a4001b74adb17ad9f", "20105": "2bca899a6e96a310fcc14c1ad978340a71ba04ed", "20106": "17247edf8439d290cd5f9410df477af8d399c839", "20107": "ee6b1318ff07806ead79dac8119ad9ce580afe1c", "20108": "58fd4491ee4aa49f628da81af978b15db16164b7", "20109": "c8eedd26853f1ca0a8923ee3196a13656b141eb4", "20111": "bb0376c209d97e49b9c94038926ee62ddc0ee84d", "20119": "971dcc11c8d9d71605582e6d37a4cdc65d996ff3", "20120": "6b51c941b29db9cfc48327da680de4b2ab46178c", "20121": "4a30fa52f9b31abf9bb6e59a2baf2686e8af5640", "20122": "bc75a7244fe77cc52cc7cb96426abca2f9462570", "20123": "b48d1ff87237cb68792590f4377e3be5c73d5ea7", "20124": "e26aa00151f8dda02e4c6ddf3e8c6dc8b31400c5", "20125": "a6e43a43f2cb1b4b7d46b262be2efb825d033eb8", "20126": "2123a96d6bc5b511ae1d1109000be7055deb2b8c", "20127": "304d8d4bc3b3cde7e2b463426bf484701df142cd", "20130": "612c24433b8486eb6b6b0013354dd6d6a296c100", "20131": "7ba2ec8a6300289cf5dba39782dbc019103e0343", "20132": "ef7dc2f46279a7fe13c75f36e88678717096af11", "20133": "e5d15b20e828c66182a4e175dd5a5b9b951d9950", "20134": "3b24fb678672ecb6ef24a1915c49f3cf815d5556", "20140": "241af3dad76e1410b34e7e0dbab8e019673e9af4", "20141": "e101dd94094636bcc7dca43c97ce5f0ca5a3634b", "20142": "0382f204a8f3fa72db433232cbd7d6d4bd66d823", "20143": "80e261555adc2f58930f2dad6c765f25e7dc8e08", "20144": "9c5165e26260483ae64300c4d98939bf575aab7e", "20205": "8154efb0c1a64295cf54e00025b4ab09bcd02752", "20206": "a60d1bd45a99519fad5024068db956e0aa1cc6a1", "20207": "7c8041b9b6dd44a7388bc8518dc0cd2f7303c2d2", "20208": "4c54dd298692783f417cbaa57d5fc1c0dc1f7c72", "20209": "0041935572774c6599dd9b48e9acc7cceb559004", "20210": "7f318658b92155678b31780722277d1f8c8df569", "20211": "c6a7cc1e08f9203caf57599244cd1c51f6347875", "20221": "73d8f96bac5bb0bc58eb6f69d47ea4329b07c6ae", "20222": "9a42cbe85461c28417a5130bc80b035044c5575a", "20223": "0dbb99efc259c5182ac88f116ebb76ae6e2db6ee", "20224": "3db9dc308bad04f180950630f5966cbee27916a7", "20225": "437efa6e974e506c7cc5f142d5186bf6a7f5ce13", "20228": "efc2adaa3553f647737307aec85399b627002c03", "20229": "5c6dd43e3e85235f32444df73abb66528336b319", "20230": "4f332f6f4b27111c9ab7ba686b3bc51db2e6f7bc", "20231": "0e3bf7f3478ffb85d64e795d72888bdb9bd9cb4b", "20232": "635458029e11ff6d94e8132577075269fb79832c", "20233": "23b0788118bd95bdf1adb8f86d667fa54a033423", "20234": "8d124ea4c5200f218db7cea8e3ff504b0045a4e6", "20235": "101370645d13e1d0f256f367f4ef56a8329b56b6", "20236": "454b8c5cdcea0cbba981d607293b990cc704f3a1", "20237": "c07d71d13b21e0b6e22146f0f546f1f8e24a64b3", "20238": "e25fd0d8ab10d6cc4dfe0f5808976f7921512c9f", "20239": "01d97d48b08c546a46b91c27a5886f52b46f22c2", "20240": "c57f206360108c327d8256e716080fb1a2523fd8", "20241": "758e35d7c8aa46279cbb9d6191ddb9842f1ce31b", "20242": "6ce7fc70a0103aaf8d6d6ff908a61b561447c218", "20243": "8ef9a6356f9f00e22908dd04aa47b2a5d6c38725", "20244": "e0c41f79104c5bc61952c9a14f1883cd5bda53f7", "20245": "047d32d20640898978dbf6d9855cd6fecbbcf0d5", "20246": "1d7ad5fd7577f3da1c8eb19cf547f62d392405d0", "20247": "30d9cf30c680596fc6e00b3e06a30d2fc62bad69", "20248": "f8b4c57ad1e4f1a105905c53ffcf40a5dc5080c3", "20249": "891a419a5155e6b42c0696a81cf853b6f3febbf7", "20250": "5a724b5cd796a6ede3cb95b8687eaf561e9d57b2", "20251": "5d2d6b4d21439861177a1edef74fbfce0c7d720f", "20252": "78ba7fcecd46b039739f13bb04bf6147463ea376", "20253": "c9c6c221865f2988c0f52dcada6b033afaf23a8a", "20254": "649ad5c91aabb95d7f200eec84b82cae1459fc65", "20260": "4d916eff3ba30bcbf9f16b8f53469088a02ff19b", "20261": "9a67ff478a2e9fb8c78e43fee348bbdb26d6d9d4", "20262": "ef30df84fcd89e8476c5ba9eab8fa4ad36d5e51c", "20263": "1cf1b96fdfa3d6153637f3540d6bf9dbcf126167", "20264": "cf25c5cd3ab1f647f780167df622c74b737fa8f5", "20272": "be2face9bf243583f05a128d2be32a2365caa6d6", "20273": "caed3133555fb80c8b6b78af6365d9de81e421de", "20274": "c865eec3bf7ff04cd420082d3fa3952d6d09b6f0", "20275": "b9a7f612677315a602a0a2b82d88e26677c6e2b5", "20276": "c7748ca057cad4a80a6c4cbf8b49c5d9f3e7ea1c", "20277": "a387110c054e0f9db40cef6b05d3cfa804532dd9", "20278": "9413591e3e43c5b3e653f129029dea032e2efda6", "20279": "f8225bc68bd3326fa3c5191852ff776d1e78b6fd", "20280": "e935c7061e2806de05349276ab07b994effddbf7", "20281": "0f3e8e8bd2118d56c7febe5d6081c5058cb22be7", "20292": "f4b6e921a25a66d8f2020071f9ac5a864c5e9161", "20293": "16e8ea8a878c2e08af9b89f08d049000b99e8d8c", "20294": "157a4e35d25cafdca2fbc48ccda2c14eb7f25bcb", "20295": "ea06f8d1157601b5fdb48598e27b02149828fba0", "20296": "370054e35ee4512ce247146daceba8af7bb99de3", "20297": "f0a4c430583bd091a04173196ebdec00602cfa58", "20298": "deffee680b6494b9f31cf68dbd404cbf4f776f9d", "20299": "b8ad9da4213be55c587db015c640d927aeb7feaf", "20300": "129aaea46db94d5f8296bd5daeff9dc124b1a99e", "20301": "b72a4ff097549aa512768b682d2fc709cfb96c5b", "20306": "429078b01af47b356084c1da270b5b275fbf50f4", "20307": "e6d27ecbdfd2852be48b76d023e9ec2b07c90c4c", "20308": "a137a9c22a4d2a5be6c345cc76b92049a5f0c14b", "20309": "634577eb9ae53da6c16a54773f9f9f8016e2a1ed", "20310": "d66da6015558faa8a7f4516f72afd382e77ab9e7", "20313": "a00659a82c9bbce29554d75c91d8e897d064ac18", "20314": "a60888ce4ce9e106537fb410688b66baa109edc3", "20315": "2d2606d8541ecf114b8708d9e6e8f9a1af7ee115", "20316": "14ee9dec1791e72ca8b13e3a93ffe2a689ac9c5f", "20317": "8374a1d2a58245067669cd6424793b134a695971", "20319": "5d0ff69544d41b5be66d58f1cc1907af676f828c", "20320": "137a886b658477caab16b5efd3c8bfcf2f1888c0", "20321": "7ecfa8eb1242a78ebb71da2f18a5b380488b1c2e", "20322": "f6e33a010fa30f25b032618cbb9677fb9dbbe8fd", "20323": "430f0fd04646a0ab44ccbfbad706dfe22e9fabfe", "20324": "2115bf3d58ecc20aa2b10e05574eaa06de1e56ec", "20325": "3381c6410c978c5808d4b864a9cd3b6a6bd9a412", "20326": "21fe224627a07e9c913d8788026a5bdc32b28b8c", "20327": "9326c1e20171a76af37251356726aa799904bb07", "20328": "adc656433ed959a9454ee6f90b5b6b1b9b9c3e42", "20329": "a890caf47e797c853b790b468b33de90134514bd", "20330": "baa77c33fb71c29acea21ba06adaf426ed4cb561", "20337": "5828b314f12f4f59d3d65ba182cd069cfdae5625", "20338": "9ceb0295e3dbd3b94c70ef90d8d64731b851b07e", "20339": "376a05e4d5b11f91bba8a3bcd422cd881a7b3511", "20340": "d47947a79099d650b4bb981a38ce09881ec6f43d", "20341": "baeb1bf92b763861212d0dee951bd8ea658deadb", "20342": "d150f17384f53c3269189daccf2276d1aded7936", "20343": "cfd65e98e694b2ad40e97d06ffdd9096a3dea909", "20354": "224362951942e1f4e05fb8948596620aedac26d9", "20355": "dda4c1a89cb0fd690a7fb24523f392f18846fd94", "20356": "f2aea09e7ce6fd6beb20d2cdffa44edab6f285cc", "20357": "ba69f95a88e372e748fb6d7f29aa4b06bad578ca", "20358": "dfcd2b2c575d474014908802d9cedf1ac3259635", "20359": "9088f5ebbaf098bd7113bfba7eaa6dcdbf0b4c3d", "20360": "171615a35574a1fc9c4e8260edca7d1e08e9c302", "20361": "9aef32db29925bec7a0372b92a63cfc4e78398c2", "20362": "a14874f3e85bae66c32ab1ae4c1cd8a72e741ffe", "20363": "2b9b58dadf8a4e02b94747b6c8b22bec4b6eeefd", "20364": "b4d4ec5a36acda40f13a8c3c3e19262c095d4c41", "20365": "e27eea8635b73082f93d44f0003f6ec5b92596a6", "20366": "cf74b0272af2e13e5b9ce40c8bf42df750ddc560", "20367": "83fe8d78b6b086f3ceabe81cd420a3c7affe9aba", "20368": "8ea2d087cda0f40a4e41ce108a32859d51b4d69f", "20369": "2da45994b63062396a2b75ead738b5df8ecc8070", "20370": "606178a91c4003f589ec64b08f853164fd45ada2", "20371": "f0919f272d9614058b5ebb5e0664d1ac6f23540f", "20372": "f5587633eec08212737158df98e3afbe3afd06f3", "20373": "c9182df84736ce060c30d386c9f3a97614ca7778", "20392": "8b48f5c75a058c239a5d0eb9ee4f1593f1be1810", "20393": "de0867f8bedab9ce7d8d4f46267c4c123ff3166c", "20394": "ce86c21ce7c64089d488965821ac36ac6eddddc9", "20395": "08a599b3478b5fb7d9e6edf6b9e0278809e6ac7b", "20396": "87d7cdf2600223f67df4b73edac4252d71155c9f", "20481": "2efb60717bda9fc64344c5f6647d58564930808e", "20572": "44322d19dad8035b9c4a8d900b8eb2c86cd28a78", "20573": "0f3e2a1e0b12510c90679a3e797fe984bd3b968c", "20574": "d1accd032b648c9affd6dce1f81feb9c99422483", "20575": "ed0c598946b0309575f57e1886d498a6ed41021b", "20576": "d48306e77c0a708e0ee33a2aa1da7e267df52ef6", "20577": "9bab81e013af33084c48b54dc2a6ef188acfd225", "20581": "4dba140f1d2e835a485d72245e5c7f6fb66ac5c0", "20582": "7b28bbcc9a5f8661cc17d0c39bc0ffe1e449b8ec", "20583": "5bd57f90c3e8a714c77ca559d63409644c36c5ef", "20584": "8f4295a6478300521689be74ad7e4f82fe6b61e1", "20585": "88ccb25e74c5e88bc393fa15790d341574f2bff8", "20586": "ed487653bc98f9e8b98e4e1175c49678ad68fa9f", "20587": "1ca62afeea02b8555e2f8bd5bfa887aa0b8127dc", "20588": "86049dd54a14d38610440c21dacd7654dee54209", "20589": "41e3b292e126f98350071bf6f2f6474ea7e8b393", "20590": "76247c142893c710e970c4cf8a25d73121aa5a2b", "20591": "2d2d670898e6fe6eeb01dabbdbc6782d435ad180", "20592": "ea666da764efdae0ded7b43677d2ffc10f25c61c", "20593": "cd2bc1a998be7331e0a14cd755b05025a3fbe821", "20594": "d749aae9549329912edabc646fcda4083af18e22", "20608": "0da8b3f818a28cbde14bfd62665d2a76e800bd19", "20610": "6502df0f7a9dc96214190c2c1967c9e11bc38861", "20611": "4d9016eea8effc58f12a6a921408eb8f48afad7e", "20612": "01babb590cb15ef5c6e9ad890ea580a5112e6999", "20615": "d7eb306cc1b6e3430895a7d2af0cfa1cbc8c4c06", "20616": "3b96ada3a17f5fcc8c32a238457075ec4dd8433a", "20617": "ba31de37d48f4627de7ac4eba27f73bda5879194", "20634": "ebcfee442b04c083b054461bb421edc031b0cb40", "20635": "d170cc9def045ddc30d3bdfe3187087dc6f25030", "20636": "a39f23855d38a91ccc7b8cb8d941943fa1ea438b", "20637": "8c0b131009ee5b47b33e3611eefe6c178fd45697", "20638": "619f52bf7c0034c63f28d266ed1e9132f1d8dfe7", "20639": "37f29e5bf967d76d76a05e84b5c9b14c9bc66f23", "20640": "c00d683914e9acf20777cd091bdf61cd42a26207", "20641": "47a6635bf17d110c2159ecf03e0760d1380a3856", "20642": "6e28b67b4705ba3a9206643e8d60b6cec0e23c34", "20643": "f6a5dd4b8c450d73f3bec964b05cca32cef4bb71", "20644": "61362be9ea4d69b33ae421f1f98b8db50be611a2", "20645": "f34dbbf28b4c4d1b241f7bda155284fe0c131d18", "20646": "0fd888c8b318d4041b0ae53c64715eca0d345dd3", "20647": "ee37443fa6c54f552434dda705fbc86062a944f9", "20648": "ffcbfc8a68e0dfcd9a0e57a95e5065e4f97d8467", "20649": "143bc34aa8f068b18e7137df7ca91b9929cc1389", "20655": "c046dfb5a27ccd0ff9afd6dd73297f020c12c086", "20656": "eb9a8e35eff001bffbe484a969ed36c818163ad0", "20657": "9000c3997b0bed60392225e9d2c6ced236eabe2b", "20658": "4ff0d616a83d3f8048291526d8d23e85eb64915c", "20659": "313665ab41ebef44e093730ac05927cd632395ae", "20661": "c7a1321029e07ee6d7ea30036649b488b2e362f7", "20662": "52362bf220d902c87850dde473c1cebc048ee744", "20663": "0bde5690b0f98e3bbc728f186eaa55323d172a0b", "20665": "96147894e9cf2987e19a1260c28b3e7660baa270", "20668": "516d7120fc647ee19a3c1a3572519831a9c2df56", "20676": "0f0dc80a61534169eca7043fb4bfbc5f44849154", "20677": "2de4fbb940fccc8e42d48b23562b0b6b1a5434de", "20679": "1fa1ad91b29c5474cbb86cbcbcdcd50537cad0ae", "20680": "08a4c1aeb2c13164e1d394ca58a99838eb917b2a", "20681": "15b11c83f62cf7878c0663453af90e9a11196e34", "20781": "6813d7796e759435e915f3dda84ad9db81ebbadb", "20782": "a656d24ff32d5113cf8db48dd3a1cdfe6e27acf0", "20783": "c1f7b39c09bb6b7e8ce5024bd071247a6076b12d", "20784": "48dd753de9caa9c7fea8ecae39bf2d5f38244b22", "20785": "9d7a282baf0702c0fe49544767c4c91e03965aae", "20786": "a818281a45f7b5bd24f050e5d6868894c5108db6", "20793": "e66ad6c77cbd66fe7bc8d7f32a70527f487cc6e2", "20794": "d03beab3b260501a832499fb92dc81a1075048d7", "20795": "802f67046bbae0a815b2fe9d20d2217485bbc942", "20797": "f4b4ec2026327021fa646f9f77cc23600feb49e4", "20798": "9f93d57025d7b906de6956f287b71cd18c17b13d", "20800": "5b0a2a6e361f75c8cbb715cd33ff55dd61c631c9", "20847": "def01cf7bbb5ef8c9bf2e19737ea918e6a76a143", "20850": "171c71611886aab8549a8620c5b0071a129ad685", "20851": "888d1fae80a975147e3f99f9254bf1dbca3affd3", "20852": "d5ba4c14c62c1a23f53773c4e3ecb3bd9a792a91", "20853": "c7ceff98395b13aded759a6ac8d1fbe49fc9113c", "20854": "9dc4d718e093ccbb15e024da6d3bad80f4e99ba6", "20855": "347ad8564ec7dbf679f61e88f6914ab20d7ae3da", "20856": "e2483c022d58d0871cf2d961b9636bbf7d81917c", "20857": "d75ee703efc0d201af2f05bd166b0f58ec5977b5", "20858": "5c0da7dd4034427745038381e8e2b77ac8c59d08", "20859": "518d8aea8f1a7053b541fc6491a50fca30e6fb08", "20860": "2165a6a64d4064af2bf79d7e6889bda2b6adb86f", "20861": "09ab18f6dca48d4dde677ce9ed86444f8a937e32", "20862": "97f9bbf6d4b8af8691fabb7014b7e5aa006e1cf2", "20868": "cebc34327c74fed38ad8ee4cffb7b63999c83b9a", "20869": "0d0daa8466d257c3329c54633a9a98867c86d009", "20870": "a1bdacfaf0693336b957b1bd3821f15c05120aff", "20872": "7528d088c9aa597174fbccbc1bddb9290ba2556e", "20873": "bca39a72b073758d3cfa7afa470462255f1bc066", "20878": "294a22c0baa2e024d12f70705c4ec85f4c82b2b0", "20879": "ddfc9a232f605e935c06efebdc0830d2b14dfdd5", "20880": "357774695a4caf7b83506686f4c29cc38d2b9726", "20881": "49d2019723b0089bd357adf6c936c5a82e0cc775", "20883": "041b6b180f8175b642977852f01e9211983b46ce", "20884": "bd8dbf906e4352567094637c9c824c350dae3ad2", "20885": "080d57ee9fef9275518908cb7665ea062684c29b", "20886": "d91ffa6407c1baf6afe7d0a1b9655f44da77ac24", "20887": "612d3b23da5b99f6c5642be574fb08713a45d7d1", "20888": "bc65fe6c12dc78679ba8584eee83c6e3e243b5b9", "20889": "2518040894ef00d9ce427539937a86b2328a9e50", "20890": "5f34933848d7daa129651a53158cb94367bacbcd", "20895": "51db82d9cc1abcec6c912d83e714811005471379", "20897": "75c9783d4924c98d84e9722060686fc7b4643259", "20898": "fadb27138a97eb96b619111f906b8921d2290d26", "20899": "cad39188c64bb844d6e915a97d1b88c6b4337723", "20900": "621ad9df37911ea577029d8cac5de0920f07f33e", "20902": "bfdbebec423d781ebde189de24f5413298ab7c81", "20903": "f8a924bcc3191ea7c82482ddf22728e629e808f3", "21008": "045880c29e4d40dc0458d2a3272d145174b5122d", "21009": "ae7145916151fd10065e2c65068b81abdaa74509", "21010": "645aaae71ab2b3beae4ef7e5cae5858e961e1194", "21011": "024d2072dc1ae04c3739a57b73893c1f60363a65", "21012": "0a082d40c4a750655a7f1ce127c58ca26cd5905e", "21013": "c94eaeec0387eb61eff303c24fc5ada24e1c563c", "21014": "2b2845435a4b66e7dba9edef5296ed538ecffa12", "21250": "0efc71b53f019c6c5a8da7a38e08646ca75c17d9", "21265": "7c8c8c8120abd5f93608cea28ec56724c0df22e3", "21266": "e4afa45c380b0d8f2c39e2e53a9e8415f685ba44", "21267": "cb76dcb6e16eed7e4df4844ba94f54383c3425f8", "21268": "693105169f514fe1ac2372bca787ad48c50bd421", "21269": "04893a954b91574279c402e8730a4b5fae2ae9e1", "21270": "e623f0fbf9a89cbf566255189c843b7ff9a79f55", "21271": "d2d8785c71cf75ae8d6363410156e96a1785f8f7", "21272": "9f0383707d20e788d28d950f14a3eabf58d978f4", "21273": "7e8628366eed56ee64b1eca1b86d03ed61bc9902", "21274": "6c898e6a58285c841511e853bb1bf8a90766df78", "21277": "68632fb5255bffdcad1388a4a22a1e6627285338", "21278": "fe97cadc4803be0b076a9ec001ba29433133eed4", "21279": "d10e25af327c678ed4d699c801a2922623d7f2b6", "21280": "ef77b5700d0829b944c332b1dbeb810797a38461", "21281": "03c1a3db221c4af359d0615f9f46f5f34912048a", "21299": "eb74ef0aeed5eef8eecdd659a27410ae93dcdbb3", "21300": "9c21bb96f8a76da059ba573ba38f50df497ba6f9", "21301": "33c1b21ac3a0fad35cb2c845a391ca03750fe7cf", "21302": "bef9baedafc83df47963f2c4f4e7e465ece44342", "21303": "7be4d86e9ffaa7dbe2dfbaceb80bed792a5d7b28", "21304": "a8a69294561629dd6aa414bd0cb05f4d6cf87a14", "21305": "30362ed828bebdd58d4f1f74d70236d32547d52a", "21306": "814c51caf2fcd377f7b9e17c7f5e19fcb1be201d", "21307": "cce0b374fcdce7d5aa6f646a3020564ab7ead6f5", "21308": "0df22b6de60e4e8786f608b732c2e34b35a66866", "21312": "ee59b7d68f8b21623e8248f2fa56a824bed27fba", "21313": "0e60bc91f5efeeacc1851738762acd9289c9631b", "21314": "bc020f638a88778c289cdfd20a660f25ad843dd5", "21315": "da1401b7acbbd3c9fc51e0c763c02601436bfaad", "21316": "b1eb97bdfe17f477600eef19e82d65480457bbf5", "21317": "bbadfa1270c4bcdcafac80f116abcd9ec8e8efd5", "21318": "de586c1d3af13b2f17f016cba4591d8ed37cd2bf", "21319": "225cc9284d1abfbcc9d13203419516575a63cc7a", "21320": "e3698dc779bbe40c34b031a57c9da304ba003515", "21321": "34de308217a4c988a7655d69cfc2e2dd3d97d151", "21331": "48e6edff5d725a8f92fbd572f727bf838829efb3", "21332": "d7de334359f1872b52abd34e5e42d2a77f97e55d", "21333": "4ccea11321cdbc5199cce0e0f4cdae8655d4e93c", "21334": "f58b07e038a933f14f608dc9ccf109038beb95c6", "21335": "08ab156eb0058682ca9fcbf8bceea251e5790883", "21336": "a38a004629f8a2d4da9392133e3e1162261b1e3f", "21337": "953757a3e37ffb80570a20a8eca52dae35fc27bb", "21372": "90132de36ada51d6bff79126569b9878e21c1486", "21373": "4fc4dbdc8cb78cdd967ff2e104368814a14878a5", "21374": "932f04e900f400862e5b4e0f2b2e714611d622c4", "21375": "b4e9ad09ccd8e6b24b39acf45f82c33cd5cbfea2", "21376": "69f27a4ca1d2bbde37045305d8b9ddf83d526331", "21380": "b501aa0ce5d6cbe2751a5afc2fca001e90cff6e9", "21381": "5f77f5f2de6d1c750d360623d59ed01b523308e2", "21382": "ae30758a7d4627af43eb6aefaebc090afc7a9f61", "21383": "3598a5e82c0f5d17d97dcae8d5deae94096c657b", "21384": "3c0cf22909804ae050fdf7609edd13d88d0460aa", "21386": "62a87bf4a2af02a8d3bc271ad26e5994292b8e6a", "21387": "75410f8c6456c628042912210d4fc0e9268c5b0b", "21388": "b2734ee9b53e001953f92e7bcf5939df46aec2de", "21389": "0de99558b497c5611cbe5d35d504763bd7692275", "21422": "b3490cbd98b96aa5064e87b11c391596e32f7993", "21423": "6cc82344fb319032465d6ee4e3d1c02991ef42c3", "21424": "0d977e94492fcfcdda632442d136ea822944c2a7", "21425": "6f530a9c47fe6d89543a813145ce3ad3f417e700", "21426": "7f6561d431561e2882dccf7b422a11c1c4b025e7", "21432": "aa0f1382fbe190c04f3c51678e64ef2695868f30", "21433": "4f85eb8d0599cbea8c329eb7f48c6f188ea96a48", "21434": "165d5ee40862ba155b5988045164e21aaaefd556", "21435": "069a3bbaab16f8565e5dbce6aae7102f38fcbdbb", "21436": "399212673ea8101a65d95830604edb633da0860d", "21439": "d31e94b4be25b015829e95c6ae74840b5218f2a1", "21440": "5b332e4db7f38e724f6a98248a3b69e2c53ac376", "21441": "11e60d748a6b257a5318a87f6f436771a33145da", "21442": "cab3a0ec14a0ebf8d99fb9c2965599ce8c775c9a", "21443": "d5699051aa7fbdb9c6c58088053043390ad409b1", "21455": "e482194fcbab376cfca1aadf1b9a2612589643e2", "21456": "b72f9289bde1b7f1a32e64732a85e27844744e87", "21457": "08087d6712b06502dc0f591b9f66987eba2bb220", "21458": "e131b21f0131122d4066b0b532022a02a0140947", "21459": "6d9b4764c4f3a67fa1a9704f261023169917102e", "21473": "e35841f6b3afe68947f74df3bdd987a80b1a1fc7", "21474": "235d1209b31abd80fd01d11290cb945ddebc4f99", "21475": "c60e107d0024a330874f40135f6b56ef994669d1", "21476": "c2305d756541dfbbf213db3fc689a1a7f8d2bc7b", "21477": "6b06f43426ccb85a3daa01223ad334089855444b", "21479": "39777cba31b3171935e735ed0d7f5bb4e108bc31", "21480": "a85f1d7dcbddb32eaf6b848bf184ae422b7771fa", "21481": "947bb8e887c3b33db9396f38f73e245a89cba300", "21482": "9cf6269bb40e54c5b6d0283e31408453c4e1f8bc", "21483": "18efcb27361478daa3118079ecb166c733691ecb", "21486": "69c61c5adedba0a1a1bbda28f1e8d5a33ea2b4f9", "21487": "62f6a42dfc0b068fec5955a1ea9223d3741c2bf0", "21488": "3b58f48a38e47027b88b0224523c0ba8bd55ef38", "21489": "6dbd2b1142a1fa1be33f031d319ee2ef7a49faef", "21490": "6498bc1e8a12003640139db4794bd5cd2462c116", "21491": "9bbb5f00c8396e5d7142eb973243c191e553c525", "21492": "7b9af02148a4febadb1fbb607c4b8ce3d0b7513e", "21493": "85b5a006ebba75888e03fbd99986cb4bd7d4d7c5", "21494": "31509629e0b5b895fccaff2ce1b62e8ee1272c2e", "21495": "404e6baec7d2587b7f50ea7f8f85fef079d09b46", "21496": "9c2505582259727b770a77139a8ac935d1d9325d", "21497": "0f15046df0c30b76e163518d4914442d8f8efef5", "21498": "78c3c16402b00b8a27fa628dcf9bc84e024f5caa", "21544": "2064876e271358f178ad806b3a97d6bc0b37e5ca", "21545": "b68899f7ed55a0f7260cb265629d30437c05fbb1", "21546": "33181d92a97a57e2ac0bf5efee9d6c301be430af", "21547": "0e991116162c3c9a606c9cad7086d7ba49efc638", "21548": "966757faa28cc536b1bca4856f1dc693ec0bd2ea", "21684": "6f1accd04ff6957b24648ee947dc103979dca350", "21685": "76e39ebcf584042fab4f224a6bd2c903bb0c8aff", "21686": "cf202bec6bba8bfcf6e2f61bfe6f2817a2a67264", "21687": "a522b5c1d42e9efb16f44b3e991294b54a4fe035", "21688": "35029d20d53a1af57823759039f57d8ff09736c3", "21689": "75ac56a19bbdb3c4cebfcaea182da31a7a7de8c5", "21690": "cc3daa6f7e140e870d57c3b02a5d2142e11d09c9", "21691": "11cb42346a1593af9ad04381a1b10b71d9256015", "21692": "7d7f885856b0c3d51eaf15beaac9d4f30c23797d", "21707": "854bcb59d30b425333f8830187153582af80b244", "21708": "06790d79b866fe457e34735f9669948f0f8e3b3e", "21709": "00b1d34532a6e50960baa67bb7f7f53a0ff3e9ae", "21710": "de28255b1605a4925636f686c6279073a2abf5cd", "21711": "db60ab6c8b6a016ea156e3c86099afc23966c0fe"}, "revision_to_date": {"104": 1262713712000, "208": 1285906928000, "288": 1298163988000, "315": 1303101648000, "473": 1308971823000, "589": 1311458440000, "694": 1313620812000, "798": 1315255505000, "862": 1315859521000, "874": 1316017084000, "915": 1316984686000, "926": 1317000085000, "933": 1317048249000, "981": 1317617173000, "1029": 1318197429000, "1033": 1318267521000, "1084": 1318951906000, "1139": 1319248032000, "1185": 1319509932000, "1194": 1320196542000, "1245": 1320729617000, "1342": 1322277354000, "1350": 1322466345000, "1440": 1323817436000, "1458": 1324060369000, "1562": 1325182613000, "1632": 1325734840000, "1678": 1325983299000, "1786": 1326934583000, "1812": 1327034032000, "1931": 1327947201000, "2066": 1328819689000, "2072": 1328826175000, "2077": 1328843532000, "2196": 1330553078000, "2247": 1330658997000, "2288": 1331241598000, "2358": 1331927660000, "2479": 1334001823000, "2539": 1334253112000, "2555": 1334276689000, "2628": 1335381436000, "2738": 1336151422000, "2844": 1336861000000, "2951": 1337361430000, "3055": 1338223586000, "3074": 1338253482000, "3170": 1338837524000, "3262": 1339519295000, "3266": 1339521874000, "3282": 1339692475000, "3344": 1340247840000, "3360": 1340393682000, "3361": 1340394271000, "3393": 1340820112000, "3403": 1340922642000, "3412": 1340986814000, "3418": 1340991466000, "3494": 1342184152000, "3551": 1342986141000, "3557": 1343003671000, "3637": 1344479297000, "3791": 1347149946000, "3905": 1348166149000, "3912": 1348197360000, "3955": 1348710085000, "4026": 1349655420000, "4084": 1350486962000, "4203": 1352225986000, "4249": 1352505519000, "4289": 1352940069000, "4374": 1353646198000, "4510": 1354157877000, "4638": 1354900852000, "4723": 1355269526000, "4770": 1355447463000, "4816": 1355762888000, "4941": 1357446804000, "5022": 1358831994000, "5082": 1360531241000, "5267": 1363111718000, "5482": 1364232404000, "5628": 1365121328000, "5767": 1365818352000, "5781": 1365867809000, "5863": 1366678471000, "5980": 1368126974000, "6199": 1369933955000, "6439": 1371512776000, "6664": 1373346771000, "6679": 1373414385000, "6794": 1374697106000, "6887": 1375403606000, "7125": 1378512651000, "7344": 1380055037000, "7576": 1381274604000, "7780": 1382923129000, "7983": 1385527286000, "8005": 1386168654000, "8139": 1388422887000, "8203": 1388896303000, "8234": 1389186315000, "8327": 1389878709000, "8419": 1390345599000, "8616": 1391083269000, "8680": 1391395738000, "8815": 1392348296000, "9020": 1393855836000, "9230": 1396563043000, "9423": 1398684037000, "9611": 1400269456000, "9617": 1400278770000, "9713": 1401450122000, "9798": 1402003509000, "10015": 1404121287000, "10140": 1405035967000, "10199": 1405943035000, "10399": 1408461173000, "10501": 1410094321000, "10585": 1410965305000, "10777": 1412603691000, "10793": 1412642319000, "10853": 1413672736000, "10956": 1415452422000, "10964": 1415541672000, "11042": 1416578711000, "11156": 1417731624000, "11188": 1418306362000, "11353": 1423145345000, "11528": 1426255236000, "11550": 1426495793000, "11564": 1427031398000, "11808": 1430388244000, "11906": 1431306604000, "12002": 1433426744000, "12077": 1434192334000, "12091": 1434584708000, "12181": 1436186502000, "12373": 1438722943000, "12566": 1440945959000, "12722": 1441988415000, "12731": 1442049754000, "12867": 1443887330000, "12896": 1444306718000, "12923": 1444751455000, "13114": 1447846614000, "13165": 1448038103000, "13291": 1450897740000, "13448": 1453840368000, "13531": 1455378460000, "13553": 1455719363000, "13622": 1457534291000, "13633": 1457732611000, "13657": 1458247628000, "13761": 1461002864000, "13843": 1462283462000, "13865": 1462973545000, "13970": 1465954930000, "14074": 1469053087000, "14178": 1470825394000, "14283": 1473253863000, "14289": 1473277332000, "14306": 1473807615000, "14323": 1474632211000, "14343": 1475416385000, "14344": 1475430051000, "14360": 1476559541000, "14376": 1477347051000, "14392": 1477552301000, "14393": 1477576270000, "14439": 1478171539000, "14448": 1478182795000, "14463": 1479262159000, "14479": 1479471947000, "14495": 1480068330000, "14511": 1480465216000, "14527": 1479365051000, "14536": 1481030108000, "14543": 1481312071000, "14559": 1481486262000, "14575": 1481731842000, "14650": 1481930528000, "14666": 1482166790000, "14682": 1482318568000, "14698": 1482526883000, "14711": 1482576646000, "14719": 1482594798000, "14733": 1482971244000, "14750": 1483133432000, "14765": 1483487706000, "14781": 1484084814000, "14797": 1484496542000, "14813": 1484856825000, "14824": 1485012656000, "14829": 1485003492000, "14845": 1485299413000, "14861": 1485981778000, "14877": 1486419972000, "14893": 1486735771000, "14909": 1486921871000, "14925": 1487254336000, "14928": 1487266767000, "14941": 1487644750000, "14957": 1487966169000, "14973": 1488256996000, "14989": 1488532605000, "15005": 1488715313000, "15021": 1488978730000, "15032": 1489061147000, "15037": 1489101303000, "15053": 1489341700000, "15069": 1489681237000, "15085": 1489770715000, "15101": 1490031949000, "15117": 1490183908000, "15133": 1490481734000, "15136": 1490535679000, "15149": 1490636252000, "15165": 1490875020000, "15180": 1491222263000, "15196": 1491419737000, "15212": 1491592149000, "15228": 1491751731000, "15242": 1492082910000, "15245": 1492123659000, "15261": 1492351517000, "15277": 1492504476000, "15293": 1492726863000, "15309": 1492824507000, "15313": 1492832004000, "15325": 1493116514000, "15341": 1493328473000, "15346": 1493550585000, "15357": 1493724388000, "15370": 1493909668000, "15373": 1493933355000, "15378": 1493951109000, "15384": 1494003581000, "15385": 1494012477000, "15389": 1494109212000, "15405": 1494518848000, "15421": 1494932560000, "15437": 1495145089000, "15450": 1495527419000, "15453": 1495537639000, "15469": 1495668254000, "15529": 1496198355000, "15545": 1496345512000, "15561": 1496573234000, "15587": 1496609647000, "15599": 1497107370000, "15601": 1497196148000, "15603": 1497223179000, "15606": 1497264412000, "15610": 1497395271000, "15613": 1497395865000, "15617": 1497481407000, "15621": 1497537930000, "15622": 1497617178000, "15623": 1497915293000, "15624": 1497915339000, "15625": 1497915404000, "15626": 1497942731000, "15627": 1498041489000, "15628": 1498041656000, "15629": 1498042339000, "15630": 1498137431000, "15631": 1498225788000, "15632": 1498251570000, "15633": 1498548220000, "15634": 1498576929000, "15635": 1498577024000, "15636": 1498626544000, "15637": 1498627758000, "15638": 1498841592000, "15639": 1498848651000, "15640": 1498852152000, "15641": 1498853154000, "15642": 1498853479000, "15643": 1498854315000, "15644": 1498854851000, "15645": 1498856193000, "15646": 1498858184000, "15647": 1498892046000, "15648": 1498898497000, "15649": 1499017138000, "15650": 1499085595000, "15651": 1499102625000, "15652": 1499200452000, "15653": 1499200536000, "15654": 1499343818000, "15655": 1499344631000, "15656": 1499380931000, "15657": 1499381160000, "15658": 1499422635000, "15659": 1499422693000, "15660": 1499423136000, "15661": 1499429815000, "15662": 1499433032000, "15663": 1499433106000, "15664": 1499435164000, "15697": 1499446444000, "15699": 1499446527000, "15700": 1499530111000, "15701": 1499681570000, "15702": 1499681629000, "15703": 1499681708000, "15704": 1499682961000, "15705": 1499682992000, "15706": 1499767272000, "15707": 1499767737000, "15708": 1499769650000, "15709": 1499791179000, "15710": 1499791220000, "15711": 1499874667000, "15712": 1499973326000, "15713": 1499978148000, "15714": 1499987069000, "15715": 1500041633000, "15716": 1500061601000, "15717": 1500067228000, "15718": 1500092160000, "15719": 1500121803000, "15720": 1500124294000, "15721": 1500127104000, "15722": 1500132844000, "15723": 1500132871000, "15724": 1500133102000, "15725": 1500134261000, "15727": 1500135970000, "15728": 1500139984000, "15729": 1500142055000, "15730": 1500146074000, "15731": 1500154103000, "15732": 1500160429000, "15733": 1500152643000, "15734": 1500162182000, "15735": 1500162548000, "15736": 1500167577000, "15737": 1500168055000, "15738": 1500169376000, "15739": 1500192275000, "15740": 1500199034000, "15741": 1500218610000, "15742": 1500219072000, "15743": 1500219165000, "15744": 1500220533000, "15745": 1500272367000, "15746": 1500296354000, "15747": 1500304297000, "15748": 1500333535000, "15749": 1500334197000, "15750": 1500341502000, "15751": 1500354086000, "15752": 1500377204000, "15753": 1500393535000, "15754": 1500394083000, "15755": 1500420711000, "15756": 1500421787000, "15757": 1500425101000, "15758": 1500432717000, "15759": 1500457907000, "15760": 1500459476000, "15761": 1500459570000, "15762": 1500459772000, "15763": 1500480021000, "15764": 1500482023000, "15765": 1500533302000, "15766": 1500546995000, "15767": 1500560619000, "15768": 1500588246000, "15769": 1500633491000, "15770": 1500634229000, "15771": 1500634859000, "15772": 1500634898000, "15773": 1500635119000, "15774": 1500679511000, "15775": 1500686510000, "15776": 1500699521000, "15777": 1500749787000, "15778": 1500749977000, "15779": 1500826857000, "15780": 1500831839000, "15781": 1500831865000, "15782": 1500835074000, "15783": 1500857218000, "15784": 1500872844000, "15785": 1500879472000, "15786": 1500930314000, "15787": 1500939688000, "15788": 1500955141000, "15789": 1500977903000, "15790": 1500995842000, "15791": 1501003665000, "15792": 1501042122000, "15793": 1501048475000, "15794": 1501064963000, "15795": 1501112322000, "15796": 1501112629000, "15797": 1501112959000, "15798": 1501133456000, "15799": 1501134536000, "15800": 1501149440000, "15801": 1501365483000, "15802": 1501407805000, "15803": 1501455242000, "15804": 1501611556000, "15805": 1501618162000, "15806": 1501626780000, "15807": 1501627000000, "15808": 1501627098000, "15809": 1501627449000, "15810": 1501667219000, "15811": 1501667277000, "15812": 1501672937000, "15813": 1501722132000, "15814": 1501722187000, "15815": 1501722307000, "15816": 1501762038000, "15817": 1501778246000, "15818": 1501794365000, "15819": 1501832693000, "15820": 1502084966000, "15821": 1502102640000, "15822": 1502102766000, "15823": 1502103958000, "15824": 1502110613000, "15825": 1502111436000, "15826": 1502129047000, "15827": 1502144313000, "15828": 1502234922000, "15829": 1502235008000, "15830": 1502236139000, "15831": 1502274454000, "15832": 1502275040000, "15833": 1502277876000, "15834": 1502309967000, "15835": 1502360818000, "15836": 1502361410000, "15837": 1502361459000, "15838": 1502368366000, "15839": 1502397817000, "15840": 1502410382000, "15841": 1502410737000, "15842": 1502446966000, "15843": 1502447013000, "15844": 1502447773000, "15845": 1502559026000, "15846": 1502559183000, "15847": 1502559232000, "15848": 1502706701000, "15849": 1502734778000, "15850": 1502792969000, "15851": 1502821566000, "15852": 1502828624000, "15853": 1502829759000, "15854": 1502837094000, "15855": 1502916749000, "15856": 1502964652000, "15857": 1502964816000, "15858": 1503009577000, "15859": 1503017554000, "15860": 1503070040000, "15861": 1503142025000, "15862": 1503161465000, "15863": 1503179734000, "15864": 1503179959000, "15865": 1503264343000, "15866": 1503301844000, "15867": 1503302199000, "15868": 1503303290000, "15869": 1503304044000, "15870": 1503344390000, "15879": 1503524149000, "15880": 1503568218000, "15881": 1503568998000, "15882": 1503571107000, "15883": 1503579230000, "15884": 1503692997000, "15885": 1503928685000, "15886": 1503929129000, "15888": 1504001415000, "15889": 1504011171000, "15890": 1504013018000, "15891": 1504026197000, "15892": 1504026247000, "15893": 1504088384000, "15894": 1504090204000, "15895": 1504111185000, "15896": 1504125053000, "15897": 1504175063000, "15898": 1504175751000, "15899": 1504175878000, "15900": 1504268370000, "15901": 1504277564000, "15902": 1504283760000, "15903": 1504285900000, "15904": 1504353055000, "15905": 1504567954000, "15906": 1504607431000, "15907": 1504699419000, "15908": 1504700586000, "15909": 1504709712000, "15916": 1504783692000, "15917": 1504784140000, "15918": 1504784484000, "15919": 1504784967000, "15920": 1504785393000, "15921": 1504831572000, "15922": 1504831672000, "15923": 1504832405000, "15924": 1504865105000, "15925": 1504865773000, "15926": 1504984148000, "15927": 1505028648000, "15928": 1505053192000, "15929": 1505054617000, "15930": 1505088101000, "15931": 1505127798000, "15932": 1505128976000, "15933": 1505210990000, "15934": 1505211962000, "15935": 1505212292000, "15936": 1505212555000, "15937": 1505220893000, "15938": 1505297010000, "15939": 1505297072000, "15940": 1505305497000, "15941": 1505344736000, "15942": 1505344853000, "15944": 1505384083000, "15945": 1505405370000, "15946": 1505429339000, "15947": 1505429573000, "15948": 1505431779000, "15949": 1505439183000, "15950": 1505463504000, "15951": 1505469106000, "15952": 1505545210000, "15953": 1505569241000, "15957": 1505660695000, "15958": 1505660743000, "15959": 1505683257000, "15960": 1505683588000, "15961": 1505686455000, "15962": 1505737806000, "15963": 1505742308000, "15964": 1505775013000, "15965": 1505821656000, "15966": 1505847123000, "15967": 1505852894000, "16031": 1506679481000, "16032": 1506679559000, "16033": 1506680195000, "16034": 1506681082000, "16035": 1506697208000, "16036": 1506785157000, "16037": 1506800032000, "16038": 1506860740000, "16039": 1506869625000, "16040": 1506869732000, "16049": 1506947564000, "16050": 1506948219000, "16051": 1506951172000, "16052": 1506953442000, "16053": 1506961991000, "16059": 1507028071000, "16060": 1507028150000, "16061": 1507029945000, "16062": 1507035665000, "16063": 1507054484000, "16064": 1507060147000, "16065": 1507060625000, "16066": 1507063372000, "16067": 1507115256000, "16075": 1507224501000, "16076": 1507228519000, "16077": 1507228555000, "16078": 1507228588000, "16079": 1507228636000, "16084": 1507290391000, "16085": 1507298902000, "16086": 1507303353000, "16087": 1507304244000, "16088": 1507304283000, "16089": 1507374178000, "16109": 1507858703000, "16122": 1508113798000, "16123": 1508137145000, "16124": 1508149640000, "16125": 1508149714000, "16126": 1508156646000, "16127": 1508163923000, "16128": 1508285024000, "16129": 1508322397000, "16130": 1508322476000, "16131": 1508322616000, "16132": 1508397382000, "16133": 1508408200000, "16134": 1508443834000, "16135": 1508452018000, "16136": 1508490134000, "16137": 1508494369000, "16138": 1508506229000, "16139": 1508594118000, "16140": 1508596308000, "16141": 1508596841000, "16142": 1508748792000, "16143": 1508749143000, "16144": 1508754058000, "16145": 1508754144000, "16146": 1508932145000, "16147": 1509026257000, "16148": 1509040254000, "16149": 1509062062000, "16151": 1509097515000, "16152": 1509104953000, "16153": 1509107390000, "16155": 1509117925000, "16156": 1509128814000, "16160": 1509136891000, "16161": 1509141835000, "16162": 1509147682000, "16163": 1509151124000, "16164": 1509157844000, "16166": 1509204884000, "16167": 1509212278000, "16168": 1509216576000, "16169": 1509216793000, "16170": 1509235928000, "16172": 1509313014000, "16173": 1509320608000, "16174": 1509352164000, "16175": 1509352264000, "16181": 1509410723000, "16182": 1509411992000, "16183": 1509413398000, "16184": 1509446472000, "16190": 1509532097000, "16191": 1509532385000, "16192": 1509533598000, "16193": 1509535533000, "16194": 1509538309000, "16196": 1509621918000, "16197": 1509622010000, "16198": 1509622089000, "16199": 1509623775000, "16200": 1509623932000, "16201": 1509662962000, "16202": 1509666594000, "16203": 1509666884000, "16204": 1509670659000, "16205": 1509713303000, "16206": 1509750231000, "16215": 1509832022000, "16216": 1509856611000, "16217": 1509879126000, "16218": 1509879289000, "16219": 1509886175000, "16220": 1509908220000, "16221": 1509943184000, "16222": 1509975321000, "16223": 1509975956000, "16225": 1509990128000, "16226": 1509992308000, "16227": 1510000423000, "16228": 1510060187000, "16229": 1510061777000, "16233": 1510109966000, "16234": 1510110034000, "16235": 1510139492000, "16236": 1510142425000, "16237": 1510146042000, "16241": 1510172746000, "16242": 1510174014000, "16243": 1510228718000, "16244": 1510229471000, "16245": 1510231650000, "16249": 1510322022000, "16250": 1510322095000, "16251": 1510323273000, "16252": 1510323345000, "16253": 1510323898000, "16256": 1510344384000, "16257": 1510350077000, "16258": 1510356465000, "16259": 1510404733000, "16260": 1510405429000, "16261": 1510434036000, "16262": 1510436471000, "16263": 1510443507000, "16277": 1510573082000, "16278": 1510578306000, "16279": 1510578346000, "16280": 1510578388000, "16281": 1510578560000, "16284": 1510650835000, "16285": 1510652588000, "16286": 1510659164000, "16287": 1510664674000, "16288": 1510674007000, "16289": 1510675398000, "16290": 1510699857000, "16291": 1510745186000, "16292": 1510745274000, "16293": 1510745372000, "16297": 1510791831000, "16298": 1510791958000, "16299": 1510830835000, "16300": 1510830941000, "16301": 1510832067000, "16305": 1510879029000, "16306": 1510881103000, "16307": 1510909346000, "16308": 1510918116000, "16309": 1510922034000, "16310": 1511051446000, "16311": 1511051643000, "16312": 1511052530000, "16313": 1511054789000, "16323": 1511176205000, "16324": 1511176354000, "16325": 1511176527000, "16326": 1511176856000, "16327": 1511179343000, "16328": 1511202063000, "16329": 1511224237000, "16330": 1511224872000, "16331": 1511270053000, "16332": 1511270298000, "16340": 1511317330000, "16341": 1511318036000, "16342": 1511346346000, "16343": 1511349937000, "16344": 1511350121000, "16347": 1511384501000, "16348": 1511391041000, "16349": 1511391148000, "16350": 1511391796000, "16351": 1511426589000, "16359": 1511453627000, "16360": 1511466063000, "16361": 1511473569000, "16362": 1511480083000, "16363": 1511524024000, "16367": 1511551633000, "16368": 1511553797000, "16369": 1511553955000, "16370": 1511554683000, "16371": 1511561822000, "16381": 1511644394000, "16382": 1511645173000, "16383": 1511646673000, "16384": 1511648019000, "16385": 1511656234000, "16399": 1511744366000, "16400": 1511782007000, "16401": 1511782093000, "16402": 1511782496000, "16403": 1511782581000, "16405": 1511818862000, "16406": 1511861737000, "16407": 1511867783000, "16408": 1511868267000, "16409": 1511868580000, "16410": 1511914960000, "16411": 1511952647000, "16412": 1511956925000, "16413": 1511960292000, "16414": 1511961840000, "16415": 1512029638000, "16416": 1512050159000, "16417": 1512051981000, "16418": 1512054702000, "16419": 1512090315000, "16420": 1512090418000, "16421": 1512127829000, "16422": 1512146719000, "16423": 1512154741000, "16424": 1512154961000, "16425": 1512155722000, "16426": 1512236076000, "16427": 1512236581000, "16437": 1512386849000, "16438": 1512387344000, "16439": 1512387446000, "16440": 1512387519000, "16441": 1512392154000, "16442": 1512418411000, "16443": 1512433434000, "16444": 1512465536000, "16445": 1512472521000, "16455": 1512559116000, "16456": 1512559606000, "16457": 1512559655000, "16458": 1512559753000, "16459": 1512560266000, "16463": 1512608774000, "16464": 1512609554000, "16465": 1512609648000, "16466": 1512644617000, "16467": 1512644925000, "16475": 1512730262000, "16476": 1512731503000, "16477": 1512731578000, "16478": 1512732366000, "16479": 1512736857000, "16480": 1512779224000, "16481": 1512831386000, "16482": 1512832354000, "16483": 1512833866000, "16484": 1512834616000, "16485": 1512914797000, "16498": 1512982454000, "16499": 1512989820000, "16500": 1512990379000, "16501": 1512990518000, "16502": 1512991424000, "16590": 1513041658000, "16601": 1513047512000, "16604": 1513047803000, "16606": 1513050947000, "16607": 1513071306000, "16608": 1513076118000, "16609": 1513116198000, "16610": 1513129661000, "16611": 1513130264000, "16612": 1513130564000, "16615": 1513175815000, "16616": 1513176133000, "16617": 1513251034000, "16618": 1513251409000, "16619": 1513254882000, "16620": 1513299786000, "16621": 1513302336000, "16622": 1513337523000, "16623": 1513359904000, "16624": 1513382086000, "16625": 1513382214000, "16626": 1513420966000, "16627": 1513421018000, "16628": 1513599164000, "16629": 1513599245000, "16630": 1513599368000, "16631": 1513600449000, "16632": 1513602000000, "16638": 1513681943000, "16639": 1513682467000, "16640": 1513682810000, "16641": 1513683238000, "16642": 1513687679000, "16643": 1513692503000, "16644": 1513694464000, "16645": 1513697627000, "16646": 1513731420000, "16647": 1513773407000, "16648": 1513779803000, "16649": 1513793396000, "16650": 1513810560000, "16651": 1513822102000, "16652": 1513863811000, "16666": 1513870257000, "16667": 1513877096000, "16668": 1513890999000, "16669": 1513952057000, "16670": 1513952920000, "16676": 1514059483000, "16677": 1514061285000, "16678": 1514061388000, "16679": 1514061795000, "16680": 1514062222000, "16681": 1514274924000, "16682": 1514275775000, "16683": 1514275917000, "16688": 1514326406000, "16689": 1514326494000, "16690": 1514362631000, "16691": 1514366580000, "16692": 1514367162000, "16698": 1514406422000, "16699": 1514410442000, "16700": 1514461068000, "16701": 1514464123000, "16702": 1514464288000, "16705": 1514481722000, "16706": 1514507152000, "16707": 1514508814000, "16708": 1514550565000, "16709": 1514552748000, "16717": 1514570467000, "16718": 1514584136000, "16725": 1514637096000, "16726": 1514637428000, "16727": 1514640824000, "16735": 1514663812000, "16736": 1514671924000, "16737": 1514673682000, "16738": 1514674081000, "16739": 1514676058000, "16740": 1514677762000, "16741": 1514731433000, "16742": 1514731764000, "16743": 1514732053000, "16744": 1514741170000, "16745": 1514816137000, "16746": 1514892058000, "16747": 1514892229000, "16751": 1514978194000, "16752": 1514978250000, "16753": 1514978420000, "16754": 1514979693000, "16755": 1514982321000, "16756": 1515023690000, "16757": 1515023791000, "16758": 1515025668000, "16759": 1515045170000, "16760": 1515075306000, "16763": 1515111860000, "16764": 1515112324000, "16765": 1515112519000, "16766": 1515113130000, "16767": 1515113599000, "16772": 1515179782000, "16773": 1515184879000, "16774": 1515190719000, "16775": 1515195259000, "16776": 1515195445000, "16784": 1515260262000, "16785": 1515286089000, "16786": 1515286130000, "16787": 1515292667000, "16788": 1515292828000, "16791": 1515341390000, "16792": 1515363146000, "16793": 1515363418000, "16794": 1515363572000, "16795": 1515363753000, "16797": 1515439812000, "16798": 1515439929000, "16799": 1515502422000, "16800": 1515502442000, "16801": 1515502467000, "16807": 1515589103000, "16808": 1515589117000, "16809": 1515589225000, "16810": 1515589249000, "16811": 1515589331000, "16812": 1515619682000, "16813": 1515668952000, "16814": 1515670333000, "16815": 1515676913000, "16821": 1515757232000, "16822": 1515757338000, "16823": 1515757520000, "16824": 1515757593000, "16825": 1515757740000, "16826": 1515854855000, "16827": 1515867521000, "16828": 1515939022000, "16829": 1515965245000, "16830": 1516025484000, "16831": 1516025861000, "16835": 1516061676000, "16836": 1516061928000, "16837": 1516063396000, "16838": 1516063643000, "16839": 1516101460000, "16840": 1516147168000, "16841": 1516148041000, "16842": 1516148130000, "16843": 1516189604000, "16846": 1516235566000, "16847": 1516236123000, "16848": 1516236557000, "16849": 1516236787000, "16850": 1516273788000, "16852": 1516352262000, "16853": 1516359708000, "16854": 1516359872000, "16855": 1516361555000, "16856": 1516398632000, "16865": 1516557456000, "16866": 1516563014000, "16867": 1516573686000, "16868": 1516619514000, "16869": 1516619686000, "16870": 1516665595000, "16871": 1516666249000, "16872": 1516705256000, "16873": 1516706410000, "16874": 1516707411000, "16879": 1516788403000, "16880": 1516792205000, "16881": 1516842473000, "16882": 1516842611000, "16883": 1516843741000, "16884": 1516881284000, "16885": 1516881544000, "16886": 1516881716000, "16887": 1516961517000, "16888": 1516965517000, "16889": 1516965825000, "16890": 1516967647000, "16891": 1517015202000, "16892": 1517015350000, "16893": 1517015415000, "16894": 1517015544000, "16895": 1517016020000, "16896": 1517070805000, "16897": 1517072123000, "16898": 1517072193000, "16899": 1517140384000, "16900": 1517229779000, "16903": 1517261949000, "16904": 1517270372000, "16905": 1517312176000, "16906": 1517312196000, "16907": 1517312236000, "16909": 1517395733000, "16910": 1517397425000, "16911": 1517398221000, "16912": 1517398452000, "16913": 1517400914000, "16921": 1517489696000, "16922": 1517490557000, "16923": 1517490942000, "16924": 1517491595000, "16925": 1517492239000, "16970": 1518053522000, "16971": 1518088632000, "16972": 1518088839000, "16973": 1518089334000, "16974": 1518089524000, "16975": 1518179132000, "16976": 1518179342000, "16977": 1518192677000, "16978": 1518209621000, "16986": 1518282520000, "16987": 1518288495000, "16988": 1518297157000, "16989": 1518307490000, "16990": 1518310162000, "16997": 1518387874000, "16998": 1518435213000, "16999": 1518437171000, "17000": 1518480775000, "17001": 1518481163000, "17002": 1518533454000, "17003": 1518548502000, "17004": 1518558074000, "17006": 1518606346000, "17007": 1518606727000, "17008": 1518606799000, "17009": 1518607611000, "17010": 1518607880000, "17012": 1518649934000, "17013": 1518682651000, "17014": 1518683769000, "17015": 1518685232000, "17016": 1518697871000, "17017": 1518805312000, "17421": 1522290697000, "17422": 1522318259000, "17423": 1522334348000, "17424": 1522340616000, "17425": 1522354203000, "17430": 1522446996000, "17431": 1522510046000, "17432": 1522512081000, "17433": 1522512179000, "17434": 1522512252000, "17435": 1522514252000, "17436": 1522590020000, "17437": 1522590145000, "17438": 1522597795000, "17439": 1522604824000, "17440": 1522676129000, "17441": 1522708712000, "17444": 1522738843000, "17445": 1522738950000, "17446": 1522760415000, "17447": 1522783330000, "17448": 1522783418000, "17449": 1522869619000, "17450": 1523260898000, "17451": 1523268143000, "17452": 1523298838000, "17453": 1523339652000, "17454": 1523413592000, "17455": 1523413794000, "17456": 1523441147000, "17457": 1523562549000, "17458": 1523620049000, "17459": 1523639629000, "17462": 1523712924000, "17463": 1523713303000, "17464": 1523716320000, "17465": 1523749652000, "17466": 1523750310000, "17467": 1523817524000, "17468": 1523818233000, "17469": 1523818647000, "17470": 1523819014000, "17471": 1523823920000, "17472": 1523874606000, "17473": 1523874794000, "17474": 1523874875000, "17475": 1523874979000, "17476": 1523890443000, "17477": 1523951612000, "17478": 1523961102000, "17479": 1523961253000, "17480": 1524041522000, "17481": 1524132454000, "17482": 1524132768000, "17483": 1524132932000, "17484": 1524141800000, "17485": 1524184513000, "17492": 1524334454000, "17493": 1524335034000, "17494": 1524349587000, "17495": 1524406937000, "17496": 1524408825000, "17497": 1524487782000, "17498": 1524491956000, "17499": 1524492383000, "17500": 1524510313000, "17501": 1524533728000, "17511": 1524566322000, "17512": 1524569374000, "17513": 1524573826000, "17514": 1524597208000, "17515": 1524619680000, "17516": 1524659897000, "17517": 1524687700000, "17518": 1524690441000, "17519": 1524704825000, "17520": 1524745094000, "17521": 1524756885000, "17522": 1524826564000, "17523": 1524834366000, "17524": 1524853758000, "17525": 1525035984000, "17526": 1525045741000, "17528": 1525089335000, "17529": 1525100765000, "17530": 1525110791000, "17531": 1525114914000, "17532": 1525134788000, "17540": 1525201047000, "17541": 1525205171000, "17542": 1525256797000, "17543": 1525259615000, "17544": 1525259813000, "17545": 1525272362000, "17546": 1525272424000, "17547": 1525306788000, "17548": 1525307028000, "17549": 1525307608000, "17550": 1525342949000, "17551": 1525343831000, "17552": 1525343917000, "17553": 1525344124000, "17554": 1525428578000, "17555": 1525428672000, "17556": 1525524225000, "17557": 1525524253000, "17558": 1525524816000, "17559": 1525525145000, "17563": 1525738736000, "17564": 1525738791000, "17565": 1525739013000, "17566": 1525739428000, "17567": 1525775710000, "17568": 1525779587000, "17569": 1525812240000, "17570": 1525861358000, "17571": 1525861478000, "17572": 1525863602000, "17573": 1525879198000, "17575": 1525947982000, "17576": 1525948329000, "17577": 1525951793000, "17578": 1525976730000, "17579": 1525976868000, "17580": 1525982385000, "17581": 1526021353000, "17582": 1526039188000, "17583": 1526039628000, "17584": 1526063386000, "17585": 1526150294000, "17586": 1516249512000, "17587": 1525977291000, "17595": 1526378492000, "17596": 1526378554000, "17597": 1526392157000, "17598": 1526396861000, "17599": 1526407788000, "17603": 1526415166000, "17604": 1526438450000, "17605": 1526439631000, "17606": 1526439720000, "17607": 1526440053000, "17608": 1526468972000, "17609": 1526477540000, "17610": 1526516442000, "17611": 1526516511000, "17612": 1526560934000, "17613": 1526590514000, "17614": 1526622825000, "17615": 1526751970000, "17616": 1526760498000, "17617": 1526760600000, "17618": 1526760903000, "17620": 1526899073000, "17621": 1526899279000, "17622": 1526899489000, "17623": 1526900404000, "17624": 1526900763000, "17625": 1526944276000, "17627": 1526973303000, "17628": 1526984391000, "17629": 1527013957000, "17630": 1527049334000, "17631": 1527071742000, "17632": 1527173967000, "17633": 1527199905000, "17634": 1527232194000, "17635": 1527247925000, "17636": 1527282369000, "17637": 1527339793000, "17641": 1527556838000, "17642": 1527557544000, "17643": 1527557674000, "17644": 1527558174000, "17645": 1527558379000, "17646": 1527590487000, "17647": 1527714287000, "17648": 1527722866000, "17651": 1527762452000, "17652": 1527782355000, "17653": 1527799492000, "17654": 1527803069000, "17655": 1527812073000, "17656": 1528105986000, "17657": 1528111282000, "17658": 1528147730000, "17659": 1528148596000, "17660": 1528174470000, "17661": 1528189442000, "17662": 1528196910000, "17663": 1528218074000, "17664": 1528270271000, "17665": 1528290923000, "17666": 1528297702000, "17672": 1528404131000, "17673": 1528406416000, "17674": 1528406468000, "17675": 1528406737000, "17676": 1528409157000, "17683": 1528476876000, "17684": 1528479551000, "17685": 1528479857000, "17686": 1528500740000, "17687": 1528501203000, "17722": 1528716534000, "17723": 1528730087000, "17724": 1528761945000, "17725": 1528762529000, "17726": 1528762596000, "17729": 1528794912000, "17730": 1528802917000, "17731": 1528803070000, "17732": 1528803421000, "17757": 1528821775000, "17760": 1528825328000, "17766": 1528887101000, "17767": 1528887295000, "17768": 1528891958000, "17769": 1528896241000, "17770": 1528919960000, "17778": 1529067078000, "17779": 1529083144000, "17780": 1529083296000, "17781": 1529083639000, "17782": 1529084014000, "17786": 1529361807000, "17787": 1529361925000, "17788": 1529370194000, "17789": 1529396412000, "17790": 1529397047000, "17794": 1529488221000, "17795": 1529489665000, "17796": 1529490589000, "17797": 1529490787000, "17798": 1529490909000, "17799": 1529539755000, "17800": 1529549663000, "17804": 1529574432000, "17805": 1529575831000, "17806": 1529576333000, "17807": 1529576660000, "17808": 1529586343000, "17818": 1529708367000, "17819": 1529708499000, "17820": 1529708678000, "17821": 1529708841000, "17822": 1529710604000, "17823": 1529753278000, "17824": 1529770338000, "17826": 1529938663000, "17827": 1529965343000, "17828": 1529965470000, "17829": 1529965797000, "17830": 1529965868000, "17840": 1530051581000, "17841": 1530051957000, "17842": 1530052049000, "17843": 1530052187000, "17844": 1440921488000, "17845": 1530093475000, "17846": 1530098602000, "17847": 1530100799000, "17848": 1530113355000, "17855": 1530232785000, "17856": 1530232859000, "17857": 1530233148000, "17858": 1530233228000, "17859": 1530237660000, "17860": 1530274935000, "17888": 1530574306000, "17889": 1530574423000, "17890": 1530575051000, "17891": 1530575662000, "17892": 1530575927000, "17899": 1530648898000, "17900": 1530661013000, "17901": 1530661117000, "17902": 1530661169000, "17903": 1530661208000, "17904": 1530708621000, "17905": 1530709180000, "17906": 1530729713000, "17929": 1530823764000, "17931": 1530828264000, "17932": 1530829030000, "17933": 1530830571000, "17934": 1530844495000, "17935": 1530844538000, "17943": 1530893926000, "17944": 1530894605000, "17946": 1530895717000, "17947": 1530902309000, "17948": 1530917871000, "17958": 1530976196000, "18135": 1533316766000, "18564": 1540384120000, "18565": 1540384393000, "18566": 1540384490000, "18567": 1540398338000, "18568": 1540407001000, "18569": 1540465591000, "18570": 1540466773000, "18571": 1540467221000, "18572": 1540467989000, "18586": 1540555663000, "18587": 1540556620000, "18588": 1540556643000, "18589": 1540556678000, "18590": 1540589001000, "18606": 1540696161000, "18607": 1540696453000, "18608": 1540696599000, "18609": 1540697204000, "18610": 1540698639000, "18620": 1540757652000, "18621": 1540765873000, "18622": 1540771026000, "18623": 1540779925000, "18624": 1540814978000, "18625": 1540839197000, "18626": 1540899725000, "18627": 1540902256000, "18628": 1540902571000, "18629": 1540903943000, "18635": 1541032538000, "18636": 1541032682000, "18637": 1541033432000, "18638": 1541034542000, "18639": 1541034612000, "18640": 1541073760000, "18641": 1541091949000, "18642": 1541092012000, "18648": 1541168109000, "18649": 1541168566000, "18650": 1541228682000, "18651": 1541250586000, "18652": 1541250769000, "18656": 1541255597000, "18657": 1541255784000, "18658": 1541256008000, "18659": 1541307681000, "18663": 1541325373000, "18670": 1541345443000, "18671": 1541346807000, "18672": 1541356966000, "18673": 1541362343000, "18674": 1541363539000, "18686": 1541474326000, "18687": 1541474390000, "18688": 1541474626000, "18689": 1541474849000, "18690": 1541476530000, "18739": 1541851913000, "18740": 1541886444000, "18741": 1541888014000, "18745": 1541898354000, "18747": 1541899698000, "18750": 1541947826000, "18751": 1541948894000, "18752": 1541949726000, "18753": 1541950842000, "18754": 1541953204000, "18757": 1541979389000, "18758": 1541981717000, "18759": 1541982118000, "18760": 1541997926000, "18761": 1542000667000, "18765": 1542027880000, "18766": 1542028379000, "18767": 1542036827000, "18771": 1542041932000, "18772": 1542042171000, "18781": 1542116937000, "18782": 1542117045000, "18783": 1542128238000, "18784": 1542130371000, "18785": 1542131561000, "18796": 1542215205000, "18797": 1542228914000, "18798": 1542229017000, "18799": 1542229786000, "18800": 1542238045000, "18808": 1542288405000, "18809": 1542288640000, "18810": 1542289756000, "18811": 1542298112000, "18812": 1542315264000, "18813": 1542376932000, "18814": 1542377370000, "18815": 1542378429000, "18816": 1542385426000, "18817": 1542389114000, "18825": 1542495637000, "18826": 1542496138000, "18827": 1542496453000, "18828": 1542497161000, "18829": 1542498440000, "18839": 1542580319000, "18840": 1542582465000, "18841": 1542590492000, "18842": 1542590727000, "18843": 1542592852000, "18863": 1542679206000, "18864": 1542680247000, "18865": 1542680316000, "18866": 1542680466000, "18867": 1542680854000, "18872": 1542727589000, "18873": 1542730705000, "18879": 1542741523000, "18893": 1542792720000, "18894": 1542796395000, "18901": 1542814669000, "18902": 1542818616000, "18903": 1542819354000, "18904": 1542820570000, "18905": 1542828766000, "18908": 1542858898000, "18925": 1542941713000, "18926": 1542942441000, "18929": 1543005909000, "18930": 1543017394000, "18931": 1543035525000, "18932": 1543074236000, "18933": 1543089646000, "18948": 1543182656000, "18949": 1543192545000, "18950": 1543239176000, "18951": 1543240251000, "18952": 1543240761000, "18962": 1543313818000, "18963": 1543321541000, "18964": 1543335445000, "18965": 1543338928000, "18966": 1543341713000, "18969": 1543357635000, "18977": 1543422144000, "18982": 1543427146000, "18986": 1543443737000, "18987": 1543443909000, "18988": 1543444060000, "19001": 1543512084000, "19002": 1543512164000, "19004": 1543528873000, "19005": 1543528908000, "19006": 1543529055000, "19010": 1543613622000, "19011": 1543613651000, "19012": 1543613839000, "19014": 1543623433000, "19019": 1543629539000, "19021": 1543666183000, "19022": 1543707454000, "19033": 1543778416000, "19106": 1544455267000, "19107": 1544455333000, "19108": 1544462595000, "19109": 1544462650000, "19110": 1544464766000, "19111": 1544507135000, "19112": 1544536450000, "19113": 1544540936000, "19114": 1544541077000, "19115": 1544546063000, "19121": 1544662270000, "19122": 1544665662000, "19123": 1544666402000, "19124": 1544666540000, "19125": 1544684979000, "19135": 1544815902000, "19136": 1544816641000, "19137": 1544819633000, "19138": 1544823783000, "19139": 1544825477000, "19146": 1544908883000, "19147": 1544923018000, "19148": 1544925552000, "19149": 1544926106000, "19150": 1544947479000, "19156": 1545050575000, "19157": 1545051373000, "19158": 1545055031000, "19160": 1545061662000, "19161": 1545090428000, "19178": 1545222923000, "19179": 1545229737000, "19180": 1545252670000, "19181": 1545259980000, "19182": 1545260023000, "19183": 1545315905000, "19184": 1545317255000, "19187": 1545410093000, "19188": 1545410182000, "19189": 1545410770000, "19190": 1545412196000, "19191": 1545412309000, "19192": 1545415930000, "19193": 1545440733000, "19194": 1545440851000, "19199": 1545580026000, "19200": 1545586261000, "19201": 1545586369000, "19202": 1545606360000, "19203": 1545606499000, "19204": 1545675907000, "19205": 1545677563000, "19206": 1545679514000, "19207": 1545680975000, "19208": 1545698483000, "19217": 1545828510000, "19218": 1545840269000, "19219": 1545868249000, "19220": 1545868315000, "19221": 1545869175000, "19229": 1545953714000, "19230": 1545953968000, "19231": 1545953997000, "19232": 1545956864000, "19233": 1545956942000, "19235": 1546006552000, "19236": 1546006733000, "19237": 1546007243000, "19238": 1546007642000, "19239": 1546021257000, "19256": 1546101866000, "19257": 1546102995000, "19258": 1546103030000, "19259": 1546114716000, "19260": 1546121289000, "19270": 1546198673000, "19271": 1546199268000, "19272": 1546205869000, "19273": 1546206847000, "19274": 1546206894000, "19301": 1546366761000, "19302": 1546373206000, "19303": 1546373227000, "19304": 1546373242000, "19305": 1546373258000, "19307": 1546391757000, "19308": 1546396102000, "19309": 1546397646000, "19310": 1546397839000, "19311": 1546410335000, "19330": 1546487113000, "19331": 1546487161000, "19332": 1546505023000, "19333": 1546517924000, "19334": 1546528752000, "19370": 1546700073000, "19371": 1546700094000, "19372": 1546700115000, "19373": 1546700133000, "19374": 1546700162000, "19383": 1546725761000, "19384": 1546726513000, "19385": 1546728441000, "19386": 1546728466000, "19387": 1546759219000, "19390": 1546790028000, "19391": 1546790628000, "19392": 1546802339000, "19393": 1546871277000, "19394": 1546877468000, "19396": 1546907277000, "19397": 1546915895000, "19398": 1546952328000, "19399": 1546952381000, "19400": 1546952869000, "19401": 1546976451000, "19402": 1546976838000, "19403": 1546976985000, "19406": 1547036269000, "19407": 1547037224000, "19408": 1547049280000, "19409": 1547050910000, "19410": 1547081833000, "19411": 1547118044000, "19412": 1547131862000, "19413": 1547138230000, "19414": 1547142166000, "19415": 1547155654000, "19416": 1547210966000, "19417": 1547211088000, "19418": 1547215517000, "19419": 1547215672000, "19420": 1547215888000, "19421": 1547289134000, "19428": 1547411680000, "19429": 1547423156000, "19430": 1547423565000, "19431": 1547423838000, "19432": 1547424229000, "19433": 1547472972000, "19434": 1547496419000, "19435": 1547499934000, "19439": 1547561526000, "19440": 1547592795000, "19441": 1547602494000, "19442": 1547602580000, "19443": 1547603000000, "19444": 1547651934000, "19445": 1547654518000, "19446": 1547655804000, "19447": 1547674130000, "19448": 1547729321000, "19449": 1547729712000, "19450": 1547729814000, "19452": 1547814165000, "19453": 1547830415000, "19454": 1547838104000, "19455": 1547851206000, "19456": 1547861717000, "19457": 1547905304000, "19458": 1547931897000, "19459": 1547932732000, "19460": 1547933227000, "19461": 1547933375000, "19462": 1547933644000, "19465": 1548000307000, "19466": 1548009845000, "19467": 1548022050000, "19468": 1548022494000, "19469": 1548038792000, "19474": 1548080491000, "19475": 1548099519000, "19476": 1548162242000, "19477": 1548168572000, "19478": 1548199773000, "19480": 1548260544000, "19481": 1548260598000, "19482": 1548265931000, "19483": 1548268234000, "19484": 1548279435000, "19488": 1548343566000, "19489": 1548348305000, "19490": 1548348534000, "19491": 1548356483000, "19492": 1548383205000, "19498": 1548426187000, "19499": 1548428076000, "19500": 1548428149000, "19501": 1548430346000, "19502": 1548451808000, "19510": 1548515330000, "19511": 1548516886000, "19512": 1548517342000, "19514": 1548524852000, "19515": 1548524921000, "19516": 1548558346000, "19583": 1549228549000, "19819": 1552425131000, "19867": 1553084815000, "19868": 1553084923000, "19869": 1553090634000, "19870": 1553090803000, "19871": 1553109240000, "19872": 1553137663000, "19873": 1553166811000, "19874": 1553166845000, "19875": 1553167425000, "19876": 1553181128000, "19877": 1553253754000, "19878": 1553255468000, "19879": 1553271517000, "19880": 1553271577000, "19881": 1553284018000, "19882": 1553306932000, "19883": 1553371722000, "19884": 1553372009000, "19886": 1553452450000, "19887": 1553461005000, "19888": 1553464138000, "19889": 1553467286000, "19890": 1553470444000, "19892": 1553513804000, "19893": 1553556272000, "19895": 1553559902000, "19896": 1553560122000, "19897": 1553575113000, "19899": 1553600390000, "19900": 1553615106000, "19901": 1553620176000, "19902": 1553630756000, "19903": 1553637077000, "19904": 1553687453000, "19905": 1553690808000, "19906": 1553719483000, "19907": 1553728527000, "19908": 1553777294000, "19909": 1553792097000, "19910": 1553804380000, "19911": 1553805914000, "19912": 1553808549000, "19913": 1553861610000, "19914": 1553862042000, "19915": 1553873180000, "19920": 1553973153000, "19921": 1553973448000, "19922": 1553973677000, "19923": 1553989525000, "19924": 1553997795000, "19925": 1554046548000, "19926": 1554055234000, "19929": 1554119464000, "19930": 1554157665000, "19931": 1554217392000, "19932": 1554218769000, "19933": 1554239219000, "19934": 1554323134000, "19935": 1554323298000, "19936": 1554323500000, "19937": 1554341462000, "19938": 1554382301000, "19939": 1554382588000, "19940": 1554386503000, "19941": 1554392522000, "19949": 1554425119000, "19950": 1554431118000, "19951": 1554431158000, "19952": 1554431216000, "19953": 1554431294000, "19954": 1554461444000, "19955": 1554470169000, "19956": 1554483283000, "19957": 1554526716000, "19958": 1554650755000, "19959": 1554672538000, "19960": 1554679160000, "19961": 1554739447000, "19962": 1554808817000, "19963": 1554830899000, "19964": 1554859118000, "19965": 1554877220000, "19966": 1554901182000, "19967": 1554901241000, "19968": 1554943666000, "19969": 1554997296000, "19974": 1555079814000, "19975": 1555080378000, "19976": 1555088909000, "19977": 1555106289000, "19978": 1555106403000, "19979": 1555189880000, "19980": 1555296603000, "19981": 1555301135000, "19982": 1555301267000, "19986": 1555331129000, "19987": 1555335335000, "19988": 1555348159000, "19989": 1555361119000, "19990": 1555399560000, "19992": 1555415763000, "19993": 1555415944000, "19994": 1555417061000, "19995": 1555435036000, "19996": 1555488403000, "20003": 1555601500000, "20004": 1555616820000, "20005": 1555624334000, "20006": 1555635834000, "20007": 1555636006000, "20008": 1555703338000, "20011": 1555779039000, "20012": 1555779144000, "20013": 1555784412000, "20014": 1555785214000, "20015": 1555785889000, "20022": 1555863659000, "20023": 1555864624000, "20024": 1555864704000, "20025": 1555868299000, "20026": 1555889328000, "20027": 1555947099000, "20028": 1555979974000, "20029": 1555994701000, "20030": 1556021435000, "20031": 1556021547000, "20032": 1556021787000, "20033": 1556022258000, "20036": 1556118320000, "20037": 1556139656000, "20038": 1556139731000, "20039": 1556139785000, "20040": 1556144834000, "20041": 1556204004000, "20042": 1556239511000, "20043": 1556240006000, "20044": 1556241162000, "20045": 1556241369000, "20046": 1556348900000, "20050": 1556469594000, "20051": 1556469939000, "20052": 1556485043000, "20053": 1556486093000, "20054": 1556498866000, "20059": 1556629548000, "20060": 1556629636000, "20061": 1556630097000, "20062": 1556630229000, "20063": 1556637478000, "20064": 1556710951000, "20065": 1556746321000, "20066": 1556747182000, "20067": 1556747280000, "20068": 1556753220000, "20069": 1556799307000, "20070": 1556799457000, "20071": 1556816158000, "20072": 1556828646000, "20073": 1556862609000, "20074": 1556889815000, "20075": 1556895134000, "20077": 1557077658000, "20078": 1557090951000, "20079": 1557091155000, "20080": 1557091314000, "20081": 1557094800000, "20087": 1557191317000, "20088": 1557192410000, "20089": 1557193024000, "20090": 1557193088000, "20091": 1557194359000, "20092": 1557202764000, "20093": 1557228479000, "20094": 1557228521000, "20095": 1557228701000, "20096": 1557251389000, "20097": 1557256670000, "20099": 1557287829000, "20100": 1557289119000, "20101": 1557297163000, "20102": 1557310321000, "20103": 1557327504000, "20104": 1557405117000, "20105": 1557405394000, "20106": 1557405428000, "20107": 1557445993000, "20108": 1557524280000, "20109": 1557524394000, "20111": 1557525391000, "20119": 1557691373000, "20120": 1557693248000, "20121": 1557693932000, "20122": 1557694318000, "20123": 1557694464000, "20124": 1557765620000, "20125": 1557767823000, "20126": 1557778913000, "20127": 1557798053000, "20130": 1557843329000, "20131": 1557849839000, "20132": 1557853774000, "20133": 1557853980000, "20134": 1557884502000, "20140": 1557963081000, "20141": 1557963144000, "20142": 1557964011000, "20143": 1557965722000, "20144": 1557971259000, "20205": 1559180956000, "20206": 1559222118000, "20207": 1559243817000, "20208": 1559245863000, "20209": 1559274036000, "20210": 1559306470000, "20211": 1559348273000, "20221": 1559400994000, "20222": 1559401386000, "20223": 1559403297000, "20224": 1559407616000, "20225": 1559408638000, "20228": 1559517108000, "20229": 1559517188000, "20230": 1559517615000, "20231": 1559518467000, "20232": 1559518974000, "20233": 1559540125000, "20234": 1559562989000, "20235": 1559600260000, "20236": 1559611429000, "20237": 1559647422000, "20238": 1559692741000, "20239": 1559719328000, "20240": 1559735620000, "20241": 1559738797000, "20242": 1559739033000, "20243": 1559739274000, "20244": 1559739552000, "20245": 1559760278000, "20246": 1559761573000, "20247": 1559766645000, "20248": 1559770674000, "20249": 1559771327000, "20250": 1559831305000, "20251": 1559831437000, "20252": 1559832605000, "20253": 1559835981000, "20254": 1559842699000, "20260": 1559936699000, "20261": 1559939647000, "20262": 1559959534000, "20263": 1559967763000, "20264": 1559967892000, "20272": 1560029119000, "20273": 1560030250000, "20274": 1560030349000, "20275": 1560030931000, "20276": 1560036180000, "20277": 1560105771000, "20278": 1560117071000, "20279": 1560117098000, "20280": 1560117502000, "20281": 1560117596000, "20292": 1560212099000, "20293": 1560212217000, "20294": 1560212338000, "20295": 1560241624000, "20296": 1560268058000, "20297": 1560277883000, "20298": 1560278797000, "20299": 1560281003000, "20300": 1560303770000, "20301": 1560330133000, "20306": 1560354295000, "20307": 1560362213000, "20308": 1560364847000, "20309": 1560365549000, "20310": 1560384010000, "20313": 1560452668000, "20314": 1560455636000, "20315": 1560458504000, "20316": 1560494634000, "20317": 1560494712000, "20319": 1560515220000, "20320": 1560516120000, "20321": 1560516665000, "20322": 1560520592000, "20323": 1560522162000, "20324": 1560675186000, "20325": 1560693920000, "20326": 1560695439000, "20327": 1560695533000, "20328": 1560718053000, "20329": 1560756269000, "20330": 1560771879000, "20337": 1560902227000, "20338": 1560903555000, "20339": 1560904862000, "20340": 1560906333000, "20341": 1560967061000, "20342": 1561013932000, "20343": 1561031293000, "20354": 1561109837000, "20355": 1561126783000, "20356": 1561132344000, "20357": 1561132708000, "20358": 1561134332000, "20359": 1561136494000, "20360": 1561139728000, "20361": 1561151998000, "20362": 1561155044000, "20363": 1561223943000, "20364": 1561231177000, "20365": 1561280726000, "20366": 1561291086000, "20367": 1561391561000, "20368": 1561423666000, "20369": 1561465184000, "20370": 1561466065000, "20371": 1561466893000, "20372": 1561479111000, "20373": 1561479199000, "20392": 1561671188000, "20393": 1561672788000, "20394": 1561677207000, "20395": 1561677239000, "20396": 1561677610000, "20481": 1562213026000, "20572": 1563462007000, "20573": 1563465395000, "20574": 1563465802000, "20575": 1563479176000, "20576": 1563479338000, "20577": 1563537319000, "20581": 1563653164000, "20582": 1563653219000, "20583": 1563654974000, "20584": 1563666587000, "20585": 1563671204000, "20586": 1563796351000, "20587": 1563797229000, "20588": 1563797319000, "20589": 1563809259000, "20590": 1563815036000, "20591": 1563830036000, "20592": 1563830093000, "20593": 1563882160000, "20594": 1563908460000, "20608": 1563969385000, "20610": 1563969510000, "20611": 1563969947000, "20612": 1563970033000, "20615": 1563973292000, "20616": 1563986570000, "20617": 1564070297000, "20634": 1564092768000, "20635": 1564141388000, "20636": 1564141464000, "20637": 1564141535000, "20638": 1564141894000, "20639": 1564158928000, "20640": 1564174621000, "20641": 1564174725000, "20642": 1564174735000, "20643": 1564236576000, "20644": 1564307687000, "20645": 1564419158000, "20646": 1564419339000, "20647": 1564471224000, "20648": 1564475187000, "20649": 1564477848000, "20655": 1564576199000, "20656": 1564576259000, "20657": 1564576355000, "20658": 1564577340000, "20659": 1564587648000, "20661": 1564604532000, "20662": 1564661627000, "20663": 1564661716000, "20665": 1564664208000, "20668": 1564667819000, "20676": 1564749826000, "20677": 1564752497000, "20679": 1564752659000, "20680": 1564761556000, "20681": 1564766059000, "20781": 1565823045000, "20782": 1565872796000, "20783": 1565872892000, "20784": 1565872957000, "20785": 1565873050000, "20786": 1565900837000, "20793": 1565957470000, "20794": 1565957547000, "20795": 1565957682000, "20797": 1565983132000, "20798": 1565985995000, "20800": 1566116627000, "20847": 1566479388000, "20850": 1566484565000, "20851": 1566547563000, "20852": 1566550888000, "20853": 1566550980000, "20854": 1566567379000, "20855": 1566583909000, "20856": 1566599818000, "20857": 1566599897000, "20858": 1566639174000, "20859": 1566748480000, "20860": 1566748575000, "20861": 1566748678000, "20862": 1566749099000, "20868": 1566829585000, "20869": 1566829660000, "20870": 1566837434000, "20872": 1566839426000, "20873": 1566842039000, "20878": 1566861065000, "20879": 1566861373000, "20880": 1566862752000, "20881": 1566863564000, "20883": 1566914981000, "20884": 1566941560000, "20885": 1566941943000, "20886": 1566942622000, "20887": 1567024496000, "20888": 1567033306000, "20889": 1567081023000, "20890": 1567081891000, "20895": 1567183119000, "20897": 1567184731000, "20898": 1567184809000, "20899": 1567184913000, "20900": 1567184943000, "20902": 1567190628000, "20903": 1567198442000, "21008": 1568810103000, "21009": 1568813108000, "21010": 1568814156000, "21011": 1568814524000, "21012": 1568815331000, "21013": 1568819406000, "21014": 1568824022000, "21250": 1571414970000, "21265": 1571504831000, "21266": 1571504916000, "21267": 1571505075000, "21268": 1571505185000, "21269": 1571508862000, "21270": 1571579394000, "21271": 1571610400000, "21272": 1571610461000, "21273": 1571640595000, "21274": 1571659048000, "21277": 1571704881000, "21278": 1571707890000, "21279": 1571708136000, "21280": 1571709218000, "21281": 1571717240000, "21299": 1571773378000, "21300": 1571775450000, "21301": 1571775502000, "21302": 1571779648000, "21303": 1571785917000, "21304": 1571791970000, "21305": 1571794736000, "21306": 1571831201000, "21307": 1571831260000, "21308": 1571840589000, "21312": 1571852887000, "21313": 1571859382000, "21314": 1571861287000, "21315": 1571865485000, "21316": 1571875452000, "21317": 1571918599000, "21318": 1571918786000, "21319": 1571919007000, "21320": 1571919056000, "21321": 1571942283000, "21331": 1572022474000, "21332": 1572022889000, "21333": 1572023432000, "21334": 1572025773000, "21335": 1572038754000, "21336": 1572078539000, "21337": 1572082844000, "21372": 1572508858000, "21373": 1572508909000, "21374": 1572509033000, "21375": 1572509162000, "21376": 1572509291000, "21380": 1572537378000, "21381": 1572537827000, "21382": 1572541448000, "21383": 1572541830000, "21384": 1572543904000, "21386": 1572553014000, "21387": 1572619858000, "21388": 1572650179000, "21389": 1572650311000, "21422": 1572819103000, "21423": 1572874683000, "21424": 1572874847000, "21425": 1572874961000, "21426": 1572875413000, "21432": 1572886494000, "21433": 1572897527000, "21434": 1572901215000, "21435": 1572905431000, "21436": 1572906086000, "21439": 1572973628000, "21440": 1572973996000, "21441": 1572974300000, "21442": 1572974392000, "21443": 1572987459000, "21455": 1573075366000, "21456": 1573075406000, "21457": 1573075506000, "21458": 1573090486000, "21459": 1573112068000, "21473": 1573164807000, "21474": 1573168093000, "21475": 1573175003000, "21476": 1573186647000, "21477": 1573188066000, "21479": 1573221949000, "21480": 1573223864000, "21481": 1573223972000, "21482": 1573224300000, "21483": 1573224490000, "21486": 1573231268000, "21487": 1573231361000, "21488": 1573231656000, "21489": 1573243056000, "21490": 1573261194000, "21491": 1573316074000, "21492": 1573324506000, "21493": 1573327110000, "21494": 1573328621000, "21495": 1573333795000, "21496": 1573345067000, "21497": 1573397049000, "21498": 1573413087000, "21544": 1573663617000, "21545": 1573663648000, "21546": 1573664287000, "21547": 1573667128000, "21548": 1573716613000, "21684": 1574550280000, "21685": 1574550600000, "21686": 1574550638000, "21687": 1574553141000, "21688": 1574583844000, "21689": 1574668516000, "21690": 1574690061000, "21691": 1574690635000, "21692": 1574696988000, "21707": 1574725846000, "21708": 1574725933000, "21709": 1574726187000, "21710": 1574726443000, "21711": 1574728347000}, "params": {"Cython": [""], "arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz"], "machine": ["asv-runner"], "matplotlib": [""], "numexpr": [""], "numpy": [""], "openpyxl": [""], "os": ["Linux 3.13.0-116-generic"], "pytables": [""], "pytest": [""], "python": ["3.6"], "ram": ["501692"], "scipy": [""], "sqlalchemy": [""], "xlrd": [""], "xlsxwriter": [""], "xlwt": [""], "odfpy": ["", null], "branch": ["master"]}, "graph_param_list": [{"Cython": "", "arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "matplotlib": "", "numexpr": "", "numpy": "", "openpyxl": "", "os": "Linux 3.13.0-116-generic", "pytables": "", "pytest": "", "python": "3.6", "ram": "501692", "scipy": "", "sqlalchemy": "", "xlrd": "", "xlsxwriter": "", "xlwt": "", "branch": "master", "odfpy": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.6", "Cython": "", "matplotlib": "", "numexpr": "", "numpy": "", "odfpy": "", "openpyxl": "", "pytables": "", "pytest": "", "scipy": "", "sqlalchemy": "", "xlrd": "", "xlsxwriter": "", "xlwt": "", "branch": "master"}], "benchmarks": {"algorithms.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, keep, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N).repeat(5)),\n            \"uint\": pd.UInt64Index(np.arange(N).repeat(5)),\n            \"float\": pd.Float64Index(np.random.randn(N).repeat(5)),\n            \"string\": tm.makeStringIndex(N).repeat(5),\n        }\n        self.idx = data[dtype]\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.Duplicated.time_duplicated", "number": 0, "param_names": ["keep", "dtype"], "params": [["'first'", "'last'", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "74d6904a4bd50534781f98df04db6cad3f61dbf663cdaaec5cb0306797741aed", "warmup_time": -1}, "algorithms.DuplicatedUniqueIndex.time_duplicated_unique": {"code": "class DuplicatedUniqueIndex:\n    def time_duplicated_unique(self, dtype):\n        self.idx.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedUniqueIndex:\n    def setup(self, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N)),\n            \"uint\": pd.UInt64Index(np.arange(N)),\n            \"float\": pd.Float64Index(np.random.randn(N)),\n            \"string\": tm.makeStringIndex(N),\n        }\n        self.idx = data[dtype]\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.DuplicatedUniqueIndex.time_duplicated_unique", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a46b27b0257c0e2a3385d7779f3fe1eb50f2894bfebfc8d8b210244b23d49fe6", "warmup_time": -1}, "algorithms.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, sort, dtype):\n        self.idx.factorize(sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, sort, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N).repeat(5)),\n            \"uint\": pd.UInt64Index(np.arange(N).repeat(5)),\n            \"float\": pd.Float64Index(np.random.randn(N).repeat(5)),\n            \"string\": tm.makeStringIndex(N).repeat(5),\n        }\n        self.idx = data[dtype]", "min_run_count": 2, "name": "algorithms.Factorize.time_factorize", "number": 0, "param_names": ["sort", "dtype"], "params": [["True", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e02c1b21bd27cdf082811994cc3c225e4e70105d30566e9e4abe13d3e68a7cf", "warmup_time": -1}, "algorithms.FactorizeUnique.time_factorize": {"code": "class FactorizeUnique:\n    def time_factorize(self, sort, dtype):\n        self.idx.factorize(sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FactorizeUnique:\n    def setup(self, sort, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Int64Index(np.arange(N)),\n            \"uint\": pd.UInt64Index(np.arange(N)),\n            \"float\": pd.Float64Index(np.arange(N)),\n            \"string\": tm.makeStringIndex(N),\n        }\n        self.idx = data[dtype]\n        assert self.idx.is_unique", "min_run_count": 2, "name": "algorithms.FactorizeUnique.time_factorize", "number": 0, "param_names": ["sort", "dtype"], "params": [["True", "False"], ["'int'", "'uint'", "'float'", "'string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "972e2a720d37ed580dc20fa1382cb6e675876cfcffa3d07a0151bdef7e92ec47", "warmup_time": -1}, "algorithms.Hashing.time_frame": {"code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_frame", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bc2c6db74bd1f488ca6783b5cd81a4b851a81e246014b6cec2110b954ec00bdd", "warmup_time": -1}, "algorithms.Hashing.time_series_categorical": {"code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_categorical", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab02ec2d092fd346762565de36d662fc7324aa0eb98c8a444fcaa3e2931b3d79", "warmup_time": -1}, "algorithms.Hashing.time_series_dates": {"code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_dates", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "36b45d66b4bf69f87d243de165371713e9669e1ad65b7583cfc86cc9fa07c79d", "warmup_time": -1}, "algorithms.Hashing.time_series_float": {"code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_float", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a28e3e5aae224b2c4f9ef82cc9649b606348c9af7ad9d8df5ae6d6affd49917c", "warmup_time": -1}, "algorithms.Hashing.time_series_int": {"code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4b75325e885a3f804e718278e33960d6f81b5896d368b6ee7bfd810aa1a9b54", "warmup_time": -1}, "algorithms.Hashing.time_series_string": {"code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b4e01cea19ae95b5b36ae39ae3347cff5a134b7b64a539b3bd8415d43649144", "warmup_time": -1}, "algorithms.Hashing.time_series_timedeltas": {"code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_timedeltas", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/algorithms.py:113", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb99aa0738d0481fed160deda787db0a56b025989985028ec0bb84423e16749e", "warmup_time": -1}, "algorithms.MaybeConvertObjects.time_maybe_convert_objects": {"code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10 ** 5\n    \n        data = list(range(N))\n        data[0] = pd.NaT\n        data = np.array(data)\n        self.data = data", "min_run_count": 2, "name": "algorithms.MaybeConvertObjects.time_maybe_convert_objects", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03820a97e076c4a119a3158f0b32576f52912a74115c24ebc90f8d23a265e82b", "warmup_time": -1}, "algorithms.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.idx.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": np.arange(N),\n            \"uint\": np.arange(N).astype(np.uint64),\n            \"float\": np.random.randn(N),\n        }\n        self.idx = pd.Series(data[dtype].repeat(5))", "min_run_count": 2, "name": "algorithms.Quantile.time_quantile", "number": 0, "param_names": ["quantile", "interpolation", "dtype"], "params": [["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"], ["'float'", "'int'", "'uint'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ebf62e9c35a12781054738fc93719e6aee86d91242279f49a8d3c3a82c211159", "warmup_time": -1}, "algorithms.SortIntegerArray.time_argsort": {"code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")", "min_run_count": 2, "name": "algorithms.SortIntegerArray.time_argsort", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8511c08938a6a85d1e3a650d9497946016c62ea27123f3f61a330eaee124870", "warmup_time": -1}, "attrs_caching.CacheReadonly.time_cache_readonly": {"code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CacheReadonly:\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()", "min_run_count": 2, "name": "attrs_caching.CacheReadonly.time_cache_readonly", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "318b441bdf0d107918b25d827fd88753a42d9fa4c589ff7faef49aabb4e7ddd4", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_get_index": {"code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.foo = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_get_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "724af0b0b4b503c9c173dad92121ac975bf7f69a8816d35742b2f9303aa5729d", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_set_index": {"code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_set_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "419269e3a9cd0e10128bbb97214df797a349d4c774c362be4e57cc055d1db0ad", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_arr_mask_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_arr_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, arr_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_arr_mask_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d293d47dc8f9c6cc9656559e3d67b5cde6efdd98b69be653bc46cc847a14df2", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_arr_rev": {"code": "class AddOverflowArray:\n    def time_add_overflow_arr_rev(self):\n        checked_add_with_arr(self.arr, self.arr_rev)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_arr_rev", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fc092d7ae693dd485812cf381907c566521cf4e92690cd03fe5b989699f58242", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_b_mask_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_b_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, b_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_b_mask_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "991c0150153d97ecd1306b9ce45c968001c7e603e95d48a6c29469bb36aa7a9c", "warmup_time": -1}, "binary_ops.AddOverflowArray.time_add_overflow_both_arg_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_both_arg_nan(self):\n        checked_add_with_arr(\n            self.arr, self.arr_mixed, arr_mask=self.arr_nan_1, b_mask=self.arr_nan_2\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "binary_ops.AddOverflowArray.time_add_overflow_both_arg_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c73fa08cd242ac103fc3fe6cda9b8e2d7fdba867d6a6fd89778db2c8adad06b", "warmup_time": -1}, "binary_ops.AddOverflowScalar.time_add_overflow_scalar": {"code": "class AddOverflowScalar:\n    def time_add_overflow_scalar(self, scalar):\n        checked_add_with_arr(self.arr, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowScalar:\n    def setup(self, scalar):\n        N = 10 ** 6\n        self.arr = np.arange(N)", "min_run_count": 2, "name": "binary_ops.AddOverflowScalar.time_add_overflow_scalar", "number": 0, "param_names": ["scalar"], "params": [["1", "-1", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "658dd351bdd9a0f422fbdd678d0bc66905208a2ea7a9bcef4bba739c0c7b5653", "warmup_time": -1}, "binary_ops.Ops.time_frame_add": {"code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_add", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "67a855b2c3c992c101f27a9879f9ae9736100576e8d003480f4c96b146c8a00f", "warmup_time": -1}, "binary_ops.Ops.time_frame_comparison": {"code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_comparison", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39273acf4a197d818e315a21b66466e0f9c80be9ff4f8f76675f01e2b06d443c", "warmup_time": -1}, "binary_ops.Ops.time_frame_mult": {"code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_mult", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "728dac3dec55093590972641a530323e7733dc873d4756bc51f384dd65b314f4", "warmup_time": -1}, "binary_ops.Ops.time_frame_multi_and": {"code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "binary_ops.Ops.time_frame_multi_and", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "692513ff2b1a23ee1bec954ddae34ac53fac5f3b6c87633ae3087d8f1c3177b1", "warmup_time": -1}, "binary_ops.Ops2.time_frame_dot": {"code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_dot", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad70c0c75ea6103b6f919b2a834d154b77790c03cb4b2b883810406413353df1", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_div": {"code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_div", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "540eee8f97793c40404ebf85acf29d8a38dbba061a39fd9bf3b04042f54764f1", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_div_by_zero": {"code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_div_by_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d512dbd604e6343f79ef81ca1974a77e55b654b91d89dfd1fa3d045e0e544750", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_floor_by_zero": {"code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_floor_by_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06aa58fa65573b3e4ed064e870f0624fc64ddbe5fe4af26841870c4f0919910c", "warmup_time": -1}, "binary_ops.Ops2.time_frame_float_mod": {"code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_float_mod", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f10eed057397643346e27d6cf17ddf4bec9d56b4a42411971dc048e3b789f859", "warmup_time": -1}, "binary_ops.Ops2.time_frame_int_div_by_zero": {"code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_int_div_by_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c6b1ce4e9bc0036dbf458265bb584e662839a1e3c05a6562c373355bd340284e", "warmup_time": -1}, "binary_ops.Ops2.time_frame_int_mod": {"code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_int_mod", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d612b555bda0db0cd2dac900fd62078e386410041c5173d1c50d2337284c57a", "warmup_time": -1}, "binary_ops.Ops2.time_frame_series_dot": {"code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_frame_series_dot", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "524612747dc8b88b4a00e9099c26e6524ab0266b379a13454f56de19cb9f410a", "warmup_time": -1}, "binary_ops.Ops2.time_series_dot": {"code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "binary_ops.Ops2.time_series_dot", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1a991daf3f6f3240a58cc36892fc8a2028caf2aa1cf9174c2cad4adfda8a8fb0", "warmup_time": -1}, "binary_ops.Timeseries.time_series_timestamp_compare": {"code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_series_timestamp_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2c83ef0d799936822029c6993ac17e2aa3fba411660ebb46b4a187a061c37584", "warmup_time": -1}, "binary_ops.Timeseries.time_timestamp_ops_diff": {"code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_timestamp_ops_diff", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfbd8cfc82cbb7938f3d207cc44a2cd9cdd4d0d19b152ea361caf8d3b830f835", "warmup_time": -1}, "binary_ops.Timeseries.time_timestamp_ops_diff_with_shift": {"code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_timestamp_ops_diff_with_shift", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8273bc69a5b133323dc319285f8dd641b46188d07244cbb3035b814cf467d58", "warmup_time": -1}, "binary_ops.Timeseries.time_timestamp_series_compare": {"code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "binary_ops.Timeseries.time_timestamp_series_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a8526ede350ba7c4f65ca375b76d5b0edb3eeffb3ed17f4caad0911d08f1f610", "warmup_time": -1}, "categoricals.CategoricalOps.time_categorical_op": {"code": "class CategoricalOps:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalOps:\n    def setup(self, op):\n        N = 10 ** 5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)", "min_run_count": 2, "name": "categoricals.CategoricalOps.time_categorical_op", "number": 0, "param_names": ["op"], "params": [["'__lt__'", "'__le__'", "'__eq__'", "'__ne__'", "'__ge__'", "'__gt__'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa1b3ce94df35beb0f96ec4778b51ea09499d0160d76f9ed54a2301242704f56", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_bool_array": {"code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "86a011011ac395f8fc5f29a50aa4bd848502098da8633bcec5bb7b26901129a4", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list": {"code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80573150f24a008d1e506af102b79e9043600c6bdf44167720392fdb6c2710ec", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list_like": {"code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "382a78a3f7ccfa9221eeac2207adaf0d469c8ac86b136bae34d73bb653a53d3a", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_scalar": {"code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a6fbf8be1b80d334be577d8daf846fff77cf4dfd3d9281863f2ef60dcb76296", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_slice": {"code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b2d401b4fc5613f63e4d9e2dd91da5a0b5048d9fc7cd70d3ffe103001f08a59", "warmup_time": -1}, "categoricals.Concat.time_concat": {"code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)", "min_run_count": 2, "name": "categoricals.Concat.time_concat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63fd9790f736284e924ed307c6421ee1f09bb33fffdb2d42a549b0947bf61d4d", "warmup_time": -1}, "categoricals.Concat.time_union": {"code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)", "min_run_count": 2, "name": "categoricals.Concat.time_union", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0b7407df4167f119dc61fda5455d8d813df42e2a707e92b9a642b82205590535", "warmup_time": -1}, "categoricals.Constructor.time_all_nan": {"code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_all_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9b025ed98b0af3757435cc3f5068bda73201de9aadcca2903d2e378b27481ec1", "warmup_time": -1}, "categoricals.Constructor.time_datetimes": {"code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ed71726ba69bec3e598802562749f3d68e59c9379a6fe97532b031c6808d998a", "warmup_time": -1}, "categoricals.Constructor.time_datetimes_with_nat": {"code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes_with_nat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fec01c81f0925b2376ceaa1ac678d6dbe9663c3da15f8ef817693d030a1c1179", "warmup_time": -1}, "categoricals.Constructor.time_existing_categorical": {"code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_categorical", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "605f4412feaf1f523743b59d2e270c3dfaedfdf94c72cda862b9a6fa1b91fb92", "warmup_time": -1}, "categoricals.Constructor.time_existing_series": {"code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f456053be0757c67b42419473dea42a6c402bbbf4af2527a3330bc7db56f03f9", "warmup_time": -1}, "categoricals.Constructor.time_fastpath": {"code": "class Constructor:\n    def time_fastpath(self):\n        pd.Categorical(self.codes, self.cat_idx, fastpath=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_fastpath", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2a34575b0930b2df5f06b8a43ddf73d38c0b19c63952c1f51505c24d19f87f0", "warmup_time": -1}, "categoricals.Constructor.time_from_codes_all_int8": {"code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_from_codes_all_int8", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d061d4e5744ecf77f79dd4d70f9bda9bbcfd11f9e5a3598ba3c35577c27a937f", "warmup_time": -1}, "categoricals.Constructor.time_regular": {"code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_regular", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "514b215a884179242991414691d877433248533cd2235f4894ab2cb5fec12126", "warmup_time": -1}, "categoricals.Constructor.time_with_nan": {"code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)", "min_run_count": 2, "name": "categoricals.Constructor.time_with_nan", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "638472edeb14c0bd1ebbf69ce0c350663f8fa5612f29b3afec70aafd50315c47", "warmup_time": -1}, "categoricals.Contains.time_categorical_contains": {"code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3d8dd005efc545cefe492bdd925b434abf10b89f6f92f8aeceb482e39d02144c", "warmup_time": -1}, "categoricals.Contains.time_categorical_index_contains": {"code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd8ebae02bfdb922015c48f72b1b1a6aff2ae989ea22d489c56158f7a2965e8e", "warmup_time": -1}, "categoricals.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_align", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e81509916cd399ab60fd97fc8cca7ca8cfacd82ec3952aec12ff5fbb91086fbf", "warmup_time": -1}, "categoricals.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "449dbdb6fe573b7b07fcfbdc500fb28fa1df6ef5a7e62c816545a5161bd47eac", "warmup_time": -1}, "categoricals.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5688fa14a16c913a25b8798aff106cd4dea846874c4f4a48f4bb7c3988d9b621", "warmup_time": -1}, "categoricals.Indexing.time_reindex": {"code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fd56f04d448d0b21abfb503d90d9ca5470fe2f200f2d3569080c0e560235ece", "warmup_time": -1}, "categoricals.Indexing.time_reindex_missing": {"code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex_missing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0911734d40abf3f6930c4e093d08bc6ea37d98b56ce012f33d8ed2cf8307af35", "warmup_time": -1}, "categoricals.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c6539cca059f9c95ebd6d085d95ca43169338f32c8305e671919b3a4cd072c6c", "warmup_time": -1}, "categoricals.Indexing.time_shape": {"code": "class Indexing:\n    def time_shape(self):\n        self.index.shape\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shape", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29c65b11293651668fca2a1876f1d9a438e17819c73c26d700c68164ed7b1256", "warmup_time": -1}, "categoricals.Indexing.time_sort_values": {"code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_sort_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7824f70d9198203326e632dad2ab979dd3b695d065a5df07434ef0a6720a2358", "warmup_time": -1}, "categoricals.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0416d555edd6329b37769db364734b1460b9298d49a5ebc7c67f7d81711f49cc", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa5876d4a3142dd06fb9b9b448e26396b1d87e2bcd0f53971f22d05f01d74b69", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd56718c84977ba1058dc6d1b12a27633b8ebb7c6d94fc9ab288ae9800841446", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49356d52f4a8f0166e1a989f49c536ba51f2aec3d37077d4ae104c3cbd9643be", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0253b760f0377ec35dbff5bdf6ff5cd2c0e7cef1ec0cb4d0903b7c355b8f14da", "warmup_time": -1}, "categoricals.Isin.time_isin_categorical": {"code": "class Isin:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.sample)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        np.random.seed(1234)\n        n = 5 * 10 ** 5\n        sample_size = 100\n        arr = list(np.random.randint(0, n // 10, size=n))\n        if dtype == \"object\":\n            arr = [f\"s{i:04d}\" for i in arr]\n        self.sample = np.random.choice(arr, sample_size)\n        self.series = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Isin.time_isin_categorical", "number": 0, "param_names": ["dtype"], "params": [["'object'", "'int64'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e35fd79e4133b0f26ebe62a5f85ea6d2c0dfadb6062034f98a326e9adcb07d6", "warmup_time": -1}, "categoricals.Rank.time_rank_int": {"code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "680add1ecee5abc1808455f95e0237006661dcf01e0fa79ca426f2081d4b89c1", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat": {"code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aacf23031ae813ac93768492d8ee858b0b21e100e85b79f999268c0bf0234323", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat_ordered": {"code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat_ordered", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea7b6de9f4513a45416a379bae165c30b2ce9967fa61b019d56bd193eeb28e57", "warmup_time": -1}, "categoricals.Rank.time_rank_string": {"code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "72479466fb69f7e3dd9a98b644a58b1ccc03cab38fba35a04c0fb6a8eaca98c4", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat": {"code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35f35b1a0188eeb3b7b3892c057db7de26f954111267929b35347a470187d781", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat_ordered": {"code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat_ordered", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70869417885aee2a19a08e0dd52d9fa72cdad8d9f78308f0c62e56eb31825ca2", "warmup_time": -1}, "categoricals.RemoveCategories.time_remove_categories": {"code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.RemoveCategories.time_remove_categories", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "88ef9b1206f5f38104b565cd51c23dfdf2fd3baf306436d71c9e67ca721871d2", "warmup_time": -1}, "categoricals.Repr.time_rendering": {"code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Repr.time_rendering", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f043899c68a0bddf1ee7a921bb598b5f105966be3ae78c715d752eade54db7b5", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_contains": {"code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "423139351f82c3ea6882246443b5161c2ad06c75b2d76c0371a7109e6fdb636b", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_index_contains": {"code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb3fad7ac713a5ae6d7140c3fa5ac53d3076492a4dc74aa1ff381c7ad0402e19", "warmup_time": -1}, "categoricals.SetCategories.time_set_categories": {"code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.SetCategories.time_set_categories", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "228f5a07bcfaf64253ff659a31090e385cb2482a3a3d8e2a978bd2ca99b36b68", "warmup_time": -1}, "categoricals.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.ValueCounts.time_value_counts", "number": 0, "param_names": ["dropna"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38c3c415a2f65b9bf52a5803806e4f310656fdf7c6e25332ef2819dc58beb1cc", "warmup_time": -1}, "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {"code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10 ** 4\n        self.iterables = [tm.makeStringIndex(N), range(20)]", "min_run_count": 2, "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "392b00af1f28ca8721dd73fb40cf295df0b722d6cc90d82906674f32ff61833f", "warmup_time": -1}, "ctors.SeriesConstructors.time_series_constructor": {"code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10 ** 4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None", "min_run_count": 2, "name": "ctors.SeriesConstructors.time_series_constructor", "number": 1, "param_names": ["data_fmt", "with_index", "dtype"], "params": [["<function no_change at 0x7f6149b10598>", "<class 'list'>", "<function list_of_str at 0x7f6149b102f0>", "<function gen_of_str at 0x7f6149b10378>", "<function arr_dict at 0x7f6149b10400>", "<function list_of_tuples at 0x7f6149b10268>", "<function gen_of_tuples at 0x7f6149b100d0>", "<function list_of_lists at 0x7f6149b10158>", "<function list_of_tuples_with_none at 0x7f6149b101e0>", "<function list_of_lists_with_none at 0x7f6149b10048>"], ["False", "True"], ["'float'", "'int'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7eef9b16b4736229aefbb3892dd90808d3615cf5a5b492a0b1e695fff6bbe4dc", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aeeff25a8f96d74fadfcf452661c48a61f77b2a3133d78b9ec317245c0bc754c", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccec589dc5d6fd152e60291c4dc2fb0242a2015a404235e26ad46a0d993ee7dd", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a23dc31f8d89a80bc087a24e080af596c00b9d4dc78e6cbe5f1615fa460cb31", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_string": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2df00803b4b6e76d5d33a1469de09fd5f7124242499149081029f29e71742ac8", "warmup_time": -1}, "dtypes.Dtypes.time_pandas_dtype": {"code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.Dtypes.time_pandas_dtype", "number": 0, "param_names": ["dtype"], "params": [["dtype('int64')", "dtype('int32')", "dtype('uint32')", "dtype('uint64')", "dtype('float32')", "dtype('float64')", "dtype('int16')", "dtype('int8')", "dtype('uint16')", "dtype('uint8')", "dtype('<M8')", "dtype('<m8')", "dtype('O')", "<class 'pandas.core.arrays.integer.Int8Dtype'>", "<class 'pandas.core.arrays.integer.Int16Dtype'>", "<class 'pandas.core.arrays.integer.Int32Dtype'>", "<class 'pandas.core.arrays.integer.Int64Dtype'>", "<class 'pandas.core.arrays.integer.UInt8Dtype'>", "<class 'pandas.core.arrays.integer.UInt16Dtype'>", "<class 'pandas.core.arrays.integer.UInt32Dtype'>", "<class 'pandas.core.arrays.integer.UInt64Dtype'>", "<class 'pandas.core.dtypes.dtypes.CategoricalDtype'>", "<class 'pandas.core.dtypes.dtypes.IntervalDtype'>", "datetime64[ns, UTC]", "period[D]", "'int64'", "'int32'", "'uint32'", "'uint64'", "'float32'", "'float64'", "'int16'", "'int8'", "'uint16'", "'uint8'", "'datetime64'", "'timedelta64'", "'object'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'category'", "'interval'", "'datetime64[ns, UTC]'", "'period[D]'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c636a90f2e83bdd77f2d6ee44d53f3f544eae867d47edcc9aa01c5fac4e847c1", "warmup_time": -1}, "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {"code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid", "number": 0, "param_names": ["dtype"], "params": [["'scalar-string'", "'scalar-int'", "'list-string'", "'array-string'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0e5e9090205efd4b2b0eaae96ef388c13f2755cbcd2e6d6055c789e521e8f26", "warmup_time": -1}, "eval.Eval.time_add": {"code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_add", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f66cb4c7625db55ad2fb47d6f967fb6168e37ad7c155ab90f9e67f3bd7352d8", "warmup_time": -1}, "eval.Eval.time_and": {"code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_and", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ceb98dd9d1fd4885f6a40036d8b20f03e014564fd923d2f526372cb342b5846", "warmup_time": -1}, "eval.Eval.time_chained_cmp": {"code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_chained_cmp", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "537101344193d00bb2f4e3ac5fcc1229b541ea3bc2d4688ed9cbc4574b7f62fa", "warmup_time": -1}, "eval.Eval.time_mult": {"code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_mult", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb3ea8ccc283549666fb49bc038fc7463a0957adbf7b59586b03ce2616e0c2b8", "warmup_time": -1}, "eval.Query.time_query_datetime_column": {"code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_column", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0bc55ac7b144ae912fe08427150c3d516602fb5dc28d8c9d8c3fe801b52b2e52", "warmup_time": -1}, "eval.Query.time_query_datetime_index": {"code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0146c2044d79deef45a880798c23724d841bbb6f2b4bca8359698b6e49f4ee1f", "warmup_time": -1}, "eval.Query.time_query_with_boolean_selection": {"code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_with_boolean_selection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19e71a2c95d218f6a6faf4f3b31e293759b0496727e95819bad7bf06851cd6bc", "warmup_time": -1}, "frame_ctor.FromDicts.time_list_of_dict": {"code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_list_of_dict", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "700022477b9677e7b5545687666583c3fe1598083ea6cda0a118e8efd3d92e03", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict": {"code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75cb6dc9abe3905bc87ea3c8de2bbe6cf1ce749569b554f7645b895244b42fee", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_columns": {"code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8432cbe52051c2d12cfb5123339cd0d8598ef01619ee8a374f1927732cdd967f", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index": {"code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe4ed1625674e550132871dd0a50063896b08c06b762c09223f1ae2022245de4", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index_columns": {"code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55423a0a7e2c5ba4d57abdc2879dedf93a15440fad062022da3cfc6ad502a53b", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_int64": {"code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_int64", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab236bf17616730a48159c4c93de7fc679eee4232a0b8dcb96ce3e587670d750", "warmup_time": -1}, "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {"code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10 ** 3\n        np.random.seed(1234)\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()", "min_run_count": 2, "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets", "number": 0, "param_names": ["offset"], "params": [["<Nano>", "<Hour>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24655c635e25c11abb8847125ce555c1eb61aa4e6c112a3b95f9e4a3a2feff02", "warmup_time": -1}, "frame_ctor.FromLists.time_frame_from_lists": {"code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]", "min_run_count": 2, "name": "frame_ctor.FromLists.time_frame_from_lists", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53551e4d1da11be641b0c0122b6943106204c9bda18ddd18263ac5c56c7f042b", "warmup_time": -1}, "frame_ctor.FromNDArray.time_frame_from_ndarray": {"code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)", "min_run_count": 2, "name": "frame_ctor.FromNDArray.time_frame_from_ndarray", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6fb5f6568d301464fbdc79a5b9701a4b5435aee21d09337b878ce3a016c89d80", "warmup_time": -1}, "frame_ctor.FromRecords.time_frame_from_records_generator": {"code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))", "min_run_count": 2, "name": "frame_ctor.FromRecords.time_frame_from_records_generator", "number": 1, "param_names": ["nrows"], "params": [["None", "1000"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eec7b09b4fa409f895b70cac11929c08947074b5e92dfb4b844dc4f349e04474", "warmup_time": -1}, "frame_ctor.FromSeries.time_mi_series": {"code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)", "min_run_count": 2, "name": "frame_ctor.FromSeries.time_mi_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31cd15987aceabc0ef946bd94b0df86240ada3c11a2d7a04358bc512d7920595", "warmup_time": -1}, "frame_methods.Apply.time_apply_axis_1": {"code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_axis_1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ced675e528437c2b073f9a06b43fb56462e93b2a712fcf31709614aae3e76f7", "warmup_time": -1}, "frame_methods.Apply.time_apply_lambda_mean": {"code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_lambda_mean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14f8c150feae7c93c72079a2d91274c9b1a2eb977ea7ae0e61ced9369f9a5507", "warmup_time": -1}, "frame_methods.Apply.time_apply_np_mean": {"code": "class Apply:\n    def time_apply_np_mean(self):\n        self.df.apply(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_np_mean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1aba79d189a50e4a68431728911ddbd16de5d3a6fb214db52c554aef6476527", "warmup_time": -1}, "frame_methods.Apply.time_apply_pass_thru": {"code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_pass_thru", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "833e1aa610793ea8e28d7d50100375dea01251e0adc0fd5f45e37fd3fc189568", "warmup_time": -1}, "frame_methods.Apply.time_apply_ref_by_name": {"code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_ref_by_name", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "47628925adc375cbfba3d3daeae599dca7bde70a57b35847fe97b285eb9ce42b", "warmup_time": -1}, "frame_methods.Apply.time_apply_user_func": {"code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_user_func", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d047285f574fea23abcaaeef80ea9b06ab9b7ae6ea21c38ac27de97a3b05b3e6", "warmup_time": -1}, "frame_methods.Count.time_count_level_mixed_dtypes_multi": {"code": "class Count:\n    def time_count_level_mixed_dtypes_multi(self, axis):\n        self.df_mixed.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        with warnings.catch_warnings(record=True):\n            self.df.ix[50:1000, 20:50] = np.nan\n            self.df.ix[2000:3000] = np.nan\n            self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )", "min_run_count": 2, "name": "frame_methods.Count.time_count_level_mixed_dtypes_multi", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7abb92b09ac8178c50573395031a0d50bc39a17fcc880d45a9bd0002b91413f9", "warmup_time": -1}, "frame_methods.Count.time_count_level_multi": {"code": "class Count:\n    def time_count_level_multi(self, axis):\n        self.df.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        with warnings.catch_warnings(record=True):\n            self.df.ix[50:1000, 20:50] = np.nan\n            self.df.ix[2000:3000] = np.nan\n            self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )", "min_run_count": 2, "name": "frame_methods.Count.time_count_level_multi", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70fa3259efdac160bdddc526c3fffc99009e921a788c606fe42d43620863527b", "warmup_time": -1}, "frame_methods.Describe.time_dataframe_describe": {"code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, int(1e6)),\n                \"b\": np.random.randint(0, 100, int(1e6)),\n                \"c\": np.random.randint(0, 100, int(1e6)),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_dataframe_describe", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "10f5f80daba076d94357f45b12a52f3adb2537f264e95b88b63f41f00dd051cf", "warmup_time": -1}, "frame_methods.Describe.time_series_describe": {"code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, int(1e6)),\n                \"b\": np.random.randint(0, 100, int(1e6)),\n                \"c\": np.random.randint(0, 100, int(1e6)),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_series_describe", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c648e66e7487deea98e2727c7eb1455592e523348d0fb53d40c0ce4ec676c4f1", "warmup_time": -1}, "frame_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        with warnings.catch_warnings(record=True):\n            self.df.ix[50:1000, 20:50] = np.nan\n            self.df.ix[2000:3000] = np.nan\n            self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "791759d03260f39d72ae6144226591db32a708b5384633ea323e6249ab32311d", "warmup_time": -1}, "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {"code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        with warnings.catch_warnings(record=True):\n            self.df.ix[50:1000, 20:50] = np.nan\n            self.df.ix[2000:3000] = np.nan\n            self.df.ix[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ac766253876fc9d72630a5e999cbede2a6342b9cc5bfff854bf67a5fdfd12bf", "warmup_time": -1}, "frame_methods.Dtypes.time_frame_dtypes": {"code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))", "min_run_count": 2, "name": "frame_methods.Dtypes.time_frame_dtypes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1eca85c37df3c0fa5ffab4f92c77a0352a28513588025f23251dda0c36027ac3", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated": {"code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddedf9c76ae2eec8e8a76fe34e8be24de43ebeb34817893c792e4d16e93b7054", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_wide": {"code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f159660d9f422b498ae7ffaada1dabe55000ad646dc7ea02e4020e126d6d097", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_equal": {"code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9297a53ea439df3ab2e9ca02044edc3ee3b07c33e8cd19be23917b37e339798b", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_unequal": {"code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_unequal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd24ede72fb979c40804fb5634728fdc1e5c582a2dae3456ae5ed5f7949c8507", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_equal": {"code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c344b5c1ca16e353416823f96f00eb0491fc789311705dd5b07406b32e7fb14b", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_unequal": {"code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_unequal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56b832b60731a2f00414080bac6349d1c70454fe294b6cfc77545161a915b8a9", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_equal": {"code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "344424713951304187cedfdfad4fffd04681938114bba4504411955542e56dd7", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_unequal": {"code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_unequal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ec9d7e64303ee2fd28c0a0a4822fc56d58320a05ebed4945b50e681834f2abe", "warmup_time": -1}, "frame_methods.Fillna.time_frame_fillna": {"code": "class Fillna:\n    def time_frame_fillna(self, inplace, method):\n        self.df.fillna(inplace=inplace, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, method):\n        values = np.random.randn(10000, 100)\n        values[::2] = np.nan\n        self.df = DataFrame(values)", "min_run_count": 2, "name": "frame_methods.Fillna.time_frame_fillna", "number": 0, "param_names": ["inplace", "method"], "params": [["True", "False"], ["'pad'", "'bfill'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7dcf12633de089958156ed6dc74812a3fb114da3adf3e4ebcd39cb9da424baf8", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {"code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df.get_dtype_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05e1100538e06a6d21decb40099e0a4454701e74df68603e27f36e2e987035e6", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_info": {"code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_info", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f9da084cf6f28a48a82fd2244d9854c98469727387a60271fc1b0da6df4e4a3", "warmup_time": -1}, "frame_methods.GetNumericData.time_frame_get_numeric_data": {"code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()", "min_run_count": 2, "name": "frame_methods.GetNumericData.time_frame_get_numeric_data", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c74ad94b824669d079bb2add80253ef91c59a14b0db4aed51afda0f17a8ff361", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate": {"code": "class Interpolate:\n    def time_interpolate(self, downcast):\n        self.df.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        self.df = DataFrame(np.random.randn(N, 100))\n        self.df.values[::2] = np.nan\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate", "number": 0, "param_names": ["downcast"], "params": [["None", "'infer'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95ef90ea2f99dc9713649feda12cc3b3bda0eef0e3a1e0294c1895927e35070a", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate_some_good": {"code": "class Interpolate:\n    def time_interpolate_some_good(self, downcast):\n        self.df2.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        self.df = DataFrame(np.random.randn(N, 100))\n        self.df.values[::2] = np.nan\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate_some_good", "number": 0, "param_names": ["downcast"], "params": [["None", "'infer'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14387244c741fc0a9c417d2ddc0036504e3d07e5b8fa986556cda28fd2a07b09", "warmup_time": -1}, "frame_methods.Isnull.time_isnull": {"code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b71f7a1ceb5631d4166280889a916e7bf24743aa74d3030cb57762915e397e2f", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_floats_no_null": {"code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_floats_no_null", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6cbb0c9dfc9c03b851b70be35012d788c4b4642efead9593f18d10cd9e9da659", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_obj": {"code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_obj", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19f4e217d85cdd700e6df3d8b6b1f6e5349092e0b351ce981051f81b168d408d", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_strngs": {"code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_strngs", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "42add58893d4f3a78db469f145a20501402213a51e5b2da27438b4c84fac5c7a", "warmup_time": -1}, "frame_methods.Iteration.mem_itertuples_raw_start": {"code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "8f73632b8d6514e777fd45d195014fd85bf88269338484ec4beb185fa3b37d01"}, "frame_methods.Iteration.mem_itertuples_raw_to_list": {"code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "4d9806126b8a3cb2ff6e82cbf25460c29943fff894fc8fe80bf032cd15ef67f7"}, "frame_methods.Iteration.mem_itertuples_read_first": {"code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_read_first", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "78ad32e399a89c43ad93586e027787799be54fd90afc0d706a92b41371074f3f"}, "frame_methods.Iteration.mem_itertuples_start": {"code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "1267273cf0568d2681a230f6c8299c306eddebcc35409648c1b22e80386c655f"}, "frame_methods.Iteration.mem_itertuples_to_list": {"code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "adca29baae0fae04e49fdb080966f578eca240942c97f441b71142bb25dd5def"}, "frame_methods.Iteration.peakmem_itertuples": {"code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3125af828cfaafb34b7b6989409191fe30095c4dd2c3396fc1abdbf78658a852"}, "frame_methods.Iteration.peakmem_itertuples_raw": {"code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "dea3a043745ff926b3eb23127f6ae1b6db83a7149ae9334aa14ed81887e8a832"}, "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {"code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "8fe359c715fd2ae9fcd23ce032db63b614c54a7ffa93d0d09f372ca8ce650a2d"}, "frame_methods.Iteration.peakmem_itertuples_raw_start": {"code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "272b9bfb026dbc2a26ff243d1472c4c5000b043b7f6d08475c58d2eea0fb7479"}, "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "5735b8cbc4657bb6b1c7647dd87916cb025ab7a0c03046967ff91328699f579b"}, "frame_methods.Iteration.peakmem_itertuples_start": {"code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "30ee8bfd4e1b0f7b3886a25e7b6b58eb841daf95d86fe777078dc3a1a6e0f7fc"}, "frame_methods.Iteration.peakmem_itertuples_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "29022ec60f31363adfe95a6e0c89b1fee588d6ff0bb60110c42cb4e6cafae3f8"}, "frame_methods.Iteration.time_items": {"code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        if hasattr(self.df, \"_item_cache\"):\n            self.df._item_cache.clear()\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "a3861731bf05eda7aa3c8d5664873ea18b2c4fff788e54c2301204b199b7a510", "warmup_time": -1}, "frame_methods.Iteration.time_items_cached": {"code": "class Iteration:\n    def time_items_cached(self):\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items_cached", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "fb2c6167ac23608e8554e7ead95d4caa02e0036638a4d25114ef18538ee25acf", "warmup_time": -1}, "frame_methods.Iteration.time_iteritems_indexing": {"code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iteritems_indexing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "e4bdc415d5210b84a25d0b2e993dfdceae965ceeb8837359a273ff01d3e119c8", "warmup_time": -1}, "frame_methods.Iteration.time_iterrows": {"code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iterrows", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9ce5cae5c87117f30c0c5bdc7bc767f0a1124338a6ccb32f389b9a79a2693b1f", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples": {"code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "359feef2c7d34f2d7df329153ee31b137f37876d15e2ccf7765abb5bf4032ddc", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_read_first": {"code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_read_first", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "57f8b0d028caac0a0d1bd16e3052d34395cd73b9c63a06c08633b378b0db9e1d", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_start": {"code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_start", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "bf751d74248c9383bc8944d91a0c6ab80eafa400d2b46d613d2a030b0535167f", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples": {"code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9a82a07e0fb33911d647b925938129fa483b40cb4987aede10c9facfcb79d95a", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {"code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "fe5b93cb5dd6cd5ed81e748d434d9e61c55c84c4de6335b795a1ce1687060238", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_read_first": {"code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_read_first", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "f9855924a32ef13ddffb66de6c9f3b3028a50906f6817a7099e10ea7faa8b3b8", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_start": {"code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_start", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "051b433da4956d7a94bee1a13cb59b3b5aa8a1ab161c335ddc0d0855710760b6", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_to_list": {"code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_to_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9d6036b304df237988082bfb3950a32acc0f34300fb5a5dad2fd3731cfaca9e1", "warmup_time": -1}, "frame_methods.Lookup.time_frame_fancy_lookup": {"code": "class Lookup:\n    def time_frame_fancy_lookup(self):\n        self.df.lookup(self.row_labels, self.col_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8), columns=list(\"abcdefgh\"))\n        self.df[\"foo\"] = \"bar\"\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype=\"object\"\n        )\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype=\"object\"\n        )", "min_run_count": 2, "name": "frame_methods.Lookup.time_frame_fancy_lookup", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b604e96edba00f1ff7d6d45598080562d7e9b1340a5f668fb04db9ce4916ecc", "warmup_time": -1}, "frame_methods.Lookup.time_frame_fancy_lookup_all": {"code": "class Lookup:\n    def time_frame_fancy_lookup_all(self):\n        self.df.lookup(self.row_labels_all, self.col_labels_all)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8), columns=list(\"abcdefgh\"))\n        self.df[\"foo\"] = \"bar\"\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype=\"object\"\n        )\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype=\"object\"\n        )", "min_run_count": 2, "name": "frame_methods.Lookup.time_frame_fancy_lookup_all", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0aca21cb40a6490db9c288e401928c525db508aba823dfc83d7f09a91a821ff", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_bools": {"code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_bools", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53396c27fe51bab040f207946d8fb824d0e5193a4a546c2a956b13c6471a17bc", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_floats": {"code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8ab2826673211a03105b29836d30048ce03a984a5717e2b7be1add61ab6fe617", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_one_column": {"code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f196da50ee662e5f45fc59348ba8dab8cd8001a8c0803391b04a15a5ab9ba1c6", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_two_columns": {"code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1cc9433dc1b9753c4cab5d1956c45fd1ab74e93f448a89f1546d440a4a0665de", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_one_column": {"code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27c5184fe8335848e6623274d362d512693ced3fc8c65554e82ee94d4a455b22", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_two_columns": {"code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad2ef1d4cc6afb192ebca737f1e7386a643327e98a08ed5aaec53dadb9240879", "warmup_time": -1}, "frame_methods.Nunique.time_frame_nunique": {"code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))", "min_run_count": 2, "name": "frame_methods.Nunique.time_frame_nunique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7e9a2a2bfaa0bd91728100f010a191c5df8ebb6b4195374fab430a8ed55aec4", "warmup_time": -1}, "frame_methods.Quantile.time_frame_quantile": {"code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Quantile.time_frame_quantile", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de7bdc35beb87fb5a1b8686e508e01472f6a3d0b1a9826051fcdf2e62a8f9f1f", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis0": {"code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis0", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f0b49140d8abc5c02950056d69ffc319f6fb3ebb415055a0b7dd1440ec33640", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1": {"code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a7cfa7fcb0fa34d014a7dccd82441b76e93cacfae68adefe4dd166acdf271c19", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_both_axes": {"code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_both_axes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92e767dd4cbc042705f4af6551bca8b62b036a30fcf00a57190673fa70427c8a", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_upcast": {"code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_upcast", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "26e863db12a9ed65563619a29a002b111054581eaa177a39d8ab3edeef952240", "warmup_time": -1}, "frame_methods.Rename.time_dict_rename_both_axes": {"code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_dict_rename_both_axes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2599de00e34952820784b2cdcd16a948a82a3d6ca752820e080958e93387a7f", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis0": {"code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis0", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77c58d2084037dbbe231d9375b7f07069698815487f491bf7433010fd87e506c", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis1": {"code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f3a4bf2fd3d707fd9c6712b755c75fa979469fa3f1eda253d1d2a9ef7633689", "warmup_time": -1}, "frame_methods.Rename.time_rename_both_axes": {"code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_both_axes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1cb408763b71013feeaac0a79d55e743d2379c3c79927e75c2e68f64342a151", "warmup_time": -1}, "frame_methods.Rename.time_rename_single": {"code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_single", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "89c801d31118615ff40353f240e20122e6e43990886fced880152dfcbec70948", "warmup_time": -1}, "frame_methods.Repr.time_frame_repr_wide": {"code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_frame_repr_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb568593c4b33a8ed38975470fe6b29f317e157c2bff6ad7e3194854ce3bbbf0", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_mi": {"code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_mi", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "640e4b10b23c1fa98c0a07091d957e75121bc0a9d12182901ff89421df574cb9", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_si": {"code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_si", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0625c38f50ef3e2614a975c3b97cfa8b69d5ba7babc9417f10f946020fd6ddfe", "warmup_time": -1}, "frame_methods.Repr.time_repr_tall": {"code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, int(nrows / 100)), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_repr_tall", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f32bf0352558e8826294895745a574c3f76d158504f298372a9f26190ec8aba7", "warmup_time": -1}, "frame_methods.SelectDtypes.time_select_dtypes": {"code": "class SelectDtypes:\n    def time_select_dtypes(self, n):\n        self.df.select_dtypes(include=\"int\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, n):\n        self.df = DataFrame(np.random.randn(10, n))", "min_run_count": 2, "name": "frame_methods.SelectDtypes.time_select_dtypes", "number": 0, "param_names": ["n"], "params": [["100", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "528d5c7263626d3ea9389215f47d94b249559e56b82daa7eea802418d9f5f72e", "warmup_time": -1}, "frame_methods.Shift.time_shift": {"code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))", "min_run_count": 2, "name": "frame_methods.Shift.time_shift", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "395684e7863d6ac7ba645245929a877db93acae804ce3111495aa5b0f1a8209a", "warmup_time": -1}, "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns": {"code": "class SortIndexByColumns:\n    def time_frame_sort_values_by_columns(self):\n        self.df.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndexByColumns:\n    def setup(self):\n        N = 10000\n        K = 10\n        self.df = DataFrame(\n            {\n                \"key1\": tm.makeStringIndex(N).values.repeat(K),\n                \"key2\": tm.makeStringIndex(N).values.repeat(K),\n                \"value\": np.random.randn(N * K),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d00f619ddd6ecf75003e3d3b3abffea78395e46922a4fdbb70b1cf564736228f", "warmup_time": -1}, "frame_methods.SortValues.time_frame_sort_values": {"code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))", "min_run_count": 2, "name": "frame_methods.SortValues.time_frame_sort_values", "number": 0, "param_names": ["ascending"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4f4ef42c704be9a9d5954f164ec62917e674951b3721eeacfc378e2879de9bb", "warmup_time": -1}, "frame_methods.ToHTML.time_to_html_mixed": {"code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)", "min_run_count": 2, "name": "frame_methods.ToHTML.time_to_html_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "715ba060a149d5eeee2b41ed24c38cd5641e94cd24868829505b1eff341d2bcb", "warmup_time": -1}, "frame_methods.ToString.time_to_string_floats": {"code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))", "min_run_count": 2, "name": "frame_methods.ToString.time_to_string_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35ba9d12bdf34f2d470d8cdd3bec022ad580be8c77b8ff412859229dd04409cd", "warmup_time": -1}, "frame_methods.XS.time_frame_xs": {"code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10 ** 4\n        self.df = DataFrame(np.random.randn(self.N, self.N))", "min_run_count": 2, "name": "frame_methods.XS.time_frame_xs", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12a817f099f2facea621b0b1853a0bedd3fd9787540882c16193a6fdc0407561", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_day": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_day", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75e772362637063b852fed995fbd98c374b63eed21ea2e967b8da73c77bb69e6", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0aa4a324839c08d386eda4a105f2f8a0bd6af4b353e736e795ef25ed08391bb6", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_normalize": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "89124d4eab67def513c8a25a8f196d8502c315b20ebdefbd181ed431772472cb", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_year": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_year", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2724c46d71779f44374a89c344c88bc6e9b0d2d6c8a81987d3be3a0b85703573", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_to_period": {"code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"S\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_to_period", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09f7045f2217de016bf68db96710a9939c4bf111ec80c48977bbf1dd4dfc8154", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_period_to_datetime": {"code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_period_to_datetime", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2974d0fe033a251229974e89054e318e26caaabf40044728c5ee5bf5b44aba8", "warmup_time": -1}, "gil.ParallelFactorize.time_loop": {"code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_loop", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "94e3f40e863170a2303d591ae0d7400bb3eb6c245c888b97d317bdbb2e4a40f5", "warmup_time": -1}, "gil.ParallelFactorize.time_parallel": {"code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_parallel", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57bd0790bc69db5cef047e9d0babf38de7c440cd50472f73f9682893205d1231", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_loop": {"code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        ngroups = 10 ** 3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_loop", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8852a82cee7fa6b0f7655a97f691cb45eb83fd83184e9b5e02f319388fa9696c", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_parallel": {"code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        ngroups = 10 ** 3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_parallel", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b33555c38212d27b55ba46856fb83c428872611d48c338819637dfd796de8cb2", "warmup_time": -1}, "gil.ParallelGroups.time_get_groups": {"code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        size = 2 ** 22\n        ngroups = 10 ** 3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups", "min_run_count": 2, "name": "gil.ParallelGroups.time_get_groups", "number": 0, "param_names": ["threads"], "params": [["2", "4", "8"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "58c29e33ad3624c669c3f7af162f16befbe7896262c6f9c4e3a0bfe21c410d04", "warmup_time": -1}, "gil.ParallelKth.time_kth_smallest": {"code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 7\n        k = 5 * 10 ** 5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest", "min_run_count": 2, "name": "gil.ParallelKth.time_kth_smallest", "number": 1, "param_names": [], "params": [], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b23b01de21edf57804e7b0c39020a966a6d357e5616f58beeb2f078162420bf4", "warmup_time": -1}, "gil.ParallelReadCSV.time_read_csv": {"code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        rows = 10000\n        cols = 50\n        data = {\n            \"float\": DataFrame(np.random.randn(rows, cols)),\n            \"datetime\": DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            ),\n            \"object\": DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            ),\n        }\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df = data[dtype]\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv", "min_run_count": 2, "name": "gil.ParallelReadCSV.time_read_csv", "number": 1, "param_names": ["dtype"], "params": [["'float'", "'object'", "'datetime'"]], "processes": 2, "repeat": 5, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70fd4b5b4fe0d106731b8f8aea1e553d0823b8d39fc3126a026c02f7cc25b628", "warmup_time": -1}, "gil.ParallelRolling.time_rolling": {"code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError", "min_run_count": 2, "name": "gil.ParallelRolling.time_rolling", "number": 0, "param_names": ["method"], "params": [["'median'", "'mean'", "'min'", "'max'", "'var'", "'skew'", "'kurt'", "'std'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5474eeb3521a09356dc9f3427339f0b76363f1cc500804964145af389add9c49", "warmup_time": -1}, "gil.ParallelTake1D.time_take1d": {"code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_1d(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d", "min_run_count": 2, "name": "gil.ParallelTake1D.time_take1d", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'float64'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5818928be5c1d540612006783a650fd8fdd5350f79d4eef42d55d07b6fd5ea0c", "warmup_time": -1}, "groupby.AggFunctions.time_different_numpy_functions": {"code": "class AggFunctions:\n    def time_different_numpy_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": np.mean, \"value2\": np.var, \"value3\": np.sum}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_numpy_functions", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:258", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ee4cc58184d4aa1269bb6a2ac74fc444182645971a229353f27b1912da5be37", "warmup_time": -1}, "groupby.AggFunctions.time_different_python_functions_multicol": {"code": "class AggFunctions:\n    def time_different_python_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_python_functions_multicol", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:258", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3edc4f3884f2bbd2493f58ca31381e1bd77a0c16cc6d11542b0682b4e551b8ac", "warmup_time": -1}, "groupby.AggFunctions.time_different_python_functions_singlecol": {"code": "class AggFunctions:\n    def time_different_python_functions_singlecol(self, df):\n        df.groupby(\"key1\").agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_python_functions_singlecol", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:258", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b8e71e5376fa38e20f04d7a1c681fad844d81fa1776dc44a6a81eb61223c3dc", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions": {"code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:258", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb0cebddbe4907ca29f6eae3b6fd8e031f8eecd9af3ca590b195a872442f7411", "warmup_time": -1}, "groupby.Apply.time_copy_function_multi_col": {"code": "class Apply:\n    def time_copy_function_multi_col(self, df):\n        df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_copy_function_multi_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:71", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7caa7cf81a6dd8d45f4b3b086c550c6f4d2c8016efb3c7b07a9870780caadf93", "warmup_time": -1}, "groupby.Apply.time_copy_overhead_single_col": {"code": "class Apply:\n    def time_copy_overhead_single_col(self, df):\n        df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_copy_overhead_single_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:71", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a45a72a6e4efcf344d8245420af3e0987cad2a4658119959a42dd0cfa795afab", "warmup_time": -1}, "groupby.Apply.time_scalar_function_multi_col": {"code": "class Apply:\n    def time_scalar_function_multi_col(self, df):\n        df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_multi_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:71", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91c0160c3a4ba10d96e163a79a23e8a38f733cd7e582d2c1bf5f2390b4ac02d8", "warmup_time": -1}, "groupby.Apply.time_scalar_function_single_col": {"code": "class Apply:\n    def time_scalar_function_single_col(self, df):\n        df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup_cache(self):\n        N = 10 ** 4\n        labels = np.random.randint(0, 2000, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_single_col", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:71", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe75d3db2c5a68826fe04e4e30e5e72486b6f605865a3940b2b8ba57304d8608", "warmup_time": -1}, "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {"code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))", "min_run_count": 2, "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7306d0425d24ffcac744bea3e865fc95af5c142c68b6548a1297223cf7df7188", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_nosort": {"code": "class Categories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_nosort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "189523e24e4fe739d68e72ec32a88e9f4cb687916fc9de16172a97521d5f10a7", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_sort": {"code": "class Categories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_sort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8c1449a8fb8244310d26844f5d5dcfeb175739bb6b72e93b659249c0ceb0c7f6", "warmup_time": -1}, "groupby.Categories.time_groupby_nosort": {"code": "class Categories:\n    def time_groupby_nosort(self):\n        self.df.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_nosort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eba44e107187ca1878919c2640adadc899230bdfe8e7aeaf3bcdf450087869e6", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_nosort": {"code": "class Categories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_nosort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1b657acae0e919defc1d9c2dee71e1f055f48461f1c6d87863a9df9aa10221e3", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_sort": {"code": "class Categories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_sort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28a34a32d7309935dabcb3ef1ec2765996888aa364f568f84d03e23a4522ad2e", "warmup_time": -1}, "groupby.Categories.time_groupby_sort": {"code": "class Categories:\n    def time_groupby_sort(self):\n        self.df.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_sort", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "245f7173c9eb7ea7e56723e6668e1fff81d3d7f681e1ea70321f6512d09ce505", "warmup_time": -1}, "groupby.CountMultiDtype.time_multi_count": {"code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiDtype.time_multi_count", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:209", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5155fc72a8f81e6f45a2f0a8bb61e21d723c3a10d15e404505ec60dfb103688b", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_count": {"code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_count", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:238", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e39723ecb7101115788a8afb077129248a15ef9441d15fd33b3a8cfbaea10a9", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_nunique": {"code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_nunique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:238", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0690c0c32a6300fc9db91ca9e638ae425b9725583089932aa680314382244798", "warmup_time": -1}, "groupby.DateAttributes.time_len_groupby_object": {"code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"H\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)", "min_run_count": 2, "name": "groupby.DateAttributes.time_len_groupby_object", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a56ea61ccf5d9d27faa0d9faa16af0eba4ae94278ce39fe3ba51014da44af8c9", "warmup_time": -1}, "groupby.Datelike.time_sum": {"code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10 ** 4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10 ** 4, 2))", "min_run_count": 2, "name": "groupby.Datelike.time_sum", "number": 0, "param_names": ["grouper"], "params": [["'period_range'", "'date_range'", "'date_range_tz'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e12f97af6eba16938d143b14c6627f690bf3ced55ad523e17dd883d5e6bc6cda", "warmup_time": -1}, "groupby.Float32.time_sum": {"code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame(dict(a=arr, b=arr))", "min_run_count": 2, "name": "groupby.Float32.time_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29518f4ff1b0f70b59a4ef5c928a6b81f00f2520372c1ee22920d3b834269041", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_field": {"code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application):\n        if method in method_blacklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups)\n        values = rng.take(np.random.randint(0, ngroups, size=size))\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        df = DataFrame({\"values\": values, \"key\": key})\n    \n        if application == \"transform\":\n            if method == \"describe\":\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\"key\")[\"values\"].transform(method)\n            self.as_field_method = lambda: df.groupby(\"values\")[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[\"values\"], method)\n            self.as_field_method = getattr(df.groupby(\"values\")[\"key\"], method)", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_field", "number": 0, "param_names": ["dtype", "method", "application"], "params": [["'int'", "'float'", "'object'", "'datetime'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'ffill'", "'first'", "'head'", "'last'", "'mad'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a485337d85204b3e1473848a1064ca72445b722ec729acff37787d3599f5f8a", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_group": {"code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application):\n        if method in method_blacklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups)\n        values = rng.take(np.random.randint(0, ngroups, size=size))\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        df = DataFrame({\"values\": values, \"key\": key})\n    \n        if application == \"transform\":\n            if method == \"describe\":\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\"key\")[\"values\"].transform(method)\n            self.as_field_method = lambda: df.groupby(\"values\")[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[\"values\"], method)\n            self.as_field_method = getattr(df.groupby(\"values\")[\"key\"], method)", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_group", "number": 0, "param_names": ["dtype", "method", "application"], "params": [["'int'", "'float'", "'object'", "'datetime'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'ffill'", "'first'", "'head'", "'last'", "'mad'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a5b5b9ebe1d23030e36afbe07997101457434455ff0f3930a65f430968e8cda", "warmup_time": -1}, "groupby.GroupManyLabels.time_sum": {"code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "groupby.GroupManyLabels.time_sum", "number": 0, "param_names": ["ncols"], "params": [["1", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b70f52b943e8d1c375a69663a0b6ae86596f170b8e7a1f57fd4866f5dad6b9f", "warmup_time": -1}, "groupby.GroupStrings.time_multi_columns": {"code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10 ** 5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)", "min_run_count": 2, "name": "groupby.GroupStrings.time_multi_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c31f22cdb9dd824661e0a4bf02aff6eac40b0ebfe0dd33467433546f64f09801", "warmup_time": -1}, "groupby.Groups.time_series_groups": {"code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10 ** 6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                tm.makeStringIndex(100).take(np.random.randint(0, 100, size=size))\n            ),\n            \"object_large\": Series(\n                tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=size))\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_groups", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:109", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3ce3b30e8ceabf2d69d9a261f981be1ef6b768be0bd74e29989cd5bda3dbac12", "warmup_time": -1}, "groupby.Int64.time_overflow": {"code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10", "min_run_count": 2, "name": "groupby.Int64.time_overflow", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0e43d115b658d3b62215c2050ccaed24e564025449b1faf46ba3c2e67a2e041c", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_lambda_sum": {"code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_lambda_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:305", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c476b17358172730bd4043672625a485a7b4659e0828670015f38eac3b968f5e", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_numpy_sum": {"code": "class MultiColumn:\n    def time_col_select_numpy_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(np.sum)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_numpy_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:305", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e48dd2290719f18ad5dd837520e9f7e3fe4cefbb9ce91ac8bb7561f714f7039", "warmup_time": -1}, "groupby.MultiColumn.time_cython_sum": {"code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_cython_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:305", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a2214dc48f432326d77ce11df2627f49ae9922194113517c30031f7aabd6bb57", "warmup_time": -1}, "groupby.MultiColumn.time_lambda_sum": {"code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_lambda_sum", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/groupby.py:305", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e650fba9f344fbb2ce9dc61688ac6af919e0e412e2eb07306ee5e01d187f9c2d", "warmup_time": -1}, "groupby.Nth.time_frame_nth": {"code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ebe980da4feeaca34e4dc52b26d89c9e0570323731a4af2150495ef9d2b69ffb", "warmup_time": -1}, "groupby.Nth.time_frame_nth_any": {"code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3029d981fc91e28f368b3e0b4569602da798a238ba8333c5fa2c0b72c52f92e2", "warmup_time": -1}, "groupby.Nth.time_groupby_nth_all": {"code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_groupby_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23f7e6ede34c209838cbe9c73289a14ba2c0ad7e57a2375840140629fc5106d4", "warmup_time": -1}, "groupby.Nth.time_series_nth": {"code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59c3e2002d3c65896d846fb8023fc334c7fc919545c50a5e8462e880b0734d37", "warmup_time": -1}, "groupby.Nth.time_series_nth_all": {"code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aa31908cb47f493080b6cd080b5a2e3fae3a3183a0933df228b06e8d0e14780", "warmup_time": -1}, "groupby.Nth.time_series_nth_any": {"code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6db5b0eafed4133c74568f9202b340fa1f36719945c502f83f7e2e86fee7a1d4", "warmup_time": -1}, "groupby.RankWithTies.time_rank_ties": {"code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10 ** 4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.array([1] * N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})", "min_run_count": 2, "name": "groupby.RankWithTies.time_rank_ties", "number": 0, "param_names": ["dtype", "tie_method"], "params": [["'float64'", "'float32'", "'int64'", "'datetime64'"], ["'first'", "'average'", "'dense'", "'min'", "'max'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccf1cafbd0467da2e8612f6cb698a5477d2885a1a66f8267a5e680ea5781d06a", "warmup_time": -1}, "groupby.Size.time_category_size": {"code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10 ** 5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_category_size", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b28daff814909c3d3c6f8ca23a0ff6f7759d36b37272b23a0a1c26909839c61", "warmup_time": -1}, "groupby.Size.time_multi_size": {"code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10 ** 5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_multi_size", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9f6465bc98fff46ce57ece80e25ecc0e5bde5e02392c407a6e62d54f625c26cb", "warmup_time": -1}, "groupby.SumBools.time_groupby_sum_booleans": {"code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})", "min_run_count": 2, "name": "groupby.SumBools.time_groupby_sum_booleans", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7f248f14a0823a7af30345b84ab55ba9feb6084d4f677d14118b6e3f9fe2575", "warmup_time": -1}, "groupby.SumMultiLevel.time_groupby_sum_multiindex": {"code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])", "min_run_count": 2, "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 120.0, "type": "time", "unit": "seconds", "version": "2959228e76e229f21b04fbd29c8c128202ad3b4031495a0d59434107c009b3c7", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max": {"code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "510ed5bd300d4ac3695b2ab7f87d0d5e9405d033e94a237920e11a7af764ab4a", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key1": {"code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key1", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b6e99cc02e93f33ab106ddc56b9c8b178b732204345b60108e6cfca51fe93a7", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key2": {"code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key2", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2db34559a8a4094936f602d70c633eab0743c7ff4d5a2ec2e6291237b938184", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key3": {"code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key3", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d9027428bfdffa896a33cc0127342dae16b98bf0789b723cb1cb5f9bacce38e", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key4": {"code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key4", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e848d5275cd586086c28efae0628532e22465426edec3d58993f2b5f4df49dd9", "warmup_time": -1}, "groupby.Transform.time_transform_ufunc_max": {"code": "class Transform:\n    def time_transform_ufunc_max(self):\n        self.df.groupby(level=\"lev1\").transform(np.max)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_ufunc_max", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d02119cc9120b46a559681e1c0010c616f58757a2f62061b22bb9ce8ed6019c", "warmup_time": -1}, "groupby.TransformBools.time_transform_mean": {"code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})", "min_run_count": 2, "name": "groupby.TransformBools.time_transform_mean", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c8ace12e915b437833994829c31c9e5aaefabe53ae9f050777abf3db40fd883", "warmup_time": -1}, "groupby.TransformNaN.time_first": {"code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5", "min_run_count": 2, "name": "groupby.TransformNaN.time_first", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5bb589e7fa70fb9fa5dc5684673945c3241d9e25f86c388763f8466a1a16166c", "warmup_time": -1}, "index_cached_properties.IndexCache.time_engine": {"code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_engine", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22886df3174aadd081d39301092cd5a83cd3927ee01737dc9e5fc2ab7d9b0456", "warmup_time": -1}, "index_cached_properties.IndexCache.time_inferred_type": {"code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_inferred_type", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28782009ee036ae76e6de0b4aa60b7f9f2e94d3ca1937d5bb4705913d9762a02", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_all_dates": {"code": "class IndexCache:\n    def time_is_all_dates(self, index_type):\n        self.idx.is_all_dates\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_all_dates", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a88e3ddebee412b9855740bfc79d1b23c8ce39660af4e1ca99883ea4f07ba1bf", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic": {"code": "class IndexCache:\n    def time_is_monotonic(self, index_type):\n        self.idx.is_monotonic\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "280197412c68b43fed51f974a9c2346521dfea1bbef8f514bc99598bf4d88981", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {"code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef0a35420de447d051cb7695bd696117cc9c577a4e6d90bc192a5d04cc89ba61", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_increasing": {"code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d836875b644ef366895a1df3a14ef938bc172f65dcfa7aea7c5d5a49422bc26d", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_unique": {"code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_unique", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09e53af7a5c8f70acb193aae594306a520897eed07aeb3a58751c215f014bdf6", "warmup_time": -1}, "index_cached_properties.IndexCache.time_shape": {"code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_shape", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cab239b729088391da012d78c4355d5bc9140608bc5825d88461dbf10f851e73", "warmup_time": -1}, "index_cached_properties.IndexCache.time_values": {"code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_values", "number": 1, "param_names": ["index_type"], "params": [["'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "processes": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cccb8ab07373e14e1fa046b9ae21a97f24bd125f84e61fa952c7e201acafaefe", "warmup_time": -1}, "index_object.Datetime.time_is_dates_only": {"code": "class Datetime:\n    def time_is_dates_only(self):\n        self.dr._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datetime:\n    def setup(self):\n        self.dr = date_range(\"20000101\", freq=\"D\", periods=10000)", "min_run_count": 2, "name": "index_object.Datetime.time_is_dates_only", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cebe44ddc8aaa0eade94145651bbc278ac56b85b05ed24584a218bc4c03a71f8", "warmup_time": -1}, "index_object.Float64IndexMethod.time_get_loc": {"code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100000\n        a = np.arange(N)\n        self.ind = Float64Index(a * 4.8000000418824129e-08)", "min_run_count": 2, "name": "index_object.Float64IndexMethod.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "717e6a136bc8af946792fa946550ad5e4bef98b9fdb2fedec255480da8bb1021", "warmup_time": -1}, "index_object.GC.peakmem_gc_instances": {"code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "name": "index_object.GC.peakmem_gc_instances", "param_names": ["param1"], "params": [["1", "2", "5"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "19eab650f43bb724de22b58f71bcf63648dc31a8adce583af46e2ff2c2d9c482"}, "index_object.IndexAppend.time_append_int_list": {"code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_int_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84bdbae116c9d458d7aa0d0e3c60241c8b4084e00781ce5957f485786bc7135b", "warmup_time": -1}, "index_object.IndexAppend.time_append_obj_list": {"code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_obj_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8551feb1646d6669519eabeb2447116679f19811ff8a28df5fe062bd91096ed", "warmup_time": -1}, "index_object.IndexAppend.time_append_range_list": {"code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_range_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27559b03a1f8d22f5b568f9f42f26f762810d1ec943e6cff4cdd670eed65714f", "warmup_time": -1}, "index_object.Indexing.time_boolean_array": {"code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_array", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "88e41542fcda1655b0e327484e5a2791e52b48d6df879f0bcb1dddff041b9676", "warmup_time": -1}, "index_object.Indexing.time_boolean_series": {"code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_series", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a43d44d409e334426748c97e80a3c694c5644c384304a82390813812ee35c37", "warmup_time": -1}, "index_object.Indexing.time_get": {"code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b652464f0cef1cd2a0569439ac74cb523b2b3c95d171f3ab12510bb26847627", "warmup_time": -1}, "index_object.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4449dbcb88ecf1102e2e73c52b3b2a28d2f49ab56190cb530edb9f84d1b8f9f3", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique": {"code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "47f9ce0d7a77081fe55addf205d1b77538be5ac7b9018bcfc38965051c0f0e3b", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique_sorted": {"code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07996d309a0ca7f3f08eff5be63e3cc1195083275c97ca1d30551c37ad227f42", "warmup_time": -1}, "index_object.Indexing.time_get_loc_sorted": {"code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9c84db1451cb5f3ea84215225eccfa8523ea69719288ada2a57fb9c3ae680a9a", "warmup_time": -1}, "index_object.Indexing.time_slice": {"code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd3b856934e5e005ce9770a69eef64d01fedd0b44fe041f010a9661de4107e27", "warmup_time": -1}, "index_object.Indexing.time_slice_step": {"code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice_step", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a2c8a2141617fde24eba6b45201f6cdaffb70be49e4a5f9039cb3a45762d7312", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection": {"code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1dcb14770d7a11f5fcb5398eac30dcce92c18cd130e63cb292a80917185f9c72", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5fafac0a96fc25f47987b70a09c6ea47260acb9daf2ed69b72c77bc05c032fe9", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ffe2919c41d4c4ffd3a311c7c19334552a05de247520b4ab61b5194e7d575327", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_is_unique": {"code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_is_unique", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91a07134997fae00ab3a85d58bcb8a58257cdfc76d83d2479442822e1cebad6f", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_monotonic_inc": {"code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_monotonic_inc", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9a9d95dcf29fdc121f84000852f2dd79bd50e668370052c0c0a15f784a04822", "warmup_time": -1}, "index_object.Ops.time_add": {"code": "class Ops:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_add", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9a27bdb0508682402c6011b57cd52b70405fb2db79ae1f1fbd2cd427f1fb745", "warmup_time": -1}, "index_object.Ops.time_divide": {"code": "class Ops:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_divide", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13d9bce65f7ea1d1069706c8512f12687f9bf805eacb36e767e2a212523504f9", "warmup_time": -1}, "index_object.Ops.time_modulo": {"code": "class Ops:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "97e246a9aa14adeeaa85399d2f6e04dd674e09b61ed53929ae3a6d91d69bb912", "warmup_time": -1}, "index_object.Ops.time_multiply": {"code": "class Ops:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61a2bea9b99becefd7cfb5a0d725ecab21ccfc180b2de74954f3bec7edcf2a0f", "warmup_time": -1}, "index_object.Ops.time_subtract": {"code": "class Ops:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "index_object.Ops.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0cf7b3f984f0faaf17990da778b2a61226940d04e19b8811d1ca93b584207776", "warmup_time": -1}, "index_object.Range.time_get_loc_dec": {"code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_dec", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c637ad2dbd4b2ea661306e0be175c081bcb12061c848fe50df2e6e58e3aba060", "warmup_time": -1}, "index_object.Range.time_get_loc_inc": {"code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_inc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7cdbbc3c2b1c7a3122af0270781ca0e33080f8b350992c4f9438bd0b784659e7", "warmup_time": -1}, "index_object.Range.time_max": {"code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e897124434bead9e78ede51a609aee324026105fb462e8952dd25f1b227db39e", "warmup_time": -1}, "index_object.Range.time_max_trivial": {"code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max_trivial", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd72f017bc895baed90a243a31dcade0debc4aba24efe0439b302ca4dbb77216", "warmup_time": -1}, "index_object.Range.time_min": {"code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84937dfafb2c2c9b37034f7ab47223fd93f2969104ae67b5ff97686452a4f449", "warmup_time": -1}, "index_object.Range.time_min_trivial": {"code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 7, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 7, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min_trivial", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca1ee4918edcec6e4b845e203280b6bc8cbb86cd98fe7d64cb3a62c829f5b9e9", "warmup_time": -1}, "index_object.SetDisjoint.time_datetime_difference_disjoint": {"code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10 ** 5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))", "min_run_count": 2, "name": "index_object.SetDisjoint.time_datetime_difference_disjoint", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b328ef6c80cf460a653d047d315f3d3f7d5e9156d930534dc92f0c73ac88b2c", "warmup_time": -1}, "index_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, dtype, method):\n        N = 10 ** 5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        str_left = tm.makeStringIndex(N)\n        data = {\n            \"datetime\": {\"left\": dates_left, \"right\": dates_left[:-1]},\n            \"date_string\": {\"left\": date_str_left, \"right\": date_str_left[:-1]},\n            \"int\": {\"left\": int_left, \"right\": int_left[:-1]},\n            \"strings\": {\"left\": str_left, \"right\": str_left[:-1]},\n        }\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "index_object.SetOperations.time_operation", "number": 0, "param_names": ["dtype", "method"], "params": [["'datetime'", "'date_string'", "'int'", "'strings'"], ["'intersection'", "'union'", "'symmetric_difference'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31d550b482a01731e8abfb829a061e54c40d3ab183c06064faba13545556983e", "warmup_time": -1}, "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {"code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"H\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)", "min_run_count": 2, "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff4000b15590520dfb25fa7169074fa847935af40c34df6617ddc79edd57e28b", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_indexer_list": {"code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa6956f658740e1066ccc45e9cddabc78355527c842ad0f8a38aa29a34eadd71", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7deee8a9f2b62b539266fdedc0ad3f6e56a95b030f8e0a74e7bfbe62d05fa50f", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75ddac18c92308b52fb7c7da5872a7b39398393d49482295bc22d919cfcbc0d1", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "258f428b267e252048768d80218d63718aa3cc6e29b7dd2de068ab7326deedf6", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list_like": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef5ac9629b65a2048822806ff49716f0fefd4130168a5c0c6fb8cba6c59b51fc", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "911683d935114f519649b6207c580be69bf054f6ed1a05af048811426aadea12", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_slice": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eccb3a7227263b535722c0b3fcfc87021585810a096b050a24420d254939e587", "warmup_time": -1}, "indexing.ChainIndexing.time_chained_indexing": {"code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})\n                df2 = df[df.A > self.N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000", "min_run_count": 2, "name": "indexing.ChainIndexing.time_chained_indexing", "number": 0, "param_names": ["mode"], "params": [["None", "'warn'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce151f23acedb4a97684f559f4396ec2f4c39c842b913555a660b8f7e1452fa8", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_bool_indexer": {"code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_bool_indexer", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6de0b2afadd58cd7b2f09554a7b46ae628d905f4231710a150204d724b6d0e3c", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc": {"code": "class DataFrameNumericIndexing:\n    def time_iloc(self):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19c77440ecbc85666fb74478b31bd63f2e4087850ad61df0a33ea2d3bba11395", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc_dups", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57a810caa20e61e3f3257bed744e297d7bda5a4a486a895b41eacc16b8e02b54", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc": {"code": "class DataFrameNumericIndexing:\n    def time_loc(self):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38ba16b6a15d8ccaba376f2efaf127505173abbe9de65e3da7e7b31e37e900f8", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(10000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 5000 + [False] * 5000", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc_dups", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "65132c2abbdc4a03cc6b29c6b764e744ab6184801cf20aa904a3410de6ec74dd", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "54871982a012c3f421c55097b328da3397aa6877be16a8e45b0a393eceeec74e", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_object": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca8451d94464c834678ae07dea24e7bdec794ac0bc2be98111b081bd90b57df7", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_getitem_scalar": {"code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de0a35b6f483b55c3e7fff5917e1a9cc88a1a1c565c4aef5c762360646d3d2d1", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_ix": {"code": "class DataFrameStringIndexing:\n    def time_ix(self):\n        with warnings.catch_warnings(record=True):\n            self.df.ix[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_ix", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "51ff5cb72f351502df86fa3bd5daaeaa89faf4149aca43b0015b6b96521cd56d", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_loc": {"code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff23d3b261f431d852ff6a0de4a28e0a5156cc63b263dd6b1967925e1d0585ad", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c04f84e3ca8985e8c14002de68bee23e270131c90ed5e5a6e7c1814f49374ff9", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "405816f15047a9da353da4892c1b8c710e76a0ea536a9e7513cc606cd62e6b76", "warmup_time": -1}, "indexing.InsertColumns.time_assign_with_setitem": {"code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        np.random.seed(1234)\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_with_setitem", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2969827df8ba2aae6baddb199107178510011031bfd2605b88cda016b4f86788", "warmup_time": -1}, "indexing.InsertColumns.time_insert": {"code": "class InsertColumns:\n    def time_insert(self):\n        np.random.seed(1234)\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ab80f68ab16150297f79788288d53cde5933b9e18dab0592503f8e06bcfee90", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_list": {"code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:244", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ceabe9099f794f534a3cee65209eef67ef8fe5910032d09dc873b61f7db9311", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_scalar": {"code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:244", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a5ed39d9e010bebebaedde8c09666f2e8ad83c8ecc321854014b0126a9262ef4", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_list": {"code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_list", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:244", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53a67c0ae3f4a03fb6ddb93ef70355a41aaab9b4eb41712bf564868bb0ecb3c9", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_scalar": {"code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_scalar", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:244", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3727b780fbb12d812e665dcc2f04f1833e4fa43f9b2be7586340a83331e9535a", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_iloc": {"code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_iloc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8964b2421e6b4b74545350fae7ce591768d80f855cd1182bcfbcda2882780356", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_ix": {"code": "class MethodLookup:\n    def time_lookup_ix(self, s):\n        with warnings.catch_warnings(record=True):\n            s.ix\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_ix", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0fc5361170cb67bbe08f4acde1c727006a0c3c04187b34f5d32f624fc8024408", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_loc": {"code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/indexing.py:306", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "513fe43a7b6d5bafa7f3ab6edd7d17d16ee76988a435c950cfd10a89236d6c7c", "warmup_time": -1}, "indexing.MultiIndexing.time_frame_ix": {"code": "class MultiIndexing:\n    def time_frame_ix(self):\n        with warnings.catch_warnings(record=True):\n            self.df.ix[999]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        with warnings.catch_warnings(record=True):\n            self.mdt = DataFrame(\n                {\n                    \"A\": np.random.choice(range(10000, 45000, 1000), n),\n                    \"B\": np.random.choice(range(10, 400), n),\n                    \"C\": np.random.choice(range(1, 150), n),\n                    \"D\": np.random.choice(range(10000, 45000), n),\n                    \"x\": np.random.choice(range(400), n),\n                    \"y\": np.random.choice(range(25), n),\n                }\n            )\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index([\"A\", \"B\", \"C\", \"D\"]).sort_index()", "min_run_count": 2, "name": "indexing.MultiIndexing.time_frame_ix", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9b4fb20ca065a713d73487011f925d792785b311851771e4323d39c954d5a72", "warmup_time": -1}, "indexing.MultiIndexing.time_index_slice": {"code": "class MultiIndexing:\n    def time_index_slice(self):\n        self.mdt.loc[self.idx, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        with warnings.catch_warnings(record=True):\n            self.mdt = DataFrame(\n                {\n                    \"A\": np.random.choice(range(10000, 45000, 1000), n),\n                    \"B\": np.random.choice(range(10, 400), n),\n                    \"C\": np.random.choice(range(1, 150), n),\n                    \"D\": np.random.choice(range(10000, 45000), n),\n                    \"x\": np.random.choice(range(400), n),\n                    \"y\": np.random.choice(range(25), n),\n                }\n            )\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index([\"A\", \"B\", \"C\", \"D\"]).sort_index()", "min_run_count": 2, "name": "indexing.MultiIndexing.time_index_slice", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fc576ed6b10238b53e8145382fa98427e2b75a2e7f7a7f73503b732fefa0b8b", "warmup_time": -1}, "indexing.MultiIndexing.time_series_ix": {"code": "class MultiIndexing:\n    def time_series_ix(self):\n        with warnings.catch_warnings(record=True):\n            self.s.ix[999]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        with warnings.catch_warnings(record=True):\n            self.mdt = DataFrame(\n                {\n                    \"A\": np.random.choice(range(10000, 45000, 1000), n),\n                    \"B\": np.random.choice(range(10, 400), n),\n                    \"C\": np.random.choice(range(1, 150), n),\n                    \"D\": np.random.choice(range(10000, 45000), n),\n                    \"x\": np.random.choice(range(400), n),\n                    \"y\": np.random.choice(range(25), n),\n                }\n            )\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index([\"A\", \"B\", \"C\", \"D\"]).sort_index()", "min_run_count": 2, "name": "indexing.MultiIndexing.time_series_ix", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82ba5d683b45eac1c25a65918b7fd89545377507e6a1635b0b50307c950ac4f1", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "99d9d0a3c72340406e9c37c2104ec9e9df330782ddb1084a5438c8be26872562", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "638479bc71b9403fd79c9fe69e4f4604ca5813f4a5706c3fb59509f2cf0de3ca", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "875d502213f42e6e1cdef59908c5c6987f6700cbb82cdff5ae205a48ba24b6e6", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "168b34323ee5105765d201a5ed6f8bdc36ae40c5480284041fd0fc059a531d36", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_array": {"code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae22c331c3449871a8e27d8a37ee88c889540e859c136cf089bebb4f7313ba8f", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_list_like": {"code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d49633e9027f593fbce47bb24f44053ee36c2ce26a43d3f21ab7bb7a686d2b98", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_lists": {"code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_lists", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09d7580b7af7e32faa56384447eddf16a5cc98e2d6f3d64c22279389f6672059", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_scalar": {"code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48f8d223342a0802b997f34f3dd0c5bc49cf2ae0fc10472262bb33dbd8f046c8", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_slice": {"code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27d99618a9bd1494a08d3f9a1011797507465e72c89ead8f6cb17e8b72e24c82", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_array": {"code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96a04807ebf048ea69feb892a8fe2c717be3b3becbe6f7e6b63953326a25a96a", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d2b828f2a548c34b2f1d44be78105402e3f21721e604949e53982a9b8443b799", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35efe8fc92a9df0c26a945e0f1202b755cb8c1ee2fcb827e63aced364c91a051", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_slice": {"code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df3ac870720d93dd89fd8b0ba0b955b2f95d22c76aa650b791c846d6d18165a1", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_ix_array": {"code": "class NumericSeriesIndexing:\n    def time_ix_array(self, index, index_structure):\n        with warnings.catch_warnings(record=True):\n            self.data.ix[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_ix_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c9f116f7358b867d0935e1417c1b743d275b3374cb41cdd100539f8b891c9db", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_ix_list_like": {"code": "class NumericSeriesIndexing:\n    def time_ix_list_like(self, index, index_structure):\n        with warnings.catch_warnings(record=True):\n            self.data.ix[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_ix_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6e688c5e72e7bd88fcf18af4777775e2cdcb4460473135cfe44645f011b7915d", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_ix_scalar": {"code": "class NumericSeriesIndexing:\n    def time_ix_scalar(self, index, index_structure):\n        with warnings.catch_warnings(record=True):\n            self.data.ix[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_ix_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "054f23f54dccb4e8531a236924dc64f65858d79ec03bf40cd002b2ef5d692b85", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_ix_slice": {"code": "class NumericSeriesIndexing:\n    def time_ix_slice(self, index, index_structure):\n        with warnings.catch_warnings(record=True):\n            self.data.ix[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_ix_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b02c0b84dc7c6d7414b9b44c36b85e40e01dd6eec654185ff74ac665ebb519fd", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_array": {"code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_array", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c457baf2423e9ad2e3dd99148e0bab8580bb1a6c6db79224861cb7df5fa125d2", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d2d656826803610dd5976d17fed734f462bfd65d91791d3e56ca3ca982b65386", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "080e246574aa42955d9b58aff2a36b4c0f8bb65c12499309623a6c17ba7b4133", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["<class 'pandas.core.indexes.numeric.Int64Index'>", "<class 'pandas.core.indexes.numeric.UInt64Index'>", "<class 'pandas.core.indexes.numeric.Float64Index'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0f40c2d4a063345280f6980c701cde07f2d4a8466823a565450e7b24f86ee19", "warmup_time": -1}, "indexing.Take.time_take": {"code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Int64Index(np.arange(N)),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"S\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = [True, False, True, True, False] * 20000", "min_run_count": 2, "name": "indexing.Take.time_take", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "568fafa0e10416e2d2c5296f3aa63ea1cf6e7fb89447324246d339bdce96b857", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc": {"code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type):\n        self.data.get_loc(2)\n\n    def setup(self, engine_and_dtype, index_type):\n        engine, dtype = engine_and_dtype\n        N = 10 ** 5\n        values = list([1] * N + [2] * N + [3] * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=dtype),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=dtype),\n            \"non_monotonic\": np.array([1, 2, 3] * N, dtype=dtype),\n        }[index_type]\n    \n        self.data = engine(lambda: arr, len(arr))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aff10ff0b98d7e5652aaf857313e2c8e50394552d45c7160a6057efd3c87bb7e", "warmup_time": -1}, "indexing_engines.ObjectEngineIndexing.time_get_loc": {"code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(lambda: arr, len(arr))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")", "min_run_count": 2, "name": "indexing_engines.ObjectEngineIndexing.time_get_loc", "number": 0, "param_names": ["index_type"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "527fa7b8e67a6a391e13d9dfb924ef23c00f914aba0a8dae3de9fd26044a91b1", "warmup_time": -1}, "inference.DateInferOps.time_add_timedeltas": {"code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "inference.DateInferOps.time_add_timedeltas", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:38", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb7e2773a0f9bd346ce94d9f4dc5f9eacf4de924e0c2d1a93fc43f146c7efba6", "warmup_time": -1}, "inference.DateInferOps.time_subtract_datetimes": {"code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "inference.DateInferOps.time_subtract_datetimes", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:38", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b453ef478e1c5c7a80311d1a50eac02abf69ba0c4e2100456af6434263cd940b", "warmup_time": -1}, "inference.DateInferOps.time_timedelta_plus_datetime": {"code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "inference.DateInferOps.time_timedelta_plus_datetime", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:38", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ac4ad8ad95440b9da9c76ca8b914eb2b3cb13a1b7f7d2a6ab1a20e44ce175900", "warmup_time": -1}, "inference.MaybeConvertNumeric.time_convert": {"code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10 ** 6\n        arr = np.repeat([2 ** 63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data", "min_run_count": 2, "name": "inference.MaybeConvertNumeric.time_convert", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/inference.py:112", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e38cc43b80293bccee8efc27da3b3d6752ae5cf181feb6d44a5c9055a46bb389", "warmup_time": -1}, "inference.NumericInferOps.time_add": {"code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_add", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd937919f68d16ec0fd2647801a9f0aeac01c03cae6f5f8d538a4c9654c26775", "warmup_time": -1}, "inference.NumericInferOps.time_divide": {"code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_divide", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccb4fb941944b9bb519412cf3539bedd422f799a0104b1e2d9ef9f903d2da238", "warmup_time": -1}, "inference.NumericInferOps.time_modulo": {"code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71cec0c2d3b56c09f945371b92cbd378e45dfeec0ba75bef727955f93039460b", "warmup_time": -1}, "inference.NumericInferOps.time_multiply": {"code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d46e497f4485a3e6f194a018797ad7df742dceff761f9dd7545bdcf654c5958a", "warmup_time": -1}, "inference.NumericInferOps.time_subtract": {"code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "inference.NumericInferOps.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cd556417211d5e88dac11ad2c705be3ae213b190a49f326bf692641b93b83cb3", "warmup_time": -1}, "inference.ToNumeric.time_from_float": {"code": "class ToNumeric:\n    def time_from_float(self, errors):\n        to_numeric(self.float, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_float", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6980309784b744feb3040ae3bf845c253edc4fa597b811329cd9c220a809ce6e", "warmup_time": -1}, "inference.ToNumeric.time_from_numeric_str": {"code": "class ToNumeric:\n    def time_from_numeric_str(self, errors):\n        to_numeric(self.numstr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_numeric_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "78f51ee5f45aeb6a13548d96cc6ddcfb7c0c836c2c7c13a889d989b0d33fe0ff", "warmup_time": -1}, "inference.ToNumeric.time_from_str": {"code": "class ToNumeric:\n    def time_from_str(self, errors):\n        to_numeric(self.str, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ded33a5d0188d8345078f054a4577205b9539b5130a9f22b36e5ad001c511e11", "warmup_time": -1}, "inference.ToNumericDowncast.time_downcast": {"code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]", "min_run_count": 2, "name": "inference.ToNumericDowncast.time_downcast", "number": 0, "param_names": ["dtype", "downcast"], "params": [["'string-float'", "'string-int'", "'string-nint'", "'datetime64'", "'int-list'", "'int32'"], ["None", "'integer'", "'signed'", "'unsigned'", "'float'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3bf441be7d1a1da58fe7040606ed5576597205aa570100b6ca3d07c8ecdb8da", "warmup_time": -1}, "io.csv.ParseDateComparison.time_read_csv_dayfirst": {"code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f73f177914ab98c71399aa7026fdd59ab6c80f75503635ba1e801fa2465635aa", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {"code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17b4d261cf1c73e37deaa136aaca086c661550b58f128907bd9940c7768c4689", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {"code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ab638a45c1a6c6ee0db60c1bf6765c0de04d1720d23c9c4b0c1abe57576ae60", "warmup_time": -1}, "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {"code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache):\n        data = (\"\\n\".join(f\"10/{year}\" for year in range(2000, 2100)) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached", "number": 0, "param_names": ["do_cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4323d984705aa43fdf7942a64ea504291f5c7a9b38ea1436a8cfe6bfc72462fd", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_direct": {"code": "class ReadCSVCategorical:\n    def time_convert_direct(self):\n        read_csv(self.fname, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_direct", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "db5db07a8cf168c9e0f85a33decd8997127975714ce52c6f7b65e942890da392", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_post": {"code": "class ReadCSVCategorical:\n    def time_convert_post(self):\n        read_csv(self.fname).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_post", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22aea17946407fdca71fff00c5ec0d5e4011d1a6639f955be9f2e9914990167f", "warmup_time": -1}, "io.csv.ReadCSVComment.time_comment": {"code": "class ReadCSVComment:\n    def time_comment(self):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))", "min_run_count": 2, "name": "io.csv.ReadCSVComment.time_comment", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a16f905694db4953dd220235a105b637321b368d013503a7efe7da4f096b76c7", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetime.time_read_csv": {"code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"S\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetime.time_read_csv", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80ee6cd634fd130589419018dad2e012555ecda1755c35188bf424d2bb8981e2", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {"code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv", "number": 0, "param_names": ["bad_date_value"], "params": [["'nan'", "'0'", "''"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9ed06d5e45df9d39dac2022a1735901cc1ef50a63e4ed9e564a4fcbde02a7e2", "warmup_time": -1}, "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {"code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, infer_datetime_format, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=infer_datetime_format,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, infer_datetime_format, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv", "number": 0, "param_names": ["infer_datetime_format", "format"], "params": [["True", "False"], ["'custom'", "'iso8601'", "'ymd'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7b1d4d1ebd61a742cecc7053c2692782936c07878abf2c4d3e9bfb81858c5ae", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join(random.choice(string.digits) for _ in range(28)) for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}\" + \"{}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d37c9fd7e4f064fb5c4124e87dc2bbc00c62ae795ebb10ac007d4911fe53844", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join(random.choice(string.digits) for _ in range(28)) for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}\" + \"{}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05412abc1aed7a5168bc58ab5497637fe53ee137ed1a2e4a84a73e1dd4ba775e", "warmup_time": -1}, "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {"code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self):\n        with open(self.fname, \"w\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")", "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks", "param_names": [], "params": [], "timeout": 60.0, "type": "memory", "unit": "bytes", "version": "ee68693f3121602831d5e6509e8961531654380b29fb99d4412e8acbb0f0e0d7"}, "io.csv.ReadCSVParseDates.time_baseline": {"code": "class ReadCSVParseDates:\n    def time_baseline(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_baseline", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "287600b6755c20a5c91d611f3fc05337fedf7a1688ea39657371e7bdbeb4ae08", "warmup_time": -1}, "io.csv.ReadCSVParseDates.time_multiple_date": {"code": "class ReadCSVParseDates:\n    def time_multiple_date(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=\",\",\n            header=None,\n            names=list(string.digits[:9]),\n            parse_dates=[[1, 2], [1, 3]],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_multiple_date", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cca952c91310c9c575faa995b840ac6bbba864b8f5ab49ae6a059ff2c312545e", "warmup_time": -1}, "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {"code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date", "number": 0, "param_names": ["value"], "params": [["'mY'", "'mdY'", "'hm'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "240689baeab768b6d6a54d64115e92b04bc5bd826144e79f91c95969c600b698", "warmup_time": -1}, "io.csv.ReadCSVSkipRows.time_skipprows": {"code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows):\n        read_csv(self.fname, skiprows=skiprows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows):\n        N = 20000\n        index = tm.makeStringIndex(N)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)", "min_run_count": 2, "name": "io.csv.ReadCSVSkipRows.time_skipprows", "number": 0, "param_names": ["skiprows"], "params": [["None", "10000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c7da67f437633156061d68c994d3b1bf80e4c3e29f8e11d78b3d60c2e0c2b95", "warmup_time": -1}, "io.csv.ReadCSVThousands.time_thousands": {"code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands):\n        read_csv(self.fname, sep=sep, thousands=thousands)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.applymap(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)", "min_run_count": 2, "name": "io.csv.ReadCSVThousands.time_thousands", "number": 0, "param_names": ["sep", "thousands"], "params": [["','", "'|'"], ["None", "','"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1dd3e2773e985d14913bdfb6bd71dd3e7ee1afecf3d9eeeb7e7b5350ef82735", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64": {"code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17e0ce93c2ffbe91868c4c9454080bfea64887fc4aac2e31ce44edcd67b64e0d", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_na_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5bb15a6455b80413a7aea5e48c5ead9f95b3434d39be6fec7bcd9e2ea995589f", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b13e96b5532c39113abca9a8ba087353bacd1ee2352bcf5059f1a56574e96379", "warmup_time": -1}, "io.csv.ToCSV.time_frame": {"code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]", "min_run_count": 2, "name": "io.csv.ToCSV.time_frame", "number": 0, "param_names": ["kind"], "params": [["'wide'", "'long'", "'mixed'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90e6b4dd3c08772f28fbb5df66a793feba4b9ca12a04d1187349aaeb8681ea89", "warmup_time": -1}, "io.csv.ToCSVDatetime.time_frame_date_formatting": {"code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetime.time_frame_date_formatting", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4425639bac7423c5376508d10e2980d898ecfb10a52b6e16d7499e104a85f7f", "warmup_time": -1}, "io.csv.ToCSVDatetimeBig.time_frame": {"code": "class ToCSVDatetimeBig:\n    def time_frame(self, obs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeBig.time_frame", "number": 0, "param_names": ["obs"], "params": [["1000", "10000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "fdb685350c42f049920d2e6fce84174c827d4fff16f164412c6f6b50635bf951", "warmup_time": -1}, "io.excel.ReadExcel.time_read_excel": {"code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        fname = self.fname_odf if engine == \"odf\" else self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcel.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'xlrd'", "'openpyxl'", "'odf'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/io/excel.py:61", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d93bce609801ba36167f62d23c589182c3b26fa16c937f99d81a26e7677c7881", "warmup_time": -1}, "io.excel.WriteExcel.time_write_excel": {"code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        writer = ExcelWriter(bio, engine=engine)\n        self.df.to_excel(writer, sheet_name=\"Sheet1\")\n        writer.save()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcel.time_write_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'", "'xlwt'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3af7a398bcc4dfb382470ff59aade5b638bcefe7a39f6305168ed4956ccd999a", "warmup_time": -1}, "io.hdf.HDF.time_read_hdf": {"code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_read_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f74c8778c8a22a9aaaf7ffe7941c24433a00b5e3987d212b7ddbc03229b866b0", "warmup_time": -1}, "io.hdf.HDF.time_write_hdf": {"code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, \"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_write_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e636486ff92b3c290a4222c8dad28c5dc9142c0ee0b8d788fd29c96e8e162324", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "555dd869ab62720acc41e3e1b9a803fe2d90ea5b623a783fb6d20c259a98ffa1", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1860c67f997f06a5c947c9065653d0f0a31e7d1b9b0caed204f51d4e504c92ab", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store": {"code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ccb4328affc895b3cdbdd2a3e3563447bd991b1549f5675788dd2e92f597799", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d473fde84bcb32a4c6c8f90bb7e14bf3980caed546cba6eacd3e75f5ecd984f6", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e00270973784628580bfef5094f06c6dcd78d0d72ebeb910bc549d5ff94dc640", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2192d54818f634111c18685c319dfbcc297d6896a7d6ef21cbdba0651dc78dfa", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e750543230fe3ac766a829d9445bd13a5b967b914c184cfa9e48a42d5237b481", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_info": {"code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_info", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e8ad8bc1498f7b0f58559e63f7d98affe5aed8386eb0db44979cadedb9c7867", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_repr": {"code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_repr", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ff12499f9fa02efe754206c409f0331291cf50c6a0e9bc851dc6e635149d28f", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_str": {"code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_str", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "009e600cb001919cfcf188c4533f6c5e9702ec0e86a6bd80ad747ed11cedb324", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store": {"code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00b2b7bde5f48f8d27a8bbf4c796be230842af99048b685a54e3190558374bb0", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0871ae497b0da012ef574dfe4650e840aaff1c843885ace3f8d06f8c714b915e", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4afe099b1a17c0ffd25aabae7e6fabfe0bef93f5a465710ffe77306b15d0803c", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43df69c535ce00beddf72e671f61d912dab128cbb618868adb7f34c818d49212", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a4ccfff0de1e76b6b8633e8777d57fcee94022106768b8a016b00550e316121", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fa31c661440c5add11f5726add4b3223bb06a787e4741c6cd142b228ec7709e", "warmup_time": -1}, "io.json.ReadJSON.time_read_json": {"code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)", "min_run_count": 2, "name": "io.json.ReadJSON.time_read_json", "number": 0, "param_names": ["orient", "index"], "params": [["'split'", "'index'", "'records'"], ["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d34aebc17d59bfe05dab62ccac5292d0f72306f4bd5a50a229be6d3625a69b88", "warmup_time": -1}, "io.json.ReadJSONLines.peakmem_read_json_lines": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "8789ab40f3731850597841b1ce0c146427effd7840f6d4efb6b9540bb3ae9086"}, "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "a95da73684f684eea2e51244d330b49e45259e1a1fbb243b44beb34cd157dcee"}, "io.json.ReadJSONLines.time_read_json_lines": {"code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a3c9b78ef553f52887dcc255b44714915ebb5d92f54acb9b8e6e2569299aaac", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_concat", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9ce484aa6c962166e907627318c31e53ed94d754fd854cc91a6b988ff7c23e22", "warmup_time": -1}, "io.json.ToJSON.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "0c9f5b7b52c8e2dcf833f15805eb6f177941ca0d4ba87df71208727c720da30c"}, "io.json.ToJSON.peakmem_to_json_wide": {"code": "class ToJSON:\n    def peakmem_to_json_wide(self, orient, frame):\n        base_df = getattr(self, frame).copy()\n        df = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        df.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json_wide", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "8068ca33b740a20040ca567d4d93e105b18103f64dc97fde07ad0a70fb35a604"}, "io.json.ToJSON.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3a49e528f8f84259bc8abd61fd06bb038ff70a11900deca35cd0669b14f30e5", "warmup_time": -1}, "io.json.ToJSON.time_to_json_wide": {"code": "class ToJSON:\n    def time_to_json_wide(self, orient, frame):\n        base_df = getattr(self, frame).copy()\n        df = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        df.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json_wide", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e76990445670143a19ec0f6b13f7415578069b0cc2098a4571e1317f578318b0", "warmup_time": -1}, "io.json.ToJSONLines.time_delta_int_tstamp_lines": {"code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76faaadd02f2e65df8ab178f1771556bc080ffddb95721ac49ca8934cd740c89", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_lines": {"code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fb93ea1aedb6e92636aa1fa32482812e0e917ee47e280f3230c3446a7153a7a", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_str_lines": {"code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_str_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41fbc44d6df2d6734d2b3f16f48c782cf9ecbf51d82c706605371a1dc593ab8b", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_dt_index_lines": {"code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7715157a172d0d422ba6e29b0939e726dcd56c84d3a1a173abd5cf909acb12d6", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_int_idex_lines": {"code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "afc0a804f66ebae7230ba386079ccd41d527c5a0d8bb5e8a25b9eeb48ef2feaa", "warmup_time": -1}, "io.json.ToJSONMem.peakmem_float": {"code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\"int\": df, \"float\": df.astype(float)}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_float", "param_names": [], "params": [], "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/io/json.py:201", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "197a0a56ae900f371a8645d68f2d35d645047a5d5b1139d123120b47ac30354d"}, "io.json.ToJSONMem.peakmem_int": {"code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\"int\": df, \"float\": df.astype(float)}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_int", "param_names": [], "params": [], "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/io/json.py:201", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "2e27c15e78b9cc97477694de369542bc9b2220f8903b8b2b06cee187d47e1f93"}, "io.msgpack.MSGPack.time_read_msgpack": {"code": "class MSGPack:\n    def time_read_msgpack(self):\n        read_msgpack(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MSGPack:\n    def setup(self):\n        self.fname = \"__test__.msg\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        with warnings.catch_warnings(record=True):\n            self.df.to_msgpack(self.fname)", "min_run_count": 2, "name": "io.msgpack.MSGPack.time_read_msgpack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3dd40da3e97f2226809132e31c51bf743de24dac448324816091c0e3f3c3b5ab", "warmup_time": -1}, "io.msgpack.MSGPack.time_write_msgpack": {"code": "class MSGPack:\n    def time_write_msgpack(self):\n        self.df.to_msgpack(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MSGPack:\n    def setup(self):\n        self.fname = \"__test__.msg\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        with warnings.catch_warnings(record=True):\n            self.df.to_msgpack(self.fname)", "min_run_count": 2, "name": "io.msgpack.MSGPack.time_write_msgpack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1db101d5a667c0606c897217aa7bfafc4ce31327a074e79d70244c4c4f73ae2", "warmup_time": -1}, "io.parsers.ConcatDateCols.time_check_concat": {"code": "class ConcatDateCols:\n    def time_check_concat(self, value, dim):\n        _concat_date_cols(self.object)\n\n    def setup(self, value, dim):\n        count_elem = 10000\n        if dim == 1:\n            self.object = (np.array([value] * count_elem),)\n        if dim == 2:\n            self.object = (\n                np.array([value] * count_elem),\n                np.array([value] * count_elem),\n            )", "min_run_count": 2, "name": "io.parsers.ConcatDateCols.time_check_concat", "number": 0, "param_names": ["value", "dim"], "params": [["1234567890", "'AAAA'"], ["1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "84c246e01e34c7b357ea8e6e9ae2b49854271d403aff72e89ffee50fdbf9f6ac", "warmup_time": -1}, "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {"code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000", "min_run_count": 2, "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes", "number": 0, "param_names": ["value"], "params": [["'2Q2005'", "'0.0'", "'10000'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7", "warmup_time": -1}, "io.pickle.Pickle.time_read_pickle": {"code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_read_pickle", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f57eda8d55e808305c1ca1b52e16da17adb3390c5cec487c50cae3e5f32a629", "warmup_time": -1}, "io.pickle.Pickle.time_write_pickle": {"code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_write_pickle", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31372bfc8f01bd027acaa0195886dc5125eb3a5dd286dc904366c7c3ef9a9825", "warmup_time": -1}, "io.sas.SAS.time_read_msgpack": {"code": "class SAS:\n    def time_read_msgpack(self, format):\n        read_sas(self.f, format=format)\n\n    def setup(self, format):\n        # Read files that are located in 'pandas/io/tests/sas/data'\n        files = {\"sas7bdat\": \"test1.sas7bdat\", \"xport\": \"paxraw_d_short.xpt\"}\n        file = files[format]\n        paths = [\n            os.path.dirname(__file__),\n            \"..\",\n            \"..\",\n            \"..\",\n            \"pandas\",\n            \"tests\",\n            \"io\",\n            \"sas\",\n            \"data\",\n            file,\n        ]\n        self.f = os.path.join(*paths)", "min_run_count": 2, "name": "io.sas.SAS.time_read_msgpack", "number": 0, "param_names": ["format"], "params": [["'sas7bdat'", "'xport'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "51d7e8c3f6ea567ede07c54157269e5ec943fb373c7f323d762f2921dbfcd6be", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_all": {"code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_all", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93795b7490c5b3636789316ac8feb36202260fa5551819a502abdb1565e7aac7", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {"code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b6173baf897c1ea5a6bf7f0b5af3710b99e19f181195f7231d2b76a92531977f", "warmup_time": -1}, "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {"code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e4cc858ae9f0e599e81579656ea7c93f8f17697ed3dd8d490754734addadbf3b", "warmup_time": -1}, "io.sql.SQL.time_read_sql_query": {"code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_read_sql_query", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "79016042e99815670145c7e48a4beb2b3c675d5a8199bacf53a58e61153e57ce", "warmup_time": -1}, "io.sql.SQL.time_to_sql_dataframe": {"code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_to_sql_dataframe", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f151c8d9b77be3cb95750ddb63c47b0b21b7ff4be47e198fa982b2b3e12e9b1", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {"code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9eaa9d9e275ab02db0cb80a0c1bb612922a840ec6d35d75d75ae708e74f1f94", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {"code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fc3602e4a9ccdccfde7ae3bdc00c986fb80e9dbd1260e939b2bb2b81da048e1", "warmup_time": -1}, "io.stata.Stata.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77e3031e044e76658d6a5d5c3492e759416dd5e84e53428cf38ec919c3bdc1b7", "warmup_time": -1}, "io.stata.Stata.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e49dabe6a2ca0fdd6c7ce58e5b7c618d038e6247499641a0d4914f6518e575bc", "warmup_time": -1}, "io.stata.StataMissing.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cfcbe658a923605375cc7b0cbd5c285e378d2d5ec34bc82034af623e10889ac5", "warmup_time": -1}, "io.stata.StataMissing.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12d0ab04f51e54180002a6044381d6ee75653701f4e8345e8dad76fd2b97e12b", "warmup_time": -1}, "join_merge.Align.time_series_align_int64_index": {"code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10 ** 5\n        rng = np.arange(0, 10 ** 13, 10 ** 7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_int64_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3308a741ed72316f1e3ceba8cae34b8a0e4bbe12a827d8c7d09cda3ca638c289", "warmup_time": -1}, "join_merge.Align.time_series_align_left_monotonic": {"code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10 ** 5\n        rng = np.arange(0, 10 ** 13, 10 ** 7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_left_monotonic", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa41898004f3566f630b221aab2716c93ef63d62983ae232cb91acfe94e8ccd4", "warmup_time": -1}, "join_merge.Append.time_append_homogenous": {"code": "class Append:\n    def time_append_homogenous(self):\n        self.df1.append(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1[\"obj1\"] = \"bar\"\n        self.mdf1[\"obj2\"] = \"bar\"\n        self.mdf1[\"int1\"] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index", "min_run_count": 2, "name": "join_merge.Append.time_append_homogenous", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d98df4ffdaa16119e4b7b252473797a72fa9b08c5277fd247576e38b0f12ee5a", "warmup_time": -1}, "join_merge.Append.time_append_mixed": {"code": "class Append:\n    def time_append_mixed(self):\n        self.mdf1.append(self.mdf2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1[\"obj1\"] = \"bar\"\n        self.mdf1[\"obj2\"] = \"bar\"\n        self.mdf1[\"int1\"] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index", "min_run_count": 2, "name": "join_merge.Append.time_append_mixed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d03c315fcf9755e023f11fb9ff9952497582a58044533d52b4d4049ffa21d2d6", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_left": {"code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_left", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5f9ad5afe1e660817d50e70247e33a3f703afd2df8be1876f04763d0be0db37", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_right": {"code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_right", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "33e07ea8976d21a40107e7d5a0b7c1ef1ac3e653fbe099d27337e2acaae07d72", "warmup_time": -1}, "join_merge.Concat.time_concat_mixed_ndims": {"code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_mixed_ndims", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9413ed44e4c0aab2c13a5268d35037f512b4af709c8c40a099e603e2ef411e0c", "warmup_time": -1}, "join_merge.Concat.time_concat_series": {"code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_series", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "591b2816028fe5343a9e969d1f6fcd64081fa9c6ea6627daa86ddfc5a1ac8c52", "warmup_time": -1}, "join_merge.Concat.time_concat_small_frames": {"code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_small_frames", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d2cfb29a06db532b9a18e7b751af74b44c42f04f80bb0d506a6b34d6b8af705", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_c_ordered": {"code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_c_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48754d9f949305e562998495e7af54bda99baeb1ff03cf3bd849e9eb2fd5e011", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_f_ordered": {"code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_f_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48643c33763bfdacb7c96d0bc792ca010df9bbf8d6558807116cbcab1c584763", "warmup_time": -1}, "join_merge.I8Merge.time_i8merge": {"code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10 ** 6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1", "min_run_count": 2, "name": "join_merge.I8Merge.time_i8merge", "number": 0, "param_names": ["how"], "params": [["'inner'", "'outer'", "'left'", "'right'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "021318fb7704cd5c3234f886011f5c807a3869d1826f118f6d21c0aaad33d6e1", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_multi": {"code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_multi", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "790821ad4bfe9150772c02fa7993d900cc3328796aec8996e155bfadb87bc369", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {"code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f9b7ee80173ebebd55faa4ad3bb60cb0ff7808ec9e32cb39fd85f67fa8dd66b", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_bigger": {"code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50b7166efa7ef17c24c79b834c7b1bf7dfc87058c53b02f8955952342e6a0786", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_small": {"code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_small", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13bb010c58575e8f4c6531d36d58ca2a76bd0b6ed389ec8dbe303891d7a93231", "warmup_time": -1}, "join_merge.JoinIndex.time_left_outer_join_index": {"code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 50000\n        self.left = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")", "min_run_count": 2, "name": "join_merge.JoinIndex.time_left_outer_join_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9dab93d66fd2e264a14e27edc03f595fa4c43784ba6fe7c0458beb9767330a70", "warmup_time": -1}, "join_merge.JoinNonUnique.time_join_non_unique_equal": {"code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"T\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"S\", \"S\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86400000000000.0\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]", "min_run_count": 2, "name": "join_merge.JoinNonUnique.time_join_non_unique_equal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b6bc3f8f5cc0b7814c325d02f69b998d8b7dbb37e746a671134bcbed6a092e58", "warmup_time": -1}, "join_merge.Merge.time_merge_2intkey": {"code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_2intkey", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ed945be79fa4f758895da38ae20e7a18708f23a0ca200274d028e94bf6601b2", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_2key": {"code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_2key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "146b4d12d3e7f46fe75784d48e6ed757ff81dab132ccf6dc7a3b9f1e7be8567e", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_key": {"code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57a9ceb8a12f4bccde9a1f65caa8dc8154e0eb846bf341e0952b5a3eebb6dda9", "warmup_time": -1}, "join_merge.MergeAsof.time_by_int": {"code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a15ff3b838ac0c680dffafecb488c6d34116513d8ea891c503b9e8359891607", "warmup_time": -1}, "join_merge.MergeAsof.time_by_object": {"code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_object", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8f5adf6bbca5860a4758a9c1cfbba6b102a4dbef99b38b109c41a9797e5b4fc", "warmup_time": -1}, "join_merge.MergeAsof.time_multiby": {"code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_multiby", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71fee353035e5fcaa9e6ac36d350ecf80d112864bb929299c18e5c65324d3961", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int": {"code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8064b9b7710b46ed6d51da78eea04ae4593d33f013aa9a3fa7e93f307a23047", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int32": {"code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int32", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "caf7ccf963fb86330fb9289dc5d6d8fe7a9c95d41a3c29ad381760e176c2e7ec", "warmup_time": -1}, "join_merge.MergeAsof.time_on_uint64": {"code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_uint64", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4078e9c6627567125c755f639e8628c2c91214601be3107a234795040ac04142", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_cat": {"code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_cat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24dbef20c9e18f6d0e96db661214e186e4042cc780d501367b3a8317dc990f23", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_object": {"code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_object", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa09d620dee07971de9ade56cba3d3628df11d1490f916fc629c9b58fff97065", "warmup_time": -1}, "join_merge.MergeOrdered.time_merge_ordered": {"code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = tm.makeStringIndex(10).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )", "min_run_count": 2, "name": "join_merge.MergeOrdered.time_merge_ordered", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a7e5ebae72547e296e22a48baa55cc38997f5fefb2cfe93ad9cb957033f9481", "warmup_time": -1}, "multiindex_object.CategoricalLevel.time_categorical_level": {"code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n    \n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})", "min_run_count": 2, "name": "multiindex_object.CategoricalLevel.time_categorical_level", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ed13d98e94a857baa73e3941062551dfcfa7db37d771965d448fb5b23ec9636", "warmup_time": -1}, "multiindex_object.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [np.arange(n), tm.makeStringIndex(n).values, 1000 + np.arange(n)]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)", "min_run_count": 2, "name": "multiindex_object.Duplicated.time_duplicated", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b14ccbe8f895db81ecbefbd4940fa2327b059bf58f9a79f27fa5b821f232101d", "warmup_time": -1}, "multiindex_object.Duplicates.time_remove_unused_levels": {"code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]", "min_run_count": 2, "name": "multiindex_object.Duplicates.time_remove_unused_levels", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52fc3b5e4ed8968affde380019b654ea84208fe579b557a8061b3a11aa90e75a", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc": {"code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d5ab3e20ac6ad3ea7917750281182ef71ecc3a54ab6ae19602066a7f468681d", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc_warm": {"code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc_warm", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fe1c8e21f3befc08d5313fff82e1d45abfa4424a6f744f8092c7f4e264bd03a", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc": {"code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6191908cf16ed040ee49aeccb20a7a309da5ea80ce7c9889d8753473447e490c", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc_warm": {"code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc_warm", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2be10a2c6052f2b18365e5fe215e8601300921ad833f4aa60719b2eb1147f915", "warmup_time": -1}, "multiindex_object.GetLoc.time_small_get_loc_warm": {"code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_small_get_loc_warm", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd340b17354d038bd394c067e1628040d7bf9eb29d9a0fa7d4fe36aa09eb09b6", "warmup_time": -1}, "multiindex_object.GetLoc.time_string_get_loc": {"code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_string_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7018b856539639e5c28d4e33579fbac8e64444952d0ed9f2afa1f62021a17529", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer": {"code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fcec1ea3f6d165c7b56f30ef6f66dd2d4197808f18d2bf31103680b41f707f0", "warmup_time": -1}, "multiindex_object.Integer.time_is_monotonic": {"code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_is_monotonic", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2343fc872e626e762dc605e552af65c3e6a22302dc96010e47e1642c2d4f300", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_int64": {"code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_int64", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3388758f5be6d27f1c810b1f3ab51c3a59f8c9fa7b7fdd2d3322f9c7c8b41ef7", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_one": {"code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_one", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c9014e77fd360ec1d0d23b385a7a415db4760d431c8369df8f9c30ea201a461", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_zero": {"code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_zero", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a514d3e4ada47f58d1d77b5a05a27db517dc74ac3c9fcec8f377ade7cef2e9f2", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_copy": {"code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/multiindex_object.py:121", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80325b021caac9139ea141463fa3899e70faaba340a77a5940b5299539555292", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_sliced": {"code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_sliced", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/multiindex_object.py:121", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93aaaf583156bc7774cb478bee76d2815888cf675cdde1433e4a095dfa1c7baf", "warmup_time": -1}, "offset.ApplyIndex.time_apply_index": {"code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        offset.apply_index(self.rng)\n\n    def setup(self, offset):\n        N = 10000\n        self.rng = pd.date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "offset.ApplyIndex.time_apply_index", "number": 0, "param_names": ["offset"], "params": [["<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5473796dcbb527b9503d2d3f5ae7a961b2b73b103e99c0a14cf81d959a75a62", "warmup_time": -1}, "offset.OffsetDatetimeIndexArithmetic.time_add_offset": {"code": "class OffsetDatetimeIndexArithmetic:\n    def time_add_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.data + offset\n\n    def setup(self, offset):\n        N = 1000\n        self.data = pd.date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "offset.OffsetDatetimeIndexArithmetic.time_add_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8f60fce4f2424912aa7c6614d98831e400f6e4d59afba3ec6c953edcd648f232", "warmup_time": -1}, "offset.OffsetSeriesArithmetic.time_add_offset": {"code": "class OffsetSeriesArithmetic:\n    def time_add_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.data + offset\n\n    def setup(self, offset):\n        N = 1000\n        rng = pd.date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.data = pd.Series(rng)", "min_run_count": 2, "name": "offset.OffsetSeriesArithmetic.time_add_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d7496a6da2f902a802eed05a193648c40b943dd664308999e1789862b3b0045a", "warmup_time": -1}, "package.TimeImport.time_import": {"code": "class TimeImport:\n    def time_import(self):\n        if PY37:\n            # on py37+ we the \"-X importtime\" usage gives us a more precise\n            #  measurement of the import time we actually care about,\n            #  without the subprocess or interpreter overhead\n            cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n            p = subprocess.run(cmd, stderr=subprocess.PIPE)\n    \n            line = p.stderr.splitlines()[-1]\n            field = line.split(b\"|\")[-2].strip()\n            total = int(field)  # microseconds\n            return total\n    \n        cmd = [sys.executable, \"-c\", \"import pandas as pd\"]\n        subprocess.run(cmd, stderr=subprocess.PIPE)", "min_run_count": 2, "name": "package.TimeImport.time_import", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9b4b577142f42a010f05c2acc07c45dc17231396cd8d701fbb93eafb43ad1c10", "warmup_time": -1}, "period.Algorithms.time_drop_duplicates": {"code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_drop_duplicates", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c", "warmup_time": -1}, "period.Algorithms.time_value_counts": {"code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_value_counts", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8", "warmup_time": -1}, "period.DataFramePeriodColumn.time_set_index": {"code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_set_index", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "223baa21285346a0b70e9d11fe853a0b156662cd2530575dc66cfcb8d65cf46a", "warmup_time": -1}, "period.DataFramePeriodColumn.time_setitem_period_column": {"code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_setitem_period_column", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7044b31af083678ecf627851ca14fa1108e6ec19cd7acf41ebe60f0283fefe8", "warmup_time": -1}, "period.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_align", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9", "warmup_time": -1}, "period.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b", "warmup_time": -1}, "period.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc", "warmup_time": -1}, "period.Indexing.time_series_loc": {"code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_series_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4", "warmup_time": -1}, "period.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cb344ef55a1ccd3f19e672102b836d76b728ced9a4a5813f2d76fc5be1df312b", "warmup_time": -1}, "period.Indexing.time_shape": {"code": "class Indexing:\n    def time_shape(self):\n        self.index.shape\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shape", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b90560f1d7bd998ce4a07d0c418d358b2118aa7b112df3561dcdb93bbf723905", "warmup_time": -1}, "period.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_date_range": {"code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_date_range", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints": {"code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints_daily": {"code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints_daily", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_pydatetime": {"code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_pydatetime", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1", "warmup_time": -1}, "plotting.FramePlotting.time_frame_plot": {"code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})", "min_run_count": 2, "name": "plotting.FramePlotting.time_frame_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'", "'scatter'", "'hexbin'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a82a6ba70b4d8b604d338f75ba50369652ada781c3e65bf690c22b54a9d4562d", "warmup_time": -1}, "plotting.Misc.time_plot_andrews_curves": {"code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N", "min_run_count": 2, "name": "plotting.Misc.time_plot_andrews_curves", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a97b4fa399b37c178eee1d0bfb886d2b6939fb52ee57620d4f78773ea3cf3ce", "warmup_time": -1}, "plotting.SeriesPlotting.time_series_plot": {"code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()", "min_run_count": 2, "name": "plotting.SeriesPlotting.time_series_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d767b86e0b27005187efbd490211b0bc52b0a87b042c0dd78093f288337392fb", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_irregular": {"code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_irregular", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09c463e16e938e14d13afbfccdd38fd15d0d8236d8c3c01ceb1743a161c6cbe5", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular": {"code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c03160971a62e9c71dbf1cd41d67d532c08fcdb6ad5e6558e700b18e899ed769", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular_compat": {"code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular_compat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e4bd7cff7dea2ee4bfcdfe2d8336071341fb5c9ec82e874a8b1800ec00f4338", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_table": {"code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f12479ad74f8626efab8c8468bfaea80edb10121f16cdddcd60cdfce3959b0ca", "warmup_time": -1}, "reindex.Align.time_align_series_irregular_string": {"code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = tm.makeStringIndex(n)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )", "min_run_count": 2, "name": "reindex.Align.time_align_series_irregular_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cd2788cb4afb3141bb5fc05d8c7aa5a75a1d94b188caf0119da7823e7d0966bb", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups": {"code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9237c94639d80a5c2162f4891f487356ce5485918beccb48398b89abae8f1808", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_bool": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_bool", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9a42ee5a1945bfff466ebffac814442a29e988f9f3380790e00cb8dd3cc5466d", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_int": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9261807f4c65e55fc53d6d73c421d108147f139980b85fdb28fe50e691f36a33", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_na": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_na", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1662080bfa2eab6ff5ba7afa7f71fe3e59da052b90b11bc05312899570a12f72", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_int": {"code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea276bb62cde4cdd53c8e3adbc2c78ee97c243bc711d94a0ea086554df7f0c72", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_string": {"code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_string", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39ae3e74e31a6a5b67fb34e737f839f35d85b5bd99c5121c6e3069b9ec759ab9", "warmup_time": -1}, "reindex.Fillna.time_float_32": {"code": "class Fillna:\n    def time_float_32(self, method):\n        self.ts_float32.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")", "min_run_count": 2, "name": "reindex.Fillna.time_float_32", "number": 0, "param_names": ["method"], "params": [["'pad'", "'backfill'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0197c9edf8b40b8bbcad67f83cfbe53e0eaf8d4ba9bd8b935d53d24b410eaea1", "warmup_time": -1}, "reindex.Fillna.time_reindexed": {"code": "class Fillna:\n    def time_reindexed(self, method):\n        self.ts_reindexed.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")", "min_run_count": 2, "name": "reindex.Fillna.time_reindexed", "number": 0, "param_names": ["method"], "params": [["'pad'", "'backfill'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6bdee4dd2ca6819211b9c9f4c3da575e033bbde298f8a9a8dc35107e0a203d8", "warmup_time": -1}, "reindex.LevelAlign.time_align_level": {"code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_align_level", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a1c48e1f021ca0595344c5b228a595996019c20b124df6cda920dfc2601a30c", "warmup_time": -1}, "reindex.LevelAlign.time_reindex_level": {"code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_reindex_level", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28f65e86fee2be64ff3a604df5fecd6ac0cb444a2c8f3b9c5cf02cfb61142fcc", "warmup_time": -1}, "reindex.LibFastZip.time_lib_fast_zip": {"code": "class LibFastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LibFastZip:\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)", "min_run_count": 2, "name": "reindex.LibFastZip.time_lib_fast_zip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76fdb90c052b51d11271496acb9a6821f878a7773f3c672274559b2ae5dacd7c", "warmup_time": -1}, "reindex.Reindex.time_reindex_columns": {"code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_columns", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "788a93ab840e0451eed006c2a03ab21175634464af82c16cd539150321f627af", "warmup_time": -1}, "reindex.Reindex.time_reindex_dates": {"code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_dates", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "072ea7775ff5e2752d9fb95ceb6a9331fa5bb6685587458b5027c97533c6fbfa", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex": {"code": "class Reindex:\n    def time_reindex_multiindex(self):\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cba70158f687c138ffd0245e2329691ba0f77f193a37a1e5740c1cccd377a67a", "warmup_time": -1}, "reindex.ReindexMethod.time_reindex_method": {"code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]", "min_run_count": 2, "name": "reindex.ReindexMethod.time_reindex_method", "number": 0, "param_names": ["method", "constructor"], "params": [["'pad'", "'backfill'"], ["<function date_range at 0x7f614a6adf28>", "<function period_range at 0x7f614a692268>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "65e6920b65629155af433aa881ca6c69f1a43c7ef066c56d2eeadac660651331", "warmup_time": -1}, "replace.Convert.time_replace": {"code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10 ** 3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]", "min_run_count": 2, "name": "replace.Convert.time_replace", "number": 0, "param_names": ["constructor", "replace_data"], "params": [["'DataFrame'", "'Series'"], ["'Timestamp'", "'Timedelta'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a381501b15044f4ccf367694555646711d929b2854428d8866a18559013cbbd", "warmup_time": -1}, "replace.FillNa.time_fillna": {"code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10 ** 6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_fillna", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea2d8ce668d229f4ca607218129ac8adad7222a1887b49a779a86e9f1027ce83", "warmup_time": -1}, "replace.FillNa.time_replace": {"code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10 ** 6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_replace", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb3764acc296685f9c32dfbc06b542217babc15807c5131f4fe3168645ca5bdf", "warmup_time": -1}, "replace.ReplaceDict.time_replace_series": {"code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10 ** 5\n        start_value = 10 ** 5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10 ** 3))", "min_run_count": 2, "name": "replace.ReplaceDict.time_replace_series", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5355f1706157acb5ebd177c64d5af0b4b8336bdf839fc88621891a02fc0f7556", "warmup_time": -1}, "replace.ReplaceList.time_replace_list": {"code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10 ** 7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7f2eb52e758e5ccca9aa1d74365b39609e14ea776dc0d6df813cd2a6b40af33", "warmup_time": -1}, "replace.ReplaceList.time_replace_list_one_match": {"code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf cant\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10 ** 7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list_one_match", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95acf97c93331fe43a4d9f339b438258ec753abd14b795cfa44e62e41ba5db10", "warmup_time": -1}, "reshape.Crosstab.time_crosstab": {"code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77853e1f97d25f0dd2a73b4a91565deb7ad0c5a0f796470e04794789b16efe40", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize": {"code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0a97c166effb33df1099cf73dda0925878dee0410b80330c4d5e5ad365a2fd00", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize_margins": {"code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize_margins", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "762af7c2d612ddea47095ceb57e359a55ba836a8b949abf69b906fef2f254210", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_values": {"code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8080df822c9d4aab1bb0f157a9086c8b6f8e3dff66a19202b9af66414e7e833d", "warmup_time": -1}, "reshape.Cut.peakmem_cut_interval": {"code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "name": "reshape.Cut.peakmem_cut_interval", "param_names": ["bins"], "params": [["4", "10", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "65f32ed0d341db6c2b0f5a37e6903c163dddded94bceb58a6014252b0d2afa4e"}, "reshape.Cut.time_cut_datetime": {"code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b452177e79002b6cde2aba150e235a71156a97d3910bc277fea5631102218769", "warmup_time": -1}, "reshape.Cut.time_cut_float": {"code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e3f1351b0833b30982d3b3842bf35e08e9f48d3920e07685ce977c63b098346", "warmup_time": -1}, "reshape.Cut.time_cut_int": {"code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a84c4f6235e020582f0511d88d52bd7b87f5f11c04271b389b762235c59a5001", "warmup_time": -1}, "reshape.Cut.time_cut_interval": {"code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_interval", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11eeaec35829b8bbb0fe2a6813d3ab35a524ef41e78027894bd523d0dde17a89", "warmup_time": -1}, "reshape.Cut.time_cut_timedelta": {"code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2f5c35407cf29255413562a88e6d55964bb5bde8a9a2b83b85ffeeda159ff65", "warmup_time": -1}, "reshape.Cut.time_qcut_datetime": {"code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1dc3bdc55e69333559a3c1bef3536ee399372354e5ac5066f4527f06b76ec6e", "warmup_time": -1}, "reshape.Cut.time_qcut_float": {"code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f6552b34390d4f7651bb7e8b62568bff93c3b4ffe833fdeac4132f0bdeab5cd", "warmup_time": -1}, "reshape.Cut.time_qcut_int": {"code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb973a705e6ceabff795799bb0662b89dc7d0c4b93112b590dd47ebf1b8e10f9", "warmup_time": -1}, "reshape.Cut.time_qcut_timedelta": {"code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e964d42204717ecb025d8aef6961b4166c8bd7b24db8a0ffa0113bb19b990ad1", "warmup_time": -1}, "reshape.Explode.time_explode": {"code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n    \n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)", "min_run_count": 2, "name": "reshape.Explode.time_explode", "number": 0, "param_names": ["n_rows", "max_list_length"], "params": [["100", "1000", "10000"], ["3", "5", "10"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a48f21156402264510a218cb5f5ef960de2a07fd58de8676b2924153c72fa838", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d": {"code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=pd.api.types.CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5fd1985770aa7131dfd607d68a5294b180bfe26fede57a1a6151aa40db06bd1", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d_sparse": {"code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=pd.api.types.CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d_sparse", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "473b3f15805d91e809350a7b66ac56f3eb5c9a3ee10ee8341d7bf7bf249fe557", "warmup_time": -1}, "reshape.Melt.time_melt_dataframe": {"code": "class Melt:\n    def time_melt_dataframe(self):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 3), columns=[\"A\", \"B\", \"C\"])\n        self.df[\"id1\"] = np.random.randint(0, 10, 10000)\n        self.df[\"id2\"] = np.random.randint(100, 1000, 10000)", "min_run_count": 2, "name": "reshape.Melt.time_melt_dataframe", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e0aac4302e06f7a040b4275da61ce9574141fcef7f38960ebf3bc8ef1a05cbe", "warmup_time": -1}, "reshape.Pivot.time_reshape_pivot_time_series": {"code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(\"date\", \"variable\", \"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "reshape.Pivot.time_reshape_pivot_time_series", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b138b7132956e60c7816e2503c74c204ae14c930a44007c048e9316edbc6fe27", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table": {"code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "691b4a78c4301b2145d3190fcc4b38d84b7a74762b08d16e7d746365233345ff", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_agg": {"code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_agg", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff643f4e3517c1e543ab62c4166d7ed80b390c168a9f355e368d57a6e011e519", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical": {"code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=np.sum, fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd8fc37bc61253ba8b69b5a10d126dedc1b2f6f4d08514ce5ccbbfb4eb6ef2e3", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical_observed": {"code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=np.sum,\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical_observed", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7ffa30cd099819c7ad2104205c0b878a39af9d7dd936029a1156bef1bd223cd", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins": {"code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7317127ece84018006dace4f982399007da7567321d7234441dda0b6835770c9", "warmup_time": -1}, "reshape.SimpleReshape.time_stack": {"code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_stack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14ed9d449ab0c21febf952d6ba4f49a2b47ecf2668c736dc5ab80dc32826c997", "warmup_time": -1}, "reshape.SimpleReshape.time_unstack": {"code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_unstack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dbf93cb1a241b4e6717154b3056e364dc2c520e2dfe51ca842ce83cfd28e3344", "warmup_time": -1}, "reshape.SparseIndex.time_unstack": {"code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])", "min_run_count": 2, "name": "reshape.SparseIndex.time_unstack", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abea94ab71de82f53dcb238f1672933e7a4e96827762b3d8b7002704073a2516", "warmup_time": -1}, "reshape.Unstack.time_full_product": {"code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n        self.df = DataFrame(values, index, columns)\n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_full_product", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5be77f4a6ac3274a8c4cb83fac685f4af66aa560d85843f3877f29977a1d685b", "warmup_time": -1}, "reshape.Unstack.time_without_last_row": {"code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n        self.df = DataFrame(values, index, columns)\n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_without_last_row", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "789ac1a30b7a41dc5b6b156e8f94b97f117780dfa8b70ef3585d21d359912716", "warmup_time": -1}, "reshape.WideToLong.time_wide_to_long_big": {"code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [l + str(num) for l, num in product(self.letters, range(1, nyrs + 1))]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index", "min_run_count": 2, "name": "reshape.WideToLong.time_wide_to_long_big", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0dfccfb326171286278a603775aadbf9a1ffcf6136abd6a7840b322164a49ff", "warmup_time": -1}, "rolling.Apply.time_rolling": {"code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10 ** 3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Apply.time_rolling", "number": 0, "param_names": ["constructor", "window", "dtype", "function", "raw"], "params": [["'DataFrame'", "'Series'"], ["3", "300"], ["'int'", "'float'"], ["<built-in function sum>", "<function sum at 0x7f6157b7b730>", "<function Apply.<lambda> at 0x7f61433809d8>"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b90b7402f3e82bc2da5a470aee1a54978e96b0017b0ed5012b190cc44119e7f", "warmup_time": -1}, "rolling.EWMMethods.time_ewm": {"code": "class EWMMethods:\n    def time_ewm(self, constructor, window, dtype, method):\n        getattr(self.ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.ewm = getattr(pd, constructor)(arr).ewm(halflife=window)", "min_run_count": 2, "name": "rolling.EWMMethods.time_ewm", "number": 0, "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'mean'", "'std'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d2d0fff3d0bcea62c9c00d332188a5e98cf3aee68c52c20f6299698dd72e1052", "warmup_time": -1}, "rolling.ExpandingMethods.time_expanding": {"code": "class ExpandingMethods:\n    def time_expanding(self, constructor, dtype, method):\n        getattr(self.expanding, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ExpandingMethods:\n    def setup(self, constructor, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.expanding = getattr(pd, constructor)(arr).expanding()", "min_run_count": 2, "name": "rolling.ExpandingMethods.time_expanding", "number": 0, "param_names": ["contructor", "window", "dtype"], "params": [["'DataFrame'", "'Series'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d0bbbbcec297cef32fe95719a3135c55c9199a30bd81f4e0806f8c54649870c", "warmup_time": -1}, "rolling.Methods.peakmem_rolling": {"code": "class Methods:\n    def peakmem_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "name": "rolling.Methods.peakmem_rolling", "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7e2a3131a7ff5bb7c9dd1bd4f4a4c8d40a6b414a04a147f2dc4884966833d72e"}, "rolling.Methods.time_rolling": {"code": "class Methods:\n    def time_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Methods.time_rolling", "number": 0, "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f43b1b585aa54e5555fc6e79ecbb5ef96b4bba1ce61852f9fc9b193061d1fe3", "warmup_time": -1}, "rolling.Pairwise.time_pairwise": {"code": "class Pairwise:\n    def time_pairwise(self, window, method, pairwise):\n        if window is None:\n            r = self.df.expanding()\n        else:\n            r = self.df.rolling(window=window)\n        getattr(r, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, window, method, pairwise):\n        N = 10 ** 4\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)", "min_run_count": 2, "name": "rolling.Pairwise.time_pairwise", "number": 0, "param_names": ["window", "method", "pairwise"], "params": [["10", "1000", "None"], ["'corr'", "'cov'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bc3a74a3426fcf4ddf5adacee721b3eceab14f6b598d4e108da17536ca805704", "warmup_time": -1}, "rolling.PeakMemFixed.peakmem_fixed": {"code": "class PeakMemFixed:\n    def peakmem_fixed(self):\n        # GH 25926\n        # This is to detect memory leaks in rolling operations.\n        # To save time this is only ran on one method.\n        # 6000 iterations is enough for most types of leaks to be detected\n        for x in range(6000):\n            self.roll.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixed:\n    def setup(self):\n        N = 10\n        arr = 100 * np.random.random(N)\n        self.roll = pd.Series(arr).rolling(10)", "name": "rolling.PeakMemFixed.peakmem_fixed", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "77ce1c06e460c88101541ae777e23badf244aa97c5ec3ac3b20b71aca6c82186"}, "rolling.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Quantile.time_quantile", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "param5"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93517902464869edfede633c9a02e9636970a16a231d67f2c556504d5154757d", "warmup_time": -1}, "rolling.VariableWindowMethods.peakmem_rolling": {"code": "class Methods:\n    def peakmem_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.roll = getattr(pd, constructor)(arr, index=index).rolling(window)", "name": "rolling.VariableWindowMethods.peakmem_rolling", "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "6648052c9124b3245a59675896dbce54c40cf38c7b447ab3ebea21369726f38d"}, "rolling.VariableWindowMethods.time_rolling": {"code": "class Methods:\n    def time_rolling(self, constructor, window, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.roll = getattr(pd, constructor)(arr, index=index).rolling(window)", "min_run_count": 2, "name": "rolling.VariableWindowMethods.time_rolling", "number": 0, "param_names": ["contructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fa563778646daff4289cf37153612f3118d5b0bd1d5cb749eba2921fab9cd7a", "warmup_time": -1}, "series_methods.All.time_all": {"code": "class All:\n    def time_all(self, N, case):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case):\n        val = case != \"fast\"\n        self.s = Series([val] * N)", "min_run_count": 2, "name": "series_methods.All.time_all", "number": 0, "param_names": ["N", "case"], "params": [["1000", "1000000"], ["'fast'", "'slow'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38d6eaf802692bd858841274c6867cdd0b231b1989e36d1bfc86dea80310ffa0", "warmup_time": -1}, "series_methods.Any.time_any": {"code": "class Any:\n    def time_any(self, N, case):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case):\n        val = case == \"fast\"\n        self.s = Series([val] * N)", "min_run_count": 2, "name": "series_methods.Any.time_any", "number": 0, "param_names": ["N", "case"], "params": [["1000", "1000000"], ["'fast'", "'slow'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "906dda919f041fa914f8d643c360623a3d812bff7a855b20c379dc92db9980c6", "warmup_time": -1}, "series_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))", "min_run_count": 2, "name": "series_methods.Clip.time_clip", "number": 0, "param_names": ["n"], "params": [["50", "1000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ccfa17d1178249cacc78c3dfa6dbb3851850815c5d14df41a39789ff6adfea2b", "warmup_time": -1}, "series_methods.Dir.time_dir_strings": {"code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=tm.makeStringIndex(10000))", "min_run_count": 2, "name": "series_methods.Dir.time_dir_strings", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e116c6dea26d05ccd39e54ddeab3096a69ba2e18e7daaa811e0cb3114cf2e9b6", "warmup_time": -1}, "series_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10 ** 6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"S\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT", "min_run_count": 2, "name": "series_methods.Dropna.time_dropna", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'datetime'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e001ffd02246487fd23ba2e497935ee748e42bae5b74235f37364d25db2bee84", "warmup_time": -1}, "series_methods.IsIn.time_isin": {"code": "class IsIn:\n    def time_isin(self, dtypes):\n        self.s.isin(self.values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsIn:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(1, 10, 100000)).astype(dtype)\n        self.values = [1, 2]", "min_run_count": 2, "name": "series_methods.IsIn.time_isin", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3d9cc6d75609adf9a495651078bae70dba81ee46f78f04ad04375e508a17bb7", "warmup_time": -1}, "series_methods.IsInFloat64.time_isin_few_different": {"code": "class IsInFloat64:\n    def time_isin_few_different(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.few_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10 ** 6, dtype=np.float64)\n        self.few_different_values = np.zeros(10 ** 7, dtype=np.float64)\n        self.only_nans_values = np.full(10 ** 7, np.nan, dtype=np.float64)", "min_run_count": 2, "name": "series_methods.IsInFloat64.time_isin_few_different", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82eb8992ae30fa6f8babf46c00b1b150f171a77b4d076a2f701ed6e15c9d4dec", "warmup_time": -1}, "series_methods.IsInFloat64.time_isin_many_different": {"code": "class IsInFloat64:\n    def time_isin_many_different(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.many_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10 ** 6, dtype=np.float64)\n        self.few_different_values = np.zeros(10 ** 7, dtype=np.float64)\n        self.only_nans_values = np.full(10 ** 7, np.nan, dtype=np.float64)", "min_run_count": 2, "name": "series_methods.IsInFloat64.time_isin_many_different", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eef8c79e3c8679df328c8a5a3e83894f608a4d91e7d45aaabdf3dc45825df03c", "warmup_time": -1}, "series_methods.IsInFloat64.time_isin_nan_values": {"code": "class IsInFloat64:\n    def time_isin_nan_values(self):\n        # runtime is dominated by creation of the lookup-table\n        self.small.isin(self.few_different_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInFloat64:\n    def setup(self):\n        self.small = Series([1, 2], dtype=np.float64)\n        self.many_different_values = np.arange(10 ** 6, dtype=np.float64)\n        self.few_different_values = np.zeros(10 ** 7, dtype=np.float64)\n        self.only_nans_values = np.full(10 ** 7, np.nan, dtype=np.float64)", "min_run_count": 2, "name": "series_methods.IsInFloat64.time_isin_nan_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eacab46bb2e530fd978af5391037eff8e2d37e771f55fe96b33651f02d3910db", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_long_series_long_values": {"code": "class IsInForObjects:\n    def time_isin_long_series_long_values(self):\n        # no dominating part\n        self.s_long.isin(self.vals_long)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_long_series_long_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "716d352656a26f8fd89bdc418cfdca0db41dc73a146b55a6953b02711fff80c5", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_long_series_long_values_floats": {"code": "class IsInForObjects:\n    def time_isin_long_series_long_values_floats(self):\n        # no dominating part\n        self.s_long_floats.isin(self.vals_long_floats)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_long_series_long_values_floats", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8ea5b0178a9aa92c34c0e57f182a360368021806f0e8fc908ec495b73f232fd7", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_long_series_short_values": {"code": "class IsInForObjects:\n    def time_isin_long_series_short_values(self):\n        # running time dominated by look-up\n        self.s_long.isin(self.vals_short)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_long_series_short_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a515bcda7dfd31fbeb0c2f9daf5f348f084891141aaf82a3b084c8216dcefb", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_nans": {"code": "class IsInForObjects:\n    def time_isin_nans(self):\n        # if nan-objects are different objects,\n        # this has the potential to trigger O(n^2) running time\n        self.s_nans.isin(self.vals_nans)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_nans", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35b4bd0ed91a3601da21eb3db468d1a954529d7cecb2fa9ee2512747ce2042d9", "warmup_time": -1}, "series_methods.IsInForObjects.time_isin_short_series_long_values": {"code": "class IsInForObjects:\n    def time_isin_short_series_long_values(self):\n        # running time dominated by the preprocessing\n        self.s_short.isin(self.vals_long)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsInForObjects:\n    def setup(self):\n        self.s_nans = Series(np.full(10 ** 4, np.nan)).astype(np.object)\n        self.vals_nans = np.full(10 ** 4, np.nan).astype(np.object)\n        self.s_short = Series(np.arange(2)).astype(np.object)\n        self.s_long = Series(np.arange(10 ** 5)).astype(np.object)\n        self.vals_short = np.arange(2).astype(np.object)\n        self.vals_long = np.arange(10 ** 5).astype(np.object)\n        # because of nans floats are special:\n        self.s_long_floats = Series(np.arange(10 ** 5, dtype=np.float)).astype(\n            np.object\n        )\n        self.vals_long_floats = np.arange(10 ** 5, dtype=np.float).astype(np.object)", "min_run_count": 2, "name": "series_methods.IsInForObjects.time_isin_short_series_long_values", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d3500cfdc7573eca3ab24321537f314c83ea2e54bb41d149319961cf4e2c9624", "warmup_time": -1}, "series_methods.Map.time_map": {"code": "class Map:\n    def time_map(self, mapper, *args, **kwargs):\n        self.s.map(self.map_data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Map.time_map", "number": 0, "param_names": ["m", "a"], "params": [["'dict'", "'Series'", "'lambda'"], ["'object'", "'category'", "'int'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8231ec926c8677b7c40a05a21f46762744e6cb8aade12af6e7eea5b58d5f997d", "warmup_time": -1}, "series_methods.NSort.time_nlargest": {"code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nlargest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "253c5ac019c9236c18146b346c88bc19e56f04eb4c5d86ec0da4cd51188b900a", "warmup_time": -1}, "series_methods.NSort.time_nsmallest": {"code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nsmallest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91f7a9783802ebb8d4430865643ddc60d047d6480337c2525bf11ce778093519", "warmup_time": -1}, "series_methods.NanOps.time_func": {"code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        self.s = Series([1] * N, dtype=dtype)\n        self.func = getattr(self.s, func)", "min_run_count": 2, "name": "series_methods.NanOps.time_func", "number": 0, "param_names": ["func", "N", "dtype"], "params": [["'var'", "'mean'", "'median'", "'max'", "'min'", "'sum'", "'std'", "'sem'", "'argmax'", "'skew'", "'kurt'", "'prod'"], ["1000", "1000000"], ["'int8'", "'int32'", "'int64'", "'float64'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41743d399f9f3a98d72e1e375ec978c9fdb05b5710e2e89bf68122cf86350c1c", "warmup_time": -1}, "series_methods.SearchSorted.time_searchsorted": {"code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10 ** 5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)", "min_run_count": 2, "name": "series_methods.SearchSorted.time_searchsorted", "number": 0, "param_names": ["dtype"], "params": [["'int8'", "'int16'", "'int32'", "'int64'", "'uint8'", "'uint16'", "'uint32'", "'uint64'", "'float16'", "'float32'", "'float64'", "'str'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "150c5461a0b3c6fbd3b961cc5ee4bbc9aa478a9e2dcd8bbaf18d5c40a0f71cf1", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor": {"code": "class SeriesConstructor:\n    def time_constructor(self, data):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self, data):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        dict_data = dict(zip(self.idx, range(len(self.idx))))\n        self.data = None if data is None else dict_data", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor", "number": 0, "param_names": ["data"], "params": [["None", "'dict'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff115ed9fb7934d909610ba5283268dd462655d2e463cf0030bc64f6dd3a4cf5", "warmup_time": -1}, "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {"code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=int(1e6)))", "min_run_count": 2, "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d5a098eedf58b5a068b69ce1ef386caea4fb22d9a3592d09f33f09e8523157e0", "warmup_time": -1}, "series_methods.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000)).astype(dtype)", "min_run_count": 2, "name": "series_methods.ValueCounts.time_value_counts", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96468feb76190801a31466445c331b28d4e65aba6b0197a5009ee4474cb02953", "warmup_time": -1}, "sparse.Arithmetic.time_add": {"code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_add", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee1c5bad63c3ec6b7f85a0070f71557a8687bfda1ee11013ccd245be2a12f489", "warmup_time": -1}, "sparse.Arithmetic.time_divide": {"code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_divide", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d13aaf4bdcbd713e3c6bacd5b3c7d07d1fc14ee8a5fffdc93fcbd72118989e5", "warmup_time": -1}, "sparse.Arithmetic.time_intersect": {"code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_intersect", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31f113dc64c8d9d5a4d2658467f1fb5a2b3a9960115a69a4763510ed6dc9bb27", "warmup_time": -1}, "sparse.Arithmetic.time_make_union": {"code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_make_union", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4cdd0234d09c55379754d56e3587295ae839c1a8cdd9d0a7f2919bdbc97da5c4", "warmup_time": -1}, "sparse.ArithmeticBlock.time_addition": {"code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_addition", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8fc2841a4836d83f5ffab0e2586b83c8142385ceb1dac830a4f114ab296bfd8", "warmup_time": -1}, "sparse.ArithmeticBlock.time_division": {"code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_division", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bcd9a60e2b8c7042e9296a23c48a02547653c73d4d508bec655414410dc34437", "warmup_time": -1}, "sparse.ArithmeticBlock.time_intersect": {"code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_intersect", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fffcc616a09966bd1697b61a99f21c1fdfff9b0818ea302a69974d536d5031b5", "warmup_time": -1}, "sparse.ArithmeticBlock.time_make_union": {"code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_make_union", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "762a15c3f7d93d6bec720560480677ac0a8ce70e3f59d09d9ce8383133f6333a", "warmup_time": -1}, "sparse.FromCoo.time_sparse_series_from_coo": {"code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        pd.Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )", "min_run_count": 2, "name": "sparse.FromCoo.time_sparse_series_from_coo", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b731b3d1c939f96bc19e22f07bb9cb8ab8cc54b2dc2892d6aec275b693a58ebd", "warmup_time": -1}, "sparse.SparseArrayConstructor.time_sparse_array": {"code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10 ** 6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)", "min_run_count": 2, "name": "sparse.SparseArrayConstructor.time_sparse_array", "number": 0, "param_names": ["dense_proportion", "fill_value", "dtype"], "params": [["0.1", "0.01"], ["0", "nan"], ["<class 'numpy.int64'>", "<class 'numpy.float64'>", "<class 'object'>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2509acc32bc8fefde58ed633987b18f22627f990fd781f9ad245536ea5397620", "warmup_time": -1}, "sparse.SparseDataFrameConstructor.time_from_scipy": {"code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.arr = np.arange(N)\n        self.sparse = scipy.sparse.rand(N, N, 0.005)", "min_run_count": 2, "name": "sparse.SparseDataFrameConstructor.time_from_scipy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "26b43a51bac9f8ea973bd53f4def2fee06f4d3b905d162ea7e2481f58863e80d", "warmup_time": -1}, "sparse.SparseSeriesToFrame.time_series_to_frame": {"code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = pd.Series(pd.SparseArray(data), index=idx)", "min_run_count": 2, "name": "sparse.SparseSeriesToFrame.time_series_to_frame", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0214aee86326199159d35d984a90c19c358cc968cb480fe2aa55cde51d4ac9b7", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo": {"code": "class ToCoo:\n    def time_sparse_series_to_coo(self):\n        self.ss.sparse.to_coo(row_levels=[0, 1], column_levels=[2, 3], sort_labels=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n        s.index = MultiIndex.from_product([range(10)] * 4)\n        self.ss = s.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9c024e8593fcde09fe6638b47a07815366f112e8c37b2ab4b8ea4d614180d3b", "warmup_time": -1}, "stat_ops.Correlation.peakmem_corr_wide": {"code": "class Correlation:\n    def peakmem_corr_wide(self, method, use_bottleneck):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "name": "stat_ops.Correlation.peakmem_corr_wide", "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "9730c938010f9a398aedf0f0aaf66d8f5d38ca0b196b32742a1eb1add962eceb"}, "stat_ops.Correlation.time_corr": {"code": "class Correlation:\n    def time_corr(self, method, use_bottleneck):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr", "number": 0, "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "65897d632af3a874c2b0f8d4e7ad86f6664538fe5fd93e16e1a6459a16671980", "warmup_time": -1}, "stat_ops.Correlation.time_corr_series": {"code": "class Correlation:\n    def time_corr_series(self, method, use_bottleneck):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_series", "number": 0, "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1373cace1556c87d5e2ae750c5927d94ee7d6f12c3ba6ce9d8e0e8d915976965", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide": {"code": "class Correlation:\n    def time_corr_wide(self, method, use_bottleneck):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide", "number": 0, "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "379d580ab87afa7c139a41de1b15deaaf40a26313dc484715416213cdea3cb80", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide_nans": {"code": "class Correlation:\n    def time_corr_wide_nans(self, method, use_bottleneck):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide_nans", "number": 0, "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "674ebf2e2f5af2d56bc5ab09e618f383c7d7b303516b4e1c9185a358a46bf700", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_cols": {"code": "class Correlation:\n    def time_corrwith_cols(self, method, use_bottleneck):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_cols", "number": 0, "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "449cadfc3254e78ba5f9224fdc2277f3a6d68838faa6bc6b6e037f8f9f37a45f", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_rows": {"code": "class Correlation:\n    def time_corrwith_rows(self, method, use_bottleneck):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df = pd.DataFrame(np.random.randn(1000, 30))\n        self.df2 = pd.DataFrame(np.random.randn(1000, 30))\n        self.df_wide = pd.DataFrame(np.random.randn(1000, 200))\n        self.df_wide_nans = self.df_wide.where(np.random.random((1000, 200)) < 0.9)\n        self.s = pd.Series(np.random.randn(1000))\n        self.s2 = pd.Series(np.random.randn(1000))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_rows", "number": 0, "param_names": ["method", "use_bottleneck"], "params": [["'spearman'", "'kendall'", "'pearson'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c7e56183f33774caee408dc5923861d12cd392b3d04e545c1f901fda36d29c8", "warmup_time": -1}, "stat_ops.Covariance.time_cov_series": {"code": "class Covariance:\n    def time_cov_series(self, use_bottleneck):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self, use_bottleneck):\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))", "min_run_count": 2, "name": "stat_ops.Covariance.time_cov_series", "number": 0, "param_names": ["use_bottleneck"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4f1ccab35c149e3286b6d1ee6d28b3c48064d4d3cfa469f2f78d295fd18feac7", "warmup_time": -1}, "stat_ops.FrameMultiIndexOps.time_op": {"code": "class FrameMultiIndexOps:\n    def time_op(self, level, op):\n        self.df_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMultiIndexOps.time_op", "number": 0, "param_names": ["level", "op"], "params": [["0", "1", "[0, 1]"], ["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f96021245703fb9bd8ae05edb7da231d655a3a803d13d8149e59e3eda3350bf4", "warmup_time": -1}, "stat_ops.FrameOps.time_op": {"code": "class FrameOps:\n    def time_op(self, op, dtype, axis, use_bottleneck):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis, use_bottleneck):\n        df = pd.DataFrame(np.random.randn(100000, 4)).astype(dtype)\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameOps.time_op", "number": 0, "param_names": ["op", "dtype", "axis", "use_bottleneck"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"], ["0", "1"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "692c504492f4591f4d51c22de4dec14b9e6924adf95ddc7264064f07f4d49894", "warmup_time": -1}, "stat_ops.Rank.time_average_old": {"code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10 ** 5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_average_old", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "555dc37265f9c9faaac31b724521056e9364da194707c9152dd2093e8d9880e5", "warmup_time": -1}, "stat_ops.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10 ** 5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_rank", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c474f586dd86a024a5e666f12d15a2cf14cac947a2e70c583be059a583faa6f", "warmup_time": -1}, "stat_ops.SeriesMultiIndexOps.time_op": {"code": "class SeriesMultiIndexOps:\n    def time_op(self, level, op):\n        self.s_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesMultiIndexOps.time_op", "number": 0, "param_names": ["level", "op"], "params": [["0", "1", "[0, 1]"], ["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6fc4f693a9b8e298a5ddeb7e4cec6220a7d8e6570e4060dfd64ee3b9c33b4cf0", "warmup_time": -1}, "stat_ops.SeriesOps.time_op": {"code": "class SeriesOps:\n    def time_op(self, op, dtype, use_bottleneck):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype, use_bottleneck):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        try:\n            pd.options.compute.use_bottleneck = use_bottleneck\n        except TypeError:\n            from pandas.core import nanops\n    \n            nanops._USE_BOTTLENECK = use_bottleneck\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesOps.time_op", "number": 0, "param_names": ["op", "dtype", "use_bottleneck"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'mad'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd5566c84f3fd80c2cb78bd97626152db3ca287f4df2f6a887520d406fffd809", "warmup_time": -1}, "strings.Cat.time_cat": {"code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10 ** 5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(tm.makeStringIndex(N)).where(mask_gen())\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {i: tm.makeStringIndex(N).where(mask_gen()) for i in range(other_cols)}\n            )", "min_run_count": 2, "name": "strings.Cat.time_cat", "number": 0, "param_names": ["other_cols", "sep", "na_rep", "na_frac"], "params": [["0", "3"], ["None", "','"], ["None", "'-'"], ["0.0", "0.001", "0.15"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8eb58a182e7e599789eb81b837dc2769e0d6f0cb6088f85682e60acb166ccac0", "warmup_time": -1}, "strings.Contains.time_contains": {"code": "class Contains:\n    def time_contains(self, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, regex):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Contains.time_contains", "number": 0, "param_names": ["regex"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "028b27170ec82a18eb9728a07bd40e1987e56b6f9f1c7c5c69ab59f534b4b779", "warmup_time": -1}, "strings.Dummies.time_get_dummies": {"code": "class Dummies:\n    def time_get_dummies(self):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5)).str.join(\"|\")", "min_run_count": 2, "name": "strings.Dummies.time_get_dummies", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b7b9d5cd10b2065fbe01d58d676387e948f905052801ab7c630e029ba4194ca", "warmup_time": -1}, "strings.Encode.time_encode_decode": {"code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(tm.makeUnicodeIndex())", "min_run_count": 2, "name": "strings.Encode.time_encode_decode", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7991afc08fb85f2e7a8a10a61fdf3f06df4a2d94f48fe9cd517f60f1b2a56a99", "warmup_time": -1}, "strings.Methods.time_center": {"code": "class Methods:\n    def time_center(self):\n        self.s.str.center(100)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_center", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b9344814f4085d71b0ce43968a5e47165ca10b26397dfa73ef4ef99962cc96f", "warmup_time": -1}, "strings.Methods.time_count": {"code": "class Methods:\n    def time_count(self):\n        self.s.str.count(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_count", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f41bf14cace9d72005495af892bf2de9b1b447e2c361721a5a8d9e63b21ec205", "warmup_time": -1}, "strings.Methods.time_endswith": {"code": "class Methods:\n    def time_endswith(self):\n        self.s.str.endswith(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_endswith", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cda6473bee3904de78639be9a0717d017e7701476b8602070d397dddb099dd03", "warmup_time": -1}, "strings.Methods.time_extract": {"code": "class Methods:\n    def time_extract(self):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_extract", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "283030056b4364264e8742ea6493214a937c29d387c2242b76d7bc42dfad925b", "warmup_time": -1}, "strings.Methods.time_find": {"code": "class Methods:\n    def time_find(self):\n        self.s.str.find(\"[A-Z]+\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_find", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2235fa3da76fd2686c98e90bb67680381f0d39e90b033ac74719aa29a429bf3", "warmup_time": -1}, "strings.Methods.time_findall": {"code": "class Methods:\n    def time_findall(self):\n        self.s.str.findall(\"[A-Z]+\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_findall", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "260c0d850c2907bcfcd75973e4f8ab7611772e62bd098e2051ee035d7920f803", "warmup_time": -1}, "strings.Methods.time_get": {"code": "class Methods:\n    def time_get(self):\n        self.s.str.get(0)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_get", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b79468d6095596e0af392d83d82f6db768a26102d406a25e94d38ccee27e84ce", "warmup_time": -1}, "strings.Methods.time_join": {"code": "class Methods:\n    def time_join(self):\n        self.s.str.join(\" \")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_join", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "396b6465ded68c24f0fe1f50cfd4b08deaf4d5cee0a0053c57c51bf73cf9b1f0", "warmup_time": -1}, "strings.Methods.time_len": {"code": "class Methods:\n    def time_len(self):\n        self.s.str.len()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_len", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "392723c6a707b1f5d8190105ba0eb4a54979ab46e92d845c87905699c28e0660", "warmup_time": -1}, "strings.Methods.time_lower": {"code": "class Methods:\n    def time_lower(self):\n        self.s.str.lower()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_lower", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ecd8f9c72774a7eeb63eafcf18290d582ea896cdd935fd9647c81284b4f1b750", "warmup_time": -1}, "strings.Methods.time_lstrip": {"code": "class Methods:\n    def time_lstrip(self):\n        self.s.str.lstrip(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_lstrip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1253d4705d239e45730759a958ef43b8b2ab8019f68e970c4e6d86fc357d588", "warmup_time": -1}, "strings.Methods.time_match": {"code": "class Methods:\n    def time_match(self):\n        self.s.str.match(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_match", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5c2377eb554952a2f53ee91707a3bce30bd2a8dd7061fe8f25b8aed0aceea2eb", "warmup_time": -1}, "strings.Methods.time_normalize": {"code": "class Methods:\n    def time_normalize(self):\n        self.s.str.normalize(\"NFC\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_normalize", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31f6520fe9542916dec0ccc42be8b80e87c77ce47fe03a77095a7b06230c1436", "warmup_time": -1}, "strings.Methods.time_pad": {"code": "class Methods:\n    def time_pad(self):\n        self.s.str.pad(100, side=\"both\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_pad", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "947cea1875415b501f0aacba8a00a282695f12ae03b161620558086efdf5b2ae", "warmup_time": -1}, "strings.Methods.time_partition": {"code": "class Methods:\n    def time_partition(self):\n        self.s.str.partition(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_partition", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16a3b89127129f923443b83be69382727529da1accbbac415ac78f2d264a4b18", "warmup_time": -1}, "strings.Methods.time_replace": {"code": "class Methods:\n    def time_replace(self):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_replace", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1fe400c54c0e1b95db00aea7500145a177e72c8eba62c587f3198eb0382377b", "warmup_time": -1}, "strings.Methods.time_rfind": {"code": "class Methods:\n    def time_rfind(self):\n        self.s.str.rfind(\"[A-Z]+\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_rfind", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6982452cee3b3b8c0351988fa787130dfe84552f61ddf360a3cc0cf62fc18e7a", "warmup_time": -1}, "strings.Methods.time_rpartition": {"code": "class Methods:\n    def time_rpartition(self):\n        self.s.str.rpartition(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_rpartition", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "be3d1177d8ea6a97d2bb3a6796adf66fecc870bfa7abd24d22586a465160dd22", "warmup_time": -1}, "strings.Methods.time_rstrip": {"code": "class Methods:\n    def time_rstrip(self):\n        self.s.str.rstrip(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_rstrip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d714119dd3b8d0b5d06c6e3b55c1394ef058a112f96aa228a3b0085e8c36497", "warmup_time": -1}, "strings.Methods.time_slice": {"code": "class Methods:\n    def time_slice(self):\n        self.s.str.slice(5, 15, 2)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_slice", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e515a39e259f5624dc88a4caecb3e00b461b1b5b2e9dec6333ad29443fad1c9d", "warmup_time": -1}, "strings.Methods.time_startswith": {"code": "class Methods:\n    def time_startswith(self):\n        self.s.str.startswith(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_startswith", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d94823bfbe228273ba233895e1fd15298da8026705ec53a8b311b192e3d17fcd", "warmup_time": -1}, "strings.Methods.time_strip": {"code": "class Methods:\n    def time_strip(self):\n        self.s.str.strip(\"A\")\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_strip", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91a6d36e7561f03c424f5462508959860577e2d21143c1acb0743666ecd14831", "warmup_time": -1}, "strings.Methods.time_title": {"code": "class Methods:\n    def time_title(self):\n        self.s.str.title()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_title", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9c59a363498907c5060c908db9f450902bec4a559b34e0c05282933cbbf8439", "warmup_time": -1}, "strings.Methods.time_translate": {"code": "class Methods:\n    def time_translate(self):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_translate", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0193e7e21294656461363cdc325658411dfe6448f0aeaf02e6389c07d1a3f0c8", "warmup_time": -1}, "strings.Methods.time_upper": {"code": "class Methods:\n    def time_upper(self):\n        self.s.str.upper()\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_upper", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e11f12067dcb71a1bf8eecbe75ce7398192559ec2acaf59f45cb9ac8910cc28", "warmup_time": -1}, "strings.Methods.time_wrap": {"code": "class Methods:\n    def time_wrap(self):\n        self.s.str.wrap(10)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_wrap", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c15e2aa54f358c2cd9c6b840091c43512b88b86faadf39a6eccddbfddb76af31", "warmup_time": -1}, "strings.Methods.time_zfill": {"code": "class Methods:\n    def time_zfill(self):\n        self.s.str.zfill(10)\n\n    def setup(self):\n        self.s = Series(tm.makeStringIndex(10 ** 5))", "min_run_count": 2, "name": "strings.Methods.time_zfill", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9a026c930b7733ea81f88c4178af820b3630d447f883d832cd6bf19f68015b63", "warmup_time": -1}, "strings.Repeat.time_repeat": {"code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10 ** 5\n        self.s = Series(tm.makeStringIndex(N))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]", "min_run_count": 2, "name": "strings.Repeat.time_repeat", "number": 0, "param_names": ["repeats"], "params": [["'int'", "'array'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1c054ab32273dc4270ccb7ade724c83ebaa9472afd7c7248dc3b28a6167ab3c", "warmup_time": -1}, "strings.Slice.time_vector_slice": {"code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)", "min_run_count": 2, "name": "strings.Slice.time_vector_slice", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86", "warmup_time": -1}, "strings.Split.time_rsplit": {"code": "class Split:\n    def time_rsplit(self, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, expand):\n        self.s = Series(tm.makeStringIndex(10 ** 5)).str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_rsplit", "number": 0, "param_names": ["expand"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9dd33b3bb35f7877625d8129b7b4abb91190d4bc043df11d8d87258703c708f", "warmup_time": -1}, "strings.Split.time_split": {"code": "class Split:\n    def time_split(self, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, expand):\n        self.s = Series(tm.makeStringIndex(10 ** 5)).str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_split", "number": 0, "param_names": ["expand"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef325356ef8c7ab3d10891283f59a9f60408fb1586caeb6638c2fbbe1d0b1512", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_days": {"code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_days", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_microseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_seconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/timedelta.py:54", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_align": {"code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_align", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_get_loc": {"code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_get_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_intersection": {"code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_intersection", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_series_loc": {"code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_series_loc", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shallow_copy": {"code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._shallow_copy()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e223b83f2fd936b5d339affcfa1ad774949ca2766cc060b98637c34644399c25", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shape": {"code": "class TimedeltaIndexing:\n    def time_shape(self):\n        self.index.shape\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shape", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fdba5a1927c7e8b7dd8622a96f481e6db146c64871d845eca8bf885be8daa535", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_union": {"code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_union", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_unique": {"code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_unique", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416", "warmup_time": -1}, "timedelta.TimedeltaOps.time_add_td_ts": {"code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")", "min_run_count": 2, "name": "timedelta.TimedeltaOps.time_add_td_ts", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43ee94357697a8810860f1545a7e3611ced939c42a03f72b0000ed8f43d518d3", "warmup_time": -1}, "timedelta.ToTimedelta.time_convert_int": {"code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "timedelta.ToTimedelta.time_convert_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b111092c17bf557721f9ff671019f2f467265db177343fc759a16f916d40d17", "warmup_time": -1}, "timedelta.ToTimedelta.time_convert_string_days": {"code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "timedelta.ToTimedelta.time_convert_string_days", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff81cb43ec547eecd3fcf6162a5f5956b7b937c35667d998cdd6050b29c2f310", "warmup_time": -1}, "timedelta.ToTimedelta.time_convert_string_seconds": {"code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "timedelta.ToTimedelta.time_convert_string_seconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19e7218ecb778f1eb7203410175a1a08ec1e8d38237f4a6f001e5b292c4e98b2", "warmup_time": -1}, "timedelta.ToTimedeltaErrors.time_convert": {"code": "class ToTimedeltaErrors:\n    def time_convert(self, errors):\n        to_timedelta(self.arr, errors=errors)\n\n    def setup(self, errors):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"", "min_run_count": 2, "name": "timedelta.ToTimedeltaErrors.time_convert", "number": 0, "param_names": ["errors"], "params": [["'coerce'", "'ignore'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "020cbaee888cb83c4c26d33022b0f19054dde290eccdf7fc86a53cc08b0d22bf", "warmup_time": -1}, "timeseries.AsOf.time_asof": {"code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3e2e62f9b0969e4e1da322ca6220cc304d5b6d723264da74d17ab2771bd292c", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan": {"code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "64dbbe4ddbe15ee388df6641ecf1f1e553d6f09647d3b494f59685cc66d3bf2a", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan_single": {"code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95da61afb9ec7dad20266bb55452ec70a8f610a5daf5de5f64a569f182420fb4", "warmup_time": -1}, "timeseries.AsOf.time_asof_single": {"code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "488d983701b8b4cb91d811f97f0b16348da50efbb9b2b34241f51ad91ae7cb36", "warmup_time": -1}, "timeseries.AsOf.time_asof_single_early": {"code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single_early", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "161306e14c591cbfb62f6b2051a4808e8f0227b1d2ff41509badd3e8a254b94d", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e275de6b99ba6a06d82734fc5fd2106ab45939f0c24573c82bf8654eabf6c26f", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_date": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_date", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce5d47c01e0522ef823ea6f24cd928adecdc8bb565b8891588cef7a597864ee5", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c1f37eb07da219478ff957be9a2b8e9f4787d0b77f4ffe37084ee97a4b3e57f", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1536985e526572c8be380754cc46f9adec3c29f4cdcce42cff0c258be53fb396", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2098f4e7f3bcb70aa59d88c184598defc25544ed8779b7d068e83b100f6f8472", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_time": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_time", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30e1748aa1cbd359819193fc2b4fe8cd0ada270200ba94457ae18cdbf8e876a9", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_year": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_year", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3d8d6f02e27018f26b53e7699f9705df922cfcff833d5682bd5bd9632f3ec68", "warmup_time": -1}, "timeseries.DatetimeIndex.time_add_timedelta": {"code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_add_timedelta", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d17561bf07eda75fca5be3f8f3bf9dc93358476c02895a95d6e48fd93965ef9", "warmup_time": -1}, "timeseries.DatetimeIndex.time_get": {"code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_get", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9d49554855cf7f28885dc19d04fc882c3e4756fdbb477c1feabf4e3ef78c5015", "warmup_time": -1}, "timeseries.DatetimeIndex.time_normalize": {"code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_normalize", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f03c3d9595f26105495ee05546299488a878071eb5f099900e9dc7023fb20b36", "warmup_time": -1}, "timeseries.DatetimeIndex.time_timeseries_is_month_start": {"code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eff692fbd7dfa0bf1c39275fc684030a6cb8e0705e9cf82c4dd0252b39d9ec25", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_date": {"code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_date", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f297519483e31ed5ffeee3718013b18bf96f805a4b1a3dfb9063e052ae88c84e", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_pydatetime": {"code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_pydatetime", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "222935f885a442eae007019a4331500f9af43350080b7d1c1faf1eb7ce9186a0", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_time": {"code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_time", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb5e8239bf229fc3e0991f2c86a965f685f81276084df7c017474ac4f3fb581a", "warmup_time": -1}, "timeseries.DatetimeIndex.time_unique": {"code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_unique", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9ccc40ce3b46b242274e3e61dce50e09bf5ce1b1131e1785f7945a12aedd694", "warmup_time": -1}, "timeseries.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, tz):\n        self.dti.factorize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, tz):\n        N = 100000\n        self.dti = date_range(\"2011-01-01\", freq=\"H\", periods=N, tz=tz)\n        self.dti = self.dti.repeat(5)", "min_run_count": 2, "name": "timeseries.Factorize.time_factorize", "number": 0, "param_names": ["t"], "params": [["None", "'Asia/Tokyo'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8c89c551371506ca4e800015fe9aa2d0265fcf72fba2b395c4527a706a481952", "warmup_time": -1}, "timeseries.InferFreq.time_infer_freq": {"code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx.freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)", "min_run_count": 2, "name": "timeseries.InferFreq.time_infer_freq", "number": 0, "param_names": ["freq"], "params": [["None", "'D'", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ac0a6c2e76caa1ffb71f2c6785af72b59cb47bde19765db8ea854cc3ec69b57e", "warmup_time": -1}, "timeseries.IrregularOps.time_add": {"code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.IrregularOps.time_add", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d6d8ce63eeb7493f26143590195d36210414b95c1f555c9b5520ef4ce40f8ee7", "warmup_time": -1}, "timeseries.Iteration.time_iter": {"code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10 ** 6\n        self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter", "number": 0, "param_names": ["time_index"], "params": [["<function date_range at 0x7f614a6adf28>", "<function period_range at 0x7f614a692268>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0e8467c9fac009ff1cbdf35236714bc49b1491293306de08eb945131b8fccd2", "warmup_time": -1}, "timeseries.Iteration.time_iter_preexit": {"code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10 ** 6\n        self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter_preexit", "number": 0, "param_names": ["time_index"], "params": [["<function date_range at 0x7f614a6adf28>", "<function period_range at 0x7f614a692268>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f2e2fbcd8984886abca860a868481455463b6c33f33d1317bb1e52f509bae87b", "warmup_time": -1}, "timeseries.Lookup.time_lookup_and_cleanup": {"code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"S\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]", "min_run_count": 2, "name": "timeseries.Lookup.time_lookup_and_cleanup", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56affd6bde67bbd710425ecad787b306358e276d222655f214bd88b43295edd4", "warmup_time": -1}, "timeseries.ResampleDataFrame.time_method": {"code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50L\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)", "min_run_count": 2, "name": "timeseries.ResampleDataFrame.time_method", "number": 0, "param_names": ["method"], "params": [["'max'", "'mean'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9019269f5444960e4d9df5981d496cd4a6d825381d957e89cb84d8e75782473", "warmup_time": -1}, "timeseries.ResampleDatetetime64.time_resample": {"code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1S\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000U\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")", "min_run_count": 2, "name": "timeseries.ResampleDatetetime64.time_resample", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5509d40bbee6c6b5cb28537dd6e775fc56f67f793410a856db59e1b02b423ac", "warmup_time": -1}, "timeseries.ResampleSeries.time_resample": {"code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)", "min_run_count": 2, "name": "timeseries.ResampleSeries.time_resample", "number": 0, "param_names": ["index", "freq", "method"], "params": [["'period'", "'datetime'"], ["'5min'", "'1D'"], ["'mean'", "'ohlc'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6f349cedc62746ed4c61a8d0a8bfba5bd818a04240bb33019f07a96475463ea", "warmup_time": -1}, "timeseries.ResetIndex.time_reest_datetimeindex": {"code": "class ResetIndex:\n    def time_reest_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"H\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)", "min_run_count": 2, "name": "timeseries.ResetIndex.time_reest_datetimeindex", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f52e3b646ab4784ab103bb280656229ba4c12b4d642ec47e6e9e85831cf3a371", "warmup_time": -1}, "timeseries.SortIndex.time_get_slice": {"code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_get_slice", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "481f42cfc27d96e42d9a54190e3e4a7478636830b143acc3c6c9a797ba23f300", "warmup_time": -1}, "timeseries.SortIndex.time_sort_index": {"code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e5c64e7b4d20d7c75f5c04aaf9d28d96a6cb6d1d67b9c3b210ad187de36ca183", "warmup_time": -1}, "timeseries.TimeDatetimeConverter.time_convert": {"code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "timeseries.TimeDatetimeConverter.time_convert", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec587c19f9fc168d46b31890ca2dd023bbae7678655b0219733c111876aaca8d", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "756b45777a695a791714d2605b1ffe5b02b3d375155f95b355ff4fc8fd8a1646", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_string_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_string_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "833932db64b226a24bb1bbdc650cb211a8447a5f4abcaaa463c2409c2cd98ab9", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_string_dates_and_format": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_string_dates_and_format", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7b013ce695476d226a54205bb6caadf6ecdd8d9e860395d02dd061f3ed12a44", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_dup_string_tzoffset_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_dup_string_tzoffset_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b295204f30ec321c133b4e5cf4cb2c315da2600d007c6ee7bdf6506a05c40d1e", "warmup_time": -1}, "timeseries.ToDatetimeCache.time_unique_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "timeseries.ToDatetimeCache.time_unique_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71644c77c2b579672d01ad606174b5a665e316952e8089e938a1119df2c0c023", "warmup_time": -1}, "timeseries.ToDatetimeCacheSmallCount.time_unique_date_strings": {"code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "timeseries.ToDatetimeCacheSmallCount.time_unique_date_strings", "number": 0, "param_names": ["cache", "count"], "params": [["True", "False"], ["50", "500", "5000", "100000"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f1b77b83865e585bd49d343df00f78c5830904e0c5cd5d8519429faedd24be72", "warmup_time": -1}, "timeseries.ToDatetimeFormat.time_exact": {"code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * 100000)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")", "min_run_count": 2, "name": "timeseries.ToDatetimeFormat.time_exact", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dfd3bfdf14d17f9ff2e06acb6a2895e0ba8b62e887fafc09ffd413a8124f7aaf", "warmup_time": -1}, "timeseries.ToDatetimeFormat.time_no_exact": {"code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * 100000)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")", "min_run_count": 2, "name": "timeseries.ToDatetimeFormat.time_no_exact", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "669e5cd4b69c2990367a28d4a92b6e5cc90e2e8773c011790ec10fb61f055921", "warmup_time": -1}, "timeseries.ToDatetimeFormatQuarters.time_infer_quarter": {"code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)", "min_run_count": 2, "name": "timeseries.ToDatetimeFormatQuarters.time_infer_quarter", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38c26091a098dae47d4027da784cbce429b5f53a782889c0e6e5e2683dec01f5", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601": {"code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1531fbcf18768ba85951bf1940c964e1daf2137f700bd1a84dc386b121757563", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_format": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_format", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d63b6ea1aa680dc15677868976dd9c20c3d3e0a7d33493e7e3fb47c4137cfa8c", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_format_no_sep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_format_no_sep", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "942846a154981c8007b34307051912ad839df85e7a3b2d892506646dc9555df6", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_nosep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_nosep", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c9c8969b2d1bd75b976218cdd7719366ef47db3af071f1630dfd8dff3ee3ab0", "warmup_time": -1}, "timeseries.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]", "min_run_count": 2, "name": "timeseries.ToDatetimeISO8601.time_iso8601_tz_spaceformat", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "348cb5b54fdfff434ae18ca802ed7b0978d50861ed28ebeb00cea737c5a1b02c", "warmup_time": -1}, "timeseries.ToDatetimeNONISO8601.time_different_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = int(N / 2)\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "timeseries.ToDatetimeNONISO8601.time_different_offset", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "db6b89c7cc2339fca294294cebf55c60955b86d1804e239dd614207bd0eedb38", "warmup_time": -1}, "timeseries.ToDatetimeNONISO8601.time_same_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = int(N / 2)\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "timeseries.ToDatetimeNONISO8601.time_same_offset", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "530f66b2871f099ca8a01bc892b9240cc7af4de29b76a13703ead4070adab761", "warmup_time": -1}, "timeseries.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {"code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))", "min_run_count": 2, "name": "timeseries.ToDatetimeYYYYMMDD.time_format_YYYYMMDD", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0231b0750bd151893d2d73a3bf8eaff1e01f54151e5cc7eafa1dd85d3d401394", "warmup_time": -1}, "timeseries.TzLocalize.time_infer_dst": {"code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"S\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"S\")\n        )", "min_run_count": 2, "name": "timeseries.TzLocalize.time_infer_dst", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "535825674e3168b99ae7eb4f9416ccc0ed0b0e23916aa315064bbfb5c040435f", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add": {"code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {"code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_apply": {"code": "class OffestDatetimeArithmetic:\n    def time_apply(self, offset):\n        offset.apply(self.date)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_apply", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "af692257767a29f497ae7d9cc6c0be4b43945e05f84879665f39032250403461", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_apply_np_dt64": {"code": "class OffestDatetimeArithmetic:\n    def time_apply_np_dt64(self, offset):\n        offset.apply(self.dt64)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_apply_np_dt64", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f194bced40cf0d9aa4959b756652f9c4823ddca885b6bcb420be8afa14e70afa", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69", "warmup_time": -1}, "tslibs.offsets.OnOffset.time_on_offset": {"code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.onOffset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]", "min_run_count": 2, "name": "tslibs.offsets.OnOffset.time_on_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BusinessYearEnd: month=12>", "<BusinessYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay>", "<CustomBusinessDay>", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd>", "<CustomBusinessMonthEnd>", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad30fa6e7d43f84dbca0e24fc59e0a75944e616e46883937843d5ae1aa3ed89c", "warmup_time": -1}, "tslibs.period.PeriodConstructor.time_period_constructor": {"code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "tslibs.period.PeriodConstructor.time_period_constructor", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d", "warmup_time": -1}, "tslibs.period.PeriodProperties.time_property": {"code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodProperties.time_property", "number": 0, "param_names": ["freq", "attr"], "params": [["'M'", "'min'"], ["'year'", "'month'", "'day'", "'hour'", "'minute'", "'second'", "'is_leap_year'", "'quarter'", "'qyear'", "'week'", "'daysinmonth'", "'dayofweek'", "'dayofyear'", "'start_time'", "'end_time'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_asfreq": {"code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_asfreq", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "deedbf5d3c7fd1ba4050791ac771023591ce7ddf98c14082e8627b2b2646cfeb", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_now": {"code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_now", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3c4792b946da369832c7ae6904edf46919fdca2bf03ad4006e36d728c2816bb", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {"code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27afe42121b54cb80919887f7d10be0869044b9c877bf53c7bfcd1f5f622e713", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_components": {"code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3bd2910bfa3ff10306ddb8a2fb92253e52ce6ab650da2e7e757af15eb440a50b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(datetime.timedelta(days=1, seconds=1))", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7998e3eec400317041ad6877a81d629e8889824eca22e9f2f3018c0c44ee4d8c", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_int": {"code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8434314c7e4a58ab4943126d48db7f2c963f479996e722c14bf383967d6ba9d6", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {"code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "308e49a3c2fbdd2bf31e1a961ca75b88fc08885558893bb57cbcafe688be0555", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {"code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0478c6a24b38a413f3cd712533950835d8b41f9229ae23b78d885c09d90f966", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(np.timedelta64(1, \"ms\"))", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8efcf8c1ffe8c22869ce653e2f1cf14a772d501814f6dbff15a22e8a0ee3a9bb", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_string": {"code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "125f8a610da995d297ac1e4a2be2316efcc5731b0bf168f483c9b803c69f9bd1", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {"code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"d\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b0f61a37e44bf0781fe2bfd9057acb6907fd559c80e907a6f2db0a77c8f6ba51", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {"code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/tslibs/timedelta.py:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/tslibs/timedelta.py:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/tslibs/timedelta.py:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/home/pandas/pandas/asv_bench/benchmarks/tslibs/timedelta.py:47", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c", "warmup_time": -1}, "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {"code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime.datetime(2016, 3, 27, 1)\n        self.tzinfo = pytz.timezone(\"CET\").localize(dt, is_dst=False).tzinfo\n        self.ts2 = Timestamp(dt)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef706cb28280171e57261ce2883942a74f7a6c273b6d90430445c8be0b8bf471", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromordinal": {"code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8558b46ef8e615bdb4e39a24bb46d841af38c3ac7f1dee29558e7836c5f1f325", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {"code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4afd2da54b515083d180740e9f4a4d2fd4d3c965f1d92457517630372009379b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {"code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9af29b3c5d287db48c44ca54992f7b9d37054ed462830bb660800f2e2728cb2b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b5c96df20a02762fbe8cf5abe5f9ff35f8a5f384ce23cf59767e8568f34c4226", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53dfdd6d97eaa8c526cdb3ce0e52f3712d135dc172c35f2023bbfa807171e1a5", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_now": {"code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_now", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cad7c0a494ee4805bddda5e122aac265c5c0278fadaf049b32266bc4b464f358", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_today": {"code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_today", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9b9adaec1ddf1bc239f4d456518430483907973367902c9f55196282e7b6e1f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_ceil": {"code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_ceil", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1428582cbad6d3d555950451594e390024aad454751ca9d18540ddf7f7548c4a", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_floor": {"code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_floor", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29681cac2448139b28d8817e024d6d3c08bcd7fe4594fb26564ed03e81c94f31", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_normalize": {"code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_normalize", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_None": {"code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_None", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_tz": {"code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=pytz.timezone(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_tz", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4364c2bc5207c0340c1149b8fb230b76c97f7646891613c57bd11cf528e78d77", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_julian_date": {"code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_julian_date", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_pydatetime": {"code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_convert": {"code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_convert", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_localize": {"code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_localize", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'", "<UTC>", "tzutc()"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofweek": {"code": "class TimestampProperties:\n    def time_dayofweek(self, tz, freq):\n        self.ts.dayofweek\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofweek", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c6daadf9626b1beb421ea24564aa6c857f50b32c4bfdf865a679ff78c075a09c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofyear": {"code": "class TimestampProperties:\n    def time_dayofyear(self, tz, freq):\n        self.ts.dayofyear\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofyear", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1970996700077d3916288f2ebfa66314fd0fa16faa65d298f43d1c452b376c1f", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_days_in_month": {"code": "class TimestampProperties:\n    def time_days_in_month(self, tz, freq):\n        self.ts.days_in_month\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_days_in_month", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f1ec12e96719dcfd857c4d2520d3c197e9c5e623eb69bd481bba8d50a3b56c7c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_freqstr": {"code": "class TimestampProperties:\n    def time_freqstr(self, tz, freq):\n        self.ts.freqstr\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_freqstr", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b7c86fb415025ed9782c86ea08bfa95b66d8c30532a8337935b49a716d37c3b", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_leap_year": {"code": "class TimestampProperties:\n    def time_is_leap_year(self, tz, freq):\n        self.ts.is_leap_year\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7a94f193c44fde8fc63549fc4515913a4284f65aa3b2cf68e4b099f5e68ecb58", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_end": {"code": "class TimestampProperties:\n    def time_is_month_end(self, tz, freq):\n        self.ts.is_month_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_end", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b5b47e2086d98cadc559128155943e2868f7af254659e927f11302852497f3b8", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_start": {"code": "class TimestampProperties:\n    def time_is_month_start(self, tz, freq):\n        self.ts.is_month_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_start", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9096eeefe2b95da5c24266d715fa7c18a2d5a1ef9e09b034e1231cd6e8295d70", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {"code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz, freq):\n        self.ts.is_quarter_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82a65562c4cca8e68b3c7f8be34145a2bc1d71a34c4544e528038b5808d6a0c1", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {"code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz, freq):\n        self.ts.is_quarter_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1088250670cc9f98108690c31465e1f62b79e9ecdad8ebd4fd150e098f5930b7", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_end": {"code": "class TimestampProperties:\n    def time_is_year_end(self, tz, freq):\n        self.ts.is_year_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_end", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e78c5d23cc3ed6005c4779c52acfaca34ed16a1f7d9d100cb88cb153d2e8350f", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_start": {"code": "class TimestampProperties:\n    def time_is_year_start(self, tz, freq):\n        self.ts.is_year_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_start", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c29221e715f65d7b7ad3989a0229500ded6c2ca2d804bfc21943e229df8644ef", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_microsecond": {"code": "class TimestampProperties:\n    def time_microsecond(self, tz, freq):\n        self.ts.microsecond\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_microsecond", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4f3bd00c49a4eceb4fd4a85cf81ad8cc0f4807dfb7c10e06be9feb1790502eda", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_month_name": {"code": "class TimestampProperties:\n    def time_month_name(self, tz, freq):\n        self.ts.month_name()\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_month_name", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a9cc7b41015b79534db9bdba3b505bbb41874eee513498664e27e4a087424d4", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_quarter": {"code": "class TimestampProperties:\n    def time_quarter(self, tz, freq):\n        self.ts.quarter\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_quarter", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61276b5e2273989bcd7c633cda4e3036d2eee15ac46f9a9ebfc5e306d3657b54", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_tz": {"code": "class TimestampProperties:\n    def time_tz(self, tz, freq):\n        self.ts.tz\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_tz", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5fb6e5c5690352c8be03312a08a681e97bd092c6a523c1d55be5617e7b1ecc65", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_week": {"code": "class TimestampProperties:\n    def time_week(self, tz, freq):\n        self.ts.week\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_week", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b1baa43468ce7c41c65ca461aa4df21820e31dbec8ca816b6619fb5f66ba801", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_weekday_name": {"code": "class TimestampProperties:\n    def time_weekday_name(self, tz, freq):\n        self.ts.day_name\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_weekday_name", "number": 0, "param_names": ["tz", "freq"], "params": [["None", "<DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>", "<UTC>", "tzutc()"], ["None", "'B'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c26888b4c7574e557df7938a70eee70e8eae1848bfe4a5da7714cf7964dc5e0d", "warmup_time": -1}}, "machines": {"asv-runner": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "version": 1}}, "tags": {"0.3.0": 288, "debian/0.4.0-1": 874, "debian/0.4.1-1": 933, "debian/0.4.3-1": 1084, "debian/0.5.0+git7-gcf32be2-1": 1194, "debian/0.6.1-1": 1632, "debian/0.7.0-1": 2077, "debian/0.7.1+git1-ga2e86c2-1": 2247, "debian/0.7.3-1": 2555, "debian/0.8.0-1": 3418, "debian/0.8.0-2": 3494, "debian/0.8.0_b2+git68-g7240b87-1": 3344, "debian/0.8.0_b2-1": 3266, "debian/0.8.0_rc2+git26-g76c6351-1": 3393, "debian/0.8.1-1": 3557, "v0.10.0": 4816, "v0.10.0b1": 4723, "v0.10.1": 5022, "v0.11.0": 5863, "v0.11.0rc1": 5767, "v0.12.0": 6794, "v0.12.0rc1": 6664, "v0.13.0": 8139, "v0.13.0_ahl1": 8234, "v0.13.0_ahl2": 8327, "v0.13.0rc1": 7983, "v0.13.1": 8680, "v0.14.0": 9713, "v0.14.0rc1": 9617, "v0.14.1": 10140, "v0.15.0": 10853, "v0.15.0rc1": 10793, "v0.15.1": 10956, "v0.15.2": 11188, "v0.15.2pre": 11042, "v0.15pre": 10501, "v0.16.0": 11564, "v0.16.0rc1": 11528, "v0.16.1": 11906, "v0.16.2": 12077, "v0.16.3": 12091, "v0.17.0": 12896, "v0.17.0rc1": 12722, "v0.17.0rc2": 12867, "v0.17.1": 13165, "v0.18.0": 13633, "v0.18.0rc1": 13531, "v0.18.0rc2": 13622, "v0.18.1": 13843, "v0.19.0": 14343, "v0.19.0rc1": 14289, "v0.19.1": 14448, "v0.19.2": 14719, "v0.20.0": 15378, "v0.20.0rc1": 15313, "v0.20.0rc2": 15370, "v0.20.1": 15384, "v0.20.2": 15587, "v0.20.3": 15699, "v0.21.0": 16155, "v0.21.0.dev": 15385, "v0.21.0rc1": 16109, "v0.21.1": 16606, "v0.22.0": 16735, "v0.22.0.dev0": 16156, "v0.23.0": 17603, "v0.23.0.dev0": 16708, "v0.23.0rc1": 17544, "v0.23.0rc2": 17546, "v0.23.1": 17760, "v0.23.2": 17931, "v0.23.3": 17958, "v0.23.4": 18135, "v0.24.0": 19501, "v0.24.0.dev0": 17604, "v0.24.0rc1": 19420, "v0.24.1": 19583, "v0.24.2": 19819, "v0.25.0": 20574, "v0.25.0.dev0": 19502, "v0.25.0rc0": 20481, "v0.25.1": 20850, "v0.25.2": 21250, "v0.25.3": 21386, "v0.26.0.dev0": 20575, "v0.4.0": 862, "v0.4.1": 926, "v0.4.2": 981, "v0.4.3": 1029, "v0.5.0": 1185, "v0.6.0": 1342, "v0.6.1": 1440, "v0.7.0": 2072, "v0.7.0rc1": 1812, "v0.7.1": 2196, "v0.7.2": 2358, "v0.7.3": 2539, "v0.8.0": 3412, "v0.8.0b1": 3074, "v0.8.0b2": 3262, "v0.8.0rc1": 3360, "v0.8.0rc2": 3361, "v0.8.1": 3551, "v0.9.0": 4026, "v0.9.0rc1": 3912, "v0.9.0rc2": 3955, "v0.9.1": 4289, "v0.9.1rc1": 4249}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}